import{_ as h,o as i,c as n,a as t,m as c,t as u,C as g,M as _,U as y,f as d,F as b,p as v,e as w,q as x}from"./chunks/framework.B1z0IdBH.js";const k={name:"PoemCard",props:{poem:{type:Object,required:!0}}},T={class:"poem-container"},E={class:"review"},q={class:"review-title"},I={class:"review-content"};function A(a,e,l,p,s,r){return i(),n("div",T,[t("div",E,[t("div",q,[e[0]||(e[0]=t("span",{class:"icon"},"question:",-1)),c(u(l.poem.question),1)]),e[2]||(e[2]=t("div",{class:"divider"},null,-1)),t("p",I,[e[1]||(e[1]=t("span",{class:"icon"},"answer:",-1)),c(u(l.poem.solution),1)])])])}const C=h(k,[["render",A],["__scopeId","data-v-417fa6f0"]]),S=JSON.parse('[{"question":"# Problem Statement Create a command-line application that simulates a basic text-based shopping cart system. Users should be able to add items to the cart, view the cart contents, remove items from the cart, and check out. # Requirements 1. **Add Item**: Allow users to add items to their shopping cart by specifying the item name and quantity. 2. **View Cart**: Display all items currently in the cart along with their quantities. 3. **Remove Item**: Allow users to remove an item or decrease the quantity of an item in the cart. 4. **Checkout**: Display the total number of items in the cart and the grand total price of all items. Implement a class `ShoppingCart` with the following methods: * `add_item(self, item_name: str, quantity: int, price: float) -> None`: Add specified quantity of the item with the given price to the cart. * `view_cart(self) -> List[Tuple[str, int, float]]`: Return a list of tuples containing item name, quantity, and price per unit for each item in the cart. * `remove_item(self, item_name: str, quantity: int) -> None`: Remove the specified quantity of the item from the cart. If the quantity to remove is greater than or equal to the current quantity, remove the item entirely. * `checkout(self) -> Tuple[int, float]`: Return the total number of items and the grand total price of all items in the cart. # Input and Output Formats 1. **add_item** * **Input**: `item_name` (string), `quantity` (integer), `price` (float). * **Output**: None. 2. **view_cart** * **Input**: None. * **Output**: A list of tuples, each containing `item_name` (string), `quantity` (integer), `price` (float). 3. **remove_item** * **Input**: `item_name` (string), `quantity` (integer). * **Output**: None. 4. **checkout** * **Input**: None. * **Output**: A tuple containing the total number of items (integer) and the grand total price (float). # Example ```python cart = ShoppingCart() # Test add_item cart.add_item(\\"apple\\", 3, 0.5) cart.add_item(\\"banana\\", 2, 0.3) # Test view_cart assert cart.view_cart() == [(\\"apple\\", 3, 0.5), (\\"banana\\", 2, 0.3)] # Test remove_item cart.remove_item(\\"apple\\", 1) assert cart.view_cart() == [(\\"apple\\", 2, 0.5), (\\"banana\\", 2, 0.3)] # Test checkout assert cart.checkout() == (4, 1.6) # Test remove all quantity of an item cart.remove_item(\\"banana\\", 2) assert cart.view_cart() == [(\\"apple\\", 2, 0.5)] # Test add more item cart.add_item(\\"orange\\", 1, 0.7) assert cart.view_cart() == [(\\"apple\\", 2, 0.5), (\\"orange\\", 1, 0.7)] # Final checkout assert cart.checkout() == (3, 1.7) ``` # Constraints: * Item names will be non-empty strings. * Quantities and prices will be positive numbers. * The cart can hold any number of items but checkout should accurately reflect the current state of the cart.","solution":"from typing import List, Tuple class ShoppingCart: def __init__(self): self.cart = {} def add_item(self, item_name: str, quantity: int, price: float) -> None: if item_name in self.cart: self.cart[item_name][\'quantity\'] += quantity else: self.cart[item_name] = {\'quantity\': quantity, \'price\': price} def view_cart(self) -> List[Tuple[str, int, float]]: return [(item_name, details[\'quantity\'], details[\'price\']) for item_name, details in self.cart.items()] def remove_item(self, item_name: str, quantity: int) -> None: if item_name in self.cart: if self.cart[item_name][\'quantity\'] <= quantity: del self.cart[item_name] else: self.cart[item_name][\'quantity\'] -= quantity def checkout(self) -> Tuple[int, float]: total_quantity = sum(details[\'quantity\'] for details in self.cart.values()) total_price = sum(details[\'quantity\'] * details[\'price\'] for details in self.cart.values()) return total_quantity, total_price"},{"question":"# Problem: Binary Tree Zigzag Level Order Traversal As a software developer, you are tasked with implementing a function to perform a zigzag level order traversal of a binary tree. The zigzag traversal implies that alternate levels are traversed from right to left and left to right, respectively. Instructions: 1. **Function Name**: `zigzag_level_order` 2. **Input**: * **root** (`TreeNode`): The root node of the binary tree. 3. **Output**: * A list of lists, where each inner list contains the values of the nodes at each level in zigzag order. 4. **Constraints**: * You may assume that `TreeNode` class is defined as follows: ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right ``` * The binary tree node values will be integers. * The number of nodes in the tree is limited to 10^4. * The node values are within the range `-1000` to `1000`. Scenario: You are provided with the root node of a binary tree, and you must traverse it in zigzag order. Your function should alternate the traversal direction at every level of the tree to create a zigzag pattern. **Hint**: You may use a deque to efficiently implement the alternating level order traversal. Example: ```python # Example Binary Tree # 3 # / # 9 20 # / # 15 7 root = TreeNode(3) root.left = TreeNode(9) root.right = TreeNode(20) root.right.left = TreeNode(15) root.right.right = TreeNode(7) print(zigzag_level_order(root)) # Expected Output: [[3], [20, 9], [15, 7]] ``` **Deliverable**: Provide a complete implementation of `zigzag_level_order` function that efficiently performs the zigzag traversal of the binary tree and returns the resulting list of lists. ```python from collections import deque def zigzag_level_order(root: TreeNode) -> [[int]]: if not root: return [] results = [] current_level = deque([root]) left_to_right = True while current_level: level_size = len(current_level) level_nodes = [] for _ in range(level_size): if left_to_right: node = current_level.popleft() level_nodes.append(node.val) if node.left: current_level.append(node.left) if node.right: current_level.append(node.right) else: node = current_level.pop() level_nodes.append(node.val) if node.right: current_level.appendleft(node.right) if node.left: current_level.appendleft(node.left) results.append(level_nodes) left_to_right = not left_to_right return results # Example Usage if __name__ == \\"__main__\\": root = TreeNode(3) root.left = TreeNode(9) root.right = TreeNode(20) root.right.left = TreeNode(15) root.right.right = TreeNode(7) print(zigzag_level_order(root)) # Expected Output: [[3], [20, 9], [15, 7]] ```","solution":"from collections import deque class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def zigzag_level_order(root: TreeNode): if not root: return [] results = [] current_level = deque([root]) left_to_right = True while current_level: level_size = len(current_level) level_nodes = [] for _ in range(level_size): if left_to_right: node = current_level.popleft() level_nodes.append(node.val) if node.left: current_level.append(node.left) if node.right: current_level.append(node.right) else: node = current_level.pop() level_nodes.append(node.val) if node.right: current_level.appendleft(node.right) if node.left: current_level.appendleft(node.left) results.append(level_nodes) left_to_right = not left_to_right return results"},{"question":"# Context You are provided with a class `BinarySearchTree` in Python, and you are required to enhance its functionality. One important method, `insert`, facilitates the insertion of nodes while maintaining the properties of a binary search tree. # Task Implement a function `find_lowest_common_ancestor(self, node1: int, node2: int) -> int` within the `BinarySearchTree` class that finds the lowest common ancestor (LCA) of two given nodes in the tree. The LCA of two nodes `node1` and `node2` in a binary search tree is defined as the lowest node in the tree that has both `node1` and `node2` as descendants. # Function Signature ```python class BinarySearchTree: def find_lowest_common_ancestor(self, node1: int, node2: int) -> int: # Your code here ``` # Input * Two integers `node1` and `node2` representing the values of the nodes to find the LCA for. # Output * Returns an integer representing the value of the lowest common ancestor. # Constraints * The binary search tree is guaranteed to contain both `node1` and `node2`. * -10^4 <= `node1`, `node2` <= 10^4 # Example ```python >>> bst = BinarySearchTree() >>> bst.insert(20) >>> bst.insert(10) >>> bst.insert(30) >>> bst.insert(5) >>> bst.insert(15) >>> bst.find_lowest_common_ancestor(5, 15) 10 >>> bst = BinarySearchTree() >>> bst.insert(20) >>> bst.insert(10) >>> bst.insert(30) >>> bst.insert(25) >>> bst.insert(35) >>> bst.find_lowest_common_ancestor(25, 35) 30 ``` # Notes * If `node1` is equal to `node2`, then the LCA is either of the nodes themselves. * The binary search tree is assumed to contain unique values for simplicity.","solution":"class Node: def __init__(self, key): self.data = key self.left = None self.right = None class BinarySearchTree: def __init__(self): self.root = None def insert(self, key): if self.root is None: self.root = Node(key) else: self._insert(self.root, key) def _insert(self, root, key): if key < root.data: if root.left is None: root.left = Node(key) else: self._insert(root.left, key) else: if root.right is None: root.right = Node(key) else: self._insert(root.right, key) def find_lowest_common_ancestor(self, node1: int, node2: int) -> int: return self._find_lca(self.root, node1, node2).data def _find_lca(self, root, node1, node2): # Base case if root is None: return None # If both node1 and node2 are smaller than root, then LCA lies in left if root.data > node1 and root.data > node2: return self._find_lca(root.left, node1, node2) # If both node1 and node2 are greater than root, then LCA lies in right if root.data < node1 and root.data < node2: return self._find_lca(root.right, node1, node2) # If one node is on the left and the other is on the right, root is the LCA return root"},{"question":"# Coding Assessment Question You are given an implementation of an algorithm that calculates the running average of a list of numbers. The running average is the mean of all numbers up to that point in the list. # Task Write a Python function that does the following: 1. Reads in a list of integers or floating-point numbers. 2. Computes the running average for each element in the list using a single pass from left to right. 3. Returns a new list containing the running averages. # Requirements 1. **Input**: A list of integers or floating-point numbers. 2. **Output**: A list of running averages as floating-point numbers. 3. **Constraints**: * The list input can have up to 1,000,000 elements. * The input list can be empty. In such a case, the function should return an empty list. # Performance: * The function must handle large lists efficiently with a time complexity of O(n). Examples: ```python # Example 1: input_list = [1, 2, 3, 4, 5] running_average(input_list) # Output: [1.0, 1.5, 2.0, 2.5, 3.0] # Example 2: input_list = [4, -1, 2, 10] running_average(input_list) # Output: [4.0, 1.5, 1.6666666666666667, 3.75] # Example 3: input_list = [] running_average(input_list) # Output: [] ```","solution":"def running_average(input_list): Computes the running average of a list of numbers. :param input_list: List of integers or floating-point numbers :return: List of floating-point numbers representing the running averages if not input_list: return [] running_sums = [] current_sum = 0 for i, value in enumerate(input_list): current_sum += value running_sums.append(current_sum / (i + 1)) return running_sums"},{"question":"# Matrix Diagonal Sort Objective Your task is to implement a function that sorts each diagonal of a given 2D matrix in ascending order. The matrix is provided as a list of lists containing integer values. Input The function will take: 1. **matrix**: A list of lists where each list represents a row in a 2D matrix. Output The function should return a matrix where each diagonal (from top-left to bottom-right) is sorted in ascending order. Constraints - The number of rows and columns in the matrix can range from 1 to 100. - Each element in the matrix will be an integer in the range from -1000 to 1000. Example Usage ```python matrix = [ [3, 3, 1, 1], [2, 2, 1, 2], [1, 1, 1, 2] ] sorted_matrix = diagonal_sort(matrix) print(sorted_matrix) # Expected output: [[1, 1, 1, 1], [1, 2, 2, 2], [1, 2, 3, 3]] ``` Implementation Details 1. Identify all the diagonals in the matrix. 2. Sort each diagonal individually. 3. Replace the original matrix elements with the sorted diagonal values. 4. Return the modified matrix with sorted diagonals. Function Signature ```python def diagonal_sort(matrix: list[list[int]]) -> list[list[int]]: # Your implementation here pass ``` You should ensure that your implementation correctly handles edge cases such as varying matrix sizes and values.","solution":"from collections import defaultdict def diagonal_sort(matrix): Sorts each diagonal of the given 2D matrix in ascending order. def sort_diagonal(r, c): diagonal = [] i, j = r, c while i < len(matrix) and j < len(matrix[0]): diagonal.append(matrix[i][j]) i += 1 j += 1 diagonal.sort() i, j = r, c for val in diagonal: matrix[i][j] = val i += 1 j += 1 # Sort each diagonal starting from each element in the first row for col in range(len(matrix[0])): sort_diagonal(0, col) # Sort each diagonal starting from each element in the first column (except the first element) for row in range(1, len(matrix)): sort_diagonal(row, 0) return matrix"},{"question":"# Odd Even Linked List Reordering Given a basic implementation of a singly linked list with a `Node` class, where each node has a `data` attribute and a `next_node` attribute pointing to the next node in the list, your task is to write a function that reorders the linked list such that all nodes at odd positions come before all nodes at even positions. In certain applications, such as rearranging tasks or items, ordering based on positions can be critical. # Input You will be provided a linked list, where each node is an instance of the `Node` class. # Output Your function should modify the linked list in place to move all nodes in odd positions to the front, followed by nodes in even positions. It should not return any value. # Constraints * The list may be empty. * The list may contain any number of nodes. * The order of nodes should remain the same among the odd or even indexed groups. # Performance * Aim for a time complexity of O(n), where n is the number of nodes. * Aim for a space complexity of O(1). # Implementation Implement the `reorder_odd_even` method in the `Node` class to reorder the list as described. ```python from typing import Any class Node: def __init__(self, data: Any) -> None: self.data: Any = data self.next_node: Node | None = None def reorder_odd_even(self) -> None: Modifies the linked list such that all nodes at odd positions come before nodes at even positions. The relative order among odd or even indexed nodes should be maintained. >>> root_node = Node(1) >>> root_node.next_node = Node(2) >>> root_node.next_node.next_node = Node(3) >>> root_node.next_node.next_node.next_node = Node(4) >>> root_node.next_node.next_node.next_node.next_node = Node(5) >>> root_node.reorder_odd_even() >>> print_linked_list(root_node) 1->3->5->2->4 >>> root_node = Node(2) >>> root_node.next_node = Node(1) >>> root_node.next_node.next_node = Node(3) >>> root_node.next_node.next_node.next_node = Node(5) >>> root_node.next_node.next_node.next_node.next_node = Node(6) >>> root_node.reorder_odd_even() >>> print_linked_list(root_node) 2->3->6->1->5 # Implement your solution here pass def print_linked_list(node: Node) -> None: current = node while current: print(current.data, end=\'->\' if current.next_node else \'n\') current = current.next_node if __name__ == \\"__main__\\": root_node = Node(1) root_node.next_node = Node(2) root_node.next_node.next_node = Node(3) root_node.next_node.next_node.next_node = Node(4) root_node.next_node.next_node.next_node.next_node = Node(5) root_node.reorder_odd_even() print_linked_list(root_node) # Should output: 1->3->5->2->4 root_node = Node(2) root_node.next_node = Node(1) root_node.next_node.next_node = Node(3) root_node.next_node.next_node.next_node = Node(5) root_node.next_node.next_node.next_node.next_node = Node(6) root_node.reorder_odd_even() print_linked_list(root_node) # Should output: 2->3->6->1->5 root_node = Node(4) root_node.next_node = Node(10) root_node.reorder_odd_even() print_linked_list(root_node) # Should output: 4->10 root_node = Node(4) root_node.reorder_odd_even() print_linked_list(root_node) # Should output: 4 ``` **Note**: The `print_linked_list` function is provided to help verify the correctness of your solution by printing the linked list. Your task is to implement the `reorder_odd_even` method in the `Node` class.","solution":"from typing import Any class Node: def __init__(self, data: Any) -> None: self.data: Any = data self.next_node: Node | None = None def reorder_odd_even(self) -> None: Modifies the linked list such that all nodes at odd positions come before nodes at even positions. The relative order among odd or even indexed nodes should be maintained. if not self or not self.next_node: return odd_head = self even_head = self.next_node odd = odd_head even = even_head while even and even.next_node: odd.next_node = even.next_node odd = odd.next_node even.next_node = odd.next_node even = even.next_node odd.next_node = even_head def print_linked_list(node: Node) -> None: current = node while current: print(current.data, end=\'->\' if current.next_node else \'n\') current = current.next_node"},{"question":"# Coding Assessment Question Problem Description You are given an integer array `cost` where `cost[i]` represents the cost of the ith step on a staircase. Once you pay the cost, you can either climb one or two steps. Your task is to write a function `min_cost_climbing_stairs(cost: list) -> int` that returns the minimum cost to reach the top of the staircase. You can either start from the step with index 0, or the step with index 1. Function Signature ```python def min_cost_climbing_stairs(cost: list) -> int: ``` Input - `cost`: A list of integers where each integer represents the cost of a step. Output - An integer representing the minimum cost to reach the top of the staircase. Constraints - `cost` will have at most 1000 elements. - Each element in `cost` will be a non-negative integer. Examples ```python # Example 1 cost = [10, 15, 20] assert min_cost_climbing_stairs(cost) == 15 # Example 2 cost = [1, 100, 1, 1, 1, 100, 1, 1, 100, 1] assert min_cost_climbing_stairs(cost) == 6 # Example 3 try: min_cost_climbing_stairs(None) except TypeError as e: print(e) try: min_cost_climbing_stairs([\'a\', 1, 2]) except TypeError as e: print(e) ``` Requirements - Handle input validation, raising a `TypeError` with the message \\"The cost list does not contain the appropriate information\\" if the cost list is invalid. - Ensure your implementation is efficient and runs within the given constraints. Good luck!","solution":"def min_cost_climbing_stairs(cost): Returns the minimum cost to reach the top of the staircase. if not all(isinstance(item, int) and item >= 0 for item in cost): raise TypeError(\\"The cost list does not contain the appropriate information\\") n = len(cost) if n == 0: return 0 elif n == 1: return cost[0] dp = [0] * (n + 1) dp[0], dp[1] = 0, 0 for i in range(2, n + 1): dp[i] = min(dp[i - 1] + cost[i - 1], dp[i - 2] + cost[i - 2]) return dp[-1]"},{"question":"# Scenario You are designing software for a bookstore that needs to track discounts on books. A special promotion is being run where each book can have a discount applied, either a fixed amount or a percentage off the original price, but not both. Your task is to create a function to compute the final prices of books after applying the given discounts. # Task Implement a function `apply_discounts` that calculates the final price of each book after the discount. The function should handle a collection of book prices and their respective discounts efficiently. # Function Signature ```python def apply_discounts(prices: List[float], discounts: List[Tuple[str, float]]) -> List[float]: Applies a collection of discounts to corresponding book prices. :param prices: List of floats representing book prices. :param discounts: List of tuples, each having a string (\'fixed\' or \'percent\') and a float. :return: List of floats, each being the final book price after the discount is applied. pass ``` # Input - A list of floats, `prices`, where each float represents the original price of a book. - A list of tuples, `discounts`, where each tuple contains a string indicating the discount type (\'fixed\' or \'percent\') and a float representing the discount value. # Output - A list of floats, each corresponding to the final price of the books after applying the discounts. # Constraints - Each price in the input list is a positive float. - Each discount is either \'fixed\' or \'percent\'. If the discount is \'fixed\', the second value will be a float representing the fixed amount to subtract. If the discount is \'percent\', the second value will be a float representing the percentage to reduce from the original price. - The number of prices and discounts will have at most (10^5) entries. # Examples Example 1: ```python prices = [100.0, 200.0, 150.0] discounts = [(\'fixed\', 10.0), (\'percent\', 20.0), (\'fixed\', 15.0)] print(apply_discounts(prices, discounts)) # Output: [90.0, 160.0, 135.0] ``` Example 2: ```python prices = [50.0, 75.0] discounts = [(\'percent\', 10.0), (\'fixed\', 5.0)] print(apply_discounts(prices, discounts)) # Output: [45.0, 70.0] ``` # Additional Requirements - Your solution should handle up to (10^5) books efficiently. - Ensure the final prices do not go negative; if a discount reduces the price below zero, set the final price to 0.","solution":"from typing import List, Tuple def apply_discounts(prices: List[float], discounts: List[Tuple[str, float]]) -> List[float]: final_prices = [] for price, discount in zip(prices, discounts): discount_type, discount_value = discount if discount_type == \'fixed\': final_price = price - discount_value elif discount_type == \'percent\': final_price = price * (1 - discount_value / 100.0) final_prices.append(max(final_price, 0.0)) return final_prices"},{"question":"# Question: Efficient Matrix Operations You are required to optimize an existing matrix manipulation class to handle large-scale matrix operations efficiently using NumPy. Specifically, add new functionalities to the `MatrixOperations` class to support common operations like matrix inversion and determinant calculation, ensuring robust performance and handling of edge cases. Problem Statement Extend the `MatrixOperations` class to include efficient methods for calculating the inverse and determinant of a given matrix. Implement additional functionality to handle cases where the matrix is singular (non-invertible) or nearly singular with appropriate error handling and fallback options. Requirements 1. **Extend MatrixOperations Class**: - Implement a method `inverse` to calculate and return the inverse of a given matrix, handling non-invertible cases by returning `None` and raising a meaningful exception. - Implement a method `determinant` to calculate and return the determinant of a given matrix. 2. **Edge Case Handling**: - For the `inverse` method, include checks to identify singular matrices and provide a fallback or notification to the user when the inversion is not possible. - Ensure that the `determinant` method gracefully handles special cases, including zero matrices or matrices with very small determinant values, which can lead to numerical instability. Input and Output - The `inverse` method should accept a NumPy matrix as input and return a NumPy matrix representing the inverse, or `None` if the matrix is non-invertible. - The `determinant` method should accept a NumPy matrix as input and return a float representing the determinant of the matrix. Constraints - Ensure the methods can handle large matrices efficiently without significant performance overhead. - Perform necessary validation to avoid common numerical issues during matrix manipulation. Testing and Performance - Add test cases to validate the functionalities including matrices of various sizes, singular matrices, and those with very small determinants. - Ensure optimal performance for large-scale matrices and validate against known mathematical properties. Example ```python import numpy as np class MatrixOperations: @staticmethod def inverse(matrix): try: inv_matrix = np.linalg.inv(matrix) return inv_matrix except np.linalg.LinAlgError: print(\\"Matrix is singular or nearly singular.\\") return None @staticmethod def determinant(matrix): return np.linalg.det(matrix) # Test the functionality matrix = np.array([[1, 2], [3, 4]]) matrix_singular = np.array([[1, 2], [2, 4]]) ops = MatrixOperations() # Inverse calculation inv_matrix = ops.inverse(matrix) inv_singular = ops.inverse(matrix_singular) # Determinant calculation det_matrix = ops.determinant(matrix) det_singular = ops.determinant(matrix_singular) ``` Output: ```plaintext inv_matrix: [[-2. 1. ] [ 1.5 -0.5]] # Expected inverse of the matrix inv_singular: None # Expected as the matrix is singular det_matrix: -2.0 # Determinant of the given matrix det_singular: 0.0 # Determinant of the singular matrix ``` Implement the above solution and validate using test cases to handle scenarios for matrix inversion and determinant calculations.","solution":"import numpy as np class MatrixOperations: @staticmethod def inverse(matrix): Returns the inverse of the given matrix if it is non-singular, otherwise returns None. :param matrix: A numpy array representing the matrix to be inverted. :return: Inverse of the matrix or None if the matrix is singular. try: inv_matrix = np.linalg.inv(matrix) return inv_matrix except np.linalg.LinAlgError: return None @staticmethod def determinant(matrix): Returns the determinant of the given matrix. :param matrix: A numpy array representing the matrix for which determinant is computed. :return: Determinant of the matrix. return np.linalg.det(matrix)"},{"question":"# Coding Assessment Question Recommendation System using Collaborative Filtering You are part of a team developing a recommendation system for an online movie streaming platform. To improve user experience, you need to implement a collaborative filtering algorithm that recommends movies to users based on their past ratings and the ratings given by other users with similar tastes. # Problem Statement Implement a function `collaborative_filtering_recommend` in Python to recommend movies to users using the collaborative filtering approach. You will be provided with user ratings in a file as specified below. # Input Your function will read from a file with the following format: ``` user movie rating user movie rating ... ``` For example: ``` u1 m1 5 u1 m2 4 u2 m3 3 u2 m1 2 u3 m2 4 u3 m3 5 ``` # Function Signature ```python def collaborative_filtering_recommend(file_path: str, user: str, num_recommendations: int) -> List[str]: pass ``` # Parameters - `file_path`: Path to the file containing user ratings. - `user`: A string representing the user ID for whom recommendations are to be generated. - `num_recommendations`: An integer representing the number of movie recommendations desired. # Output * Returns a list of recommended movie IDs for the given user. * The list should contain up to `num_recommendations` movie IDs. # Constraints * User IDs and movie IDs are uniquely identifiable strings (i.e., no duplicates). * Ratings are integers between 1 and 5 inclusive. * The maximum number of users is 1000. * The maximum number of movies is 500. # Performance Requirements * The solution should handle input files with up to 1000 users efficiently. * Optimize the algorithm to provide recommendations within a reasonable time frame for the full input size. # Example For the input file with the following ratings: ``` u1 m1 5 u1 m2 4 u2 m3 3 u2 m1 2 u3 m2 4 u3 m3 5 ``` And the function call `collaborative_filtering_recommend(\'input.txt\', \'u1\', 2)`, a possible output could be: ```python [\'m3\', \'m1\'] ``` This indicates the top 2 recommended movies for user `u1`. # Additional Instructions * Ensure your implementation handles file reading errors gracefully. * Document your code with comments explaining the key parts. * You are encouraged to write helper functions to break down different parts of the algorithm (e.g., computing similarities, generating recommendations). # Optional Hints * Use similarity measures like cosine similarity or Pearson correlation for collaborative filtering. * Consider normalizing the ratings to improve the quality of recommendations. * Implement a fallback mechanism in case the user has no prior ratings or insufficient data for meaningful recommendations.","solution":"from typing import List, Tuple import pandas as pd from sklearn.metrics.pairwise import cosine_similarity def collaborative_filtering_recommend(file_path: str, user: str, num_recommendations: int) -> List[str]: # Read data from file data = pd.read_csv(file_path, sep=\' \', header=None, names=[\'user\', \'movie\', \'rating\']) # Create a user-item matrix user_item_matrix = data.pivot_table(index=\'user\', columns=\'movie\', values=\'rating\').fillna(0) # Compute cosine similarity between users user_similarity = cosine_similarity(user_item_matrix) # Convert similarity matrix to dataframe for easier access user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index) # Get the similarity scores for the target user similar_users = user_similarity_df[user].sort_values(ascending=False) # Weighted sum of ratings of similar users weighted_ratings = user_item_matrix.mul(similar_users, axis=0).sum(axis=0) # Normalize by the sum of weights (excluding the target user itself) norm_factor = similar_users.sum() - 1 recommendation_scores = weighted_ratings / norm_factor # Exclude movies already rated by the user rated_movies = user_item_matrix.loc[user] non_rated_movies = rated_movies[rated_movies == 0].index recommendations = recommendation_scores[non_rated_movies] # Return the top N recommendations return recommendations.nlargest(num_recommendations).index.tolist()"},{"question":"# Question You need to implement a custom sorted data structure that supports fast insertion, lookup, and deletion of keys while preserving the order of elements based on their frequency of access. The structure should provide O(log n) time complexity for insertion, lookup, and deletion operations. Objectives - Design a class `FrequencyOrderedDict` that maintains an ordered collection of keys where the order is determined by the frequency of access (most accessed keys come first). - The frequency of access for each key should be updated for each lookup operation. Input - Implement methods for the data structure: `insert(key: str) -> None`, `delete(key: str) -> None`, and `lookup(key: str) -> bool`. Output - For `insert()`: No return value. - For `delete()`: No return value. - For `lookup()`: Returns `True` if the key exists in the structure, otherwise `False`. Constraints - Your solution should handle up to 10^5 operations efficiently. - Key strings have a maximum length of 100 characters. Example ```python # Sample usage fod = FrequencyOrderedDict() fod.insert(\\"apple\\") fod.insert(\\"banana\\") fod.insert(\\"cherry\\") fod.lookup(\\"banana\\") # Returns True fod.lookup(\\"orange\\") # Returns False fod.delete(\\"apple\\") assert \\"apple\\" not in fod # True if deletion is successful ``` Requirements 1. Implement the `FrequencyOrderedDict` class with three methods: `insert`, `delete`, and `lookup`. 2. Ensure that the internal structure maintains the order of keys based on their access frequency. 3. Achieve O(log n) time complexity for all operations. 4. You may use any appropriate data structures to support the functionality, such as balanced binary search trees or heaps, but ensure the memory usage is efficient. 5. Do not modify the provided method signatures.","solution":"from collections import defaultdict import heapq class FrequencyOrderedDict: def __init__(self): self.key_frequency = defaultdict(int) self.frequency_heap = [] self.key_set = set() def insert(self, key: str) -> None: if key not in self.key_set: self.key_set.add(key) self.key_frequency[key] = 0 heapq.heappush(self.frequency_heap, (-self.key_frequency[key], key)) def delete(self, key: str) -> None: if key in self.key_set: self.key_set.remove(key) del self.key_frequency[key] # Create a new heap without the deleted key self.frequency_heap = [(-self.key_frequency[k], k) for k in self.key_set] heapq.heapify(self.frequency_heap) def lookup(self, key: str) -> bool: if key in self.key_set: self.key_frequency[key] += 1 # Create a new heap with updated frequency self.frequency_heap = [(-self.key_frequency[k], k) for k in self.key_set] heapq.heapify(self.frequency_heap) return True return False # End of solution code."},{"question":"# Coding Assessment Question Context: Develop an algorithm that compresses a given string using Run-Length Encoding (RLE). This method replaces consecutive identical characters with a single instance of the character followed by the number of occurrences. The algorithm should handle both uppercase and lowercase letters and should treat them as distinct characters. Task: Implement the function `encode_rle(input_string: str) -> str` which: 1. Accepts a string representing the input to be compressed. 2. Returns a string representing the compressed output using Run-Length Encoding. Input: - `input_string`: A string containing only uppercase and lowercase letters. Output: - A string representing the run-length encoded version of the input string. Constraints: 1. The length of `input_string` will be between `1` and `100` characters. Example: ```python input_string = \\"aaabbCCCCddDD\\" assert encode_rle(input_string) == \\"a3b2C4d2D2\\" input_string = \\"AABBBCCCCddddEEE\\" assert encode_rle(input_string) == \\"A2B3C4d4E3\\" ``` Note: - Ensure your implementation handles characters with both uppercase and lowercase forms separately. - The function should be case-sensitive. You may use the following function skeleton: ```python def encode_rle(input_string: str) -> str: pass ```","solution":"def encode_rle(input_string: str) -> str: Compresses the input string using Run-Length Encoding (RLE). :param input_string: The input string to be compressed. :return: The run-length encoded version of the input string. if not input_string: return \\"\\" encoded_string = [] current_char = input_string[0] count = 1 for char in input_string[1:]: if char == current_char: count += 1 else: encoded_string.append(f\\"{current_char}{count}\\") current_char = char count = 1 encoded_string.append(f\\"{current_char}{count}\\") return \\"\\".join(encoded_string)"},{"question":"# Matrix Transpose Description Given a 2D matrix, implement a function to calculate and return the transpose of the matrix. The transpose of a matrix is obtained by swapping its rows and columns. Function Signature ```python def transpose_matrix(matrix: List[List[int]]) -> List[List[int]]: pass ``` Input * `matrix` (List[List[int]]): A 2D list representing the matrix with dimensions `m x n`. Output * (List[List[int]]): A 2D list which is the transpose of the input matrix with dimensions `n x m`. Constraints * 1 ≤ m, n ≤ 100 * -10^3 ≤ matrix[i][j] ≤ 10^3 for 0 ≤ i < m, 0 ≤ j < n Example ```python # Example 1 transpose_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) # should return [[1, 4, 7], [2, 5, 8], [3, 6, 9]] # Example 2 transpose_matrix([[1, 2], [3, 4], [5, 6]]) # should return [[1, 3, 5], [2, 4, 6]] # Example 3 transpose_matrix([[1]]) # should return [[1]] # Example 4 transpose_matrix([[5]]) # should return [[5]] ``` Notes Consider edge cases where the matrix might have only one row or one column. Ensure the function handles these cases appropriately and consistently returns the correct transposition.","solution":"from typing import List def transpose_matrix(matrix: List[List[int]]) -> List[List[int]]: Returns the transpose of a given 2D matrix. return [list(row) for row in zip(*matrix)]"},{"question":"# Problem Description: You need to implement a function that simulates the rolling of a dice. The function should simulate rolling a six-sided die for a given number of times and then return a dictionary summarizing the results of the rolls – the count of each value (1 through 6). # Function Signature: ```python def roll_dice(simulations: int) -> Dict[int, int]: ``` # Input: * `simulations` (int): The number of times the six-sided die should be rolled. # Output: * A dictionary where keys are integers from 1 to 6, and values are the corresponding counts of those integers after simulating the rolls. # Constraints: 1. The `simulations` will be a positive integer not exceeding 100,000. 2. You can assume each roll is uniformly random. # Example: ```python simulations = 10 expected_output = { 1: 1, 2: 2, 3: 3, 4: 1, 5: 2, 6: 1 } assert roll_dice(simulations) == expected_output ``` # Notes: - Use standard random number generation techniques available in Python. - The distribution of the results does not have to match the example exactly, as the rolls are random.","solution":"import random from typing import Dict def roll_dice(simulations: int) -> Dict[int, int]: Simulate rolling a six-sided die for a given number of times and return a dictionary summarizing the results. :param simulations: The number of times to roll the dice :return: A dictionary with keys from 1 to 6 and values representing the counts of each face result = {i: 0 for i in range(1, 7)} for _ in range(simulations): roll = random.randint(1, 6) result[roll] += 1 return result"},{"question":"Context Binary Search Tree (BST) operations are foundational for various computational tasks. They provide efficient solutions for searching, insertion, and deletion operations due to their structural properties. # Problem Statement Implement a function to find the k-th smallest element in a Binary Search Tree. The function should traverse the tree efficiently to identify and return the desired element without modifying the tree structure. # Requirements * **Function Name**: `kth_smallest` * **Input**: A root node of a BST, and an integer `k` * **Output**: An integer representing the k-th smallest element in the BST # Constraints - The BST node contains only integer values. - Assume `1 <= k <= number of nodes in the BST`. # Performance - Aim for a time complexity of O(h + k), where h is the height of the tree. - Optimize space complexity by using a solution that does not require additional space apart from the recursion stack. # Example ```python class TreeNode: def __init__(self, value=0, left=None, right=None): self.value = value self.left = left self.right = right def kth_smallest(root: TreeNode, k: int) -> int: # Your code here # Examples: # Constructing the BST # 5 # / # 3 6 # / # 2 4 # / # 1 root = TreeNode(5) root.left = TreeNode(3) root.right = TreeNode(6) root.left.left = TreeNode(2) root.left.right = TreeNode(4) root.left.left.left = TreeNode(1) print(kth_smallest(root, 3)) # Output: 3 print(kth_smallest(root, 1)) # Output: 1 ``` # Special Considerations - Implement in-order traversal to access nodes in ascending order. - Ensure the function handles edge cases, such as `k` being out of range or the root being None. - Consider balancing the tree manually for testing if the tree is initially skewed. # Testing Create a series of unit tests to ensure your function correctly identifies the k-th smallest element. Test with different tree structures including balanced, unbalanced, and edge cases with minimum and maximum number of nodes.","solution":"class TreeNode: def __init__(self, value=0, left=None, right=None): self.value = value self.left = left self.right = right def kth_smallest(root: TreeNode, k: int) -> int: Return the k-th smallest element in the BST. def in_order_traversal(node): if not node: return [] return in_order_traversal(node.left) + [node.value] + in_order_traversal(node.right) elements = in_order_traversal(root) return elements[k - 1]"},{"question":"Longest Repeating Subsequence Write a function `longest_repeating_subsequence(s: str) -> int` that returns the length of the longest subsequence of a given string `s` that appears more than once in the string. A subsequence should keep the relative order of characters in the original string. # Function Signature ```python def longest_repeating_subsequence(s: str) -> int: pass ``` # Input - `s` (str): A string consisting of lowercase English letters. # Output - An integer representing the length of the longest repeating subsequence in the given string. # Constraints - (1 leq |s| leq 1000) - The input string `s` will consist only of lowercase English letters. # Example ```python print(longest_repeating_subsequence(\\"aabb\\")) # Output: 2 print(longest_repeating_subsequence(\\"abc\\")) # Output: 0 print(longest_repeating_subsequence(\\"aab\\")) # Output: 1 ``` # Notes - A subsequence is a sequence that appears in the same order as the given string but not necessarily contiguous. - You are looking for the longest subsequence that appears at least twice in the given string. # Hints 1. This problem can be approached using dynamic programming. 2. Consider tracking the character positions using a 2-dimensional array where you store the lengths of matching subsequences.","solution":"def longest_repeating_subsequence(s: str) -> int: n = len(s) dp = [[0] * (n + 1) for _ in range(n + 1)] for i in range(1, n + 1): for j in range(1, n + 1): if s[i - 1] == s[j - 1] and i != j: dp[i][j] = 1 + dp[i - 1][j - 1] else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[n][n]"},{"question":"# Objective Create a function to fetch Bitcoin price data from a public API and handle various edge cases, including invalid dates and network errors. The function should be robust, handling potential exceptions, and should also include basic data validation. # Task Write a Python function `get_bitcoin_price(date: str) -> dict` that retrieves the closing Bitcoin price for the given date using the Coindesk API. The function should handle the following: - Validate that the input date is in the proper `YYYY-MM-DD` format. - Safely handle network errors and invalid dates. - In case of an invalid API response or other issues, the function should raise an appropriate exception. # Input - `date` (string): The date for which to fetch the Bitcoin price in `YYYY-MM-DD` format. # Output - A dictionary with the keys \\"date\\" and \\"closing_price\\", representing the date and the closing price of Bitcoin on that date. # Constraints - The date should be a valid date in the `YYYY-MM-DD` format. - If the input date is invalid or if there is no data for the provided date, raise an appropriate exception. - Ensure that your function performs efficiently and handles errors gracefully. # Example Usage ```python try: price_data = get_bitcoin_price(\\"2021-09-01\\") print(price_data) # Output: {\\"date\\": \\"2021-09-01\\", \\"closing_price\\": 48800.35} except Exception as e: print(f\\"Error: {e}\\") ``` # Notes - Use the Coindesk API for fetching Bitcoin price data. - If the input date is in an incorrect format or does not yield data, raise a `ValueError` with a clear message. - If a network error occurs, handle it gracefully and raise an appropriate exception with a clear message. - Adhere to best practices for performance and error handling.","solution":"import requests from datetime import datetime API_URL = \\"https://api.coindesk.com/v1/bpi/historical/close.json\\" def get_bitcoin_price(date: str) -> dict: Fetch the closing Bitcoin price for the given date using the Coindesk API. :param date: Date in \'YYYY-MM-DD\' format. :returns: Dictionary with the keys \\"date\\" and \\"closing_price\\". :raises ValueError: If the date format is invalid or data is not found for the given date. :raises Exception: If there is a network error or other issues fetching data. # Validate date format try: datetime.strptime(date, \'%Y-%m-%d\') except ValueError: raise ValueError(\\"Invalid date format. Please use \'YYYY-MM-DD\'.\\") # Fetching Bitcoin price data from the API try: response = requests.get(API_URL, params={\'start\': date, \'end\': date}) response.raise_for_status() except requests.exceptions.RequestException as e: raise Exception(f\\"Network error occurred: {e}\\") data = response.json() closing_price = data[\'bpi\'].get(date) if closing_price is None: raise ValueError(f\\"No data found for the date {date}.\\") return {\\"date\\": date, \\"closing_price\\": closing_price}"},{"question":"Coding Assessment Question You are tasked with writing a function that simulates a simplified inventory management system for a small business. The function will handle the addition, removal, and inventory count of items. You will build the function based on the provided code snippet. # Function Signature ```python def manage_inventory(actions: List[Tuple[str, str, int]]) -> Dict[str, int]: ``` # Objective Modify the provided `manage_inventory` function to: 1. Take `actions` as a parameter. 2. Keep track of item counts effectively. 3. Ensure that the item count does not drop below zero for any item. # Input/Output Format * **Input**: * `actions` (List[Tuple[str, str, int]]): A list of tuples where each tuple represents an action. * The first element of the tuple is a string representing the action (`\\"add\\"` or `\\"remove\\"`). * The second element is a string representing the item name. * The third element is an integer representing the quantity of the item to add or remove. * **Output**: * A dictionary representing the final inventory, where keys are item names and values are quantities. # Constraints * If a \\"remove\\" action would result in a negative quantity, do not perform that action. * Initial inventory is empty. * Assume all item names are unique. # Context This function will be part of a larger inventory management system for a small business where actions are processed in bulk. Proper handling of inventory counts and ensuring they do not drop below zero is crucial to maintain accurate and realistic records. # Examples *Example 1* ```python actions = [(\\"add\\", \\"apple\\", 10), (\\"remove\\", \\"apple\\", 5), (\\"add\\", \\"banana\\", 3)] assert manage_inventory(actions) == {\\"apple\\": 5, \\"banana\\": 3} ``` *Example 2* ```python actions = [(\\"add\\", \\"apple\\", 10), (\\"remove\\", \\"apple\\", 15), (\\"add\\", \\"banana\\", 3)] assert manage_inventory(actions) == {\\"apple\\": 10, \\"banana\\": 3} ``` *Example 3* ```python actions = [(\\"add\\", \\"apple\\", 10), (\\"remove\\", \\"apple\\", 5), (\\"add\\", \\"banana\\", 6), (\\"remove\\", \\"banana\\", 2)] assert manage_inventory(actions) == {\\"apple\\": 5, \\"banana\\": 4} ``` # Performance Requirements * Ensure the function handles a large list of action tuples efficiently. # Implementation Notes * Use dictionaries to map item names to their respective counts. * Ensure proper handling of add and remove actions by checking current inventory status before making changes. Design and implement the `manage_inventory` function based on the above requirements.","solution":"from typing import List, Tuple, Dict def manage_inventory(actions: List[Tuple[str, str, int]]) -> Dict[str, int]: inventory = {} for action, item, quantity in actions: if action == \\"add\\": if item in inventory: inventory[item] += quantity else: inventory[item] = quantity elif action == \\"remove\\": if item in inventory and inventory[item] >= quantity: inventory[item] -= quantity # else do nothing if item does not exist or not enough quantity to remove return inventory"},{"question":"# Counting Good Triplets in an Array You are tasked with counting the number of \\"good triplets\\" in an array. A triplet `(arr[i], arr[j], arr[k])` is considered good if the following conditions are met: 1. `0 ≤ i < j < k < len(arr)` 2. `|arr[i] - arr[j]| ≤ a` 3. `|arr[j] - arr[k]| ≤ b` 4. `|arr[i] - arr[k]| ≤ c` **Function Signature**: ```python def count_good_triplets(arr: list[int], a: int, b: int, c: int) -> int: pass ``` # Input: * `arr` (list of integers): A list of integers where ( 1 leq len(arr) leq 100) and each integer ( |arr[i]| leq 1000 ). * `a` (integer): A nonnegative integer ( 0 leq a leq 1000 ). * `b` (integer): A nonnegative integer ( 0 leq b leq 1000 ). * `c` (integer): A nonnegative integer ( 0 leq c leq 1000 ). # Output: * Returns an integer count of the number of good triplets found in `arr`. # Examples: ```python >>> count_good_triplets([3, 0, 1, 1, 9, 7], 7, 2, 3) 4 >>> count_good_triplets([1,1,2,2,3], 0, 0, 1) 0 ``` # Constraints: * The function should efficiently count the number of good triplets without unnecessary computations. * Consider all possible triplets `(i, j, k)` and check if they satisfy the conditions to be counted as a good triplet. # Example Explanation: - For the first example, the good triplets are: - `(3, 0, 1)` satisfying: ( |3-0|=3 leq 7 ), ( |0-1|=1 leq 2 ), ( |3-1|=2 leq 3 ). - `(3, 1, 1)` satisfying: ( |3-1|=2 leq 7 ), ( |1-1|=0 leq 2 ), ( |3-1|=2 leq 3 ). - `(0, 1, 1)` satisfying: ( |0-1|=1 leq 7 ), ( |1-1|=0 leq 2 ), ( |0-1|=1 leq 3 ). - `(1, 1, 9)` satisfying: ( |1-1|=0 leq 7 ), ( |1-9|=8 leq 2 ), and it does NOT satisfy all conditions. - For the second example, no triplets satisfy the given conditions.","solution":"def count_good_triplets(arr: list[int], a: int, b: int, c: int) -> int: count = 0 n = len(arr) for i in range(n): for j in range(i + 1, n): for k in range(j + 1, n): if abs(arr[i] - arr[j]) <= a and abs(arr[j] - arr[k]) <= b and abs(arr[i] - arr[k]) <= c: count += 1 return count"},{"question":"# Problem Statement Implement a function `find_missing_number(arr: List[int]) -> int` that finds the one missing number from a list containing `n` distinct integers in the range `[0, n]`. Function Signature ```python def find_missing_number(arr: List[int]) -> int: ``` # Input - `arr`: A list of integers of length `n` containing distinct integers from `0` to `n`. # Output - An integer representing the missing number in the list. # Constraints - The function should raise a `ValueError` if `arr` is not of length `n` or contains duplicates. - A list of `n` distinct integers ranging between `0` and `n`. # Example ```python >>> find_missing_number([3, 0, 1]) 2 >>> find_missing_number([0, 1]) 2 >>> find_missing_number([9,6,4,2,3,5,7,0,1]) 8 >>> find_missing_number([0]) 1 ``` # Explanation 1. For `arr = [3, 0, 1]`, the missing number is `2` because numbers should be `0, 1, 2, 3`. 2. For `arr = [0, 1]`, the missing number is `2` because numbers should be `0, 1, 2`. 3. For `arr = [9, 6, 4, 2, 3, 5, 7, 0, 1]`, the missing number is `8` because numbers should be `0, 1, 2, 3, 4, 5, 6, 7, 8, 9`. 4. For `arr = [0]`, the missing number is `1` because numbers should be `0, 1`. # Notes - Your solution should aim for a time complexity better than O(n^2). - Consider typical edge cases, such as array having the smallest and largest values, as well as arrays missing the first or last elements. - You may use mathematical properties or algorithms to aid in your implementation. # Testing Ensure your implementation is tested against various scenarios: 1. Lists with the missing number at the beginning, middle, and end. 2. Edge cases like a single-element list. 3. Invalid inputs such as lists not meeting the constraints (duplicates, incorrect length).","solution":"from typing import List def find_missing_number(arr: List[int]) -> int: n = len(arr) # Validate input if len(arr) != n or len(set(arr)) != n: raise ValueError(\\"The array does not meet the constraints\\") # Expected sum of numbers from 0 to n expected_sum = n * (n + 1) // 2 actual_sum = sum(arr) return expected_sum - actual_sum"},{"question":"# Scenario You are tasked with developing a ride-sharing service\'s matching algorithm. One of the critical needs is to match riders with drivers as efficiently as possible, taking into account various constraints like distance, driver availability, and rider preferences. # Task Implement a data structure that supports efficient rider-driver matching. Your structure should handle the following functions efficiently: 1. **Add Driver:** Add a new driver with their current location. 2. **Remove Driver:** Remove a driver from the system. 3. **Match Rider:** Given a rider\'s location and desired distance range, find the nearest available driver within that range. # Specifications 1. **Input:** * **Drivers:** A list of drivers\' locations as tuples `(id, x, y)`. * **Queries:** A list of tuples where each tuple represents a query type and its parameters. 2. **Output:** * A list of results, one for each query in the order they are given. 3. **Query Types:** * **Add Driver:** `(\\"add_driver\\", id, x, y)` - Adds a driver with ID `id` at coordinates `(x, y)`. * **Remove Driver:** `(\\"remove_driver\\", id)` - Removes the driver with ID `id` from the system. * **Match Rider:** `(\\"match_rider\\", x, y, distance_range)` - Finds the nearest driver to coordinates `(x, y)` within `distance_range`. # Constraints * 1 ≤ number of drivers ≤ 100,000 * `(x, y)` coordinates are integers between 0 and 1,000,000 * distance_range is an integer between 0 and 1,000,000 * Each driver ID is unique. * Queries are given such that the `id` in `remove_driver` is guaranteed to exist in the system before removal. # Requirements 1. Implement the data structure to manage drivers. 2. Implement the functions to handle add driver, remove driver, and match rider queries. 3. Ensure efficient handling to scale with large numbers of drivers and queries. # Example ```python queries = [ (\\"add_driver\\", 1, 10, 10), (\\"add_driver\\", 2, 15, 15), (\\"add_driver\\", 3, 20, 20), (\\"match_rider\\", 12, 12, 10), (\\"remove_driver\\", 1), (\\"match_rider\\", 12, 12, 10) ] results = ride_sharing_query(queries) print(results) # Output should be [1, 2] ``` # Note Ensure your solution accounts for efficient handling of drivers\' locations and matches within large coordinate spaces, maintaining quick query performance.","solution":"import math import bisect class RideSharingService: def __init__(self): self.drivers = {} self.locations = [] def add_driver(self, driver_id, x, y): self.drivers[driver_id] = (x, y) bisect.insort(self.locations, (x, y, driver_id)) def remove_driver(self, driver_id): if driver_id in self.drivers: x, y = self.drivers[driver_id] self.locations.remove((x, y, driver_id)) del self.drivers[driver_id] def match_rider(self, rider_x, rider_y, distance_range): nearest_driver = None min_distance = float(\'inf\') for (x, y, driver_id) in self.locations: distance = math.sqrt((x - rider_x)**2 + (y - rider_y)**2) if distance <= distance_range and distance < min_distance: min_distance = distance nearest_driver = driver_id return nearest_driver def ride_sharing_query(queries): service = RideSharingService() results = [] for query in queries: if query[0] == \\"add_driver\\": _, driver_id, x, y = query service.add_driver(driver_id, x, y) elif query[0] == \\"remove_driver\\": _, driver_id = query service.remove_driver(driver_id) elif query[0] == \\"match_rider\\": _, rider_x, rider_y, distance_range = query result = service.match_rider(rider_x, rider_y, distance_range) results.append(result) return results"},{"question":"# Problem Statement You are given an unsorted array of integers, `arr`. Your goal is to find the length of the longest consecutive elements sequence in the array. A **consecutive elements sequence** is a sequence of numbers such that each number equals to the previous one plus one. # Function Signature ```python def longest_consecutive_sequence(arr: List[int]) -> int: pass ``` # Input * `arr`: A list of integers of length `n` where `0 <= n <= 10^5`. # Output * Returns an integer representing the length of the longest consecutive elements sequence in the array. # Constraints * The function should handle a variety of inputs including large arrays. * Time complexity should be considered to ensure efficiency for large inputs. # Examples The function should operate as follows: ```python assert longest_consecutive_sequence([100, 4, 200, 1, 3, 2]) == 4 # The consecutive sequence is [1, 2, 3, 4] assert longest_consecutive_sequence([0, 3, 7, 2, 5, 8, 4, 6, 0, 1]) == 9 # The consecutive sequence is [0, 1, 2, 3, 4, 5, 6, 7, 8] assert longest_consecutive_sequence([]) == 0 # No elements, so the longest sequence length is 0 ``` # Additional Notes * Consider both trivial (no consecutive elements) and complex cases (multiple distinct sequences). * Ensure efficient use of space and time to adhere to provided constraints. * The input list can contain negative numbers. # Hints 1. Think about how you can utilize a data structure to quickly find and extend consecutive sequences. 2. Use a set to eliminate duplicate entries and allow fast membership checks.","solution":"from typing import List def longest_consecutive_sequence(arr: List[int]) -> int: if not arr: return 0 num_set = set(arr) longest_streak = 0 for num in num_set: # Only check for the beginning of the sequence if num - 1 not in num_set: current_num = num current_streak = 1 while current_num + 1 in num_set: current_num += 1 current_streak += 1 longest_streak = max(longest_streak, current_streak) return longest_streak"},{"question":"# Coding Assessment Question Scenario You\'ve been tasked with developing a search utility for a file system that can locate files based on their names and return their full paths. Task Description Write a function `find_files` that searches for files with a given name in a specified directory and all its subdirectories. Your function should take the following parameters: * `file_name`: A string representing the name of the file to search for. * `directory_path`: A string representing the path to the directory where the search should begin. * `absolute_paths`: A boolean indicating whether the returned paths should be absolute (`True`) or relative (`False`). * `case_sensitive`: A boolean indicating whether the search should be case sensitive (`True`) or case insensitive (`False`). Your function should return a list of paths (either absolute or relative) to the files found with the specified name. Input and Output Formats ```python import os def find_files(file_name, directory_path, absolute_paths=True, case_sensitive=True): paths = [] for root, dirs, files in os.walk(directory_path): if case_sensitive: matches = [f for f in files if f == file_name] else: matches = [f for f in files if f.lower() == file_name.lower()] for match in matches: if absolute_paths: paths.append(os.path.join(root, match)) else: paths.append(os.path.relpath(os.path.join(root, match), directory_path)) return paths # Example usage: directory = \\"/path/to/search\\" search_file = \\"example.txt\\" found_paths = find_files(search_file, directory, absolute_paths=True, case_sensitive=False) print(found_paths) # Expected to print the list of full paths to \'example.txt\' found in the directory and subdirectories. ``` Constraints * The search should include all subdirectories of the specified directory. * Ensure that the search can handle case sensitivity based on the parameter provided. * Efficiently handle directories with large numbers of files and nested subdirectories. Performance Requirements * Your function should efficiently traverse and search directories with up to 10,000 files. * Minimize the use of system calls where possible to improve performance.","solution":"import os def find_files(file_name, directory_path, absolute_paths=True, case_sensitive=True): Search for files with a given name in a specified directory and its subdirectories. Parameters: file_name (str): The name of the file to search for. directory_path (str): The path to the directory where the search should begin. absolute_paths (bool): Whether the returned paths should be absolute (True) or relative (False). case_sensitive (bool): Whether the search should be case sensitive (True) or case insensitive (False). Returns: list: A list of paths (either absolute or relative) to the files found with the specified name. paths = [] for root, dirs, files in os.walk(directory_path): if case_sensitive: matches = [f for f in files if f == file_name] else: matches = [f for f in files if f.lower() == file_name.lower()] for match in matches: if absolute_paths: paths.append(os.path.join(root, match)) else: paths.append(os.path.relpath(os.path.join(root, match), directory_path)) return paths"},{"question":"# Task: Given a list of integers `nums` and an integer `target`, write a function `num_pairs_with_sum(nums: list[int], target: int) -> int` that returns the number of unique pairs of elements in the list that add up to the target sum. # Requirements: * **Input**: * `nums`: A list of integers. * Constraints: * 1 ≤ len(nums) ≤ 10,000 * -10^4 ≤ nums[i] ≤ 10^4 * `target`: An integer representing the target sum. * Constraints: * -10^8 ≤ target ≤ 10^8 * **Output**: * An integer representing the number of unique pairs of elements that have a sum equal to `target`. # Example: ```python assert num_pairs_with_sum([1, 2, 3, 4, 3], 6) == 2 # Pairs: (2, 4), (3, 3) assert num_pairs_with_sum([1, 3, 2, 2], 4) == 2 # Pairs: (1, 3), (2, 2) assert num_pairs_with_sum([1, 1, 1, 1], 2) == 1 # Pair: (1, 1) assert num_pairs_with_sum([1, 2, 3, 4, 5], 10) == 0 # No pairs add up to 10 assert num_pairs_with_sum([], 0) == 0 # No pairs in an empty list ``` # Constraints: * The solution must have a time complexity of O(n). * The space complexity should be O(n). # Explanation: We should ensure that the function identifies all unique pairs without considering the order of elements, i.e., the pair (2, 4) is deemed the same as the pair (4, 2).","solution":"def num_pairs_with_sum(nums: list[int], target: int) -> int: Returns the number of unique pairs of elements in the list that add up to the target sum. seen = set() pairs = set() for num in nums: complement = target - num if complement in seen: pairs.add(tuple(sorted((num, complement)))) seen.add(num) return len(pairs)"},{"question":"# Coding Task: Matrix Zigzag Traversal You are given a 2D matrix. Implement a function to return a list of all the elements of the matrix in zigzag order. The traversal should start from the top-left corner of the matrix and proceed to the top-right corner, then move to the bottom-left corner, and finish at the bottom-right corner of the matrix in a diagonal-like manner. Function Signature: ```python def zigzag_traversal(matrix: list) -> list: Returns the elements of the 2D matrix in zigzag order. :param matrix: a list of lists of integers representing the 2D matrix. :return: a list of integers representing the matrix elements in zigzag order. ``` Example: ```python matrix = [ [1, 2, 3], [4, 5, 6], [7, 8, 9] ] print(zigzag_traversal(matrix)) # Output: [1, 2, 3, 6, 9, 8, 7, 4, 5] ``` ```python matrix = [ [1, 2], [3, 4] ] print(zigzag_traversal(matrix)) # Output: [1, 2, 4, 3] ``` Constraints: - You may assume that the given matrix has at least one row and one column. - Elements within the matrix are integers. Performance Requirement: - Aim to solve the problem with an efficient space complexity, ideally using no more space than needed for the output list and minimal extra state variables. Edge Cases: - The matrix has a single row or a single column. - The matrix has only one element. # Explanation: The zigzag traversal of a matrix is essentially moving diagonally first from top-left to top-right, then moving from bottom-left to bottom-right. This involves careful management of row and column indices to ensure that all elements are visited in the specified order. The traversal order example given in the problem statement clarifies the expected output, establishing a sequence in which elements should be listed. The implementation should traverse elements accordingly and handle matrices of varying shapes and sizes.","solution":"def zigzag_traversal(matrix): Returns the elements of the 2D matrix in zigzag order. :param matrix: a list of lists of integers representing the 2D matrix. :return: a list of integers representing the matrix elements in zigzag order. rows = len(matrix) cols = len(matrix[0]) result = [] for i in range(rows + cols - 1): if i % 2 == 0: x = min(i, rows - 1) y = i - x while x >= 0 and y < cols: result.append(matrix[x][y]) x -= 1 y += 1 else: y = min(i, cols - 1) x = i - y while y >= 0 and x < rows: result.append(matrix[x][y]) y -= 1 x += 1 return result"},{"question":"# Problem Statement You are required to implement a `DoublyLinkedList` class in Python to represent a doubly linked list data structure. The class should support the following operations: * `append(item)`: Adds an item to the end of the list. * `prepend(item)`: Adds an item to the beginning of the list. * `insert(index, item)`: Inserts an item at the specified index. Raises an `IndexError` if the index is out of bounds. * `remove(item)`: Removes the first occurrence of an item from the list. Raises a `ValueError` if the item is not found. * `pop(index)`: Removes and returns the item at the specified index. Raises an `IndexError` if the index is out of bounds. * `get(index)`: Returns the item at the specified index. Raises an `IndexError` if the index is out of bounds. * `clear()`: Empties the list. * `is_empty()`: Returns `True` if the list is empty, `False` otherwise. * `__len__()`: Returns the number of items in the list. # Input/Output Format * The `DoublyLinkedList` class does not take any input during instantiation. * Operations include `append(item: T) -> None`, `prepend(item: T) -> None`, `insert(index: int, item: T) -> None`, `remove(item: T) -> None`, `pop(index: int) -> T`, `get(index: int) -> T`, `clear() -> None`, `is_empty() -> bool`, and `__len__() -> int`. # Constraints * You may assume that the item to be added or removed from the list will always be valid and can be any type. * You must handle the scenario where operations like `pop`, `get`, or `insert` are called with an out-of-bounds index, by raising an appropriate exception. * You must handle the scenario where `remove` is called with an item that is not in the list, by raising an appropriate exception. # Example Usage ```python dll = DoublyLinkedList() dll.append(5) dll.prepend(3) dll.insert(1, 4) print(dll.get(0)) # Output: 3 print(dll.get(1)) # Output: 4 print(dll.get(2)) # Output: 5 dll.remove(4) print(dll.pop(0)) # Output: 3 print(len(dll)) # Output: 1 print(dll.is_empty()) # Output: False dll.clear() # Empties the list print(dll.is_empty()) # Output: True ``` Implement the class `DoublyLinkedList` in Python by completing the following definitions.","solution":"class Node: def __init__(self, data=None): self.data = data self.next = None self.prev = None class DoublyLinkedList: def __init__(self): self.head = None self.tail = None self.size = 0 def append(self, item): new_node = Node(item) if self.tail is None: self.head = self.tail = new_node else: self.tail.next = new_node new_node.prev = self.tail self.tail = new_node self.size += 1 def prepend(self, item): new_node = Node(item) if self.head is None: self.head = self.tail = new_node else: new_node.next = self.head self.head.prev = new_node self.head = new_node self.size += 1 def insert(self, index, item): if index < 0 or index > self.size: raise IndexError(\\"Index out of bounds\\") if index == 0: self.prepend(item) elif index == self.size: self.append(item) else: new_node = Node(item) current = self.head for _ in range(index): current = current.next previous = current.prev previous.next = new_node new_node.prev = previous new_node.next = current current.prev = new_node self.size += 1 def remove(self, item): current = self.head while current: if current.data == item: if current.prev: current.prev.next = current.next else: self.head = current.next if current.next: current.next.prev = current.prev else: self.tail = current.prev self.size -= 1 return current = current.next raise ValueError(\\"Item not found\\") def pop(self, index): if index < 0 or index >= self.size: raise IndexError(\\"Index out of bounds\\") current = self.head for _ in range(index): current = current.next data = current.data if current.prev: current.prev.next = current.next else: self.head = current.next if current.next: current.next.prev = current.prev else: self.tail = current.prev self.size -= 1 return data def get(self, index): if index < 0 or index >= self.size: raise IndexError(\\"Index out of bounds\\") current = self.head for _ in range(index): current = current.next return current.data def clear(self): self.head = self.tail = None self.size = 0 def is_empty(self): return self.size == 0 def __len__(self): return self.size"},{"question":"Binary Search Tree (BST) Implementation and Range Sum Calculation You are required to implement a Binary Search Tree (BST) and provide functions to insert elements and calculate the range sum of values within a specified range. Implement the following functions: 1. **insert** - To insert a new value into the BST. 2. **find_range_sum** - To find the sum of all values within a given range [low, high]. # Function Definitions Function 1: insert ```python class TreeNode: def __init__(self, value: int): self.value = value self.left = None self.right = None def insert(root: TreeNode, value: int) -> TreeNode: Insert a value into the BST. Args: - root (TreeNode): The root node of the BST. - value (int): The value to be inserted. Returns: - TreeNode: The root node of the BST after insertion. ``` Function 2: find_range_sum ```python def find_range_sum(root: TreeNode, low: int, high: int) -> int: Calculate the sum of all values in the BST within the range [low, high]. Args: - root (TreeNode): The root node of the BST. - low (int): The lower bound of the range. - high (int): The upper bound of the range. Returns: - int: The sum of all values within the range [low, high]. ``` # Input and Output - **Input**: - For insertion, a root node of the BST and a new integer value to be inserted. - For finding range sum, a root node of the BST and two integers representing the range [low, high]. - **Output**: - For insertion, the root node of the BST after the value is inserted. - For finding range sum, an integer representing the sum of all values within the specified range. # Constraints - The value array contains only integers. - The BST does not contain duplicate values. - Low and high values are integers within the range [INT_MIN, INT_MAX]. # Additional Notes - Ensure that the BST maintains its properties after each insertion. - Optimize range sum calculation for time complexity. - Handle edge cases like an empty tree or the specified range containing no nodes. - Include comments and docstrings for code clarity. # Example Usage ```python # Create the BST with initial node root = TreeNode(10) root = insert(root, 5) root = insert(root, 15) root = insert(root, 3) root = insert(root, 8) root = insert(root, 12) root = insert(root, 18) # Calculate the range sum low, high = 5, 15 range_sum = find_range_sum(root, low, high) print(f\\"Sum of values in range [{low}, {high}]: {range_sum}\\") ``` In this example: - The BST is constructed by inserting values 10, 5, 15, 3, 8, 12, 18. - The function `find_range_sum` is then called to find the sum of values between 5 and 15, inclusive.","solution":"class TreeNode: def __init__(self, value: int): self.value = value self.left = None self.right = None def insert(root: TreeNode, value: int) -> TreeNode: Insert a value into the BST. Args: - root (TreeNode): The root node of the BST. - value (int): The value to be inserted. Returns: - TreeNode: The root node of the BST after insertion. if root is None: return TreeNode(value) if value < root.value: root.left = insert(root.left, value) else: root.right = insert(root.right, value) return root def find_range_sum(root: TreeNode, low: int, high: int) -> int: Calculate the sum of all values in the BST within the range [low, high]. Args: - root (TreeNode): The root node of the BST. - low (int): The lower bound of the range. - high (int): The upper bound of the range. Returns: - int: The sum of all values within the range [low, high]. if root is None: return 0 # If the current node\'s value is within the range, include it in the sum if low <= root.value <= high: return (root.value + find_range_sum(root.left, low, high) + find_range_sum(root.right, low, high)) elif root.value < low: # Current node\'s value is less than the low bound return find_range_sum(root.right, low, high) else: # Current node\'s value is greater than the high bound return find_range_sum(root.left, low, high)"},{"question":"Problem Statement You are given an array of integers `nums` and an integer `k`. Write a function `find_max_average` that returns the maximum average value that can be obtained from any contiguous subarray of length `k`. If no valid subarray of length `k` exists, return `None`. # Input * `nums` (list of integers): The array of integers. Constraints: (1 leq text{len(nums)} leq 10^5) and (-10^4 leq text{nums[i]} leq 10^4). * `k` (integer): The length of the subarray. Constraints: (1 leq k leq 10^5). # Output * A float representing the maximum average of the contiguous subarray of length `k`, limited to 5 decimal places, or `None` if no such subarray exists. # Examples ```python find_max_average([1,12,-5,-6,50,3], 4) # Expected output: 12.75000 find_max_average([5,5,5,5], 3) # Expected output: 5.00000 find_max_average([8], 1) # Expected output: 8.00000 find_max_average([], 1) # Expected output: None find_max_average([1,2], 3) # Expected output: None ``` # Constraints * Ensure the function handles edge cases where `k` is greater than the length of the array by returning `None`. * Format the output to exactly five decimal places.","solution":"def find_max_average(nums, k): if len(nums) < k: return None max_sum = sum(nums[:k]) current_sum = max_sum for i in range(k, len(nums)): current_sum = current_sum - nums[i - k] + nums[i] if current_sum > max_sum: max_sum = current_sum max_average = max_sum / k return round(max_average, 5)"},{"question":"# Infix to Postfix Conversion In your data structures and algorithms class, you studied different ways to evaluate arithmetic expressions. One common method is converting an infix expression to a postfix expression, which can then be easily evaluated using a stack. Your task is to implement a function that converts infix expressions into their postfix forms. Task Write a Python function `infix_to_postfix(expression: str) -> str` that converts a given infix expression to postfix notation. The function should return the resulting postfix expression as a string. Function Signature ```python def infix_to_postfix(expression: str) -> str: pass ``` Details 1. **Operators**: The supported operators include +, -, *, /, and ^ (exponentiation). 2. **Operands**: The operands are single-letter variables (e.g., a, b, c, ...). 3. **Parentheses**: The algorithm must correctly handle parentheses to ensure the order of operations. 4. **Precedence and Associativity**: Ensure that the operators are pushed and popped from the stack according to their precedences and associativity rules. Input * `expression`: A non-empty string representing a valid infix expression. The expression contains single-letter variables, operators, and parentheses. (1 ≤ len(expression) ≤ 100). Output * A string representing the postfix expression. Example ```python expression = \\"a+b*(c^d-e)^(f+g*h)-i\\" output = infix_to_postfix(expression) print(output) # Expected output: # \\"abcd^e-fgh*+^*+i-\\" ``` Constraints * Ensure your implementation can handle various valid infix expressions. * You must use a stack data structure to manage operators and parentheses. Notes 1. Follow the standard algorithm for converting infix to postfix notation. 2. Test your implementation thoroughly with different cases, including expressions with nested parentheses and all supported operators.","solution":"def infix_to_postfix(expression: str) -> str: Convert the given infix expression to postfix notation. precedence = {\'+\': 1, \'-\': 1, \'*\': 2, \'/\': 2, \'^\': 3} associativity = {\'+\': \'L\', \'-\': \'L\', \'*\': \'L\', \'/\': \'L\', \'^\': \'R\'} stack = [] output = [] for token in expression: if token.isalpha(): # Operand output.append(token) elif token == \'(\': # Left parenthesis stack.append(token) elif token == \')\': # Right parenthesis while stack and stack[-1] != \'(\': output.append(stack.pop()) stack.pop() # Remove \'(\' from stack else: # Operator while (stack and stack[-1] != \'(\' and ((associativity[token] == \'L\' and precedence[token] <= precedence[stack[-1]]) or (associativity[token] == \'R\' and precedence[token] < precedence[stack[-1]]))): output.append(stack.pop()) stack.append(token) while stack: output.append(stack.pop()) return \'\'.join(output)"},{"question":"Task # Graph Traversal Challenge **Context:** In graph theory, traversing a graph is a fundamental operation. It is crucial in various applications, including network analysis, pathfinding, and scheduling. This problem requires you to implement a graph traversal algorithm that can navigate through the graph and return specific information about its structure. **Task:** Implement a `Graph` class with the following functionalities: 1. **bfs(start: int) -> List[int]** - Performs Breadth-First Search (BFS) starting from the vertex `start` and returns a list of vertices in the order they are visited. 2. **shortest_path(u: int, v: int) -> List[int]** - Finds the shortest path between the vertices `u` and `v` using BFS and returns the list of vertices representing this path. If no path exists, return an empty list. **Specifications:** 1. **Method Signatures:** - `def bfs(self, start: int) -> List[int]` - `def shortest_path(self, u: int, v: int) -> List[int]` 2. **Constraints:** - The graph will have `n` vertices labeled from `0` to `n-1`. - Edges will be represented as an adjacency list. - `0 <= u, v < n` where `n` is the number of vertices. 3. **Expected Time Complexity:** - BFS Traversal and finding the shortest path should both be O(V + E) where V is the number of vertices and E is the number of edges. **Example Usage:** ```python graph = Graph(5) # initializes a graph with 5 vertices graph.add_edge(0, 1) graph.add_edge(0, 2) graph.add_edge(1, 2) graph.add_edge(1, 3) graph.add_edge(3, 4) print(graph.bfs(0)) # [0, 1, 2, 3, 4] print(graph.shortest_path(0, 4)) # [0, 1, 3, 4] print(graph.shortest_path(0, 5)) # [] ``` **Helper Code:** Here is a starting point for the `Graph` class: ```python from collections import deque, defaultdict class Graph: def __init__(self, n: int): self.n = n self.adj_list = defaultdict(list) def add_edge(self, u: int, v: int): self.adj_list[u].append(v) self.adj_list[v].append(u) def bfs(self, start: int) -> List[int]: visited = [False] * self.n queue = deque([start]) visited[start] = True order = [] while queue: vertex = queue.popleft() order.append(vertex) for neighbor in self.adj_list[vertex]: if not visited[neighbor]: queue.append(neighbor) visited[neighbor] = True return order def shortest_path(self, u: int, v: int) -> List[int]: if u == v: return [u] parent = {u: None} queue = deque([u]) while queue: vertex = queue.popleft() if vertex == v: break for neighbor in self.adj_list[vertex]: if neighbor not in parent: parent[neighbor] = vertex queue.append(neighbor) path = [] if v in parent: while v is not None: path.append(v) v = parent[v] path.reverse() return path ``` Ensure your implementation handles edge cases such as querying paths between unconnected vertices and performing BFS from a non-existent vertex.","solution":"from collections import deque, defaultdict from typing import List, Dict class Graph: def __init__(self, n: int): self.n = n self.adj_list = defaultdict(list) def add_edge(self, u: int, v: int): self.adj_list[u].append(v) self.adj_list[v].append(u) def bfs(self, start: int) -> List[int]: if start < 0 or start >= self.n: return [] # If the start vertex doesn\'t exist visited = [False] * self.n queue = deque([start]) visited[start] = True order = [] while queue: vertex = queue.popleft() order.append(vertex) for neighbor in self.adj_list[vertex]: if not visited[neighbor]: queue.append(neighbor) visited[neighbor] = True return order def shortest_path(self, u: int, v: int) -> List[int]: if u < 0 or u >= self.n or v < 0 or v >= self.n: return [] # If either vertex doesn\'t exist if u == v: return [u] parent = {u: None} queue = deque([u]) while queue: vertex = queue.popleft() if vertex == v: break for neighbor in self.adj_list[vertex]: if neighbor not in parent: parent[neighbor] = vertex queue.append(neighbor) path = [] if v in parent: while v is not None: path.append(v) v = parent[v] path.reverse() return path"},{"question":"# Problem Statement You are working on a data analytics platform and one of your tasks involves performing statistical transformations on provided datasets. Specifically, you need to implement a function that standardizes each column of a 2D numpy array (matrix), such that each column has a mean of 0 and a standard deviation of 1. This transformation is often required in data preprocessing for machine learning models. # Function Signature ```python def standardize_matrix(matrix: np.ndarray) -> np.ndarray: This function standardizes each column of the input 2D numpy array (matrix). Args: matrix: numpy array, the input 2D matrix. Returns: numpy array, the matrix after standardizing each column. ``` # Expected Input and Output - **Input**: - A 2D numpy array representing the dataset to be standardized. - **Output**: - A 2D numpy array where each column has been standardized to have a mean of 0 and standard deviation of 1. # Example ```python import numpy as np data = np.array([[10, 20, 30], [12, 22, 32], [14, 24, 34], [16, 26, 36]]) result = standardize_matrix(data) print(result) # array([[-1.34164079, -1.34164079, -1.34164079], # [-0.4472136 , -0.4472136 , -0.4472136 ], # [ 0.4472136 , 0.4472136 , 0.4472136 ], # [ 1.34164079, 1.34164079, 1.34164079]]) ``` # Constraints * The input dataset will always be a valid 2D numpy array with at least one row and one column. * Values within the 2D array can be any real numbers, but each column must contain at least two distinct values (to avoid division by zero during standardization). # Evaluation * **Correctness**: Ensure that your function accurately standardizes each column of the matrix. The mean of each column post-transformation should be 0, and the standard deviation should be 1. * **Efficiency**: Your implementation should be efficient in terms of both time and space complexity.","solution":"import numpy as np def standardize_matrix(matrix: np.ndarray) -> np.ndarray: This function standardizes each column of the input 2D numpy array (matrix). Args: matrix: numpy array, the input 2D matrix. Returns: numpy array, the matrix after standardizing each column. means = matrix.mean(axis=0) std_devs = matrix.std(axis=0) standardized_matrix = (matrix - means) / std_devs return standardized_matrix"},{"question":"# Coding Assessment Question **Problem Statement:** You are provided with a group of people, each identified by their unique ID from `0` to `n - 1`. Each person may have friendships with others, forming networks of friends. Your task is to determine the size of the largest network of mutual friends. Implement a function `largestFriendNetwork(n: int, friendships: List[Tuple[int, int]]) -> int` that returns the size of the largest network of friends. **Function Signature:** ```python def largestFriendNetwork(n: int, friendships: List[Tuple[int, int]]) -> int: pass ``` **Input:** - An integer `n` (1 ≤ n ≤ 10^4), representing the number of people. - A list of tuples `friendships`, where each tuple `(a, b)` represents a mutual friendship between person `a` and person `b`. **Output:** - An integer representing the size of the largest network of friends. **Constraints:** - No repeated friendships. - Friendships are undirected edges, meaning if `a` is friends with `b`, then `b` is friends with `a`. **Example:** 1. `largestFriendNetwork(5, [(0, 1), (1, 2), (3, 4)])` should return `3`. 2. `largestFriendNetwork(4, [(0, 1), (0, 2), (1, 2), (1, 3)])` should return `4`. **Explanation:** 1. There are two networks: {0, 1, 2} and {3, 4}. The largest one is {0, 1, 2} with size 3. 2. All individuals are connected in a single network of size 4. # Hints: 1. Use the Disjoint Set data structure or Depth-First Search (DFS) to manage and find the size of connected components. 2. Keep track of the maximum size of the discovered connected components throughout the traversal process.","solution":"def largestFriendNetwork(n, friendships): # Helper function for Depth First Search def dfs(person): stack = [person] visited[person] = True size = 0 while stack: current = stack.pop() size += 1 for friend in adjacency_list[current]: if not visited[friend]: visited[friend] = True stack.append(friend) return size # Create an adjacency list from friendships adjacency_list = {i: [] for i in range(n)} for a, b in friendships: adjacency_list[a].append(b) adjacency_list[b].append(a) visited = [False] * n largest_network_size = 0 # Find the size of the largest network using DFS for person in range(n): if not visited[person]: network_size = dfs(person) largest_network_size = max(largest_network_size, network_size) return largest_network_size"},{"question":"# Question Implement a function `find_unique_character` that takes a string as input and returns the first non-repeating character in the string. If there are no unique characters, the function should return an empty string. The function signature should be: ```python def find_unique_character(s: str) -> str: pass ``` # Input - `s`: A string containing uppercase and lowercase English letters. # Output - Returns the first non-repeating character as a string. If no such character exists, returns an empty string. # Constraints - The input string will have a length `1 <= len(s) <= 10^6`. - The function must be efficient and handle large inputs within reasonable time limits. # Example ```python s = \\"swiss\\" print(find_unique_character(s)) # Output: \\"w\\" s = \\"aabbcc\\" print(find_unique_character(s)) # Output: \\"\\" s = \\"alphabet\\" print(find_unique_character(s)) # Output: \\"l\\" ``` **Hint**: You may use an auxiliary data structure to keep track of character frequencies and their positions.","solution":"def find_unique_character(s: str) -> str: Returns the first non-repeating character in the string. If no unique character exists, returns an empty string. char_count = {} for char in s: if char in char_count: char_count[char] += 1 else: char_count[char] = 1 for char in s: if char_count[char] == 1: return char return \'\'"},{"question":"# Sudoku Solver In this exercise, you are required to implement a Sudoku solver that uses backtracking to solve a 9x9 Sudoku puzzle. The goal is to verify students\' ability to understand recursion, backtracking, and constraint satisfaction problems. Task Implement the `SudokuSolver` class which can solve a given 9x9 Sudoku puzzle. # Function Signatures and Description ```python class SudokuSolver: def __init__(self, board: list[list[int]]): board : a 2D list representing a 9x9 Sudoku grid, where 0 represents empty cells. Initializes the SudokuSolver object with the given board. pass def solve(self) -> list[list[int]]: Solves the Sudoku puzzle using backtracking. Returns: A 2D list representing the solved Sudoku grid. pass def is_valid(self, num: int, pos: tuple[int, int]) -> bool: Checks whether placing num at the position pos (row, col) is valid. num : int, the number to be placed (1-9). pos : tuple, a pair (row, col) representing the position on the board. Returns: Boolean indicating whether the placement is valid. pass ``` # Constraints and Performance Requirements * The input board will be a list of nine lists, each containing nine integers in the range `[0, 9]`, specifically formatted to represent a Sudoku puzzle. * The Sudoku solver should modify the board in place, using backtracking, until the puzzle is solved. * The solver must validate that each number (1-9) appears only once per row, per column, and per 3x3 subgrid. * The time complexity acceptable for the solution should allow solving standard Sudoku puzzles (under normal difficulty) in a reasonable amount of time. # Example Usage ```python if __name__ == \\"__main__\\": puzzle = [ [5, 3, 0, 0, 7, 0, 0, 0, 0], [6, 0, 0, 1, 9, 5, 0, 0, 0], [0, 9, 8, 0, 0, 0, 0, 6, 0], [8, 0, 0, 0, 6, 0, 0, 0, 3], [4, 0, 0, 8, 0, 3, 0, 0, 1], [7, 0, 0, 0, 2, 0, 0, 0, 6], [0, 6, 0, 0, 0, 0, 2, 8, 0], [0, 0, 0, 4, 1, 9, 0, 0, 5], [0, 0, 0, 0, 8, 0, 0, 7, 9] ] solver = SudokuSolver(puzzle) solved_board = solver.solve() print(\\"Solved Sudoku board:\\") for row in solved_board: print(row) ``` # Scenarios to Consider 1. A nearly completed sudoku puzzle where only a few numbers are missing. 2. A completely empty sudoku grid. 3. A puzzle with multiple solutions to ensure the solver finds at least one valid solution. 4. Testing the solver for its ability to detect unsolvable grids and handle them gracefully.","solution":"class SudokuSolver: def __init__(self, board: list[list[int]]): board : a 2D list representing a 9x9 Sudoku grid, where 0 represents empty cells. Initializes the SudokuSolver object with the given board. self.board = board def solve(self) -> list[list[int]]: Solves the Sudoku puzzle using backtracking. Returns: A 2D list representing the solved Sudoku grid. self._solve_sudoku() return self.board def _solve_sudoku(self) -> bool: empty = self._find_empty_location() if not empty: return True row, col = empty for num in range(1, 10): if self.is_valid(num, (row, col)): self.board[row][col] = num if self._solve_sudoku(): return True self.board[row][col] = 0 return False def _find_empty_location(self) -> tuple[int, int] | None: for i in range(9): for j in range(9): if self.board[i][j] == 0: return (i, j) return None def is_valid(self, num: int, pos: tuple[int, int]) -> bool: Checks whether placing num at the position pos (row, col) is valid. num : int, the number to be placed (1-9). pos : tuple, a pair (row, col) representing the position on the board. Returns: Boolean indicating whether the placement is valid. # Check row for col in range(9): if self.board[pos[0]][col] == num: return False # Check column for row in range(9): if self.board[row][pos[1]] == num: return False # Check 3x3 box box_row_start = pos[0] // 3 * 3 box_col_start = pos[1] // 3 * 3 for i in range(box_row_start, box_row_start + 3): for j in range(box_col_start, box_col_start + 3): if self.board[i][j] == num: return False return True"},{"question":"# Coding Assessment Question Scenario You are building a scheduling system for a conference with multiple talks and limited rooms. Each talk is represented by a pair of integers (start_time, end_time), and your task is to determine the minimum number of rooms required to accommodate all the talks without any overlaps. Task Write a function named `min_rooms_needed` which takes a list of pairs of integers `schedule` representing the start and end times of each talk. Your function should return the minimum number of rooms required to ensure that no two talks overlap in the same room. # Function Signature ```python def min_rooms_needed(schedule: list[tuple[int, int]]) -> int: ``` # Input * `schedule` - A list of tuples where each tuple consists of two integers `(start_time, end_time)` representing the start and end times of a talk (1 <= len(schedule) <= 10^4, 0 <= start_time < end_time <= 10^4). # Output * An integer representing the minimum number of rooms required to schedule all talks without overlap. # Constraints * Start and end times are non-negative integers. * The schedule list can have overlapping time intervals that need to be handled efficiently. # Example ```python >>> min_rooms_needed([(1, 4), (2, 5), (3, 6)]) 3 >>> min_rooms_needed([(1, 3), (3, 5), (4, 6)]) 2 >>> min_rooms_needed([(7, 10), (1, 2), (2, 4), (5, 9)]) 2 ``` Performance Requirements Your implementation should be efficient enough to handle the upper limits of the constraints effectively. Consider edge cases such as overlapping schedules, as well as situations where no rooms are required or where all talks happen sequentially.","solution":"def min_rooms_needed(schedule): if not schedule: return 0 start_times = sorted([start for start, end in schedule]) end_times = sorted([end for start, end in schedule]) start_index = 0 end_index = 0 max_rooms = 0 rooms = 0 while start_index < len(start_times): if start_times[start_index] < end_times[end_index]: rooms += 1 start_index += 1 else: rooms -= 1 end_index += 1 max_rooms = max(max_rooms, rooms) return max_rooms"},{"question":"# Cache System with Time-Based Expiry and Auto-Purging Implement an advanced cache system called `TimeBasedCache` that stores key-value pairs and automatically purges expired entries based on a predefined expiry time. The cache should efficiently handle frequent accesses and provide accurate timing mechanisms to ensure the validity of the stored entries. Class Definition Your task is to implement the `TimeBasedCache` class with the following methods: - `put(key: str, value: any, ttl: int)`: Inserts a key-value pair into the cache with a specified TTL (time-to-live) in seconds. If the cache exceeds 50 elements, raise a `CacheFullError`. - `get(key: str) -> Any`: Retrieves the value associated with the key if it exists and has not expired. Raise a `KeyError` if the key does not exist or has expired. - `purge()`: Removes all expired entries from the cache. - `__str__() -> str`: Returns a string representation of all non-expired entries in the cache. Requirements: 1. The cache should handle up to 50 elements. 2. Each entry should have an associated TTL that determines its expiry. 3. The `purge()` method should be called periodically to clean up expired entries, maintaining performance and accuracy. 4. Implement edge case handling for full cache and expired entries. Constraints: - TTLs are positive integers representing seconds. - The cache should provide thread-safe access for concurrent operations. ```python import time import threading class CacheFullError(Exception): pass class TimeBasedCache: def __init__(self): self.cache = {} self.lock = threading.Lock() self.max_size = 50 self.cleaner_thread = threading.Thread(target=self._auto_purge, daemon=True) self.cleaner_thread.start() def put(self, key: str, value: any, ttl: int) -> None: with self.lock: current_time = time.time() expiry_time = current_time + ttl if len(self.cache) >= self.max_size: raise CacheFullError(\\"Cache is full\\") self.cache[key] = (value, expiry_time) def get(self, key: str) -> any: with self.lock: current_time = time.time() if key not in self.cache or self.cache[key][1] < current_time: raise KeyError(\\"Key not found or expired\\") return self.cache[key][0] def purge(self) -> None: with self.lock: current_time = time.time() keys_to_remove = [ key for key, (_, expiry) in self.cache.items() if expiry < current_time ] for key in keys_to_remove: del self.cache[key] def _auto_purge(self) -> None: while True: time.sleep(5) # Check for expired keys every 5 seconds self.purge() def __str__(self) -> str: with self.lock: current_time = time.time() non_expired_items = { key: value for key, (value, expiry) in self.cache.items() if expiry > current_time } return str(non_expired_items) # Example usage: # cache = TimeBasedCache() # cache.put(\'key1\', \'value1\', 10) # cache.put(\'key2\', \'value2\', 5) # time.sleep(6) # print(cache) # Should print only \'key1\' # assert cache.get(\'key1\') == \'value1\' # try: # cache.get(\'key2\') # except KeyError: # print(\\"key2 expired or not found\\") # cache.put(\'key3\', \'value3\', 20) # time.sleep(5) # cache.purge() # print(cache) # Should print both \'key1\' and \'key3\' ``` The above class definition outlines the necessary structure and methods. Ensure the cache appropriately manages timing, limits, and thread safety as described.","solution":"import time import threading class CacheFullError(Exception): pass class TimeBasedCache: def __init__(self): self.cache = {} self.lock = threading.Lock() self.max_size = 50 self.cleaner_thread = threading.Thread(target=self._auto_purge, daemon=True) self.cleaner_thread.start() def put(self, key: str, value: any, ttl: int) -> None: with self.lock: current_time = time.time() expiry_time = current_time + ttl if len(self.cache) >= self.max_size: raise CacheFullError(\\"Cache is full\\") self.cache[key] = (value, expiry_time) def get(self, key: str) -> any: with self.lock: current_time = time.time() if key not in self.cache or self.cache[key][1] < current_time: raise KeyError(\\"Key not found or expired\\") return self.cache[key][0] def purge(self) -> None: with self.lock: current_time = time.time() keys_to_remove = [ key for key, (_, expiry) in self.cache.items() if expiry < current_time ] for key in keys_to_remove: del self.cache[key] def _auto_purge(self) -> None: while True: time.sleep(5) # Check for expired keys every 5 seconds self.purge() def __str__(self) -> str: with self.lock: current_time = time.time() non_expired_items = { key: value for key, (value, expiry) in self.cache.items() if expiry > current_time } return str(non_expired_items)"},{"question":"# Finding the Longest Increasing Subsequence **Context:** You are required to implement a function that helps manage a sequence of tasks by finding the longest increasing sequence based on their difficulty levels. The tasks are given with unique difficulty levels and you need to identify the subsequence where each subsequent task is of higher difficulty than the previous one. **Problem Statement:** Implement a function `longest_increasing_subsequence(tasks)` that receives: 1. A list of task difficulty levels represented as integers. Your function should output the length of the longest increasing subsequence of tasks. **Function Signature:** ```python def longest_increasing_subsequence(tasks: List[int]) -> int: pass ``` **Input:** - `tasks`: A list of integers representing task difficulty levels. **Output:** - An integer representing the length of the longest increasing subsequence. **Constraints:** - The length of the list `tasks` is at most 1000. - All values in the `tasks` list are unique. **Example:** ```python # Example input tasks = [10, 22, 9, 33, 21, 50, 41, 60, 80] # Example output 6 ``` **Notes:** - Your implementation should consider only strictly increasing subsequences. - Ensure that your solution efficiently handles the input size constraint. In the given example, the longest increasing subsequence is `[10, 22, 33, 50, 60, 80]`, which has a length of 6.","solution":"from typing import List def longest_increasing_subsequence(tasks: List[int]) -> int: if not tasks: return 0 n = len(tasks) lis = [1] * n for i in range(1, n): for j in range(i): if tasks[i] > tasks[j]: lis[i] = max(lis[i], lis[j] + 1) return max(lis)"},{"question":"# Context: You are given an implementation of a binary search tree (BST) that supports basic operations like insertion and search. The task is to extend the functionality of this BST to support additional operations that are often required in practical scenarios. # Problem: 1. Write a method `find_kth_smallest(self, k)` that returns the k-th smallest element in the BST. Ensure your implementation is efficient. 2. Write a method `range_sum(self, low, high)` that returns the sum of all elements in the BST that fall within the inclusive range `[low, high]`. # Implementation Details: - Class definition: `class ExtendedBinarySearchTree(BinarySearchTree):` - Methods to implement: * `def find_kth_smallest(self, k):` * `def range_sum(self, low, high):` # Input: - `find_kth_smallest(self, k)` takes a single parameter: * `k` (int): The position of the smallest element to find. - `range_sum(self, low, high)` takes two parameters: * `low` (int): The lower bound of the range. * `high` (int): The upper bound of the range. # Output: - `find_kth_smallest(self, k)` will return the k-th smallest element in the BST. - `range_sum(self, low, high)` will return the sum of the elements within the range `[low, high]`. # Constraints: - You can assume the BST contains unique elements. - k is a valid integer such that 1 ≤ k ≤ number of elements in the BST. - `low` and `high` are integers where `low ≤ high`. # Performance Requirements: - `find_kth_smallest(self, k)` should have an average time complexity of O(h + k), where h is the height of the tree. - `range_sum(self, low, high)` should have an average time complexity of O(n), where n is the number of elements in the BST. # Example Usage: ```python bst = ExtendedBinarySearchTree() bst.insert(20) bst.insert(10) bst.insert(30) bst.insert(5) bst.insert(15) # Finding the k-th smallest element print(bst.find_kth_smallest(3)) # Output: 15 # Calculating the range sum print(bst.range_sum(10, 30)) # Output: 75 ```","solution":"class TreeNode: def __init__(self, key): self.left = None self.right = None self.val = key self.size = 1 # Initialize size of the subtree for each node class ExtendedBinarySearchTree: def __init__(self): self.root = None def insert(self, key): self.root = self._insert(self.root, key) def _insert(self, node, key): if not node: return TreeNode(key) if key < node.val: node.left = self._insert(node.left, key) else: node.right = self._insert(node.right, key) node.size = 1 + self._size(node.left) + self._size(node.right) return node def _size(self, node): if node is None: return 0 return node.size def find_kth_smallest(self, k): return self._find_kth_smallest(self.root, k) def _find_kth_smallest(self, node, k): if not node: return None left_size = self._size(node.left) if k == left_size + 1: return node.val elif k <= left_size: return self._find_kth_smallest(node.left, k) else: return self._find_kth_smallest(node.right, k - left_size - 1) def range_sum(self, low, high): return self._range_sum(self.root, low, high) def _range_sum(self, node, low, high): if not node: return 0 total = 0 if node.val >= low: total += self._range_sum(node.left, low, high) if low <= node.val <= high: total += node.val if node.val <= high: total += self._range_sum(node.right, low, high) return total"},{"question":"# Question You are given two arrays `arr1` and `arr2` of integers. Your task is to find the length of the longest subarray that appears in both arrays. # Function Signature ```python def find_length(arr1: list, arr2: list) -> int: ``` # Input * `arr1` and `arr2` are lists of integers where `1 <= len(arr1), len(arr2) <= 1000`. # Output * The function should return an integer representing the length of the longest common subarray. # Constraints * The elements of `arr1` and `arr2` are integers. * Both arrays will have at least one element. # Examples ```python # Example 1 arr1 = [1, 2, 3, 2, 1] arr2 = [3, 2, 1, 4, 7] print(find_length(arr1, arr2)) # Output: 3 # Example 2 arr1 = [0, 1, 2, 3, 4] arr2 = [2, 3, 4, 5, 6] print(find_length(arr1, arr2)) # Output: 3 # Example 3 arr1 = [1, 1, 1, 1] arr2 = [1, 1, 1, 1] print(find_length(arr1, arr2)) # Output: 4 # Example 4 arr1 = [1, 2, 3] arr2 = [4, 5, 6] print(find_length(arr1, arr2)) # Output: 0 # Example 5 arr1 = [] arr2 = [1, 2, 3] print(find_length(arr1, arr2)) # Output: 0 ``` # Explanation * In **Example 1**, the longest common subarray is `[3, 2, 1]` which has a length of 3. * In **Example 2**, the longest common subarray is `[2, 3, 4]` which has a length of 3. * In **Example 3**, both arrays are identical so the longest common subarray is the entire array `[1, 1, 1, 1]` with length 4. * In **Example 4**, there is no common subarray, so the length is 0. * In **Example 5**, one of the arrays is empty; hence, the longest common subarray length is 0 even though the other array has elements. # Additional Information * Use dynamic programming to efficiently find the solution with a time complexity of `O(n * m)` where `n` and `m` are the lengths of `arr1` and `arr2`, respectively. * Consider edge cases such as arrays with no common elements and arrays with repeated elements.","solution":"def find_length(arr1: list, arr2: list) -> int: dp = [[0] * (len(arr2) + 1) for _ in range(len(arr1) + 1)] max_length = 0 for i in range(1, len(arr1) + 1): for j in range(1, len(arr2) + 1): if arr1[i - 1] == arr2[j - 1]: dp[i][j] = dp[i - 1][j - 1] + 1 max_length = max(max_length, dp[i][j]) return max_length"},{"question":"# Question: Implementing a Dijkstra-Based Shortest Path Finder You are provided with a function to find the shortest path in a weighted graph using Dijkstra\'s algorithm. Your task is to implement the `shortest_path` function as described below: Function Signature ```python def shortest_path(num_nodes: int, edges: List[Tuple[int, int, int]], start_node: int, end_node: int) -> List[int]: ``` Inputs 1. `num_nodes`: The total number of nodes in the graph. 2. `edges`: A list of tuples representing the edges in the graph, where each tuple is of the form `(u, v, w)` indicating an edge from node `u` to node `v` with weight `w`. 3. `start_node`: The starting node for the path. 4. `end_node`: The destination node for the path. Outputs 1. `path`: A list of integers representing the nodes in the shortest path from `start_node` to `end_node`, including the start and end nodes themselves. Constraints - Each node is numbered from `0` to `num_nodes-1`. - If there are multiple shortest paths, return any one of them. - The graph is guaranteed to be connected, and all edge weights are non-negative. # Context You are working on a navigation system that computes the shortest route between two locations represented as nodes in a graph. Implementing Dijkstra\'s algorithm will allow you to efficiently find the shortest path between any two nodes while considering the weights of the edges. Example ```python num_nodes = 5 edges = [ (0, 1, 10), (0, 2, 3), (1, 2, 1), (1, 3, 2), (2, 1, 4), (2, 3, 8), (2, 4, 2), (3, 4, 7), (4, 3, 9) ] start_node = 0 end_node = 4 path = shortest_path(num_nodes, edges, start_node, end_node) # Output: [0, 2, 4] ``` In the above example, the shortest path from node `0` to node `4` in the given graph can be `[0, 2, 4]` with a total weight of `5`. Ensure that your function returns the correct path by following Dijkstra\'s algorithm.","solution":"from typing import List, Tuple import heapq def shortest_path(num_nodes: int, edges: List[Tuple[int, int, int]], start_node: int, end_node: int) -> List[int]: # Create the adjacency list adj_list = [[] for _ in range(num_nodes)] for u, v, w in edges: adj_list[u].append((v, w)) adj_list[v].append((u, w)) # Assuming undirected graph # Dijkstra\'s algorithm distances = [float(\'inf\')] * num_nodes previous_nodes = [None] * num_nodes distances[start_node] = 0 min_heap = [(0, start_node)] # (distance, node) while min_heap: current_distance, current_node = heapq.heappop(min_heap) if current_distance > distances[current_node]: continue for neighbor, weight in adj_list[current_node]: distance = current_distance + weight if distance < distances[neighbor]: distances[neighbor] = distance previous_nodes[neighbor] = current_node heapq.heappush(min_heap, (distance, neighbor)) # Reconstructing the path path = [] current = end_node while current is not None: path.append(current) current = previous_nodes[current] path.reverse() return path"},{"question":"# Problem Statement You are given a string representing a mathematical expression containing single-digit numbers and basic operators (+, -, *, /). Your task is to evaluate this expression according to the order of operations (also known as BODMAS/BIDMAS rules). The expression may contain spaces, which you should ignore. You will need to parse and compute the result using a stack-based approach, ensuring that your implementation properly handles the hierarchy of operations. # Function Signature ```python def evaluate_expression(expression: str) -> int: ``` # Input Format * A single argument: `expression` (string) - a string representing the mathematical expression. The string may include: - Single-digit integers (0-9). - Operators (+, -, *, /). - Spaces. # Output Format * Return an integer - the result of evaluating the expression. # Constraints * The length of `expression` will be between 1 and 100 inclusive. * The input expression is guaranteed to be valid and will not result in division by zero. # Example ```python Input evaluate_expression(\\"3 + 5 * 2\\") Output 13 ``` ```python Input evaluate_expression(\\"(1 + 2) * 3\\") Output 9 ``` # Notes * You must properly handle edge cases, such as expressions with multiple spaces or different levels of nested parentheses. * Ensure the implementation correctly respects the order of operations. * Avoid using Python\'s `eval` function for security reasons and to ensure the robustness of your solution. # Implementation Advice * Use a stack to keep track of numbers and operators. * Implement a helper function to perform operations based on operator precedence. * Carefully manage parentheses to ensure expressions within them are evaluated first. * Consider edge cases such as consecutive operators and invalid characters. This question is designed to test your understanding of parsing strings, implementing basic arithmetic operations, and applying stack-based solutions to maintain the correct order of operations.","solution":"def evaluate_expression(expression: str) -> int: def apply_operator(operators, values): operator = operators.pop() right = values.pop() left = values.pop() if operator == \'+\': values.append(left + right) elif operator == \'-\': values.append(left - right) elif operator == \'*\': values.append(left * right) elif operator == \'/\': values.append(left // right) def precedence(op): if op == \'+\' or op == \'-\': return 1 if op == \'*\' or op == \'/\': return 2 return 0 operators = [] values = [] i = 0 while i < len(expression): if expression[i] == \' \': i += 1 continue elif expression[i] == \'(\': operators.append(expression[i]) elif expression[i].isdigit(): val = 0 while (i < len(expression) and expression[i].isdigit()): val = (val * 10) + int(expression[i]) i += 1 values.append(val) i -= 1 elif expression[i] == \')\': while len(operators) != 0 and operators[-1] != \'(\': apply_operator(operators, values) operators.pop() else: while (len(operators) != 0 and precedence(operators[-1]) >= precedence(expression[i])): apply_operator(operators, values) operators.append(expression[i]) i += 1 while len(operators) != 0: apply_operator(operators, values) return values[-1]"},{"question":"# Problem Statement You are tasked with implementing a function that calculates the Body Mass Index (BMI) of an individual given their weight and height. BMI is a measure of body fat based on an individual\'s weight in kilograms and height in meters. Your function should return the BMI using the following formula: [ BMI = frac{weight}{height^2} ] where: - `weight` is the weight in kilograms and must be a positive value. - `height` is the height in meters and must be a positive value. Your implementation should account for invalid inputs by raising an appropriate exception with a clear error message. # Function Signature ```python def calculate_bmi(weight: float, height: float) -> float: pass ``` # Input - `weight` (float): Weight in kilograms (positive). - `height` (float): Height in meters (positive). # Output - `float`: BMI value of the individual. # Constraints - The weight (`weight`) must be > 0. - The height (`height`) must be > 0. # Example ```python >>> calculate_bmi(70, 1.75) 22.857142857142858 >>> calculate_bmi(60, 1.65) 22.03856749311295 ``` # Notes - You may assume all inputs will be valid floats. - Handle edge cases such as weight being less than or equal to 0 or height being less than or equal to 0 by raising a `ValueError` with appropriate error messages. # Requirements - Complete the function `calculate_bmi` with the above constraints and details.","solution":"def calculate_bmi(weight: float, height: float) -> float: Calculate the Body Mass Index (BMI) given the weight in kilograms and height in meters. Parameters: - weight (float): The weight of the individual in kilograms (must be positive). - height (float): The height of the individual in meters (must be positive). Returns: - float: The BMI of the individual. Raises: - ValueError: If weight or height are not positive values. if weight <= 0: raise ValueError(\\"Weight must be a positive value.\\") if height <= 0: raise ValueError(\\"Height must be a positive value.\\") return weight / (height ** 2)"},{"question":"# Coding Assessment Question Scenario You have been hired to work on a project that involves string manipulation techniques to enhance text processing capabilities in a data analysis system. One of the pending tasks is to implement and verify a function to reverse the order of words in a given string. # Objective Implement the `reverse_words` function that returns a string with the words in reverse order. Words are defined as sequences of characters separated by spaces. # Function Signature ```python def reverse_words(sentence: str) -> str: pass ``` # Constraints - The function should handle empty strings and strings with multiple spaces between words. - Do not use any built-in reverse functions or methods. - Ensure that leading, trailing, and multiple spaces between words are preserved in the output. # Input - `sentence` (str): A sentence where words need to be reversed. # Output - (str): A string with words in reversed order. # Examples ```python assert reverse_words(\\"Hello world\\") == \\"world Hello\\" assert reverse_words(\\"The quick brown fox\\") == \\"fox brown quick The\\" assert reverse_words(\\" This is a test \\") == \\" test a is This \\" assert reverse_words(\\"\\") == \\"\\" assert reverse_words(\\"Single\\") == \\"Single\\" ``` # Implementation Details 1. Implement the `reverse_words` function such that it adheres to the specified behavior and constraints. 2. Develop a comprehensive test suite `test_reverse_words()` to ensure the function handles all edge cases, including multiple spaces and empty input strings.","solution":"def reverse_words(sentence: str) -> str: Returns the given sentence with words in reversed order, preserving leading, trailing, and multiple spaces between words. # Split the sentence based on spaces without stripping leading/trailing spaces words = sentence.split(\' \') # Reverse the list of words reversed_words = words[::-1] # Join the reversed list to form the new sentence reversed_sentence = \' \'.join(reversed_words) return reversed_sentence"},{"question":"# Problem: Polygon Perimeter Calculation System Your task is to design a perimeter calculation system that integrates various geometric perimeter calculation functions into a unified module. The goal is to develop functions for each of these shapes, ensuring proper input validation, and efficient computation while adhering to geometric formulas. Task Requirements: 1. **Function Signature**: - Implement functions corresponding to each of the following shapes: * Triangle * Rectangle * Square * Pentagon * Hexagon * Heptagon * Octagon * Nonagon * Decagon - The function names should be prefixed with `perim_` followed by the shape name (e.g., `perim_triangle`). 2. **Input and Output**: - The shape functions should accept `float` values and return the perimeter as a `float`. - If invalid values are provided (e.g. negative dimensions), the function should raise a `ValueError` with an appropriate message. 3. **Constraints**: - All inputs must be non-negative floats or integers. - For regular polygons (Pentagon, Hexagon, Heptagon, Octagon, Nonagon, Decagon), provide the length of one side. 4. **Performance Requirements**: - Ensure that the functions run in constant time O(1) and use constant space O(1). Example Functions: 1. **Triangle Perimeter** ```python def perim_triangle(side1: float, side2: float, side3: float) -> float: if side1 < 0 or side2 < 0 or side3 < 0: raise ValueError(\\"perim_triangle() only accepts non-negative values\\") return side1 + side2 + side3 ``` 2. **Rectangle Perimeter** ```python def perim_rectangle(length: float, width: float) -> float: if length < 0 or width < 0: raise ValueError(\\"perim_rectangle() only accepts non-negative values\\") return 2 * (length + width) ``` 3. **Square Perimeter** ```python def perim_square(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_square() only accepts non-negative values\\") return 4 * side_length ``` Test Your Functions: Ensure to cover the following cases in your tests: - Typical valid inputs showing correct perimeter calculations. - Boundary inputs like zero dimensions. - Invalid inputs like negative dimensions raising appropriate errors. Provide at least one test example for each perimeter calculation function in the form of `assert` statements to validate their behavior. Example: ```python # Testing perim_triangle assert perim_triangle(3, 4, 5) == 12 assert perim_triangle(0, 0, 0) == 0 try: perim_triangle(-1, 2, 3) except ValueError as e: assert str(e) == \\"perim_triangle() only accepts non-negative values\\" # Testing perim_rectangle assert perim_rectangle(3, 4) == 14 assert perim_rectangle(0, 0) == 0 try: perim_rectangle(-1, 2) except ValueError as e: assert str(e) == \\"perim_rectangle() only accepts non-negative values\\" ```","solution":"def perim_triangle(side1: float, side2: float, side3: float) -> float: if side1 < 0 or side2 < 0 or side3 < 0: raise ValueError(\\"perim_triangle() only accepts non-negative values\\") return side1 + side2 + side3 def perim_rectangle(length: float, width: float) -> float: if length < 0 or width < 0: raise ValueError(\\"perim_rectangle() only accepts non-negative values\\") return 2 * (length + width) def perim_square(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_square() only accepts non-negative values\\") return 4 * side_length def perim_pentagon(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_pentagon() only accepts non-negative values\\") return 5 * side_length def perim_hexagon(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_hexagon() only accepts non-negative values\\") return 6 * side_length def perim_heptagon(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_heptagon() only accepts non-negative values\\") return 7 * side_length def perim_octagon(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_octagon() only accepts non-negative values\\") return 8 * side_length def perim_nonagon(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_nonagon() only accepts non-negative values\\") return 9 * side_length def perim_decagon(side_length: float) -> float: if side_length < 0: raise ValueError(\\"perim_decagon() only accepts non-negative values\\") return 10 * side_length"},{"question":"# Problem Statement: You are given a string containing an arithmetic expression in infix notation. The expression will only contain integers, \'+\', \'-\', \'*\', \'/\', and parentheses. Your task is to evaluate the expression and return the result as an integer. To solve this problem, you must do the following: 1. Parse the infix expression. 2. Convert it to postfix notation (Reverse Polish Notation). 3. Evaluate the postfix expression to get the result. # Function Signature: ```python def evaluate_expression(expression: str) -> int: pass ``` # Parameters: - `expression` (str): A string representing the arithmetic expression in infix notation. # Returns: - `int`: The result of evaluating the arithmetic expression. # Constraints: - The expression will only contain non-negative integers and the operators \'+\', \'-\', \'*\', \'/\', and parentheses. - The result of the expression will always be an integer. - The expression is guaranteed to be valid. # Example: ```python assert evaluate_expression(\\"3+(2*2)\\") == 7 assert evaluate_expression(\\" 3/2 \\") == 1 assert evaluate_expression(\\" 3+5 / 2 \\") == 5 ``` **Note:** - Apply the correct operator precedence and associativity rules when parsing and evaluating the expression. - Ensure the function handles edge cases such as whitespace within the expression and division by zero appropriately. In case of a division by zero, you can assume the function shall not encounter such scenarios as per the input constraints. # Performance Requirements: - The solution should be efficient and handle typical constraints within reasonable time and space limits. Consider O(n) time complexity for parsing and evaluating the expression, where n is the length of the input string.","solution":"def evaluate_expression(expression: str) -> int: def precedence(op): if op in (\'+\', \'-\'): return 1 if op in (\'*\', \'/\'): return 2 return 0 def apply_op(a, b, op): if op == \'+\': return a + b if op == \'-\': return a - b if op == \'*\': return a * b if op == \'/\': return a // b def infix_to_postfix(expression): stack = [] postfix = [] i = 0 while i < len(expression): if expression[i].isdigit(): num = 0 while i < len(expression) and expression[i].isdigit(): num = num * 10 + int(expression[i]) i += 1 postfix.append(num) i -= 1 elif expression[i] == \'(\': stack.append(expression[i]) elif expression[i] == \')\': while stack and stack[-1] != \'(\': postfix.append(stack.pop()) stack.pop() else: while stack and precedence(stack[-1]) >= precedence(expression[i]): postfix.append(stack.pop()) stack.append(expression[i]) i += 1 while stack: postfix.append(stack.pop()) return postfix def evaluate_postfix(tokens): stack = [] for token in tokens: if isinstance(token, int): stack.append(token) else: b = stack.pop() a = stack.pop() stack.append(apply_op(a, b, token)) return stack[0] expression = expression.replace(\\" \\", \\"\\") postfix = infix_to_postfix(expression) return evaluate_postfix(postfix)"},{"question":"# Coding Assessment Question **Scenario**: You are working as a software developer, and your team is implementing various geometric algorithms. One algorithm heavily used in computer graphics deals with determining if a point lies inside a convex polygon. Your task is to implement this algorithm efficiently. **Problem Statement**: Implement a function `is_point_inside_polygon()` that determines if a given point lies inside a convex polygon. The polygon is represented as a list of points, each point being a tuple of two integers. The point to be checked is also a tuple of two integers. Function Signature ```python def is_point_inside_polygon(polygon: list[tuple[int, int]], point: tuple[int, int]) -> bool: # Implementation here ``` Input & Output Formats - **Input**: - A list of tuples `polygon` where each tuple represents a vertex of the convex polygon in clockwise or counter-clockwise order. The number of vertices (n) is such that (3 leq n leq 100). Each coordinate value ranges from (-10^3 leq x, y leq 10^3). - A tuple of two integers `point` representing the point to check, where each coordinate ranges from (-10^3 leq x, y leq 10^3). - **Output**: A boolean value `True` if the point lies inside the polygon (including on the boundary), otherwise `False`. Constraints - The polygon is always convex. - Use computational geometry principles to achieve accurate results. Examples ```python >>> is_point_inside_polygon([(0, 0), (4, 0), (4, 4), (0, 4)], (2, 2)) True >>> is_point_inside_polygon([(0, 0), (4, 0), (4, 4), (0, 4)], (5, 5)) False >>> is_point_inside_polygon([(0, 0), (4, 0), (4, 4), (0, 4)], (4, 2)) True >>> is_point_inside_polygon([(1, 1), (3, 0), (4, 2), (2, 4)], (2, 2)) True >>> is_point_inside_polygon([(1, 1), (3, 0), (4, 2), (2, 4)], (5, 5)) False ``` **Note**: Ensure your implementation handles edge cases such as points exactly on the boundary of the polygon effectively. Utilize computational geometry techniques to ensure precision and correctness.","solution":"def is_point_inside_polygon(polygon: list[tuple[int, int]], point: tuple[int, int]) -> bool: def cross_product(o, a, b): Cross product of vectors OA and OB A positive cross product indicates a counter-clockwise turn, and a negative cross product indicates a clockwise turn. return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0]) n = len(polygon) prev_cross = None for i in range(n): a = polygon[i] b = polygon[(i + 1) % n] cross = cross_product(a, b, point) if cross == 0: # Point is on the boundary. # Check if point is within the segment bounds if min(a[0], b[0]) <= point[0] <= max(a[0], b[0]) and min(a[1], b[1]) <= point[1] <= max(a[1], b[1]): return True else: return False if prev_cross is None: prev_cross = cross elif (cross > 0 and prev_cross < 0) or (cross < 0 and prev_cross > 0): return False prev_cross = cross return True"},{"question":"# Question: Implement a Word Break Validator Given a non-empty string `s` and a dictionary containing a list of non-empty words, determine if `s` can be segmented into a space-separated sequence of one or more dictionary words. Implement a function that takes a string and a list of words, and returns whether the string can be segmented into a sequence of one or more dictionary words. Function Signature ```python def word_break(s: str, wordDict: list[str]) -> bool: ``` # Input * `s`: A non-empty string consisting of lowercase English letters (1 ≤ |s| ≤ 10^4). * `wordDict`: A list of non-empty strings consisting of lowercase English letters (1 ≤ |wordDict| ≤ 10^3 and 1 ≤ |word| in wordDict ≤ 20). # Output * A boolean value `True` if the string can be segmented, `False` otherwise. # Constraints * Ensure your solution is efficient in terms of both time and space complexity, focusing on optimizing the segmentation check. # Example ```python word_break(\\"leetcode\\", [\\"leet\\", \\"code\\"]) # Returns: True word_break(\\"applepenapple\\", [\\"apple\\", \\"pen\\"]) # Returns: True word_break(\\"catsandog\\", [\\"cats\\", \\"dog\\", \\"sand\\", \\"and\\", \\"cat\\"]) # Returns: False ``` # Additional Information * Consider dynamic programming or other efficient techniques to solve this problem. * Make sure to handle edge cases such as an empty string `s` or an empty `wordDict`.","solution":"def word_break(s: str, wordDict: list[str]) -> bool: Determine if string `s` can be segmented into a sequence of one or more dictionary words. word_set = set(wordDict) dp = [False] * (len(s) + 1) dp[0] = True # Base case: an empty string can be segmented for i in range(1, len(s) + 1): for j in range(i): if dp[j] and s[j:i] in word_set: dp[i] = True break return dp[len(s)]"},{"question":"# Coding Assessment Question: Clustering with K-Means and Hierarchical Clustering Context A company dealing with customer data wants to run clustering algorithms to segment their customer base for better-targeted marketing strategies. They plan to use two popular clustering methods: K-Means and Hierarchical Clustering. As a data scientist, you need to implement these algorithms to group similar customers based on their features. Problem Specification You are provided a dataset `data` in the form of a 2D Numpy array where each row represents a sample and each column represents a feature. You need to implement K-Means and Hierarchical Clustering based on the given requirements. Task 1. **Implement K-Means Clustering Function**: * Function name: `k_means_clustering` * Input: * `data` (np.ndarray): A 2D array of shape ((n, m)) where (n) is the number of samples and (m) is the number of features. * `k` (int): The number of clusters to form. * `max_iterations` (int): The maximum number of iterations for the algorithm to run. * Output: * Tuple: * `centroids` (np.ndarray): A 2D array of shape ((k, m)) representing the cluster centroids. * `labels` (np.ndarray): A 1D array of shape ((n, )) representing the cluster assignment for each sample. * Constraints: * `k` must be less than or equal to (n). 2. **Implement Hierarchical Clustering Function**: * Function name: `hierarchical_clustering` * Input: * `data` (np.ndarray): A 2D array of shape ((n, m)) where (n) is the number of samples and (m) is the number of features. * `num_clusters` (int): The number of clusters to form. * Output: * (np.ndarray): A 1D array of shape ((n, )) representing the cluster assignment for each sample. * Constraints: * `num_clusters` must be less than or equal to (n). Sample Inputs and Outputs # K-Means Clustering Example ```python data = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]]) k = 2 max_iterations = 100 centroids, labels = k_means_clustering(data, k, max_iterations) assert centroids.shape == (k, data.shape[1]) assert labels.shape == (data.shape[0],) ``` # Hierarchical Clustering Example ```python data = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]]) num_clusters = 2 labels = hierarchical_clustering(data, num_clusters) assert labels.shape == (data.shape[0],) ``` Performance Requirements * Your implementation should handle large datasets efficiently. * Utilize vectorized operations using numpy for better performance. Additional Instructions * For K-Means, initialize the centroids randomly from the data points. * For Hierarchical Clustering, use the Agglomerative Clustering method with a linkage criterion of your choice. Provide your implementations for the functions within the specified constraints and test them with the sample inputs provided.","solution":"import numpy as np from scipy.cluster.hierarchy import linkage, fcluster def k_means_clustering(data, k, max_iterations=100): np.random.seed(0) n_samples = data.shape[0] initial_indices = np.random.choice(n_samples, k, replace=False) centroids = data[initial_indices] for _ in range(max_iterations): distances = np.linalg.norm(data[:, np.newaxis] - centroids, axis=2) labels = np.argmin(distances, axis=1) new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)]) if np.all(centroids == new_centroids): break centroids = new_centroids return centroids, labels def hierarchical_clustering(data, num_clusters): Z = linkage(data, method=\'ward\') labels = fcluster(Z, num_clusters, criterion=\'maxclust\') return labels - 1 # Adjusting label to start from 0 to k-1"},{"question":"Implement a Scheduler for Frequency-based Tasks Using a Priority Queue Description You are given a list of tasks, each characterized by a name and a frequency which indicates how often the task needs to be performed within a given timeframe. Implement a function that uses a priority queue to schedule these tasks based on their frequency. The function should return an order of execution that adheres to these frequencies as closely as possible. Function Signature ```python def schedule_tasks(tasks: list[tuple[str, int]]) -> list[str]: pass ``` Input 1. `tasks` (list of tuples): A list of tasks where each task is represented as a tuple containing the task name (str) and its frequency (int). Output - Returns a list of task names in the order they should be executed. Constraints 1. Each task\'s frequency will be a positive integer. 2. The number of tasks will not exceed 1,000. 3. Task names will be unique and will contain only alphanumeric characters. 4. Handle up to 1,000 total execution steps reasonably within performance constraints. Example ```python tasks = [(\'A\', 3), (\'B\', 2), (\'C\', 5), (\'D\', 1)] result = schedule_tasks(tasks) print(result) # Expected output: # [\'C\', \'A\', \'B\', \'C\', \'A\', \'C\', \'B\', \'C\', \'A\', \'C\', \'D\', \'C\'] # Note: The exact order might vary as long as task frequencies are respected closely. ``` Performance Requirements - Implement the scheduling such that frequent tasks are executed according to their specified frequency while managing less frequent tasks within a feasible schedule. Note - Consider utilizing a priority queue to efficiently manage task scheduling based on their frequencies. - Ensure that each task is scheduled in a way that the more frequent tasks get appropriately spaced, without strictly adhering to rigid intervals. - Provide thorough test cases to demonstrate the correctness and efficiency of your implementation.","solution":"import heapq def schedule_tasks(tasks): Schedule the given tasks based on their frequency using a priority queue. Parameters: tasks (list(tuple(str, int))): list of (task_name, frequency) Returns: list(str): the scheduled order of tasks max_heap = [] # Use a max heap where frequency is negative for priority on max frequency for task_name, frequency in tasks: heapq.heappush(max_heap, (-frequency, task_name)) schedule = [] while max_heap: # Temp storage for current round to avoid immediate re-insertion temp = [] for _ in range(min(len(max_heap), 2)): if max_heap: freq, task = heapq.heappop(max_heap) schedule.append(task) if -freq > 1: temp.append((freq + 1, task)) # decrease frequency for the next round for item in temp: heapq.heappush(max_heap, item) return schedule"},{"question":"# Coding Assessment Question Context You are developing a simple text editor with a feature that automatically formats text into paragraphs of a given maximum width. Each word should be separated by a single space, and lines should be left-justified. Objective Write a function that formats a given list of words into a paragraph, with each line containing as many words as possible without exceeding a given maximum width. The final line should have left justification. Requirements 1. Implement the function `format_paragraph(words: list[str], max_width: int) -> list[str]` which takes a list of words and an integer representing the maximum width of a line. 2. Ensure the function correctly handles multiple words, spaces, and the width constraint to format the paragraph. 3. If a single word exceeds the maximum width, it should be placed on a new line by itself. Constraints * All words in the input list are valid strings and are non-empty. * All words are separated by a single space. * The `max_width` is a positive integer. Examples ```python def format_paragraph(words: list[str], max_width: int) -> list[str]: # Your implementation here pass # Example usage and results assert format_paragraph([\\"This\\", \\"is\\", \\"a\\", \\"sample\\", \\"paragraph\\", \\"formatted\\", \\"into\\", \\"multiple\\", \\"lines\\"], 10) == [ \\"This is a\\", \\"sample\\", \\"paragraph\\", \\"formatted\\", \\"into\\", \\"multiple\\", \\"lines\\" ] assert format_paragraph([\\"Here\\", \\"is\\", \\"another\\", \\"example\\", \\"with\\", \\"even\\", \\"more\\", \\"words\\", \\"to\\", \\"check\\", \\"alignment\\"], 15) == [ \\"Here is another\\", \\"example with\\", \\"even more words\\", \\"to check\\", \\"alignment\\" ] assert format_paragraph([\\"LongWordExceedsWidth\\"], 5) == [ \\"LongWordExceedsWidth\\" ] assert format_paragraph([], 10) == [] ``` Notes: * The function should prioritize filling each line to its maximum capacity without breaking words. * The final line should be left-justified with no additional spaces at the end.","solution":"def format_paragraph(words: list[str], max_width: int) -> list[str]: Formats a list of words into a paragraph of lines, each with a maximum width of max_width. Args: words (list of str): The list of words to format. max_width (int): The maximum width of each line. Returns: list of str: The formatted paragraph as a list of lines. if not words: return [] lines = [] current_line = [] for word in words: if not current_line or len(\\" \\".join(current_line + [word])) <= max_width: current_line.append(word) else: lines.append(\\" \\".join(current_line)) current_line = [word] if current_line: lines.append(\\" \\".join(current_line)) return lines"},{"question":"# Question: Implement a Sudoku Solver You need to implement a class `SudokuSolver` that can solve any given Sudoku puzzle. Your implementation should follow the standards below: Class: `SudokuSolver` Methods: 1. **`is_valid(self, board: List[List[int]], row: int, col: int, num: int) -> bool`**: * Input: The Sudoku board (9x9 grid represented as a list of lists), a row index, a column index, and a number. * Output: A boolean indicating whether the number can be placed at the given row and column without violating Sudoku rules. * Example: `SudokuSolver().is_valid(board, 0, 0, 5)` should return `True` or `False` based on the board\'s state. 2. **`solve_sudoku(self, board: List[List[int]]) -> bool`**: * Input: The Sudoku board (9x9 grid represented as a list of lists) with some cells filled with numbers and others filled with 0. * Output: A boolean indicating whether the board was solved successfully. The method should modify the board in place. * Example: `SudokuSolver().solve_sudoku(board)` should return `True` if the Sudoku was solved and modify the board to the solved state. Constraints: * The input board will always be a 9x9 grid. * The board will contain numbers between 0 and 9, where 0 represents an empty cell. * There will always be at least one possible solution for the Sudoku provided. ```python from typing import List class SudokuSolver: def __init__(self) -> None: pass def is_valid(self, board: List[List[int]], row: int, col: int, num: int) -> bool: # Check if num is absent in the row for i in range(9): if board[row][i] == num: return False # Check if num is absent in the column for i in range(9): if board[i][col] == num: return False # Check if num is absent in the 3x3 sub-grid start_row, start_col = 3 * (row // 3), 3 * (col // 3) for i in range(3): for j in range(3): if board[start_row + i][start_col + j] == num: return False return True def solve_sudoku(self, board: List[List[int]]) -> bool: for row in range(9): for col in range(9): if board[row][col] == 0: for num in range(1, 10): if self.is_valid(board, row, col, num): board[row][col] = num if self.solve_sudoku(board): return True board[row][col] = 0 return False return True # Example Usage: # board = [ # [5, 3, 0, 0, 7, 0, 0, 0, 0], # [6, 0, 0, 1, 9, 5, 0, 0, 0], # [0, 9, 8, 0, 0, 0, 0, 6, 0], # [8, 0, 0, 0, 6, 0, 0, 0, 3], # [4, 0, 0, 8, 0, 3, 0, 0, 1], # [7, 0, 0, 0, 2, 0, 0, 0, 6], # [0, 6, 0, 0, 0, 0, 2, 8, 0], # [0, 0, 0, 4, 1, 9, 0, 0, 5], # [0, 0, 0, 0, 8, 0, 0, 7, 9] # ] # solver = SudokuSolver() # solver.solve_sudoku(board) # print(board) ```","solution":"from typing import List class SudokuSolver: def __init__(self) -> None: pass def is_valid(self, board: List[List[int]], row: int, col: int, num: int) -> bool: # Check if num is absent in the row for i in range(9): if board[row][i] == num: return False # Check if num is absent in the column for i in range(9): if board[i][col] == num: return False # Check if num is absent in the 3x3 sub-grid start_row, start_col = 3 * (row // 3), 3 * (col // 3) for i in range(3): for j in range(3): if board[start_row + i][start_col + j] == num: return False return True def solve_sudoku(self, board: List[List[int]]) -> bool: for row in range(9): for col in range(9): if board[row][col] == 0: for num in range(1, 10): if self.is_valid(board, row, col, num): board[row][col] = num if self.solve_sudoku(board): return True board[row][col] = 0 return False return True"},{"question":"# Coding Question: Course Dependency Resolution Imagine you are designing a system for managing course prerequisites at a university. There are several courses and some of them depend on the completion of other courses. Your goal is to determine the order in which the courses should be taken to satisfy all prerequisites. If there are multiple valid orders, any one of them is acceptable. You need to implement a function `course_order` that takes the total number of courses and a list of prerequisite pairs, and returns a list representing one possible order to take the courses. Function Signature ```python def course_order(num_courses: int, prerequisites: List[Tuple[int, int]]) -> List[int]: ``` Parameters - **num_courses**: (integer) The total number of courses, where courses are labeled from 0 to `num_courses - 1`. - **prerequisites**: (list of tuples) Each tuple represents a pair (a, b) where course `b` must be completed before course `a`. Returns - (list of integers) A list representing the order in which courses should be taken. Constraints - **num_courses** is a positive integer and is at most 1000. - **prerequisites** list length can be at most 5000. Example Usage ```python print(course_order(4, [(1, 0), (2, 1), (3, 2)])) # One valid order might be [0, 1, 2, 3], where you can take course 0 first, # course 1 next after completing course 0, and so on. print(course_order(2, [(1, 0), (0, 1)])) # Return an empty list as it is impossible to complete the courses due to a circular dependency. ``` Notes - Use a graph-based algorithm to detect and process course dependencies. - Consider scenarios where the graph may have multiple valid topological orders or may contain cycles that make it impossible to order the courses.","solution":"from collections import defaultdict, deque from typing import List, Tuple def course_order(num_courses: int, prerequisites: List[Tuple[int, int]]) -> List[int]: Determine the order of courses to complete given the prerequisites. If there is a cycle, return an empty list. # Create adjacency list and in-degree count adj_list = defaultdict(list) in_degree = {i: 0 for i in range(num_courses)} # Build the graph for course, prereq in prerequisites: adj_list[prereq].append(course) in_degree[course] += 1 # Initialize the queue with courses that have no prerequisites zero_in_degree_queue = deque([k for k in in_degree if in_degree[k] == 0]) order = [] while zero_in_degree_queue: current_course = zero_in_degree_queue.popleft() order.append(current_course) # For all the courses that depend on the current course for neighbor in adj_list[current_course]: in_degree[neighbor] -= 1 # If in-degree becomes zero, add it to the queue if in_degree[neighbor] == 0: zero_in_degree_queue.append(neighbor) # If the number of courses in the order is not equal to num_courses, return [] if len(order) == num_courses: return order else: return []"},{"question":"# Binary to Decimal Converter Objective: You need to write a function that converts a given binary number (represented as a string) to its corresponding decimal value. Your implementation should efficiently handle binary strings and ensure the correctness of the conversion. Function Signature: ```python def binary_to_decimal(binary_str: str) -> int: ... ``` Inputs: * `binary_str` (str): A string representing a binary number. It only contains characters \'0\' and \'1\'. Constraints: ( 1 leq text{len(binary_str)} leq 20 ) Output: * `int`: Returns the decimal representation of the input binary string. Examples: ```python binary_to_decimal(\\"10\\") # returns 2 binary_to_decimal(\\"1101\\") # returns 13 binary_to_decimal(\\"1000000\\") # returns 64 binary_to_decimal(\\"11111\\") # returns 31 binary_to_decimal(\\"0\\") # returns 0 binary_to_decimal(\\"1\\") # returns 1 ``` Edge Cases to Consider: 1. Input is \\"0\\". 2. Input is \\"1\\". 3. Binary strings of various lengths, ensuring correct conversion across all cases. Performance Requirements: - Your implementation should handle the input size constraint efficiently and complete within a reasonable time frame.","solution":"def binary_to_decimal(binary_str: str) -> int: Converts a binary string to its decimal equivalent. Args: binary_str (str): A string representing a binary number. Returns: int: The decimal representation of the binary string. return int(binary_str, 2)"},{"question":"# Question: Design a Custom HashMap Implementation Create a custom implementation of a HashMap data structure. The HashMap should support basic functionalities including insert, delete, and lookup operations. Your implementation should handle collisions using separate chaining (linked lists) at each bucket. Requirements: 1. **Input**: A series of commands to perform insertion, deletion, or lookup operations on the HashMap. 2. **Output**: For lookup operations, return the value associated with the given key, or `None` if the key does not exist. 3. **Constraints**: * The initial size of the backing array for buckets is 10. * Rehashing should occur dynamically when the load factor exceeds 0.7. * Handle basic data types for keys such as integers and strings. Operations to Implement: - **insert(key, value)**: Inserts the key-value pair into the HashMap. - **delete(key)**: Removes the key and its associated value from the HashMap. - **lookup(key)**: Returns the value associated with the key, or `None` if the key does not exist. ```python class ListNode: def __init__(self, key=None, value=None, next_node=None): self.key = key self.value = value self.next_node = next_node class CustomHashMap: def __init__(self): self.size = 0 self.buckets = [None] * 10 def _hash(self, key): return hash(key) % len(self.buckets) def _rehash(self): old_buckets = self.buckets new_size = len(self.buckets) * 2 self.buckets = [None] * new_size for bucket in old_buckets: current = bucket while current: self._insert_without_rehash(current.key, current.value) current = current.next_node def _insert_without_rehash(self, key, value): index = self._hash(key) if not self.buckets[index]: self.buckets[index] = ListNode(key, value) else: current = self.buckets[index] while current: if current.key == key: current.value = value return if not current.next_node: current.next_node = ListNode(key, value) return current = current.next_node def insert(self, key, value): self._insert_without_rehash(key, value) self.size += 1 if self.size / len(self.buckets) > 0.7: self._rehash() def lookup(self, key): index = self._hash(key) current = self.buckets[index] while current: if current.key == key: return current.value current = current.next_node return None def delete(self, key): index = self._hash(key) current = self.buckets[index] prev = None while current: if current.key == key: if prev: prev.next_node = current.next_node else: self.buckets[index] = current.next_node self.size -= 1 return True prev = current current = current.next_node return False if __name__ == \\"__main__\\": hashmap = CustomHashMap() hashmap.insert(\\"apple\\", 5) hashmap.insert(10, 25) hashmap.insert(\\"banana\\", 11) assert hashmap.lookup(\\"apple\\") == 5 assert hashmap.lookup(10) == 25 assert hashmap.delete(\\"apple\\") == True assert hashmap.lookup(\\"apple\\") == None hashmap.insert(15, 32) hashmap.insert(12, 9) hashmap.insert(\\"orange\\", 10) assert hashmap.lookup(15) == 32 assert hashmap.lookup(12) == 9 assert hashmap.lookup(\\"orange\\") == 10 ``` This question aligns with the original sample by involving a custom implementation of a commonly used data structure, requiring the candidate to handle complexity and optimize their solution without reliance on built-in functions.","solution":"class ListNode: def __init__(self, key=None, value=None, next_node=None): self.key = key self.value = value self.next_node = next_node class CustomHashMap: def __init__(self): self.size = 0 self.buckets = [None] * 10 def _hash(self, key): return hash(key) % len(self.buckets) def _rehash(self): old_buckets = self.buckets new_size = len(self.buckets) * 2 self.buckets = [None] * new_size self.size = 0 for bucket in old_buckets: current = bucket while current: self.insert(current.key, current.value) current = current.next_node def _insert_without_rehash(self, key, value): index = self._hash(key) if not self.buckets[index]: self.buckets[index] = ListNode(key, value) else: current = self.buckets[index] while current: if current.key == key: current.value = value return if not current.next_node: current.next_node = ListNode(key, value) return current = current.next_node def insert(self, key, value): self._insert_without_rehash(key, value) self.size += 1 if self.size / len(self.buckets) > 0.7: self._rehash() def lookup(self, key): index = self._hash(key) current = self.buckets[index] while current: if current.key == key: return current.value current = current.next_node return None def delete(self, key): index = self._hash(key) current = self.buckets[index] prev = None while current: if current.key == key: if prev: prev.next_node = current.next_node else: self.buckets[index] = current.next_node self.size -= 1 return True prev = current current = current.next_node return False"},{"question":"# Variable Basic Authorization Token Generation You are provided with a dictionary where keys represent user IDs and values represent the associated user’s password. The goal is to generate a basic authorization token for each user and return a dictionary with user IDs as keys and their corresponding basic authorization tokens as values. A basic authorization token is formed by concatenating the user ID and password with a colon (`:`), encoding the result in Base64, and prefixing the encoded string with `Basic `. Problem Statement Implement a function `generate_auth_tokens(credentials: dict) -> dict` that generates the basic authorization tokens. Input * `credentials` (dict): A dictionary where keys are user IDs (strings) and values are passwords (strings). Output * `dict`: A dictionary where keys are user IDs (strings) and values are the corresponding basic authorization tokens (strings). Constraints * The user ID and password are non-empty strings. * The dictionary can have at most 500 user ID-password pairs. Example ```python credentials = { \\"user1\\": \\"pass1\\", \\"admin\\": \\"adminPass\\", \\"guest\\": \\"guest123\\" } ``` For the above credentials, the expected output is: ```python { \\"user1\\": \\"Basic dXNlcjE6cGFzczE=\\", \\"admin\\": \\"Basic YWRtaW46YWRtaW5QYXNz\\", \\"guest\\": \\"Basic Z3Vlc3Q6Z3Vlc3QxMjM=\\" } ``` Performance Requirements The solution should efficiently handle up to 500 user ID-password pairs. The expected time complexity should be approximately O(n), where `n` is the number of user ID-password pairs. Notes * Use the `base64` module to perform Base64 encoding. * Ensure that the function handles edge cases such as empty credentials dictionaries gracefully by returning an empty dictionary. * The string concatenation should adhere to the format `userID:password`.","solution":"import base64 def generate_auth_tokens(credentials): Generates basic authorization tokens for given user credentials. Args: credentials (dict): A dictionary with user IDs as keys and passwords as values. Returns: dict: A dictionary with user IDs as keys and basic authorization tokens as values. auth_tokens = {} for user_id, password in credentials.items(): token = f\\"{user_id}:{password}\\" encoded_token = base64.b64encode(token.encode()).decode() auth_tokens[user_id] = f\\"Basic {encoded_token}\\" return auth_tokens"},{"question":"# Coding Question - Implementing the Sieve of Eratosthenes with Prime Count As part of an educational platform focusing on algorithm efficiency, you are required to implement the Sieve of Eratosthenes to find all prime numbers up to a given limit. Beyond implementation, extend the function to return the count of primes within this range. # Scenario Educators want to use your algorithm to demonstrate one of the classical means of efficiently finding prime numbers. They are also interested in analyzing the density of prime numbers within different numerical ranges. # Task 1. Implement the `sieve_of_eratosthenes` function according to the given specification. 2. Extend the function to also return the total count of prime numbers found. # Function Signature ```python def sieve_of_eratosthenes(limit: int) -> (list, int): pass ``` # Input * `limit`: A positive integer up to which primes need to be found. # Output * Return a tuple containing two elements: - A list of all prime numbers smaller than or equal to `limit`. - An integer representing the count of prime numbers within that list. # Constraints * Handle limits within a reasonable range for a typical educational demonstration (e.g., up to 10^6). * Ensure complexity remains efficient using the Sieve of Eratosthenes algorithm (O(n log log n)). # Example ```python assert sieve_of_eratosthenes(10) == ([2, 3, 5, 7], 4) assert sieve_of_eratosthenes(1) == ([], 0) assert sieve_of_eratosthenes(20) == ([2, 3, 5, 7, 11, 13, 17, 19], 8) ``` # Additional Notes * Be cautious with memory usage for large values of `limit`. * Ensure your algorithm appropriately handles edge cases, such as very small limits. # Performance Requirements * Aim to maintain efficient performance with respect to both time and space. * Your implementation should be capable of handling the upper constraint smoothly without significant slowdowns.","solution":"def sieve_of_eratosthenes(limit: int) -> (list, int): This function returns all prime numbers up to a given limit using the Sieve of Eratosthenes algorithm. It also returns the count of these prime numbers. if limit < 2: return ([], 0) # Mark initial assumption: all numbers are prime is_prime = [True] * (limit + 1) is_prime[0] = is_prime[1] = False # 0 and 1 are not primes p = 2 while p * p <= limit: if is_prime[p] == True: # Marking multiples of p as false starting from p*p and incrementing by p for i in range(p * p, limit + 1, p): is_prime[i] = False p += 1 # Collecting all prime numbers primes = [number for number, prime in enumerate(is_prime) if prime] return primes, len(primes)"},{"question":"# Problem Statement Implement a function to convert a decimal number to its hexadecimal representation, ensuring efficient handling of large integers. The function should avoid using any built-in conversion functions and should manually handle conversion by repeatedly dividing the input number by 16 and recording remainders. # Task 1. **Conversion Algorithm (Core Algorithm)**: - Implement the `decimal_to_hex` function that takes an integer `num` and returns its hexadecimal representation as a string. - The function should repeatedly divide `num` by 16 and map the remainders to their corresponding hexadecimal characters (0-9, A-F). 2. **Ensure Input/Output Specifications (Integration)**: - `num` will be a non-negative integer. - Your output should be a string representing the hexadecimal format (0-9, A-F). # Constraints - 0 (leq) `num` (leq 10^{18}) - Handle the number zero (`0`) as a special case since its hexadecimal representation should simply be \\"0\\". # Performance Requirements - Time Complexity: O(log(num)) where num is the input number. - Space Complexity: O(1) for constants and log(n) for storing the hex string as output. # Function Signature ```python def decimal_to_hex(num: int) -> str: pass ``` # Example Input ```python num = 2545 ``` Output ```python \\"9F1\\" ``` Input ```python num = 0 ``` Output ```python \\"0\\" ``` # Implementation Details - Start by defining a mapping from remainder values (0-15) to their respective hexadecimal characters. - If `num` is zero, immediately return \\"0\\". - Otherwise, iterate through the division of `num` by 16, appending the corresponding hexadecimal characters in reverse order. - Reverse the collected characters to form the final hexadecimal string before returning it. - Handle very large integers efficiently by avoiding unnecessary operations and by leveraging efficient algorithms for processing.","solution":"def decimal_to_hex(num: int) -> str: if num == 0: return \\"0\\" hex_chars = \\"0123456789ABCDEF\\" hex_string = \\"\\" while num > 0: remainder = num % 16 hex_string = hex_chars[remainder] + hex_string num //= 16 return hex_string"},{"question":"# Balanced Binary Search Tree Construction and Traversal You are given a list of integers. Your task is to construct a balanced binary search tree (BST) from this list and implement methods to perform in-order, pre-order, and post-order traversals of the tree. **Task**: 1. Implement a class for a single node in the BST. 2. Implement a class for the BST that includes methods for insertion and checks for balanced tree construction. 3. Implement methods to traverse the tree in in-order, pre-order, and post-order. **Function Signatures**: 1. `class Node:` 2. `def __init__(self, value: int): -> None` 3. `class BalancedBST:` 4. `def __init__(self): -> None` 5. `def insert(self, value: int): -> None` 6. `def build_from_list(self, values: list[int]): -> None` 7. `def inorder_traversal(self): -> list[int]` 8. `def preorder_traversal(self): -> list[int]` 9. `def postorder_traversal(self): -> list[int]` **Input Format**: - `values`: A list of integers representing the elements to be inserted into the tree. **Output Format**: - `inorder_traversal`: A list of integers representing the in-order traversal of the tree. - `preorder_traversal`: A list of integers representing the pre-order traversal of the tree. - `postorder_traversal`: A list of integers representing the post-order traversal of the tree. **Constraints**: - The integers in the list can include negative and positive values. **Example**: ```python # Example Input values = [15, 10, 20, 8, 12, 17, 25] # Example Usage bst = BalancedBST() bst.build_from_list(values) in_order = bst.inorder_traversal() # Example Output: [8, 10, 12, 15, 17, 20, 25] pre_order = bst.preorder_traversal() # Example Output: [15, 10, 8, 12, 20, 17, 25] post_order = bst.postorder_traversal() # Example Output: [8, 12, 10, 17, 25, 20, 15] ``` **Function Illustrations**: - **Node** class represents each node in the tree. - **BalancedBST** class should include methods `insert` to add a node, `build_from_list` to construct a tree, and traversal methods. - Ensure the tree is balanced during construction to maintain optimal search and traversal performance. Your task is to implement a balanced binary search tree that allows efficient insertion, construction from a list, and tree traversal methods.","solution":"class Node: def __init__(self, value: int) -> None: self.value = value self.left = None self.right = None class BalancedBST: def __init__(self) -> None: self.root = None def insert(self, value: int) -> None: if self.root is None: self.root = Node(value) else: self.root = self._insert(self.root, value) def _insert(self, node: Node, value: int) -> Node: if node is None: return Node(value) if value < node.value: node.left = self._insert(node.left, value) else: node.right = self._insert(node.right, value) return node def build_from_list(self, values: list[int]) -> None: values.sort() self.root = self._sorted_array_to_bst(values) def _sorted_array_to_bst(self, values: list[int]) -> Node: if not values: return None mid = len(values) // 2 node = Node(values[mid]) node.left = self._sorted_array_to_bst(values[:mid]) node.right = self._sorted_array_to_bst(values[mid+1:]) return node def inorder_traversal(self) -> list[int]: result = [] self._inorder_traversal(self.root, result) return result def _inorder_traversal(self, node: Node, result: list[int]) -> None: if node: self._inorder_traversal(node.left, result) result.append(node.value) self._inorder_traversal(node.right, result) def preorder_traversal(self) -> list[int]: result = [] self._preorder_traversal(self.root, result) return result def _preorder_traversal(self, node: Node, result: list[int]) -> None: if node: result.append(node.value) self._preorder_traversal(node.left, result) self._preorder_traversal(node.right, result) def postorder_traversal(self) -> list[int]: result = [] self._postorder_traversal(self.root, result) return result def _postorder_traversal(self, node: Node, result: list[int]) -> None: if node: self._postorder_traversal(node.left, result) self._postorder_traversal(node.right, result) result.append(node.value)"},{"question":"# Problem Statement Create a function that calculates the nth Fibonacci number using dynamic programming. The Fibonacci sequence is characterized by the fact that every number after the first two is the sum of the two preceding ones. # Input Format * An integer ( n ) where ( n ) can range from ( 0 ) to ( 10^5 ). # Output Format * An integer which is the nth Fibonacci number. # Constraints * The input number ( n ) will be a non-negative integer. # Example ```python For an input n = 5, the output should be 5. For an input n = 10, the output should be 55. ``` # Instructions 1. Do not use recursion due to potential stack overflow issues with large ( n ). 2. Optimize for both time and space complexity. # Solution Template Here is a starting template for your solution: ```python def fibonacci(n): if n == 0: return 0 elif n == 1: return 1 fib = [0] * (n + 1) fib[1] = 1 for i in range(2, n + 1): fib[i] = fib[i - 1] + fib[i - 2] return fib[n] if __name__ == \\"__main__\\": n = int(input(\\"Enter a number:n\\").strip()) print(fibonacci(n)) ``` In your implementation, ensure that you handle all edge cases effectively and test the function against a variety of input scenarios before finalizing your code.","solution":"def fibonacci(n): Calculates the nth Fibonacci number using dynamic programming. :param n: The position of the Fibonacci number to calculate. :type n: int :return: The nth Fibonacci number. :rtype: int if n == 0: return 0 elif n == 1: return 1 a, b = 0, 1 for _ in range(2, n + 1): a, b = b, a + b return b"},{"question":"# Fibonacci Sequence Generator with Caching Background: The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, typically starting with 0 and 1. This is a classic problem, often used to teach recursion and dynamic programming. Task: Implement the function `fibonacci_with_cache` which: - Accepts an integer `n`, representing the position in the Fibonacci sequence. - Returns an integer which is the `n`th Fibonacci number. - Uses memoization to cache previously computed Fibonacci numbers to optimize performance. Input Format: * An integer `n`. Output Format: * An integer which is the `n`th Fibonacci number. Constraints: * 0 <= n <= 40 Example: ```python # Example 1 n = 10 result = fibonacci_with_cache(n) print(result) # Expected: # 55 # Example 2 n = 0 result = fibonacci_with_cache(n) print(result) # Expected: # 0 # Example 3 n = 1 result = fibonacci_with_cache(n) print(result) # Expected: # 1 ``` Notes: - Ensure your function handles base cases correctly. - Your solution should be optimized to handle the upper constraint efficiently.","solution":"def fibonacci_with_cache(n, cache={0: 0, 1: 1}): Returns the nth Fibonacci number using caching to optimize performance. Args: n (int): The position in the Fibonacci sequence. Returns: int: The nth Fibonacci number. if n in cache: return cache[n] cache[n] = fibonacci_with_cache(n - 1, cache) + fibonacci_with_cache(n - 2, cache) return cache[n]"},{"question":"# Multi-Dimensional Array Traversal You have been asked to implement a function to help analyze weather data stored in a multi-dimensional array. The given data structure represents various attributes across several locations and times. Your task is to implement the `weather_data_sum` function which calculates the sum of all the entries in the given multi-dimensional array. The array can have any number of dimensions. **Function Signature** ```python def weather_data_sum(data: List) -> float: ``` ```python def weather_data_sum(data: List) -> float: Calculate the sum of all numbers in a multi-dimensional array of weather data. Parameters ---------- data : List A multi-dimensional array of floats or integers representing weather data. Returns ------- total_sum : float The sum of all numbers in the data array. Example ------- >>> weather_data_sum([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]) 36.0 >>> weather_data_sum([[[1.5, 2.5], [3.5, 4.5]], [[5.5, 6.5], [7.5, 8.5]]]) 40.0 if not isinstance(data, list): if isinstance(data, (int, float)): return float(data) else: raise ValueError(\\"Invalid data type.\\") total_sum = 0.0 for element in data: total_sum += weather_data_sum(element) return total_sum ``` **Constraints** - The `data` should be either a single element (int or float) or a list that can contain other nested lists up to any level. - Each individual element in the lists should be either an integer or a floating-point number. - The function should handle lists with different levels of nesting. **Notes** - Ensure that the function checks for valid input types and raises `ValueError` for invalid data types. - This implementation should be able to traverse any deeply nested list and return the correct sum of all numerical entries.","solution":"from typing import List, Union def weather_data_sum(data: Union[List, float, int]) -> float: Calculate the sum of all numbers in a multi-dimensional array of weather data. Parameters ---------- data : List A multi-dimensional array of floats or integers representing weather data, which can be deeply nested. Returns ------- total_sum : float The sum of all numbers in the data array. Examples -------- >>> weather_data_sum([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]) 36.0 >>> weather_data_sum([[[1.5, 2.5], [3.5, 4.5]], [[5.5, 6.5], [7.5, 8.5]]]) 40.0 if isinstance(data, (int, float)): return float(data) elif isinstance(data, list): total_sum = 0.0 for element in data: total_sum += weather_data_sum(element) return total_sum else: raise ValueError(\\"Invalid data type: must be list, int, or float.\\")"},{"question":"# Coding Question Context Farm management systems often require automated tools to help track the growth and yield of crops. One key aspect is to predict the total weight of a specific crop based on past growth data. This task aims to calculate the expected total weight of a crop given its initial weight and an array representing its growth rates over a particular period. Task Write a function `calculate_total_weight(data: Dict) -> float` where `data` is a dictionary containing the initial weight of the crop and an array of daily growth rates. Each growth rate represents the percentage increase in weight for each day. # Function Signature ```python def calculate_total_weight(data: Dict) -> float: pass ``` # Input - `data`: A dictionary with the following keys: - `initial_weight`: (float) - the initial weight of the crop in kilograms. - `growth_rates`: (List[float]) - a list of daily growth rates (in percentage). # Output - A floating-point value representing the total expected weight of the crop after applying the growth rates. # Constraints - `initial_weight` will be a positive float less than or equal to 1000. - Each growth rate in `growth_rates` will be a non-negative float less than or equal to 100. - `growth_rates` list will contain between 1 to 365 values (inclusive). # Example ```python data = { \\"initial_weight\\": 10.0, \\"growth_rates\\": [10, 20, 30] } output = calculate_total_weight(data) print(output) # Output should be 15.6 ``` The function `calculate_total_weight` should calculate the total weight of the crop after applying the series of daily growth rates provided in the input dictionary.","solution":"def calculate_total_weight(data): Calculate the total weight of a crop after applying a series of daily growth rates. :param data: Dictionary containing initial_weight and a list of daily growth rates :type data: dict :return: Total weight of the crop after applying the growth rates :rtype: float initial_weight = data[\'initial_weight\'] growth_rates = data[\'growth_rates\'] current_weight = initial_weight for rate in growth_rates: current_weight += current_weight * (rate / 100) return current_weight"},{"question":"# Sum of the Digits of an Integer Implement the function `sum_of_digits(num: int) -> int` that calculates the sum of the individual digits of a non-negative integer `num`. The function should iterate through each digit of the number and compute the total sum. Function Signature ```python def sum_of_digits(num: int) -> int: ``` Input/Output format - **Input**: - `num`: A non-negative integer (0 ≤ num ≤ 10^19) - **Output**: - Return an integer representing the sum of the digits in `num`. Constraints: 1. Ensure the function handles typical edge cases such as `num = 0`. 2. The input should be an integer; raise a `ValueError` if the input is negative or non-integer. 3. The implementation should be efficient in terms of time complexity (O(n)), where `n` is the number of digits in the input number. Examples: ```python >>> sum_of_digits(0) 0 >>> sum_of_digits(1) 1 >>> sum_of_digits(123) 6 >>> sum_of_digits(9876543210) 45 >>> sum_of_digits(1000000000000000000) 1 >>> sum_of_digits(9999999999999999999) 171 ``` Additional Instructions: - Make sure to conduct thorough testing with edge cases and typical inputs. - You may find `import doctest` and `doctest.testmod()` helpful for testing purposes as demonstrated in the question. This question requires the candidate to practice simple arithmetic operations, handle integer manipulation, and add a condition to handle edge cases. Given its requirement to iterate digit-by-digit, it ensures comprehension of fundamental iterative processes. This new question should seamlessly integrate with the existing set, as it follows similar complexity, scope, and style.","solution":"def sum_of_digits(num: int) -> int: Returns the sum of the digits of a non-negative integer num. Parameters: num (int): A non-negative integer. Returns: int: The sum of the digits of num. Raises: ValueError: If num is negative or not an integer. if not isinstance(num, int) or num < 0: raise ValueError(f\\"The input must be a non-negative integer, got {num} instead.\\") return sum(int(digit) for digit in str(num))"},{"question":"# Scenario You are working as a software developer at a finance company. Your task is to create a system that analyzes and processes large streams of stock price data to identify significant trends. Due to the high volume of data, your analysis must be efficient and able to handle real-time updates. One way to achieve this is by utilizing a data structure called a Fenwick Tree (Binary Indexed Tree) to perform efficient range queries and updates. # Task Implement a Fenwick Tree (Binary Indexed Tree) to support efficient update and prefix sum queries on a list of stock prices. # Implement the Following Functions 1. `class FenwickTree:` - `__init__(self, size: int)`: Initialize the Fenwick Tree with a given size. - `update(self, index: int, value: int)`: Update the external array at the given index by adding the value. - `query(self, index: int) -> int`: Return the prefix sum from the beginning of the array to the given index. # Constraints - Assume the initial list of stock prices is generated randomly and the size of the list is `n`. - Indices for update and query operations are 0-based. - The list size `n` will be between 1 and 10^5. - Each stock price value and update value will be an integer between -10^4 and 10^4. # Expected Input and Output Formats - Input: ```python n = 10 updates = [(index1, value1), (index2, value2), ...] queries = [index1, index2, ...] ``` - Output: ```python [sum1, sum2, ...] ``` # Example ```python # Initialize Fenwick Tree with size 10 fenwick_tree = FenwickTree(10) # Update the tree fenwick_tree.update(1, 5) fenwick_tree.update(4, 6) fenwick_tree.update(7, 3) # Perform prefix sum queries result1 = fenwick_tree.query(5) # Output should be the sum of values from index 0 to 5 result2 = fenwick_tree.query(7) # Output should be the sum of values from index 0 to 7 print(result1) # Output might look like 11 (0, 5, 0, 0, 6, 0) print(result2) # Output might look like 14 (0, 5, 0, 0, 6, 0, 0, 3) ``` # Notes - The Fenwick Tree should support both range updates and prefix sum query operations efficiently. - Pay attention to edge cases, such as updates and queries on the boundaries of the array.","solution":"class FenwickTree: def __init__(self, size: int): self.size = size self.tree = [0] * (size + 1) # Fenwick Tree is generally 1-based index def update(self, index: int, value: int): index += 1 # converting 0-based index to 1-based index for Fenwick Tree while index <= self.size: self.tree[index] += value index += index & -index def query(self, index: int) -> int: index += 1 # converting 0-based index to 1-based index for Fenwick Tree sum_ = 0 while index > 0: sum_ += self.tree[index] index -= index & -index return sum_"},{"question":"# Coding Assessment Question Context You are enhancing a text analysis toolkit by adding functionality for text preprocessing. As part of this task, you need to implement a function to normalize text by converting it to lowercase, removing punctuation, and optionally removing stopwords. Task Implement a function to normalize a given string of text such that: - All characters are converted to lowercase. - All punctuation characters are removed. - Optionally, all stopwords are removed. Stopwords are common words like \\"the\\", \\"and\\", \\"is\\", etc., which are often removed in natural language processing to focus on the core content. Requirements 1. **Function Definition**: Implement a function named `normalize_text`. 2. **Input**: - A string of text. - An optional boolean parameter `remove_stopwords` to indicate if stopwords should be removed (default is `False`). 3. **Output**: The normalized string. 4. **Constraints**: * Assume a predefined list of stopwords. * Consider edge cases such as an empty string or a string with only punctuation. 5. **Performance**: The implementation should efficiently handle strings of up to 10,000 characters. Function Signature ```python def normalize_text(text: str, remove_stopwords: bool = False) -> str: pass ``` Example 1. Input: `\\"Hello, World!\\"`, `False` Output: `\\"hello world\\"` 2. Input: `\\"The quick brown fox.\\"`, `True` Output: `\\"quick brown fox\\"` 3. Input: `\\"A quick, brown fox jumps over the lazy dog!\\"`, `False` Output: `\\"a quick brown fox jumps over the lazy dog\\"` 4. Input: `\\"A quick, brown fox jumps over the lazy dog!\\"`, `True` Output: `\\"quick brown fox jumps lazy dog\\"` Testing * Test your function with various text inputs, including those with different cases, punctuation, and stopwords. * Verify the correctness by manually comparing the outputs with expected results.","solution":"import string def normalize_text(text: str, remove_stopwords: bool = False) -> str: Normalize the text by converting it to lowercase, removing punctuation, and optionally removing stopwords. :param text: The input text string to normalize. :param remove_stopwords: Boolean flag to indicate if stopwords should be removed. :return: The normalized text string. # List of common English stopwords stopwords = set([ \\"a\\", \\"an\\", \\"the\\", \\"and\\", \\"or\\", \\"but\\", \\"if\\", \\"while\\", \\"of\\", \\"at\\", \\"by\\", \\"for\\", \\"with\\", \\"about\\", \\"against\\", \\"between\\", \\"into\\", \\"through\\", \\"during\\", \\"before\\", \\"after\\", \\"above\\", \\"below\\", \\"to\\", \\"from\\", \\"up\\", \\"down\\", \\"in\\", \\"out\\", \\"on\\", \\"off\\", \\"over\\", \\"under\\", \\"again\\", \\"further\\", \\"then\\", \\"once\\", \\"here\\", \\"there\\", \\"when\\", \\"where\\", \\"why\\", \\"how\\", \\"all\\", \\"any\\", \\"both\\", \\"each\\", \\"few\\", \\"more\\", \\"most\\", \\"other\\", \\"some\\", \\"such\\", \\"no\\", \\"nor\\", \\"only\\", \\"own\\", \\"same\\", \\"so\\", \\"than\\", \\"too\\", \\"very\\", \\"s\\", \\"t\\", \\"can\\", \\"will\\", \\"just\\", \\"don\\", \\"should\\", \\"now\\" ]) # Convert text to lowercase text = text.lower() # Remove punctuation text = text.translate(str.maketrans(\'\', \'\', string.punctuation)) # Remove stopwords if required if remove_stopwords: words = text.split() words = [word for word in words if word not in stopwords] text = \' \'.join(words) return text"},{"question":"# Question: Implementing and Visualizing a Custom IIR Filter Response Context You have been provided with code snippets that perform FFT on signals to analyze the frequency and phase response of audio filters. Your task is to implement a custom Infinite Impulse Response (IIR) filter and visualize its frequency and phase response using the provided framework. Task 1. Implement a custom IIR filter class that adheres to the `FilterType` Protocol. The class must have: - An `__init__` method to initialize filter coefficients for both the numerator and the denominator. - A `process()` method that takes a single sample as input and returns a filtered sample. 2. Use the `show_frequency_response()` and `show_phase_response()` functions to visualize your IIR filter for a given sample rate. Requirements * **Filter Specification**: You will implement a low-pass IIR filter with a given set of coefficients. * **Input/Output**: - The IIR filter class will take two lists of coefficients (numerator and denominator). - The `process()` method will output the filtered value for each sample. * **Constraints**: - Sample rate for visualization: 48000 Hz. - Length of input signal for visualization: 512 samples. * **Performance**: - The implementation must handle signals efficiently. - The plot should be clear and cover the frequency range effectively. # Example ```python class IIRFilter: def __init__(self, b_coefficients: list[float], a_coefficients: list[float]) -> None: self.b = b_coefficients self.a = a_coefficients self.buffer_x = [0] * len(self.b) self.buffer_y = [0] * len(self.a) def process(self, sample: float) -> float: self.buffer_x.pop(0) self.buffer_x.append(sample) result = sum(b * x for b, x in zip(self.b, self.buffer_x)) - sum(a * y for a, y in zip(self.a[1:], self.buffer_y[1:])) self.buffer_y.pop(0) self.buffer_y.append(result) return result # Coefficients of a simple low-pass IIR filter (numerator and denominator) b_coefficients = [0.2, 0.2] a_coefficients = [1.0, -0.6] filt = IIRFilter(b_coefficients, a_coefficients) show_frequency_response(filt, 48000) show_phase_response(filt, 48000) ```","solution":"import numpy as np import matplotlib.pyplot as plt from scipy.signal import freqz class IIRFilter: def __init__(self, b_coefficients: list[float], a_coefficients: list[float]) -> None: self.b = b_coefficients self.a = a_coefficients self.buffer_x = [0] * len(self.b) self.buffer_y = [0] * len(self.a) def process(self, sample: float) -> float: self.buffer_x.pop(0) self.buffer_x.append(sample) result = sum(b * x for b, x in zip(self.b, self.buffer_x)) - sum(a * y for a, y in zip(self.a[1:], self.buffer_y[1:])) self.buffer_y.pop(0) self.buffer_y.append(result) return result def show_frequency_response(filter_obj, sample_rate): w, h = freqz(filter_obj.b, filter_obj.a, worN=8000) plt.subplot(2, 1, 1) plt.plot(0.5 * sample_rate * w / np.pi, np.abs(h), \'b\') plt.title(\'Frequency response\') plt.xlabel(\'Frequency (Hz)\') plt.ylabel(\'Gain\') plt.grid() def show_phase_response(filter_obj, sample_rate): w, h = freqz(filter_obj.b, filter_obj.a, worN=8000) plt.subplot(2, 1, 2) plt.plot(0.5 * sample_rate * w / np.pi, np.angle(h), \'b\') plt.title(\'Phase response\') plt.xlabel(\'Frequency (Hz)\') plt.ylabel(\'Phase (radians)\') plt.grid() plt.show() # Coefficients of a simple low-pass IIR filter (numerator and denominator) b_coefficients = [0.2, 0.2] a_coefficients = [1.0, -0.6] filt = IIRFilter(b_coefficients, a_coefficients) show_frequency_response(filt, 48000) show_phase_response(filt, 48000)"},{"question":"Implementing a Binary Search Tree and Performing Various Operations Objective Create a Binary Search Tree (BST) that supports insertion, searching, and in-order traversal. Additionally, analyze the operational performance and explain suitable applications for BSTs. Task 1. **Class Implementation**: Implement a `BinarySearchTree` class with methods to insert elements, search for an element, and perform in-order traversal of the tree. 2. **Performance Analysis**: Write a brief analysis (approximately 200 words) discussing the time and space complexity of the insert, search, and in-order traversal operations. Highlight scenarios where BSTs perform well and discuss limitations in terms of skewed trees and balanced trees. Class Signature ```python class BinarySearchTree: class Node: def __init__(self, key): self.left = None self.right = None self.value = key def __init__(self): Initializes an empty Binary Search Tree. self.root = None def insert(self, key: int) -> None: Inserts a key into the BST. :param key: The integer key to be inserted into the BST. pass def search(self, key: int) -> bool: Searches for a key in the BST. :param key: The integer key to search in the BST. :return: True if the key is found, False otherwise. pass def in_order_traversal(self) -> list: Performs an in-order traversal of the BST. :return: A list of integers representing the in-order traversal of the BST. pass ``` Input Format * Operations can be one among \'insert\', \'search\', and \'in-order traversal\', followed by the necessary parameters. Output Format * For `insert`: No output. * For `search`: Returns `True` if the key is found, `False` otherwise. * For `in-order traversal`: Returns a list of integers representing the in-order traversal of the BST. Constraints * Keys are unique integers for `insert` operations. * You may assume that the `search` key exists in the tree. Example ```python bst = BinarySearchTree() bst.insert(10) bst.insert(5) bst.insert(15) bst.insert(2) bst.insert(7) assert bst.search(7) == True assert bst.search(20) == False assert bst.in_order_traversal() == [2, 5, 7, 10, 15] ``` Analysis Evaluate the implementation in terms of: * **Average and Worst-case Time Complexity**: Provide a detailed explanation of the O(log n) average-case and O(n) worst-case time complexity of insertion, searching, and traversal operations. * **Space Complexity**: Justify the O(n) space complexity in terms of the storage for nodes in the tree. * **Use Case Suitability**: Discuss practical applications for BSTs, emphasizing scenarios where they are ideal and highlighting the need for self-balancing in some cases to prevent performance degradation due to skewed trees. Notes * Ensure to handle edge cases such as operations on an empty tree. * Include docstrings and comments to explain the logic behind the implementation.","solution":"class BinarySearchTree: class Node: def __init__(self, key): self.left = None self.right = None self.value = key def __init__(self): Initializes an empty Binary Search Tree. self.root = None def insert(self, key: int) -> None: Inserts a key into the BST. :param key: The integer key to be inserted into the BST. def _insert(root, key): if root is None: return self.Node(key) elif key < root.value: root.left = _insert(root.left, key) else: root.right = _insert(root.right, key) return root self.root = _insert(self.root, key) def search(self, key: int) -> bool: Searches for a key in the BST. :param key: The integer key to search in the BST. :return: True if the key is found, False otherwise. def _search(root, key): if root is None: return False if root.value == key: return True elif key < root.value: return _search(root.left, key) else: return _search(root.right, key) return _search(self.root, key) def in_order_traversal(self) -> list: Performs an in-order traversal of the BST. :return: A list of integers representing the in-order traversal of the BST. result = [] def _in_order_traversal(root): if root is not None: _in_order_traversal(root.left) result.append(root.value) _in_order_traversal(root.right) _in_order_traversal(self.root) return result"},{"question":"# Prime Number Checker & List Generator Objective You need to write two functions: one to check if a number is prime and another to generate a list of prime numbers up to a given limit. Scenario In mathematics and computer science, prime numbers play a crucial role in various algorithms and cryptographic operations. Implementing efficient prime-checking and prime-generating algorithms is essential for performance-critical applications. Function Specifications: * **Function Name**: `is_prime` * **Input**: An integer `n` (1 ≤ n ≤ 10^6) * **Output**: Returns `True` if `n` is a prime number, otherwise `False`. * **Constraints**: - The function should raise a `ValueError` with the message \\"is_prime() not defined for non-integer values\\" if `n` is not an integer. - The function should raise a `ValueError` with the message \\"is_prime() not defined for negative values or zero\\" if `n` is less than 1. * **Performance Requirements**: The function should have a time complexity of O(sqrt(n)) or better. * **Function Name**: `generate_primes` * **Input**: An integer `limit` (1 ≤ limit ≤ 10^6) * **Output**: Returns a list of prime numbers up to `limit` (inclusive). * **Constraints**: - The function should raise a `ValueError` with the message \\"generate_primes() not defined for non-integer values\\" if `limit` is not an integer. - The function should raise a `ValueError` with the message \\"generate_primes() not defined for negative values or zero\\" if `limit` is less than 1. * **Performance Requirements**: Use the Sieve of Eratosthenes algorithm for efficient prime number generation with a time complexity of O(n log log n). Example Usage ```python # Prime checker implementation examples assert is_prime(5) is True assert is_prime(4) is False assert is_prime(2) is True try: is_prime(-1) except ValueError as e: assert str(e) == \\"is_prime() not defined for negative values or zero\\" try: is_prime(1.5) except ValueError as e: assert str(e) == \\"is_prime() not defined for non-integer values\\" # Prime generator implementation examples assert generate_primes(10) == [2, 3, 5, 7] assert generate_primes(1) == [] assert generate_primes(15) == [2, 3, 5, 7, 11, 13] try: generate_primes(-1) except ValueError as e: assert str(e) == \\"generate_primes() not defined for negative values or zero\\" try: generate_primes(1.5) except ValueError as e: assert str(e) == \\"generate_primes() not defined for non-integer values\\" ```","solution":"import math def is_prime(n): Checks whether n is a prime number. if not isinstance(n, int): raise ValueError(\\"is_prime() not defined for non-integer values\\") if n <= 0: raise ValueError(\\"is_prime() not defined for negative values or zero\\") if n == 1: return False if n == 2: return True if n % 2 == 0: return False for i in range(3, int(math.sqrt(n)) + 1, 2): if n % i == 0: return False return True def generate_primes(limit): Generates a list of prime numbers up to the given limit (inclusive). if not isinstance(limit, int): raise ValueError(\\"generate_primes() not defined for non-integer values\\") if limit <= 0: raise ValueError(\\"generate_primes() not defined for negative values or zero\\") is_prime = [True] * (limit + 1) is_prime[0] = is_prime[1] = False for i in range(2, int(math.sqrt(limit)) + 1): if is_prime[i]: for j in range(i * i, limit + 1, i): is_prime[j] = False return [i for i in range(2, limit + 1) if is_prime[i]]"},{"question":"# Question Context: Given a list of integers, you are required to create a balanced partition where the absolute difference between the sums of the two partitions is minimized. This problem is commonly known as the \\"Partition Problem\\" and is a well-known NP-complete problem. The objective is to use dynamic programming to find the optimal partition. Task: Write a Python function `min_partition_diff(nums: list) -> int` that receives a list of integers `nums` and returns the minimum possible absolute difference between the sums of two partitions of the list. Input: - `nums` (list): A list of integers where each integer is in the range [-10^3, 10^3]. - The length of the list is between 1 and 100 inclusive. Output: - Return an integer representing the minimum possible absolute difference between the sums of two partitions. Constraints: - Ensure your solution uses dynamic programming efficiently to handle the input size. Example: ```python assert min_partition_diff([1, 6, 11, 5]) == 1 # Partition into {1, 6, 5} and {11}, difference is 1 assert min_partition_diff([2]) == 2 # Partition into {2}, difference is 2 assert min_partition_diff([1, 2, 3, 9]) == 3 # Partition into {1, 2, 3} and {9}, difference is 3 ```","solution":"def min_partition_diff(nums: list) -> int: total_sum = sum(nums) n = len(nums) # Initialize dynamic programming table dp = [[False] * (total_sum // 2 + 1) for _ in range(n + 1)] # There is always a way to partition with sum 0 (both sets empty) for i in range(n + 1): dp[i][0] = True # Fill the table for i in range(1, n + 1): for j in range(1, total_sum // 2 + 1): if nums[i - 1] <= j: dp[i][j] = dp[i - 1][j] or dp[i - 1][j - nums[i - 1]] else: dp[i][j] = dp[i - 1][j] # Find the maximum possible sum of the smaller partition for j in range(total_sum // 2, -1, -1): if dp[n][j]: return total_sum - 2 * j return total_sum"},{"question":"# Coding Assessment Question: **Context**: You are developing a system for managing inventory in a warehouse. The system tracks various items identified by their unique IDs and needs to process requests to add, remove, or query items in an efficient manner. **Task**: Write a Python class `Warehouse` that supports the following operations: - `add_item(id: int, quantity: int) -> None`: Adds a given quantity of the item identified by `id` to the inventory. If the item already exists, increase its quantity. - `remove_item(id: int, quantity: int) -> bool`: Removes a given quantity of the item identified by `id` from the inventory. If the item does not exist, or if there is not enough quantity to remove, return `False`. Otherwise, decrease the quantity and return `True`. - `get_quantity(id: int) -> int`: Returns the current quantity of the item identified by `id`. If the item does not exist, return `0`. **Specifications**: * Class name: `Warehouse` * Methods: * `add_item` * `remove_item` * `get_quantity` **Constraints**: * The item `id` is a unique positive integer (1 <= id <= 10^6). * The quantity is always a non-negative integer (0 <= quantity <= 10^6). * Initial quantity of any item is assumed to be `0`. **Example**: ```python class Warehouse: def add_item(self, id: int, quantity: int) -> None: Adds a given quantity of the item identified by `id` to the inventory. Parameters: id (int): The unique identifier for the item. quantity (int): The quantity of the item to be added. pass def remove_item(self, id: int, quantity: int) -> bool: Removes a given quantity of the item identified by `id` from the inventory. Parameters: id (int): The unique identifier for the item. quantity (int): The quantity of the item to be removed. Returns: bool: True if the quantity was successfully removed, False if the item does not exist or there is not enough quantity. pass def get_quantity(self, id: int) -> int: Returns the current quantity of the item identified by `id`. Parameters: id (int): The unique identifier for the item. Returns: int: The current quantity of the item, or 0 if the item does not exist. pass # Example usage: warehouse = Warehouse() warehouse.add_item(1, 100) warehouse.add_item(2, 50) print(warehouse.get_quantity(1)) # Output: 100 print(warehouse.get_quantity(2)) # Output: 50 print(warehouse.remove_item(1, 20)) # Output: True print(warehouse.get_quantity(1)) # Output: 80 print(warehouse.remove_item(2, 60)) # Output: False print(warehouse.get_quantity(2)) # Output: 50 ``` **Notes**: * Thoroughly test your class with a variety of test cases, including edge cases. * Ensure that your implementation handles the inventory management efficiently.","solution":"class Warehouse: def __init__(self): # Initialize an empty dictionary to store item ids and their corresponding quantities self.inventory = {} def add_item(self, id: int, quantity: int) -> None: Adds a given quantity of the item identified by `id` to the inventory. Parameters: id (int): The unique identifier for the item. quantity (int): The quantity of the item to be added. if id in self.inventory: self.inventory[id] += quantity else: self.inventory[id] = quantity def remove_item(self, id: int, quantity: int) -> bool: Removes a given quantity of the item identified by `id` from the inventory. Parameters: id (int): The unique identifier for the item. quantity (int): The quantity of the item to be removed. Returns: bool: True if the quantity was successfully removed, False if the item does not exist or there is not enough quantity. if id not in self.inventory or self.inventory[id] < quantity: return False else: self.inventory[id] -= quantity if self.inventory[id] == 0: del self.inventory[id] return True def get_quantity(self, id: int) -> int: Returns the current quantity of the item identified by `id`. Parameters: id (int): The unique identifier for the item. Returns: int: The current quantity of the item, or 0 if the item does not exist. return self.inventory.get(id, 0)"},{"question":"# Scenario: You are tasked with designing a system to manage and query rainfall data in various cities. Each update involves recording a new rainfall amount for a specific city, and queries consist of calculating the average rainfall across a specified range of cities. To achieve efficiency, you decide to use a **Fenwick Tree** to manage prefix sums and support range queries quickly. # Task: Implement a class that supports the following operations: 1. **update_rainfall(city: int, amount: int)**: Update the rainfall amount recorded in a specific city. 2. **average_rainfall(start_city: int, end_city: int)**: Calculate the average rainfall in the range [start_city, end_city). # Constraints: - `0 <= city < N`, where `N` represents the total number of cities. - `0 <= amount <= 10^5` - `0 <= start_city < end_city <= N` - You cannot use built-in library functions for querying or calculating average ranges (like `sum` and `len`). # Function Signature: ```python class RainfallMonitor: def __init__(self, size: int) -> None: ... def update_rainfall(self, city: int, amount: int) -> None: ... def average_rainfall(self, start_city: int, end_city: int) -> float: ... # Example Usage: # monitor = RainfallMonitor(5) # monitor.update_rainfall(1, 50) # monitor.update_rainfall(3, 70) # print(monitor.average_rainfall(0, 4)) # Output: 30.0 since (50+70)/4 = 30 # print(monitor.average_rainfall(2, 5)) # Output: 23.33 since (0+70)/3 ≈ 23.33 (up to 2 decimal places) ``` # Notes: - Ensure your solution efficiently supports both update and range average queries. - Handle cases where cities may have zero recorded rainfall, especially for the calculation of averages. - Put emphasis on maintaining the performance goals stated by Fenwick Tree principles. In this task, you\'ll manage city-wise rainfall data using efficient data structures and algorithmic techniques. This setup tests both your understanding of advanced tree structures and your ability to handle real-world data storage and querying scenarios effectively.","solution":"class FenwickTree: def __init__(self, size: int): self.size = size self.tree = [0] * (size + 1) def update(self, index: int, delta: int) -> None: index += 1 # Fenwick Tree is 1-indexed while index <= self.size: self.tree[index] += delta index += index & -index def prefix_sum(self, index: int) -> int: index += 1 # Fenwick Tree is 1-indexed result = 0 while index > 0: result += self.tree[index] index -= index & -index return result class RainfallMonitor: def __init__(self, size: int) -> None: self.size = size self.rainfall = [0] * size self.fenwick_tree = FenwickTree(size) def update_rainfall(self, city: int, amount: int) -> None: delta = amount - self.rainfall[city] self.rainfall[city] = amount self.fenwick_tree.update(city, delta) def average_rainfall(self, start_city: int, end_city: int) -> float: total_rainfall = self.fenwick_tree.prefix_sum(end_city - 1) - self.fenwick_tree.prefix_sum(start_city - 1) num_cities = end_city - start_city average_rainfall = total_rainfall / num_cities return average_rainfall"},{"question":"# Binary Search Tree: Range Sum Queries You are required to implement a binary search tree (BST) data structure and include operations to support sum queries within a specified range of node values. # Task Implement a class `RangeSumBST` which extends the functionality of a basic BST. Your implementation should include the following methods: 1. `insert`: Inserts a new value into the BST. 2. `range_sum`: Computes the sum of node values within a specified range `[low, high]`. # Specifications Method 1: `insert` - **Input**: An integer `val`. - **Output**: None. The method will insert `val` into the BST maintaining the BST properties. Method 2: `range_sum` - **Input**: Two integers `low` and `high`. - **Output**: The sum of all node values in the BST that fall within the inclusive range `[low, high]`. # Constraints 1. The BST should not contain duplicate values. 2. `low` and `high` are integers, and `low` ≤ `high`. # Performance Requirements - `insert`: Expected time complexity - O(log n) on average. - `range_sum`: Expected time complexity - O(n) in the worst case, but should be efficient. # Example ```python >>> bst = RangeSumBST() >>> bst.insert(10) >>> bst.insert(5) >>> bst.insert(15) >>> bst.insert(3) >>> bst.insert(7) >>> bst.insert(18) >>> bst.range_sum(7, 15) 32 >>> bst.range_sum(5, 10) 22 ``` # Implementation ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right class RangeSumBST: def __init__(self): self.root = None def insert(self, val: int): if self.root is None: self.root = TreeNode(val) else: self._insert_recursive(self.root, val) def _insert_recursive(self, node: TreeNode, val: int): if val < node.val: if node.left is None: node.left = TreeNode(val) else: self._insert_recursive(node.left, val) elif val > node.val: if node.right is None: node.right = TreeNode(val) else: self._insert_recursive(node.right, val) def range_sum(self, low: int, high: int) -> int: return self._range_sum_recursive(self.root, low, high) def _range_sum_recursive(self, node: TreeNode, low: int, high: int) -> int: if node is None: return 0 total = 0 if low <= node.val <= high: total += node.val if node.val > low: total += self._range_sum_recursive(node.left, low, high) if node.val < high: total += self._range_sum_recursive(node.right, low, high) return total ``` The added question maintains the style and complexity of the original sample by integrating traditional BST operations with a query function, similar to the original problem\'s extension of a base heap with new methods. It is an appropriate addition, ensuring a consistent challenge in line with the provided question.","solution":"class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right class RangeSumBST: def __init__(self): self.root = None def insert(self, val: int): if self.root is None: self.root = TreeNode(val) else: self._insert_recursive(self.root, val) def _insert_recursive(self, node: TreeNode, val: int): if val < node.val: if node.left is None: node.left = TreeNode(val) else: self._insert_recursive(node.left, val) elif val > node.val: if node.right is None: node.right = TreeNode(val) else: self._insert_recursive(node.right, val) def range_sum(self, low: int, high: int) -> int: return self._range_sum_recursive(self.root, low, high) def _range_sum_recursive(self, node: TreeNode, low: int, high: int) -> int: if node is None: return 0 total = 0 if low <= node.val <= high: total += node.val if node.val > low: total += self._range_sum_recursive(node.left, low, high) if node.val < high: total += self._range_sum_recursive(node.right, low, high) return total"},{"question":"# **Reverse a String Using Recursion** Background You are working on a project that involves various string manipulations. One of the tasks requires reversing a string. While there are several ways to reverse a string, you are specifically asked to implement this using recursion. Task Write a Python function `reverse_string(s: str) -> str` that takes a single string as input and returns the string reversed by using a recursive approach. Details: 1. **Input Format**: A single string `s`. 2. **Output Format**: A string which is the reversed version of the input string. Constraints: - The function should raise a `TypeError` if the input is not a string. - The string can be of any length, including an empty string. Examples: ``` reverse_string(\\"hello\\") # \\"olleh\\" reverse_string(\\"world\\") # \\"dlrow\\" reverse_string(\\"a\\") # \\"a\\" reverse_string(\\"\\") # \\"\\" reverse_string(\\"ab\\") # \\"ba\\" reverse_string(123) # Raises TypeError ``` Notes: 1. The base case for the recursion should handle the empty string or a single character string. 2. Use concatenation to build the reversed string in the recursive calls. 3. Ensure that your function handles both typical and edge cases effectively.","solution":"def reverse_string(s: str) -> str: Reverses a string using recursion. if not isinstance(s, str): raise TypeError(\\"Input must be a string\\") if len(s) <= 1: return s return s[-1] + reverse_string(s[:-1])"},{"question":"# Coding Assessment Question **Context**: You are to implement a function that computes the factorial of an integer but avoids recursive depth limitations and optimizes for large integers. This is useful in combinatorial computations, algorithmic problem-solving, and where high precision is crucial for large factorials. Write a Python function `compute_factorial(n: int) -> int` to compute the factorial of a given non-negative integer. The function should avoid recursion and optimize for the handling of large numbers. **Function Signature**: ```python def compute_factorial(n: int) -> int: ``` **Input**: 1. `n`: an integer, the number for which the factorial is to be computed. It is guaranteed to be non-negative. **Output**: - Return an integer representing the factorial of the given number `n`. **Constraints**: - `0 <= n <= 100` **Example**: ```python assert compute_factorial(0) == 1 # 0! = 1 assert compute_factorial(5) == 120 # 5! = 120 assert compute_factorial(10) == 3628800 # 10! = 3628800 ``` **Additional Instructions**: 1. The function must be efficient and handle the given constraints without causing performance issues. 2. Consider using iterative approaches to avoid potential issues of stack overflow with recursion. 3. Large integer management should be handled using Python\'s built-in capabilities. Note: Factorials grow extremely quickly, so the function should be able to handle the large result sizes correctly.","solution":"def compute_factorial(n: int) -> int: Computes the factorial of a given non-negative integer n. This implementation avoids recursion to prevent stack overflow issues and optimizes for large integers. Parameters: n (int): A non-negative integer whose factorial is to be computed. Returns: int: The factorial of the given number n. if n == 0: return 1 factorial = 1 for i in range(1, n + 1): factorial *= i return factorial"},{"question":"# Context You are developing a library for matrix operations, and you need to implement a matrix class that can perform addition, subtraction, multiplication, and transpose operations efficiently. Each matrix is represented as a list of lists containing integers. # Task Implement the `Matrix` class. Method Details 1. **`__init__(self, data: list[list[int]])`** * Initializes the Matrix with the given 2D list of integers. * Ensures the matrix is well-formed (i.e., all rows have the same number of columns). * Raises a `ValueError` if the input matrix is not well-formed. 2. **`__add__(self, other: \\"Matrix\\") -> \\"Matrix\\"`** * Adds the current matrix with another matrix. * Raises a `ValueError` if the two matrices have different dimensions. 3. **`__sub__(self, other: \\"Matrix\\") -> \\"Matrix\\"`** * Subtracts another matrix from the current matrix. * Raises a `ValueError` if the two matrices have different dimensions. 4. **`__mul__(self, other: \\"Matrix\\") -> \\"Matrix\\"`** * Performs matrix multiplication with another matrix. * Raises a `ValueError` if the dimensions do not align for matrix multiplication. 5. **`transpose(self) -> \\"Matrix\\"`** * Returns the transpose of the current matrix. # Requirement Ensure your implementation of the `Matrix` class: * **Is robust**: checks for and handles incorrect inputs gracefully. * **Is efficient**: handles large matrices efficiently. * **Produces accurate results**: performs operations correctly based on matrix rules. # Input and Output * Input: * Two matrices for addition, subtraction, and multiplication operations, each represented as a list of lists containing integers. * A single matrix for the transpose operation. * Output: * A new matrix resulting from the specified operation (addition, subtraction, multiplication, transpose). # Example ```python M1 = Matrix([[1, 2], [3, 4]]) M2 = Matrix([[5, 6], [7, 8]]) print((M1 + M2).data) # Output: [[6, 8], [10, 12]] print((M1 - M2).data) # Output: [[-4, -4], [-4, -4]] print((M1 * M2).data) # Output: [[19, 22], [43, 50]] print(M1.transpose().data) # Output: [[1, 3], [2, 4]] ``` # Constraints * Matrix elements are integers. * Each matrix contains between (1 leq text{rows}, text{cols} leq 1000) elements. * Matrix dimensions for multiplication must align. **Note**: Make sure to handle the relevant edge cases and optimize for efficient computation where possible.","solution":"class Matrix: def __init__(self, data: list[list[int]]): Initializes the Matrix with the given 2D list of integers. # Validate matrix dimensions if not all(len(row) == len(data[0]) for row in data): raise ValueError(\\"All rows must have the same number of columns\\") self.data = data self.rows = len(data) self.cols = len(data[0]) def __add__(self, other: \\"Matrix\\") -> \\"Matrix\\": Adds the current matrix with another matrix if self.rows != other.rows or self.cols != other.cols: raise ValueError(\\"Matrices must have the same dimensions for addition\\") result = [ [self.data[i][j] + other.data[i][j] for j in range(self.cols)] for i in range(self.rows) ] return Matrix(result) def __sub__(self, other: \\"Matrix\\") -> \\"Matrix\\": Subtracts another matrix from the current matrix if self.rows != other.rows or self.cols != other.cols: raise ValueError(\\"Matrices must have the same dimensions for subtraction\\") result = [ [self.data[i][j] - other.data[i][j] for j in range(self.cols)] for i in range(self.rows) ] return Matrix(result) def __mul__(self, other: \\"Matrix\\") -> \\"Matrix\\": Performs matrix multiplication with another matrix if self.cols != other.rows: raise ValueError(\\"Number of columns of the first matrix must be equal to the number of rows of the second matrix\\") result = [ [ sum(self.data[i][k] * other.data[k][j] for k in range(self.cols)) for j in range(other.cols) ] for i in range(self.rows) ] return Matrix(result) def transpose(self) -> \\"Matrix\\": Returns the transpose of the current matrix result = [ [self.data[j][i] for j in range(self.rows)] for i in range(self.cols) ] return Matrix(result)"},{"question":"# Longest Increasing Path in a Matrix You are given an `M x N` matrix of integers. Find the length of the longest increasing path in the matrix. From each cell, you can either move to four directions: left, right, up, or down. You may not move diagonally or move outside the boundary. Function Signature ```python def longest_increasing_path(matrix: List[List[int]]) -> int: Returns the length of the longest increasing path in the matrix. ``` Input * `matrix` (List[List[int]]): A 2D list of integers representing the matrix. Output * Returns the length of the longest increasing path (int). Constraints * The matrix must be a list of lists where each inner list is of the same length. * Each cell contains an integer value. * The matrix size is guaranteed to be at least 1x1 and at most 200x200. Examples ```python assert longest_increasing_path([ [9, 9, 4], [6, 6, 8], [2, 1, 1] ]) == 4 assert longest_increasing_path([ [3, 4, 5], [3, 2, 6], [2, 2, 1] ]) == 4 assert longest_increasing_path([[1]]) == 1 ``` Scenario As a software engineer working on analyzing geographical data, you need to determine the longest increasing path in a given terrain matrix. This path represents a sequence of cells with strictly increasing elevation, which will help in identifying steepest hiking trails over the landscape. An optimal solution for finding the longest path will assist mountaineers in planning their routes efficiently.","solution":"from typing import List def longest_increasing_path(matrix: List[List[int]]) -> int: if not matrix or not matrix[0]: return 0 rows, cols = len(matrix), len(matrix[0]) dp = [[-1 for _ in range(cols)] for _ in range(rows)] def dfs(x, y): if dp[x][y] != -1: return dp[x][y] max_len = 1 for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]: nx, ny = x + dx, y + dy if 0 <= nx < rows and 0 <= ny < cols and matrix[nx][ny] > matrix[x][y]: max_len = max(max_len, 1 + dfs(nx, ny)) dp[x][y] = max_len return dp[x][y] max_path = 0 for i in range(rows): for j in range(cols): max_path = max(max_path, dfs(i, j)) return max_path"},{"question":"# Coding Problem You are required to implement a `DisjointSetUnion` (DSU) or Union-Find data structure that supports union and find operations efficiently. This data structure helps to keep track of a partition of a set into disjoint (non-overlapping) subsets. Specifications 1. **Class Structure**: Implement the `DisjointSetUnion` class with the following methods: - `__init__(self, size: int) -> None` - `find(self, x: int) -> int` - `union(self, x: int, y: int) -> None` - `connected(self, x: int, y: int) -> bool` - `count(self) -> int` 2. **DSU Properties**: - The DSU should maintain an efficient mechanism to find the representative/root of each element. - It should also allow merging of subsets and keeping them disjoint. 3. **Functionality**: - `__init__(size: int)`: Initializes the DSU with `size` elements (0 to size-1), each in their own subset. - `find(x: int) -> int`: Returns the representative of the subset containing `x`. - `union(x: int, y: int) -> None`: Merges the subsets containing `x` and `y`. - `connected(x: int, y: int) -> bool`: Returns `True` if `x` and `y` are in the same subset, otherwise `False`. - `count() -> int`: Returns the number of disjoint sets currently in the DSU. 4. **Constraints**: - `size` is an integer in the range `[1, 10^5]`. - `x` and `y` are indices in the range `[0, size-1]`. 5. **Performance Requirements**: - Both `find` and `union` operations should be optimized with path compression and union by rank, achieving nearly constant time complexity, specifically O(α(N)), where α is the inverse Ackermann function. Example Usage ```python dsu = DisjointSetUnion(5) assert dsu.count() == 5 dsu.union(0, 1) dsu.union(1, 2) assert dsu.connected(0, 2) == True assert dsu.connected(0, 3) == False assert dsu.count() == 3 dsu.union(3, 4) assert dsu.connected(3, 4) == True assert dsu.count() == 2 dsu.union(2, 3) assert dsu.connected(0, 4) == True assert dsu.count() == 1 ``` Notes * Make sure to handle edge cases such as merging already connected elements appropriately.","solution":"class DisjointSetUnion: def __init__(self, size: int) -> None: self.parent = list(range(size)) self.rank = [0] * size self.size = size self.count_sets = size def find(self, x: int) -> int: if self.parent[x] != x: self.parent[x] = self.find(self.parent[x]) # Path compression return self.parent[x] def union(self, x: int, y: int) -> None: rootX = self.find(x) rootY = self.find(y) if rootX != rootY: if self.rank[rootX] > self.rank[rootY]: self.parent[rootY] = rootX elif self.rank[rootX] < self.rank[rootY]: self.parent[rootX] = rootY else: self.parent[rootY] = rootX self.rank[rootX] += 1 self.count_sets -= 1 def connected(self, x: int, y: int) -> bool: return self.find(x) == self.find(y) def count(self) -> int: return self.count_sets"},{"question":"# Question: Neural Network From Scratch In this task, you will implement a simple neural network with forward and backward propagation. Understanding and implementing these mechanisms are crucial for building and optimizing neural network models. Objectives: 1. Implement a simple feedforward neural network capable of binary classification. 2. Implement both forward propagation for prediction and backward propagation for training. 3. Use the Sigmoid activation function and Binary Cross-Entropy loss for training the network. Network Structure: - 1 input layer with `n` features - 1 hidden layer with `h` units - 1 output layer with 1 unit (for binary classification) Function Specifications: **Initialize Parameters** ```python def initialize_parameters(n_features: int, n_hidden_units: int) -> dict: Initialize the parameters of the network. Parameters: - n_features: Number of features in the input data - n_hidden_units: Number of units in the hidden layer Returns: - dict: Dictionary containing the initialized weights and biases ``` **Forward Propagation** ```python def forward_propagation(X: np.ndarray, parameters: dict) -> tuple: Perform forward propagation. Parameters: - X: Input data of shape (n_samples, n_features) - parameters: Dictionary containing weights and biases Returns: - A: Output of the neural network after applying the sigmoid activation - cache: Dictionary containing the intermediate values used for backward propagation ``` **Backward Propagation** ```python def backward_propagation(X: np.ndarray, y: np.ndarray, cache: dict, parameters: dict) -> dict: Perform backward propagation. Parameters: - X: Input data of shape (n_samples, n_features) - y: True binary labels of shape (n_samples,) - cache: Dictionary containing the intermediate values from forward propagation - parameters: Dictionary containing weights and biases Returns: - dict: Dictionary containing the gradients with respect to weights and biases ``` **Update Parameters** ```python def update_parameters(parameters: dict, gradients: dict, learning_rate: float) -> dict: Update the parameters using the gradients. Parameters: - parameters: Dictionary containing weights and biases - gradients: Dictionary containing gradients with respect to weights and biases - learning_rate: Learning rate for gradient descent Returns: - dict: Dictionary containing the updated parameters ``` Constraints: 1. Ensure that input arrays (`X` and `y`) are numpy arrays. 2. Handle mismatched lengths or shapes of input arrays using appropriate error messages. 3. Ensure values in `y` are properly formatted as binary labels (0 or 1). 4. Proper vectorization of operations should be implemented for efficient computation. Example Usage: ```python # Example values X = np.array([[0.2, 0.5], [0.1, 0.8], [0.4, 0.2]]) y = np.array([1, 0, 1]) # Initialize parameters parameters = initialize_parameters(n_features=2, n_hidden_units=3) # Forward propagation A, cache = forward_propagation(X, parameters) # Backward propagation gradients = backward_propagation(X, y, cache, parameters) # Update parameters parameters = update_parameters(parameters, gradients, learning_rate=0.01) print(parameters) ``` You need to write these functions from scratch. You are encouraged to use vectorized numpy operations for efficient computation. Good luck!","solution":"import numpy as np def initialize_parameters(n_features: int, n_hidden_units: int) -> dict: Initialize the parameters of the network. Parameters: - n_features: Number of features in the input data - n_hidden_units: Number of units in the hidden layer Returns: - dict: Dictionary containing the initialized weights and biases np.random.seed(1) W1 = np.random.randn(n_hidden_units, n_features) * 0.01 b1 = np.zeros((n_hidden_units, 1)) W2 = np.random.randn(1, n_hidden_units) * 0.01 b2 = np.zeros((1, 1)) return {\\"W1\\": W1, \\"b1\\": b1, \\"W2\\": W2, \\"b2\\": b2} def sigmoid(z): return 1 / (1 + np.exp(-z)) def forward_propagation(X: np.ndarray, parameters: dict) -> tuple: Perform forward propagation. Parameters: - X: Input data of shape (n_samples, n_features) - parameters: Dictionary containing weights and biases Returns: - A: Output of the neural network after applying the sigmoid activation - cache: Dictionary containing the intermediate values used for backward propagation W1 = parameters[\'W1\'] b1 = parameters[\'b1\'] W2 = parameters[\'W2\'] b2 = parameters[\'b2\'] Z1 = np.dot(W1, X.T) + b1 A1 = np.tanh(Z1) Z2 = np.dot(W2, A1) + b2 A = sigmoid(Z2) cache = {\'Z1\': Z1, \'A1\': A1, \'Z2\': Z2, \'A\': A} return A, cache def backward_propagation(X: np.ndarray, y: np.ndarray, cache: dict, parameters: dict) -> dict: Perform backward propagation. Parameters: - X: Input data of shape (n_samples, n_features) - y: True binary labels of shape (n_samples,) - cache: Dictionary containing the intermediate values from forward propagation - parameters: Dictionary containing weights and biases Returns: - dict: Dictionary containing the gradients with respect to weights and biases m = X.shape[0] W1, W2 = parameters[\'W1\'], parameters[\'W2\'] A1, A = cache[\'A1\'], cache[\'A\'] dZ2 = A - y.reshape(1, -1) dW2 = (1 / m) * np.dot(dZ2, A1.T) db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True) dA1 = np.dot(W2.T, dZ2) dZ1 = dA1 * (1 - np.power(A1, 2)) dW1 = (1 / m) * np.dot(dZ1, X) db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True) gradients = {\\"dW1\\": dW1, \\"db1\\": db1, \\"dW2\\": dW2, \\"db2\\": db2} return gradients def update_parameters(parameters: dict, gradients: dict, learning_rate: float) -> dict: Update the parameters using the gradients. Parameters: - parameters: Dictionary containing weights and biases - gradients: Dictionary containing gradients with respect to weights and biases - learning_rate: Learning rate for gradient descent Returns: - dict: Dictionary containing the updated parameters parameters[\'W1\'] -= learning_rate * gradients[\'dW1\'] parameters[\'b1\'] -= learning_rate * gradients[\'db1\'] parameters[\'W2\'] -= learning_rate * gradients[\'dW2\'] parameters[\'b2\'] -= learning_rate * gradients[\'db2\'] return parameters"},{"question":"# Coding Assessment Question **Problem Context**: You are developing a small utility function to reverse the words in a given sentence. The function should be able to handle multiple spaces between words and leading or trailing spaces properly. For the purpose of this problem, a word is defined as a sequence of non-space characters. **Task**: Create a function `reverse_words(sentence: str) -> str` that takes a string input and returns a new string with the words in reverse order. The function should ignore any additional spaces and ensure words are properly separated by a single space in the output. **Function Signature**: ```python def reverse_words(sentence: str) -> str: pass ``` **Constraints**: 1. The function should handle an empty string and return an empty string. 2. Multiple spaces between words should be reduced to a single space. 3. Leading and trailing spaces should be removed in the final output. **Input Format**: - A single string of words separated by spaces. The length of the string will be between 0 and 1000 characters. **Output Format**: - A single string with words in reverse order, properly spaced. **Example**: ``` >>> reverse_words(\\" the sky is blue \\") \\"blue is sky the\\" >>> reverse_words(\\"hello world\\") \\"world hello\\" >>> reverse_words(\\"a good example\\") \\"example good a\\" >>> reverse_words(\\" \\") \\"\\" >>> reverse_words(\\"\\") \\"\\" ``` **Additional Task**: - Implement a `main` function to prompt user input, call the `reverse_words` function, and print the result. Ensure that inputs with mixed spaces are properly handled as per the described functionality. **Performance Requirements**: - The function should run in O(n) time complexity where n is the length of the input string, ensuring it efficiently processes even the upper limit of input sizes.","solution":"def reverse_words(sentence: str) -> str: Reverses the words in a given sentence. Handle leading, trailing, and multiple spaces. words = sentence.split() # Split the sentence by spaces to get the words reversed_words = \' \'.join(reversed(words)) # Reverse the list of words and join them with a single space return reversed_words"},{"question":"# Coding Challenge: Finding Rotated Array\'s Minimum Problem Statement You are given a sorted array that has been rotated at some unknown pivot. Your task is to find the minimum element in this rotated array. Write a function `find_min_in_rotated_array(arr: List[int]) -> int` that accepts a list of integers `arr` and returns the minimum element in the array. Input - `arr`: A list of integers representing a rotated sorted array. The array does not contain duplicates. (1 ≤ len(arr) ≤ 10^5, -10^4 ≤ arr[i] ≤ 10^4) Output - Returns the minimum element in the rotated array. Constraints 1. The solution should operate in O(log n) time complexity to efficiently handle large input sizes. 2. The input array length is between 1 and 100,000 inclusive. Example ```python assert find_min_in_rotated_array([3, 4, 5, 1, 2]) == 1 assert find_min_in_rotated_array([4, 5, 6, 7, 0, 1, 2]) == 0 assert find_min_in_rotated_array([11, 13, 15, 17]) == 11 ``` Detailed Steps 1. **Binary Search**: Implement binary search to efficiently find the minimum element. 2. **Pivot Identification**: Determine the point where the rotation occurred. 3. **Left and Right Pointers**: Utilize two pointers to narrow down the search space. 4. **Handling Sorted Segments**: Compare mid-element to determine which segment to discard. Good luck and Happy Coding!","solution":"from typing import List def find_min_in_rotated_array(arr: List[int]) -> int: This function finds the minimum element in a rotated sorted array. Parameters: arr (List[int]): A list of integers representing a rotated sorted array. Returns: int: The minimum element in the rotated array. left, right = 0, len(arr) - 1 while left < right: mid = (left + right) // 2 if arr[mid] > arr[right]: left = mid + 1 else: right = mid return arr[left]"},{"question":"# Problem Statement You are tasked with implementing a function that returns an array containing the first `n` terms of the Fibonacci sequence. The Fibonacci sequence is defined as follows: * The first term is 0. * The second term is 1. * Each subsequent term is the sum of the previous two terms. # Function Signature ```python def fibonacci_sequence(n: int) -> list: ``` # Input * A single integer `n`. # Output * A list of integers representing the first `n` terms of the Fibonacci sequence. # Constraints * The input `n` must be a non-negative integer. * If `n` is 0, the function should return an empty list. * If the input is a negative integer or not an integer, the function should raise appropriate exceptions: * `ValueError` for negative values. * `TypeError` for non-integer types. # Examples ```python fibonacci_sequence(0) => [] fibonacci_sequence(1) => [0] fibonacci_sequence(5) => [0, 1, 1, 2, 3] fibonacci_sequence(10) => [0, 1, 1, 2, 3, 5, 8, 13, 21, 34] ``` # Additional Information * You should handle edge cases, such as when `n` is 0 or 1. * Consider using an iterative approach rather than recursion to prevent stack overflow issues on large inputs. * Ensure your solution runs efficiently by avoiding redundant computations. # Implementation Challenge Make sure to validate the input types and values and raise appropriate exceptions. Additionally, try to explain in your comments or documentation your choice of implementation approach and how you maintain efficiency.","solution":"def fibonacci_sequence(n): if not isinstance(n, int): raise TypeError(\\"Input must be an integer.\\") if n < 0: raise ValueError(\\"Input must be a non-negative integer.\\") if n == 0: return [] if n == 1: return [0] sequence = [0, 1] for i in range(2, n): next_value = sequence[-1] + sequence[-2] sequence.append(next_value) return sequence"},{"question":"**Scenario**: Since you\'ve been hired as a software engineer for a logistics company, your first task is to optimize the delivery routes within a city grid. The city is represented as a 2D grid where each cell represents a block. Some blocks contain obstacles, and some are open roads. You need to design a navigation system that can compute the shortest path from a starting point to a destination within the city grid while avoiding obstacles. **Requirements**: 1. Implement a function `find_shortest_path` that takes in the city grid, the starting point, and the destination point. 2. Use the Breadth-First Search (BFS) algorithm to find the shortest path from the start to the destination. 3. The function should return the shortest path as a list of coordinates representing the route from start to finish. If there is no valid path, return an empty list. **Function Specifications**: - **find_shortest_path(grid, start, destination):** - Input: - `grid`: 2D list representing the city grid. Each element can be either 0 (open road) or 1 (obstacle). - `start`: Tuple representing the starting coordinates (row, col). - `destination`: Tuple representing the destination coordinates (row, col). - Output: List of tuples representing the coordinates of the shortest path from start to destination. If no path exists, return an empty list. **Constraints**: 1. The grid will be of size m x n (1 ≤ m, n ≤ 100). 2. The start and destination points will always be within the grid bounds. 3. Each move can only go to an adjacent block (up, down, left, right) that is not an obstacle. 4. Both the start and destination points will be on open roads (not obstacles). **Example**: ```python def find_shortest_path(grid, start, destination): from collections import deque if start == destination: return [start] m, n = len(grid), len(grid[0]) directions = [(0, 1), (1, 0), (0, -1), (-1, 0)] visited = set() queue = deque([(start, [start])]) visited.add(start) while queue: (x, y), path = queue.popleft() for dx, dy in directions: nx, ny = x + dx, y + dy if 0 <= nx < m and 0 <= ny < n and grid[nx][ny] == 0 and (nx, ny) not in visited: if (nx, ny) == destination: return path + [(nx, ny)] queue.append(((nx, ny), path + [(nx, ny)])) visited.add((nx, ny)) return [] # Example usage grid = [ [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 0, 0, 1, 0], [0, 1, 1, 1, 0], [0, 0, 0, 0, 0] ] start = (0, 0) destination = (4, 4) print(find_shortest_path(grid, start, destination)) # Output: [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)] ``` Analyze the grid and use the provided example to verify your function\'s correctness.","solution":"def find_shortest_path(grid, start, destination): from collections import deque if start == destination: return [start] m, n = len(grid), len(grid[0]) directions = [(0, 1), (1, 0), (0, -1), (-1, 0)] visited = set() queue = deque([(start, [start])]) visited.add(start) while queue: (x, y), path = queue.popleft() for dx, dy in directions: nx, ny = x + dx, y + dy if 0 <= nx < m and 0 <= ny < n and grid[nx][ny] == 0 and (nx, ny) not in visited: if (nx, ny) == destination: return path + [(nx, ny)] queue.append(((nx, ny), path + [(nx, ny)])) visited.add((nx, ny)) return []"},{"question":"# Problem Statement Write a function that takes a list of integers and returns a list containing the first and the last elements of this list. If the original list has less than two elements, the function should return the list as is. # Function Signature ```python def first_and_last_elements(lst: list) -> list: pass ``` # Input Format * `lst` - A list of integers with at least 0 elements. # Output Format * A list containing the first and the last elements of the input list. If the list has less than two elements, return the list itself. # Constraints * The length of the list will be in the range (0 leq text{len}(lst) leq 10^5) # Sample Usage and Expected Output ```python >>> first_and_last_elements([3, 8, 9, 15]) [3, 15] >>> first_and_last_elements([10]) [10] >>> first_and_last_elements([]) [] >>> first_and_last_elements([5, 23, 12, 99, 3]) [5, 3] ``` # Explanation The function should extract the first and the last elements of a list if the length of the list is greater than or equal to 2. For lists with fewer than two elements, the function should simply return the list itself.","solution":"def first_and_last_elements(lst: list) -> list: Returns a list containing the first and last elements of the input list. If the input list has fewer than two elements, returns the list itself. if len(lst) < 2: return lst return [lst[0], lst[-1]]"},{"question":"# Coding Assessment Question: Anagram Grouping Context: A large e-commerce platform wants to analyze customer reviews to improve the user experience and better understand customer feedback. They have noticed that many reviews contain variations of the same words, scrambled differently. To effectively analyze these reviews, they want to group words that are anagrams of each other together. You\'re tasked with creating a function that can help them achieve this by identifying and grouping anagrams from a given list of words. Your Task: Write a function called `group_anagrams` that: 1. **Takes a list of words** and: - Groups them into lists of anagrams. 2. **Returns** a list of these groups, where each group is a list containing words that are anagrams of each other. Function Signature: ```python def group_anagrams(words: list[str]) -> list[list[str]]: Groups a list of words into anagrams. :param words: A list of strings representing the input words. :return: A list of groups, each containing words which are anagrams of one another. Example: >>> group_anagrams([\\"eat\\", \\"tea\\", \\"tan\\", \\"ate\\", \\"nat\\", \\"bat\\"]) [[\\"eat\\", \\"tea\\", \\"ate\\"], [\\"tan\\", \\"nat\\"], [\\"bat\\"]] >>> group_anagrams([\\"listen\\", \\"silent\\", \\"enlist\\", \\"inlets\\", \\"google\\", \\"gogole\\"]) [[\\"listen\\", \\"silent\\", \\"enlist\\", \\"inlets\\"], [\\"google\\", \\"gogole\\"]] >>> group_anagrams([\\"hello\\", \\"world\\"]) [[\\"hello\\"], [\\"world\\"]] ``` # Constraints: * The length of each word will not exceed 100 characters. * Each list of words will contain between 1 and 1000 words. Implementation: Ensure your solution is efficient in time complexity for large lists and correctly handles any possible edge cases. Use appropriate data structures to facilitate quick grouping and retrieval of anagrams.","solution":"from collections import defaultdict def group_anagrams(words: list[str]) -> list[list[str]]: Groups a list of words into anagrams. :param words: A list of strings representing the input words. :return: A list of groups, each containing words which are anagrams of one another. anagram_map = defaultdict(list) for word in words: sorted_word = \'\'.join(sorted(word)) anagram_map[sorted_word].append(word) return list(anagram_map.values())"},{"question":"# Question: Longest Arithmetic Sequence You are to implement a function `longest_arithmetic_sequence(nums: List[int]) -> int` which finds the length of the longest arithmetic subsequence in a list of integers. An arithmetic sequence is a sequence of numbers such that the difference between any two consecutive terms is the same. # Inputs and Outputs: - **Input**: A list of integers `nums`. - **Output**: An integer representing the length of the longest arithmetic subsequence. # Constraints: 1. The input list must be non-empty. 2. The function should handle lists of various sizes, including very large lists efficiently. 3. If the list contains only one element, the output should be 1. 4. You must raise a `TypeError` with a meaningful message if the input is not a list of integers. # Examples: ```python longest_arithmetic_sequence([3, 6, 9, 12]) # Output: 4 longest_arithmetic_sequence([1, 7, 10, 15, 27, 29]) # Output: 3 longest_arithmetic_sequence([5, 5, 5, 5]) # Output: 4 longest_arithmetic_sequence([3]) # Output: 1 # Raises TypeError longest_arithmetic_sequence(\\"not a list\\") longest_arithmetic_sequence([1, 2, \\"three\\"]) ``` # Implementation Challenges: 1. Efficiently determining the longest arithmetic subsequence for large lists. 2. Handling input validation to ensure the list contains only integers. 3. Managing edge cases such as lists with one element or multiple identical elements.","solution":"def longest_arithmetic_sequence(nums: list) -> int: if not isinstance(nums, list): raise TypeError(\\"Input must be a list\\") if not all(isinstance(x, int) for x in nums): raise TypeError(\\"All elements of the list must be integers\\") if len(nums) == 0: raise ValueError(\\"List should not be empty\\") if len(nums) == 1: return 1 n = len(nums) longest = 1 dp = [{} for _ in range(n)] for i in range(1, n): for j in range(i): diff = nums[i] - nums[j] if diff in dp[j]: dp[i][diff] = dp[j][diff] + 1 else: dp[i][diff] = 2 longest = max(longest, dp[i][diff]) return longest"},{"question":"# Scenario As part of a cyber security tool, you need a function to verify if a given string is a valid globally unique identifier (GUID). A GUID is a 128-bit number used to uniquely identify information in computer systems, usually represented as a string in the format `8-4-4-4-12` where each segment is a set of hexadecimal characters. # Problem Statement Implement a function `is_valid_guid(guid: str) -> bool` that checks if the provided string is a properly formatted GUID. # Input and Output Formats * The function will receive a string `guid` as the input parameter. * The function will return a boolean `True` if the string is a valid GUID and `False` otherwise. # Constraints * The input string will have a maximum length of 50 characters, covering all reasonable cases including improper formatting, and leading and trailing spaces. * The function will be case insensitive. # Performance Requirements * The implementation should run in linear time complexity (O(n)), where (n) is the length of the string. # Example Cases ```python >>> is_valid_guid(\\"550e8400-e29b-41d4-a716-446655440000\\") True >>> is_valid_guid(\\"550e8400-E29B-41D4-A716-446655440000\\") True >>> is_valid_guid(\\"550e8400e29b41d4a716446655440000\\") False >>> is_valid_guid(\\"550e8400-e29b-41d4-a716-44665544000Z\\") False >>> is_valid_guid(\\"550e8400-e29b-41d4-a716-44665544000\\") False >>> is_valid_guid(\\" 550e8400-e29b-41d4-a716-446655440000 \\") True >>> is_valid_guid(\\"550e8400-e29b-41d4-a716-446655440000n\\") True ``` # Additional Notes * Ensure to trim any leading or trailing spaces before processing the input. * Validate that each segment adheres to its specified length in the format. * Consider different letter cases when validating hexadecimal characters (0-9, A-F).","solution":"import re def is_valid_guid(guid: str) -> bool: Checks if the provided string is a properly formatted GUID. A valid GUID has the format 8-4-4-4-12 where each segment is a set of hexadecimal characters (0-9, a-f, A-F). Args: guid (str): The string to be checked. Returns: bool: True if the string is a valid GUID, False otherwise. # Trim any leading or trailing spaces from the input guid = guid.strip() # Define the regex pattern for a valid GUID pattern = r\'^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\' # Check if the input matches the regex pattern return bool(re.match(pattern, guid))"},{"question":"# Coding Assessment Question Scenario You are developing a module for a productivity application where users can manage their to-do lists. One feature requested by users is the ability to format deadlines in a human-readable style. The deadlines are initially provided in ISO 8601 format (YYYY-MM-DDThh:mm:ssZ), and users would like these deadlines to be displayed in a more friendly format, such as \\"DD Month YYYY, hh:mm AM/PM\\", where month is the full month name. Task Your task is to implement the `format_deadline` function which converts a given ISO 8601 deadline string into the specified readable format. Requirements - The function should take one input, a string `deadline`. - Convert the deadline string from ISO 8601 format to \\"DD Month YYYY, hh:mm AM/PM\\". Input Format: - A single string `deadline` in ISO 8601 format. Output Format: - A single string representing the deadline in a human-readable format \\"DD Month YYYY, hh:mm AM/PM\\". Constraints: - Assume the input string always follows the ISO 8601 format. Example: ``` Input: \\"2023-11-05T14:30:00Z\\" Output: \\"05 November 2023, 02:30 PM\\" ``` Function Signature: ```python def format_deadline(deadline: str) -> str: pass ``` **Hint**: Consider using Python\'s `datetime` module for parsing and formatting date and time strings. Good luck!","solution":"from datetime import datetime def format_deadline(deadline: str) -> str: Converts an ISO 8601 deadline string into a human-readable format. Args: - deadline: str: a deadline string in ISO 8601 format Returns: - str: the deadline in \\"DD Month YYYY, hh:mm AM/PM\\" format # Parse the ISO 8601 formatted string to a datetime object dt = datetime.strptime(deadline, \'%Y-%m-%dT%H:%M:%SZ\') # Format the datetime object to the desired output format readable_format = dt.strftime(\'%d %B %Y, %I:%M %p\') return readable_format"},{"question":"# Question You need to implement a function that simulates the behavior of a simple cache for storing and retrieving data. The cache should have a specified capacity, and when the capacity is reached, it should evict the least recently used (LRU) item before inserting the new item. Requirements 1. The function should allow for the insertion of key-value pairs into the cache. 2. It should allow for the retrieval of values by key. 3. When inserting a new key-value pair into a cache that is at full capacity, evict the least recently used item and then insert the new item. 4. LRU is determined by the sequence of calls to insert and retrieve functions. 5. Add appropriate documentation and type hints to your function and classes. Function Signature ```python class LRUCache: def __init__(self, capacity: int): Initialize the LRU cache with a given capacity. :param capacity: An integer representing the maximum number of items the cache can hold. pass def put(self, key: int, value: int) -> None: Insert a key-value pair into the cache. If the cache is full, evict the least recently used item first. :param key: The key to be inserted. :param value: The value to be associated with the key. pass def get(self, key: int) -> int: Retrieve the value associated with the given key from the cache. Mark the key as recently used. :param key: The key whose value needs to be retrieved. :return: The value associated with the key if it exists, otherwise -1. pass ``` Input - `capacity`: An integer representing the capacity of the cache (1 <= capacity <= 1000). - Series of operations: A list of operations, where each operation is a list containing a string (\\"put\\" or \\"get\\") and the respective arguments. Output - For each \\"get\\" operation, return the value associated with the given key or -1 if the key is not found in the cache. - For each \\"put\\" operation, return nothing. Constraints - Ensure that the operations are executed efficiently, with an average time complexity of O(1) for both `put` and `get` operations. Example ```python cache = LRUCache(2) cache.put(1, 1) # Cache is {1=1} cache.put(2, 2) # Cache is {1=1, 2=2} print(cache.get(1)) # Returns 1 # Cache state remains {1=1, 2=2} cache.put(3, 3) # Cache is {1=1, 3=3} (2 is evicted because it is the least recently used) print(cache.get(2)) # Returns -1 # 2 has been evicted cache.put(4, 4) # Cache is {4=4, 3=3} (1 is evicted because it is now the least recently used) print(cache.get(1)) # Returns -1 # 1 has been evicted print(cache.get(3)) # Returns 3 # Cache is {3=3, 4=4} print(cache.get(4)) # Returns 4 # Cache is {3=3, 4=4} ``` Hints - Consider using an OrderedDict from the collections module to maintain the order of insertion and access. - Ensure efficient lookups and updates by maintaining the order in which items are accessed or added.","solution":"from collections import OrderedDict class LRUCache: def __init__(self, capacity: int): Initialize the LRU cache with a given capacity. :param capacity: An integer representing the maximum number of items the cache can hold. self.cache = OrderedDict() self.capacity = capacity def put(self, key: int, value: int) -> None: Insert a key-value pair into the cache. If the cache is full, evict the least recently used item first. :param key: The key to be inserted. :param value: The value to be associated with the key. if key in self.cache: self.cache.move_to_end(key) self.cache[key] = value if len(self.cache) > self.capacity: self.cache.popitem(last=False) def get(self, key: int) -> int: Retrieve the value associated with the given key from the cache. Mark the key as recently used. :param key: The key whose value needs to be retrieved. :return: The value associated with the key if it exists, otherwise -1. if key not in self.cache: return -1 self.cache.move_to_end(key) return self.cache[key]"},{"question":"# Question: Data Compression and Decompression Algorithm Your task is to implement two functions, one for compressing a string using Run-Length Encoding (RLE) and another for decompressing an RLE string. Function Specifications 1. **Function Signature** ```python def rle_compress(data: str) -> str: def rle_decompress(encoded: str) -> str: ``` 2. **Input** - `data` (for `rle_compress`): A string consisting of uppercase and lowercase alphabets. - `encoded` (for `rle_decompress`): A string that is the result of RLE compression. 3. **Output** - `rle_compress(data: str) -> str`: A compressed string where consecutive identical characters are replaced with a single character followed by the number of occurrences. - `rle_decompress(encoded: str) -> str`: The original string obtained by decompressing the RLE string. Constraints - The input strings (`data` and `encoded`) will only contain alphabets and digits. - The length of `data` will be between 1 and 1000. - The lengths of the decompressed strings from `encoded` will not exceed 1000 characters. - Assume well-formed input for `encoded` (i.e., no invalid RLE strings). Performance Requirements - Both functions should operate efficiently within the given constraints. Edge Cases to Consider - Single character strings. - Strings without consecutive identical characters. - Strings with maximum allowed length. Example ```python # Test case 1 for rle_compress data = \\"aaabbc\\" compressed = rle_compress(data) print(compressed) # Expected output: \\"a3b2c1\\" # Test case 2 for rle_compress data = \\"a\\" compressed = rle_compress(data) print(compressed) # Expected output: \\"a1\\" # Test case 1 for rle_decompress encoded = \\"a3b2c1\\" decompressed = rle_decompress(encoded) print(decompressed) # Expected output: \\"aaabbc\\" # Test case 2 for rle_decompress encoded = \\"a1\\" decompressed = rle_decompress(encoded) print(decompressed) # Expected output: \\"a\\" ``` Implement the `rle_compress` and `rle_decompress` functions to handle the compression and decompression of strings as specified.","solution":"def rle_compress(data: str) -> str: Compresses the given string using Run-Length Encoding (RLE). Args: - data (str): The string to be compressed. Returns: - str: The compressed string. if not data: return \\"\\" compressed = [] count = 1 for i in range(1, len(data)): if data[i] == data[i - 1]: count += 1 else: compressed.append(data[i - 1] + str(count)) count = 1 compressed.append(data[-1] + str(count)) return \'\'.join(compressed) def rle_decompress(encoded: str) -> str: Decompresses the given RLE string. Args: - encoded (str): The RLE encoded string. Returns: - str: The decompressed original string. if not encoded: return \\"\\" decompressed = [] i = 0 while i < len(encoded): char = encoded[i] num = \'\' i += 1 while i < len(encoded) and encoded[i].isdigit(): num += encoded[i] i += 1 decompressed.append(char * int(num)) return \'\'.join(decompressed)"},{"question":"# Coding Challenge **Problem Statement**: Write a function that accepts a list of integers and returns the list sorted in ascending order, but with the position of any zeros in the original list preserved. **Function Specifications**: Complete the function `sort_list_preserve_zeros(arr: list[int]) -> list[int]` which takes in the following parameter: - `arr`: A list of integers containing at least one element. The function should return a new list where: - All non-zero integers are sorted in ascending order. - Zeros remain in their original positions. **Input Constraints**: - The elements in `arr` are integers. - The length of `arr` is between 1 and 1000. - The values in `arr` are between -10^6 and 10^6. **Output**: - A list of integers, sorted as per the above-stated rules. **Example**: ```python assert sort_list_preserve_zeros([5, 0, 3, 0, 9, -1]) == [-1, 0, 3, 0, 5, 9] assert sort_list_preserve_zeros([0, 34, -2, 0, 9, 0, 5]) == [0, -2, 5, 0, 9, 0, 34] assert sort_list_preserve_zeros([0, 0, 0]) == [0, 0, 0] assert sort_list_preserve_zeros([-3, 0, -1, 0, 2]) == [-3, 0, -1, 0, 2] ``` **Additional Specifications**: - You must solve the problem without changing the positions of the zeros. **Explanation**: Given the array `[5, 0, 3, 0, 9, -1]`, we sort the non-zero elements `[5, 3, 9, -1]` to get `[-1, 3, 5, 9]`. By retaining the positions of the zeros, we get the final output `[-1, 0, 3, 0, 5, 9]`. Given the array `[0, 34, -2, 0, 9, 0, 5]`, we sort the non-zero elements `[34, -2, 9, 5]` to get `[-2, 5, 9, 34]`. By retaining the positions of the zeros, we get the final output `[0, -2, 5, 0, 9, 0, 34]`.","solution":"def sort_list_preserve_zeros(arr): Sort the list of integers in ascending order while preserving the position of zeros. Args: arr (list[int]): The input list of integers. Returns: list[int]: The sorted list with zero positions preserved. non_zero_elements = [x for x in arr if x != 0] non_zero_elements.sort() result = [] non_zero_index = 0 for num in arr: if num == 0: result.append(0) else: result.append(non_zero_elements[non_zero_index]) non_zero_index += 1 return result"},{"question":"**Coding Challenge: Counting Paths in a Grid with Obstacles** You are given a `m x n` grid initialized with `0`s and `1`s. A grid cell is considered \\"empty\\" if it contains a `0` and \\"obstacle\\" if it contains a `1`. You start at the top-left corner of the grid (0,0) and you are required to find the number of distinct paths to the bottom-right corner of the grid (m-1, n-1) while avoiding obstacles. You can only move either down or right at any point in time. # Function Signature ```python def count_paths(grid: List[List[int]]) -> int: pass ``` # Input - A 2D list of integers `grid` (1 <= len(grid) <= 100, 1 <= len(grid[0]) <= 100), where each element is either `0` (empty) or `1` (obstacle). # Output - An integer representing the number of distinct paths from the top-left corner to the bottom-right corner avoiding obstacles. # Constraints - You can move either down or right at any point in time. - You cannot move through grid cells containing `1`s (obstacles). # Requirements - Your solution should handle grids with up to 100x100 cells efficiently. # Example ```python grid1 = [ [0, 0, 0], [0, 1, 0], [0, 0, 0] ] assert count_paths(grid1) == 2 grid2 = [ [0, 1], [0, 0] ] assert count_paths(grid2) == 1 ``` # Performance Your solution should efficiently handle the maximum constraints of the grid size using dynamic programming or any other suitable algorithmic approach for fast computation.","solution":"def count_paths(grid): m = len(grid) n = len(grid[0]) # If the start or end points are obstacles, return 0 if grid[0][0] == 1 or grid[m-1][n-1] == 1: return 0 # Create a 2D dp list initialized to 0 dp = [[0 for _ in range(n)] for _ in range(m)] # Initialize the starting point dp[0][0] = 1 # Fill the dp array for i in range(m): for j in range(n): if grid[i][j] == 1: dp[i][j] = 0 # No path through an obstacle else: if i > 0: dp[i][j] += dp[i-1][j] # Add paths from the top if j > 0: dp[i][j] += dp[i][j-1] # Add paths from the left # The result is the number of ways to reach the bottom-right corner return dp[m-1][n-1]"},{"question":"# Problem Statement A software development team is designing an automated testing framework with the aim of generating test cases based on predefined requirements. One of the components of this framework is a `TestGenerator` class that produces valid input combinations for the test cases, ensuring that all required conditions are met. Your task is to implement this `TestGenerator` class that can generate all possible valid input combinations based on given condition constraints. # Requirements 1. Implement the logic to generate valid input combinations. 2. Ensure the function handles various types of conditions (e.g., range constraints, inclusion/exclusion constraints). 3. Provide an option to limit the maximum number of generated test cases. 4. Generate the test cases in lexicographical order. # Function Signature ```python class TestGenerator: def __init__(self, conditions: dict, max_tests: int = None): # constructor def generate_tests(self) -> list: # generates and returns the list of test cases ``` # Input Constraints 1. **Conditions**: Dictionary of conditions where keys are the input variable names (strings) and values are the possible range or set of valid values. - Ranges are given as tuples `(min_value, max_value)` inclusive. - Sets are given as lists of valid values. 2. **Max Tests**: An optional integer specifying the maximum number of test cases to generate. If `None`, generate all possible combinations. # Output Return a list of all possible valid input combinations that meet the given condition constraints, ordered lexicographically. # Example **Test the class with the following:** ```python conditions = { \'a\': (1, 3), # a can be 1, 2, or 3 \'b\': [\'x\', \'y\'], # b can be \'x\' or \'y\' \'c\': (0, 1) # c can be 0 or 1 } test_generator = TestGenerator(conditions, max_tests=5) test_cases = test_generator.generate_tests() for i, test in enumerate(test_cases): print(f\\"Test Case {i+1}: {test}\\") ``` # Expected Output ``` Test Case 1: {\'a\': 1, \'b\': \'x\', \'c\': 0} Test Case 2: {\'a\': 1, \'b\': \'x\', \'c\': 1} Test Case 3: {\'a\': 1, \'b\': \'y\', \'c\': 0} Test Case 4: {\'a\': 1, \'b\': \'y\', \'c\': 1} Test Case 5: {\'a\': 2, \'b\': \'x\', \'c\': 0} ``` Implement the `TestGenerator` class to match the above specifications.","solution":"from itertools import product class TestGenerator: def __init__(self, conditions: dict, max_tests: int = None): self.conditions = conditions self.max_tests = max_tests def generate_range_values(self, range_tuple): return list(range(range_tuple[0], range_tuple[1] + 1)) def generate_tests(self) -> list: # Generate all possible values for each condition condition_values = [] for key in sorted(self.conditions.keys()): if isinstance(self.conditions[key], tuple): condition_values.append(self.generate_range_values(self.conditions[key])) elif isinstance(self.conditions[key], list): condition_values.append(self.conditions[key]) # Generate Cartesian product of all values all_combinations = list(product(*condition_values)) # Convert combinations into list of dictionaries test_cases = [] for combination in all_combinations: test_case = {} for i, key in enumerate(sorted(self.conditions.keys())): test_case[key] = combination[i] test_cases.append(test_case) # Optionally limit the number of test cases if self.max_tests is not None: test_cases = test_cases[:self.max_tests] return test_cases"},{"question":"# Problem Scenario You are designing a simple social media platform and need a mechanism to track and suggest friends to users based on mutual connections. Each user can have an arbitrary number of friends, and suggestions should be based on the number of mutual friends between two users. The goal is to implement features to add friendships and to suggest friends based on these mutual connections. # Task: Implement a class `SocialNetwork` that supports adding friendships between users and suggesting new friends based on mutual connections. # Key Requirements: 1. Add friendships between users. 2. Suggest friends for a user based on mutual friends. # Specifications: 1. **Class**: `SocialNetwork` 2. **Methods**: * `__init__(self)`: Initializes the social network. * `add_friendship(self, user1: str, user2: str)`: Adds a bi-directional friendship between `user1` and `user2`. * `suggest_friends(self, user: str) -> list[str]`: Suggests a list of users who are not already friends with `user` but share the most mutual friends with `user`. 3. **Input/Output**: * The `add_friendship` method takes two strings `user1` and `user2` representing user names. It establishes a friendship between these users. * The `suggest_friends` method takes a single string `user` and returns a list of suggested friends sorted by decreasing number of mutual friends. If multiple users have the same number of mutual friends, the order is arbitrary. # Constraints: * Friendships are bidirectional. * User names are unique and represented as non-empty strings. # Example: ```python # Example Usage network = SocialNetwork() network.add_friendship(\\"Alice\\", \\"Bob\\") network.add_friendship(\\"Alice\\", \\"Charlie\\") network.add_friendship(\\"Bob\\", \\"Diana\\") network.add_friendship(\\"Charlie\\", \\"Diana\\") network.add_friendship(\\"Diana\\", \\"Eve\\") suggestions_for_alice = network.suggest_friends(\\"Alice\\") # could return [\'Diana\', \'Eve\'] based on mutual friends suggestions_for_charlie = network.suggest_friends(\\"Charlie\\") # could return [\'Bob\', \'Eve\'] based on mutual friends ``` # Notes: * Ensure that users are not repeatedly suggested to each other. * Handle edge cases where users have no friends or no possible suggestions. * The system should efficiently manage friendships and suggest friends even as the network grows large.","solution":"class SocialNetwork: def __init__(self): self.friendships = {} def add_friendship(self, user1, user2): if user1 not in self.friendships: self.friendships[user1] = set() if user2 not in self.friendships: self.friendships[user2] = set() self.friendships[user1].add(user2) self.friendships[user2].add(user1) def suggest_friends(self, user): if user not in self.friendships: return [] user_friends = self.friendships[user] mutual_friend_count = {} for friend in user_friends: for friend_of_friend in self.friendships[friend]: if friend_of_friend != user and friend_of_friend not in user_friends: if friend_of_friend not in mutual_friend_count: mutual_friend_count[friend_of_friend] = 0 mutual_friend_count[friend_of_friend] += 1 suggestions = sorted(mutual_friend_count, key=lambda x: (-mutual_friend_count[x], x)) return suggestions"},{"question":"# Coding Assessment Question Context: You are working on a customer relationship management (CRM) system that needs to send personalized email campaigns to a large number of users. To improve the system\'s efficiency, you are tasked with implementing a batch processing feature that collects user data and sends emails in groups. Task: Enhance the provided `send_emails_batch` function to send emails in batches, handle possible exceptions, and log any failures for further inspection. Requirements: 1. **Function Signature**: ```python def send_emails_batch(users: list, batch_size: int, email_content: str) -> None: ``` 2. **Input**: * `users` (list): A list of user dictionaries, each containing `email` and `name`. * `batch_size` (int): The number of emails to send in each batch. * `email_content` (str): The content of the email to be sent. 3. **Output**: * None. The function sends emails and logs failures internally. 4. **Constraints**: * Handle up to 1000 users in total. * Ensure that each user\'s name is personalized within the email content. * Log any failed email attempts with the user’s email and error message. 5. **Performance Requirements**: * Efficiently process and send emails in batches to improve performance. * Minimize the overall time taken to send emails to all users. Example Usage: ```python users = [ {\\"email\\": \\"user1@example.com\\", \\"name\\": \\"John\\"}, {\\"email\\": \\"user2@example.com\\", \\"name\\": \\"Jane\\"}, # more users ] batch_size = 100 email_content = \\"Dear {name}, we have exciting news for you!\\" send_emails_batch(users, batch_size, email_content) # Expected Behavior # Emails are sent in batches of 100, each email being personalized. # Failures are logged with user email and error details. ``` Hints: * Utilize Python\'s `smtplib` for sending emails. * Consider using logging for recording failed email attempts. * Implement a simple template replacement using the `format` method. Good luck!","solution":"import smtplib from typing import List, Dict import logging # Configure logging to capture email failures logging.basicConfig(filename=\'email_failures.log\', level=logging.ERROR) def send_individual_email(to_email: str, content: str) -> None: # This function mocks the actual email sending process. # Replace this with actual smtplib or email sending logic. pass def send_emails_batch(users: List[Dict[str, str]], batch_size: int, email_content: str) -> None: Send emails in batches of specified size with personalized content. :param users: List of user dictionaries with \'email\' and \'name\' keys. :param batch_size: Number of emails to send in each batch. :param email_content: The content of the email to be sent. for i in range(0, len(users), batch_size): batch = users[i:i + batch_size] for user in batch: personalized_content = email_content.format(name=user[\'name\']) try: send_individual_email(user[\'email\'], personalized_content) except Exception as e: logging.error(f\\"Failed to send email to {user[\'email\']}: {e}\\")"},{"question":"# Question: Evaluating Mathematical Expressions from Strings Context: You have been assigned to help build a simple calculator that can evaluate mathematical expressions embedded within strings. This calculator should be able to handle integers and basic arithmetic operations, observing the correct order of operations (BODMAS/BIDMAS rules). Problem Statement: Write a function `evaluate_expression(expression: str) -> float` that evaluates a given string arithmetic expression and returns the result as a floating-point number. The function should handle addition (`+`), subtraction (`-`), multiplication (`*`), division (`/`), and parentheses for grouping. Input: - A single string `expression` containing the arithmetic expression. - The string may include spaces which should be ignored during evaluation. - The expression will only contain valid characters and operators as mentioned. Output: - A floating-point number representing the evaluated result of the arithmetic expression. Constraints: - If the input string is empty or contains only spaces, raise a `ValueError` with the message: \\"Empty expression passed for evaluation\\". - The division should be a floating-point division, even if both operands are integers. - Parentheses may be nested. Examples: ```python >>> evaluate_expression(\\"3 + 5 \\") 8.0 >>> evaluate_expression(\\"10 + 2 * 6\\") 22.0 >>> evaluate_expression(\\"100 * 2 + 12\\") 212.0 >>> evaluate_expression(\\"100 * ( 2 + 12 )\\") 1400.0 >>> evaluate_expression(\\"100 * ( 2 + 12 ) / 14\\") 100.0 >>> evaluate_expression(\\"\\") Traceback (most recent call last): ... ValueError: Empty expression passed for evaluation >>> evaluate_expression(\\" \\") Traceback (most recent call last): ... ValueError: Empty expression passed for evaluation ``` Notes: - You may assume the input string is always properly formatted and contains no invalid characters. - Ensure that your implementation handles operator precedence and parentheses correctly. - The evaluated result should always be a floating-point number, even if it is a whole number.","solution":"def evaluate_expression(expression: str) -> float: import operator import re # Define necessary operators and functions operators = { \'+\': (1, operator.add), \'-\': (1, operator.sub), \'*\': (2, operator.mul), \'/\': (2, operator.truediv) } def parse_expression(expression: str): # Tokenize the string skipping spaces tokens = re.findall(r\'d+.?d*|[+-*/()]\', expression.replace(\' \', \'\')) return tokens def shunting_yard(parsed_expression): stack = [] output = [] for token in parsed_expression: if re.match(r\'d\', token): output.append(float(token)) elif token in operators: while (stack and stack[-1] != \'(\' and operators[stack[-1]][0] >= operators[token][0]): output.append(stack.pop()) stack.append(token) elif token == \'(\': stack.append(token) elif token == \')\': while stack and stack[-1] != \'(\': output.append(stack.pop()) stack.pop() while stack: output.append(stack.pop()) return output def evaluate_rpn(rpn): stack = [] for token in rpn: if token in operators: b = stack.pop() a = stack.pop() stack.append(operators[token][1](a, b)) else: stack.append(token) return stack[0] expression = expression.strip() if not expression: raise ValueError(\\"Empty expression passed for evaluation\\") parsed_expression = parse_expression(expression) rpn = shunting_yard(parsed_expression) result = evaluate_rpn(rpn) return float(result)"},{"question":"# **Question: Implement a Customizable Sorting Algorithm for Large Data Sets** Your task is to build and implement a customizable sorting algorithm optimized for large data sets. The sorting algorithm should be flexible, allowing various configuration options through user input. **Requirements:** 1. **Algorithm Structure**: - Implement the `CustomSort` class. - The algorithm must support multiple sorting methods like quick sort, merge sort, and heap sort. - The algorithm should include an option to sort in either ascending or descending order. 2. **Function Implementation**: - `select_sorting_method(method: str)`: Sets the sorting method to use (e.g., \'quick\', \'merge\', \'heap\'). - `set_order(order: str)`: Specifies the order of sorting (either \'ascending\' or \'descending\'). - `sort(data: list)`: Performs the sort on the input data list according to the selected method and order. 3. **I/O Specifications**: - **Input**: - Data (`data`): A list of numerical values to be sorted. - Sorting method (`method`): A string denoting the sorting algorithm (\'quick\', \'merge\', \'heap\'). - Order (`order`): A string representing the sort order (\'ascending\' or \'descending\'). - **Output**: - A sorted list of numerical values based on the provided sorting method and order. **Constraints**: - The algorithm must handle lists with up to 1,000,000 numerical values. - Optimize for time and space complexity to ensure efficiency with large data sets. # Example Usage: ```python # Initialize and configure the sorting algorithm custom_sort = CustomSort() # Select sorting method and order custom_sort.select_sorting_method(\'merge\') custom_sort.set_order(\'ascending\') # Sample data to be sorted data = [10, 7, 8, 9, 1, 5, 3, 4, 2, 6] # Perform sorting sorted_data = custom_sort.sort(data) print(sorted_data) ``` # Example Output: ``` [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ``` In the example above, you should design the class methods to ensure flexibility and efficiency when sorting large lists. Evaluate the performance of your sorting algorithm and make adjustments when necessary to optimize for speed and accuracy across different sorts and orders.","solution":"class CustomSort: def __init__(self): self.sorting_method = \'quick\' # default sorting method self.order = \'ascending\' # default order def select_sorting_method(self, method: str): if method in [\'quick\', \'merge\', \'heap\']: self.sorting_method = method else: raise ValueError(\\"Invalid sorting method. Choose from \'quick\', \'merge\', \'heap\'.\\") def set_order(self, order: str): if order in [\'ascending\', \'descending\']: self.order = order else: raise ValueError(\\"Invalid order. Choose from \'ascending\' or \'descending\'.\\") def sort(self, data: list): if self.sorting_method == \'quick\': sorted_data = self.quick_sort(data) elif self.sorting_method == \'merge\': sorted_data = self.merge_sort(data) elif self.sorting_method == \'heap\': sorted_data = self.heap_sort(data) if self.order == \'descending\': return sorted_data[::-1] return sorted_data def quick_sort(self, data): if len(data) <= 1: return data pivot = data[len(data) // 2] left = [x for x in data if x < pivot] middle = [x for x in data if x == pivot] right = [x for x in data if x > pivot] return self.quick_sort(left) + middle + self.quick_sort(right) def merge_sort(self, data): if len(data) <= 1: return data mid = len(data) // 2 left = self.merge_sort(data[:mid]) right = self.merge_sort(data[mid:]) return self.merge(left, right) def merge(self, left, right): result = [] while left and right: if left[0] < right[0]: result.append(left.pop(0)) else: result.append(right.pop(0)) result.extend(left if left else right) return result def heap_sort(self, data): import heapq heapq.heapify(data) return [heapq.heappop(data) for _ in range(len(data))]"},{"question":"# City Walk Simulation - Optimized Pathfinding You are tasked with improving the efficiency of a city walk simulation, focusing on the pathfinding algorithm. The provided `city_walk.py` script simulates walking through a city represented as a grid, and you need to enhance the pathfinding algorithm to find the shortest path from a start to an end point. Problem Statement Enhance the `find_shortest_path` function to optimize the pathfinding process. The current implementation uses a basic breadth-first search (BFS) algorithm. You need to modify it to use A* (A-star) search instead, ensuring better performance in finding the shortest path. # Function Signature ```python def find_shortest_path(grid, start, end): Optimized implementation of finding the shortest path using A* algorithm. :param grid: 2D list representing the city grid, where 0 is a passable cell and 1 is an obstacle. :param start: Tuple (x, y) coordinates of the starting point. :param end: Tuple (x, y) coordinates of the endpoint. :return: List of tuples representing the path from start to end, or an empty list if no path is found. pass ``` # Requirements 1. **Function Implementation**: Implement the `find_shortest_path` function using the A* search algorithm. This function should take a grid, a start tuple, and an end tuple as input and return the shortest path as a list of coordinates. 2. **Performance Improvement**: Ensure optimizations are in place to reduce the computational effort required to find the shortest path. 3. **Correctness**: Ensure the function correctly navigates through the grid, avoiding obstacles and evaluating the optimal path. 4. **Constraints**: The grid cells are either 0 (passable) or 1 (obstacle). # Input - `grid`: 2D list where each cell is either 0 (passable) or 1 (obstacle). - `start`: Tuple (x, y) indicating the starting point coordinates. - `end`: Tuple (x, y) indicating the endpoint coordinates. Example Input ```python grid = [ [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 0, 0, 1, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0] ] start = (0, 0) end = (4, 4) ``` # Output - Return a list of coordinates representing the path from start to end, or an empty list if no path is found. Example Output ```python [(0, 0), (1, 0), (2, 0), (2, 1), (2, 2), (3, 2), (4, 2), (4, 3), (4, 4)] ``` # Constraints - The grid dimensions (number of rows `m` and columns `n`) will not exceed 100x100. - The start and end points will always be within the grid boundaries. - Ensure the solution is implemented such that it can handle the largest possible grid efficiently.","solution":"import heapq def heuristic(a, b): Calculates the Manhattan distance heuristic between point a and point b. return abs(a[0] - b[0]) + abs(a[1] - b[1]) def find_shortest_path(grid, start, end): Optimized implementation of finding the shortest path using A* algorithm. :param grid: 2D list representing the city grid, where 0 is a passable cell and 1 is an obstacle. :param start: Tuple (x, y) coordinates of the starting point. :param end: Tuple (x, y) coordinates of the endpoint. :return: List of tuples representing the path from start to end, or an empty list if no path is found. rows = len(grid) cols = len(grid[0]) if rows > 0 else 0 open_set = [] heapq.heappush(open_set, (0 + heuristic(start, end), start)) came_from = {} g_score = {start: 0} f_score = {start: heuristic(start, end)} while open_set: current = heapq.heappop(open_set)[1] if current == end: path = [] while current in came_from: path.append(current) current = came_from[current] path.append(start) path.reverse() return path neighbors = [(current[0]-1, current[1]), (current[0]+1, current[1]), (current[0], current[1]-1), (current[0], current[1]+1)] for neighbor in neighbors: if 0 <= neighbor[0] < rows and 0 <= neighbor[1] < cols and grid[neighbor[0]][neighbor[1]] == 0: tentative_g_score = g_score[current] + 1 if neighbor not in g_score or tentative_g_score < g_score[neighbor]: came_from[neighbor] = current g_score[neighbor] = tentative_g_score f_score[neighbor] = tentative_g_score + heuristic(neighbor, end) if neighbor not in [i[1] for i in open_set]: heapq.heappush(open_set, (f_score[neighbor], neighbor)) return []"},{"question":"# Coding Assessment Question Scenario: You are working on a text editor application that has a unique feature to allow highlighting specific phrases. The requirement is to capitalize the first letter of each word in a given sentence. Your task is to implement a function that takes a sentence string and capitalizes the first letter of each word. Problem Statement: Write a function `capitalize_first_letter(sentence: str) -> str` that capitalizes the first letter of each word in the given sentence. Input: * A string `sentence` containing one or more words separated by spaces. Output: * A string where the first letter of each word is capitalized, and the rest of the letters are in lower case. Constraints: * The input string will contain only alphabetic characters and spaces. * The input string will have at most 1000 characters. Examples: * For `sentence = \\"hello world\\"`, the function should return `\\"Hello World\\"`. * For `sentence = \\"this is a test sentence\\"`, the function should return `\\"This Is A Test Sentence\\"`. * For `sentence = \\"capitalize THIS sentence\\"`, the function should return `\\"Capitalize This Sentence\\"`. Implementation Notes: The function `capitalize_first_letter` should handle multiple spaces between words gracefully and ensure uniform capitalization. Make sure the code is efficient and easy to read. Write your implementation below: ```python def capitalize_first_letter(sentence: str) -> str: # Split the sentence into words words = sentence.split() # Capitalize the first letter of each word and join them back capitalized_words = [word.capitalize() for word in words] capitalized_sentence = \' \'.join(capitalized_words) return capitalized_sentence # Function call for illustration if __name__ == \\"__main__\\": print(capitalize_first_letter(\\"hello world\\")) print(capitalize_first_letter(\\"this is a test sentence\\")) print(capitalize_first_letter(\\"capitalize THIS sentence\\")) ```","solution":"def capitalize_first_letter(sentence: str) -> str: Capitalizes the first letter of each word in the given sentence. :param sentence: A string containing one or more words separated by spaces. :return: A string where the first letter of each word is capitalized. # Split the sentence into words words = sentence.split() # Capitalize the first letter of each word and join them back capitalized_words = [word.capitalize() for word in words] capitalized_sentence = \' \'.join(capitalized_words) return capitalized_sentence"},{"question":"# Question: Implement a Min-Heap Class with Extract-Min and Decrease-Key Operations Background A heap is a specialized tree-based data structure that satisfies the heap property. In a min-heap, for any given node `i`, the value of `i` is less than or equal to the value of its children. This property makes it useful for tasks like implementing priority queues. In this task, you will implement a min-heap class in Python that supports inserting elements, extracting the minimum element, and decreasing the value of a specific key. Task Create a Python class `MinHeap` that supports the following operations: 1. `insert(key)` - Inserts a key into the min-heap. 2. `extract_min()` - Removes and returns the minimum key from the min-heap. 3. `decrease_key(old_key, new_key)` - Decreases the value of an existing key (`old_key`) to a lower value (`new_key`). Additionally, ensure the `MinHeap` supports maintaining the heap property after any of these operations. Function Signatures The methods in the `MinHeap` class should have the following signatures: ```python class MinHeap: def __init__(self): # Initialize the heap pass def insert(self, key: int) -> None: # Insert a key into the heap pass def extract_min(self) -> int: # Extract and return the minimum key pass def decrease_key(self, old_key: int, new_key: int) -> None: # Decrease the value of a given key pass ``` Expected Input and Output 1. **Input**: * A series of method calls to insert keys, extract the minimum key, and decrease the value of specific keys. 2. **Output**: * The result of `extract_min()` calls and the heap structure after certain operations for validation. Constraints * Keys are unique integers. * Key values will be non-negative integers. Example 1. **Input**: ```python heap = MinHeap() heap.insert(10) heap.insert(5) heap.insert(20) heap.insert(3) print(heap.extract_min()) # Expected output: 3 heap.decrease_key(10, 2) print(heap.extract_min()) # Expected output: 2 ``` **Output**: ```python 3 2 ``` Notes * Define the helper methods `_heapify_up` and `_heapify_down` for maintaining the heap property after insertions and deletions. * For `decrease_key`, if the `new_key` is greater than or equal to `old_key`, throw an appropriate exception. * Verify that the input keys remain unique and handle possible errors gracefully. * Perform thorough testing to ensure the robustness and correctness of your implementation.","solution":"class MinHeap: def __init__(self): self.heap = [] def insert(self, key: int) -> None: self.heap.append(key) self._heapify_up(len(self.heap) - 1) def extract_min(self) -> int: if not self.heap: raise IndexError(\\"extract_min from an empty heap\\") self._swap(0, len(self.heap) - 1) min_elem = self.heap.pop() self._heapify_down(0) return min_elem def decrease_key(self, old_key: int, new_key: int) -> None: if new_key >= old_key: raise ValueError(\\"new_key must be smaller than old_key\\") try: index = self.heap.index(old_key) except ValueError: raise ValueError(\\"old_key not found in the heap\\") self.heap[index] = new_key self._heapify_up(index) def _heapify_up(self, index): parent_index = (index - 1) // 2 if index > 0 and self.heap[index] < self.heap[parent_index]: self._swap(index, parent_index) self._heapify_up(parent_index) def _heapify_down(self, index): smallest = index left_child = 2 * index + 1 right_child = 2 * index + 2 if left_child < len(self.heap) and self.heap[left_child] < self.heap[smallest]: smallest = left_child if right_child < len(self.heap) and self.heap[right_child] < self.heap[smallest]: smallest = right_child if smallest != index: self._swap(index, smallest) self._heapify_down(smallest) def _swap(self, i, j): self.heap[i], self.heap[j] = self.heap[j], self.heap[i]"},{"question":"# Coding Assessment Question You are tasked with processing a list of integers that represent audio signal amplitudes recorded over time. Your goal is to write two functions that analyze the signal to determine the highest peak in the signal and the duration of the longest flat segment where the signal remains constant. # Function Specifications Function 1: `find_highest_peak` **Input**: - A list of integers (amplitudes), representing the audio signal over time. The list has at least one element. **Output**: - An integer representing the highest peak in the signal. A peak is defined as an element that is greater than its immediate neighbors. **Constraints**: - Raise a `ValueError` with the message \\"Empty signal list provided!\\" if the input list is empty. Function 2: `longest_flat_segment` **Input**: - A list of integers (amplitudes), representing the audio signal over time. The list has at least one element. **Output**: - An integer representing the length of the longest flat segment where consecutive elements have the same value. **Constraints**: - Raise a `ValueError` with the message \\"Empty signal list provided!\\" if the input list is empty. # Examples ```python # Example for find_highest_peak print(find_highest_peak([3, 6, 5, 10, 7, 6, 4])) # Output: 10 try: print(find_highest_peak([])) except ValueError as e: print(e) # Output: Empty signal list provided! # Example for longest_flat_segment print(longest_flat_segment([3, 3, 3, 4, 4, 5, 5, 5, 5, 2, 2])) # Output: 4 try: print(longest_flat_segment([])) except ValueError as e: print(e) # Output: Empty signal list provided! ``` Note: Implement the functions ensuring linear time complexity and constant space complexity beyond the input list. ---","solution":"def find_highest_peak(signal): Finds the highest peak in the signal. A peak is defined as an element that is greater than its immediate neighbors. Parameters: signal (list): A list of integers representing the audio signal over time. Returns: int: The highest peak in the signal. Raises: ValueError: If the input list is empty. if not signal: raise ValueError(\\"Empty signal list provided!\\") n = len(signal) if n == 1: return signal[0] highest_peak = float(\'-inf\') for i in range(n): if (i == 0 and signal[i] > signal[i + 1]) or (i == n - 1 and signal[i] > signal[i - 1]) or (0 < i < n - 1 and signal[i] > signal[i - 1] and signal[i] > signal[i + 1]): highest_peak = max(highest_peak, signal[i]) return highest_peak def longest_flat_segment(signal): Finds the length of the longest flat segment where consecutive elements have the same value. Parameters: signal (list): A list of integers representing the audio signal over time. Returns: int: The length of the longest flat segment. Raises: ValueError: If the input list is empty. if not signal: raise ValueError(\\"Empty signal list provided!\\") longest_flat = 1 current_flat = 1 n = len(signal) for i in range(1, n): if signal[i] == signal[i - 1]: current_flat += 1 longest_flat = max(longest_flat, current_flat) else: current_flat = 1 return longest_flat"},{"question":"# Problem Statement You are tasked with implementing a simplified version of the k-means clustering algorithm. Your implementation will handle multi-dimensional data and support basic operations to compute centroids and assign clusters efficiently. Specifically, your algorithm will support initialization with random points and will iteratively refine the centroids. # Requirements 1. **Input**: - `data`: A two-dimensional numpy array of floating-point numbers (`n_samples x n_features`) representing the dataset. - `k` (int): The number of clusters. Default value: 3. - `max_iterations` (int): Maximum number of iterations for the algorithm to run. Default value: 100. - `tolerance` (float): A small number to determine if the centroids have stabilized. Default value: 1e-4. 2. **Output**: - You will create two methods, `fit(data)` and `predict(data)`. The `fit` method clusters the data into `k` clusters. The `predict` method outputs the cluster each data point belongs to. # Constraints - The number of rows in `data` will be at least 3 and less than or equal to 10,000. - The number of columns in `data` will be at least 1 and less than or equal to 100. - All entries in `data` are continuous values. # Example ```python # Sample inputs data = np.array([ [1.0, 2.0], [1.5, 1.8], [5.0, 8.0], [8.0, 8.0], [1.0, 0.6], [9.0, 11.0] ]) # Creating the k-means object kmeans = SimpleKMeans(k=2, max_iterations=50, tolerance=1e-3) kmeans.fit(data) # Predicting cluster for the sample input prediction = kmeans.predict(data) print(f\\"Cluster assignments: {prediction}\\") ``` # Instructions: 1. Implement the class `SimpleKMeans` with methods: - `__init__(self, k=3, max_iterations=100, tolerance=1e-4)`: Initialize attributes. - `initialize_centroids(self, data)`: Initialize centroids randomly from the data samples. - `compute_distances(self, data)`: Compute the distance between each data point and all centroids. - `assign_clusters(self, data)`: Assign each data point to the nearest centroid. - `update_centroids(self, data)`: Update centroid positions based on the mean of assigned data points. - `fit(self, data)`: Perform the k-means clustering algorithm, including initializing centroids, assigning clusters, and updating centroids iteratively. - `predict(self, data)`: Predict the closest cluster each sample in `data` belongs to. 2. Ensure efficient handling of distance calculations and centroid updates. 3. Include methods to check for convergence based on the tolerance level to stop the iterations when centroid positions stabilize.","solution":"import numpy as np class SimpleKMeans: def __init__(self, k=3, max_iterations=100, tolerance=1e-4): self.k = k self.max_iterations = max_iterations self.tolerance = tolerance self.centroids = None def initialize_centroids(self, data): np.random.seed(42) # For reproducibility indices = np.random.choice(data.shape[0], self.k, replace=False) self.centroids = data[indices] def compute_distances(self, data): distances = np.zeros((data.shape[0], self.k)) for i in range(self.k): distances[:, i] = np.linalg.norm(data - self.centroids[i], axis=1) return distances def assign_clusters(self, data): distances = self.compute_distances(data) return np.argmin(distances, axis=1) def update_centroids(self, data, assignments): new_centroids = np.zeros((self.k, data.shape[1])) for i in range(self.k): points = data[assignments == i] if points.size: new_centroids[i] = points.mean(axis=0) return new_centroids def fit(self, data): self.initialize_centroids(data) for _ in range(self.max_iterations): assignments = self.assign_clusters(data) new_centroids = self.update_centroids(data, assignments) if np.all(np.linalg.norm(new_centroids - self.centroids, axis=1) < self.tolerance): break self.centroids = new_centroids def predict(self, data): return self.assign_clusters(data)"},{"question":"# Scenario: You are working on an e-commerce platform that needs to implement a coupon system. Each coupon has a unique code and a discount value. The application needs to ensure that the generated coupon codes are unique and follow a specific format. # Task: Implement a function `generate_coupon(existing_codes: set, discount: float) -> str` that generates a unique coupon code which consists of 6 alphanumeric characters. The code should not already exist in the `existing_codes` set, and it should be stored in uppercase. If the discount value is not between 0 and 100 (inclusive), raise a `ValueError` exception. # Input: - `existing_codes` (set): A set of existing coupon codes. - `discount` (float): The discount percentage for the coupon. # Output: - `str`: The generated unique coupon code. # Constraints: - The generated coupon code must be a string of 6 alphanumeric characters in uppercase. - The coupon code must be unique and not present in the `existing_codes` set. - The discount percentage should be a float between 0 and 100 (inclusive). If not, raise a `ValueError` exception. # Example: ```plaintext Input: {\\"ABC123\\", \\"DEF456\\"}, 15.0 Output: \\"A1B2C3\\" (or any other unique 6-character alphanumeric code not in the provided set) Input: {\\"GHI789\\", \\"JKL012\\"}, 50.0 Output: \\"D4E5F6\\" (or any other unique 6-character alphanumeric code not in the provided set) Input: {\\"MNO345\\", \\"PQR678\\"}, 101.0 Output: \\"Discount value must be between 0 and 100 inclusive!\\", ValueError Exception Input: {\\"STU901\\", \\"VWX234\\"}, -5.0 Output: \\"Discount value must be between 0 and 100 inclusive!\\", ValueError Exception ```","solution":"import random import string def generate_coupon(existing_codes: set, discount: float) -> str: Generates a unique coupon code which consists of 6 alphanumeric characters in uppercase. The code should not already exist in the `existing_codes` set, and it should be stored in uppercase. If the discount value is not between 0 and 100 (inclusive), raises a ValueError exception. Parameters: existing_codes (set): A set of existing coupon codes. discount (float): The discount percentage for the coupon. Returns: str: The generated unique coupon code. if not (0 <= discount <= 100): raise ValueError(\\"Discount value must be between 0 and 100 inclusive!\\") def generate_code(): return \'\'.join(random.choices(string.ascii_uppercase + string.digits, k=6)) while True: new_code = generate_code() if new_code not in existing_codes: return new_code"},{"question":"# String Manipulation Coding Challenge Objective Implement a function `compress_string` that compresses a string such that \'aaabccddd\' becomes \'a3b1c2d3\'. Consecutive occurrences of the same character should be replaced with that character followed by the number of occurrences. # Requirements - The function should take a string as input and return a compressed version of the string. - If the compressed string is not smaller than the original string, return the original string. Input Format: - **input_string**: `str` - A non-empty string consisting of only lowercase letters (a-z). Output Format: - **str** - The compressed version of the input string or the original string if compression does not reduce the length. Constraints: - 1 ≤ length of input_string ≤ 10^4 Example: ```python input_string = \\"aaabccddd\\" print(compress_string(input_string)) # Output: \\"a3b1c2d3\\" input_string = \\"abcdef\\" print(compress_string(input_string)) # Output: \\"abcdef\\" (since compression does not reduce the length) ``` # Implementation Steps: 1. **Initialize Counters and Variables**: - Create a variable to store the current character and its count. - Use variables to maintain the running compressed string. 2. **Iterate Through the String**: - For each character in the string, compare it with the previous character. - If it is the same, increment the count. - If it is different, append the previous character and its count to the compressed string, then reset the count for the new character. 3. **Finalize the Result**: - Append the last counted character and its count to the compressed string. - Compare the length of the compressed string with the original string. - Return the shorter of the two. Edge Cases: - Single character input. - No consecutive repeating characters in the input string. - Entire string of a single character repeated many times. ```python def compress_string(input_string): if not input_string: return \\"\\" compressed = [] count = 1 current_char = input_string[0] for char in input_string[1:]: if char == current_char: count += 1 else: compressed.append(f\\"{current_char}{count}\\") current_char = char count = 1 compressed.append(f\\"{current_char}{count}\\") compressed_string = \'\'.join(compressed) if len(compressed_string) >= len(input_string): return input_string return compressed_string ```","solution":"def compress_string(input_string): if not input_string: return \\"\\" compressed = [] count = 1 current_char = input_string[0] for char in input_string[1:]: if char == current_char: count += 1 else: compressed.append(f\\"{current_char}{count}\\") current_char = char count = 1 compressed.append(f\\"{current_char}{count}\\") compressed_string = \'\'.join(compressed) if len(compressed_string) >= len(input_string): return input_string return compressed_string"},{"question":"# Question: Create a function `rotate_elements` that rotates the elements of a list to the right by a given number of positions. Each position shift should move every element one place to the right, and the last element should wrap around to the first position. **Function Signature**: ```python def rotate_elements(nums: List[int], k: int) -> List[int]: # Implement this function ``` # Requirements: 1. **Input Format**: - `nums`: A list of integers representing the elements to be rotated. - `k`: An integer representing the number of positions to rotate to the right. 2. **Output Format**: - A list of integers representing the rotated elements. # Constraints: - The list will have a length of `1` to `10^5`. - The integer `k` will be in the range `0` to `10^9`. - The elements in `nums` will be integers in the range `-10^9` to `10^9`. # Performance Requirements: - The algorithm should be optimized to handle large lists and large numbers of rotations efficiently. # Example: ```python rotated_list = rotate_elements([1, 2, 3, 4, 5], 2) print(rotated_list) # Output: [4, 5, 1, 2, 3] rotated_list = rotate_elements([3, 8, 9, 7, 6], 3) print(rotated_list) # Output: [9, 7, 6, 3, 8] ``` # Function Behavior: 1. The function should rotate the elements `k` times to the right. 2. Handle cases where `k` is larger than the length of the list by using `k % len(nums)` to minimize unnecessary rotations. 3. Return the rotated list. # Additional Notes: - Ensure edge cases such as an empty list or `k` being zero are handled gracefully. - Consider creating helper functions if necessary to maintain code clarity and modularity. # Hints: * Use list slicing to perform rotations more efficiently. * Utilize modulo operations to minimize redundant rotations.","solution":"from typing import List def rotate_elements(nums: List[int], k: int) -> List[int]: if not nums: return nums n = len(nums) k = k % n # effective rotations if k > n return nums[-k:] + nums[:-k]"},{"question":"# Question: Distinct Element Subarray **Context**: Finding subarrays with particular properties in a list of integers is a common problem in algorithmic challenges and technical interviews. It tests the understanding of sliding window techniques and efficient searching. **Problem Statement**: Write a function named `count_distinct_element_subarrays` that counts the number of contiguous subarrays (subsequences) that contain exactly `k` distinct elements. **Function Signature**: ```python def count_distinct_element_subarrays(nums: list, k: int) -> int: ``` **Input**: * `nums` (list of int): A list of integers where each integer represents an element of the list. * `k` (int): An integer representing the exact number of distinct elements a subarray must have to be counted. **Output**: * Returns an integer representing the number of contiguous subarrays containing exactly `k` distinct elements. **Constraints**: * `1 <= len(nums) <= 10^5` * `0 <= nums[i] <= 10^6` for all valid `i` * `1 <= k <= len(nums)` **Example**: ```python print(count_distinct_element_subarrays([1, 2, 1, 2, 3], 2)) # Output: 7 print(count_distinct_element_subarrays([1, 1, 1, 1], 1)) # Output: 10 ``` **Explanation**: - In the first example, subarrays with exactly 2 distinct elements are: `[1, 2]`, `[2, 1]`, `[1, 2]`, `[2, 3]`, `[1, 2, 1]`, `[2, 1, 2]`, `[1, 2, 3]`. Total 7 subarrays. - In the second example, subarrays with exactly 1 distinct element are: `[1]` (appears 4 times in single-element subarrays), `[1, 1]` (appears 3 times in two-element subarrays), `[1, 1, 1]` (appears 2 times in three-element subarrays), `[1, 1, 1, 1]` (appears once as a four-element subarray). Total 10 subarrays. **Verification**: 1. Handle edge cases like having fewer distinct elements than required. 2. Ensure the algorithm efficiently handles large lists and constraints. 3. Validate the uniqueness condition effectively in subarray calculations.","solution":"def count_distinct_element_subarrays(nums, k): from collections import Counter def at_most_k_distinct(nums, k): count = Counter() result = left = 0 for right in range(len(nums)): if count[nums[right]] == 0: k -= 1 count[nums[right]] += 1 while k < 0: count[nums[left]] -= 1 if count[nums[left]] == 0: k += 1 left += 1 result += right - left + 1 return result return at_most_k_distinct(nums, k) - at_most_k_distinct(nums, k - 1)"},{"question":"# Problem Statement Binary search is an efficient algorithm for finding an element in a sorted list. However, it can be challenging to implement correctly, especially when dealing with indexes and middle calculations in various edge cases. Your task is to implement a recursive version of the binary search algorithm. # Implement the Function ```python def binary_search_recursive(arr: list, target: int, left: int = 0, right: int = None) -> int: Perform a binary search to find the index of the target element in a sorted list. Parameters: - arr (list): A sorted list of integers where the search is to be performed. - target (int): The integer value to search for in the list. - left (int): The starting index of the list segment to be searched. - right (int): The ending index of the list segment to be searched. Defaults to the last index of the list. Returns: - index (int): The index of the target element in the list if found. If not found, returns -1. Example: >>> binary_search_recursive([1, 3, 5, 7, 9], 7) 3 >>> binary_search_recursive([1, 3, 5, 7, 9], 4) -1 >>> binary_search_recursive([2, 4, 6, 8, 10], 8, 1, 4) 3 >>> binary_search_recursive([2, 4, 6, 8, 10], 2, 1, 3) -1 Constraints: - The input list \'arr\' is sorted in non-decreasing order. - \'target\' can be any integer. - The list \'arr\' can contain duplicate elements, but the function should return the index of the first occurrence of \'target\'. - The function should implement the search in a recursive manner. pass ``` # Requirements: 1. **Initial Call Setup**: * If the right index is not provided (None), set it to the last index of the list. 2. **Search Logic**: * Calculate the middle index as ( text{mid} = left + frac{text{right} - left}{2} ). * Compare the target with the middle element and recursively call the function on the appropriate half of the list. 3. **Base Cases**: * If the left index exceeds the right index, return -1 indicating the target is not found within the segment. 4. **Duplicate Handling**: * Ensure to return the index of the first occurrence of the target element if duplicates are present by checking the left half first when equal. 5. **Edge Cases**: * Handle empty lists and cases where the target element is at the boundaries of the list correctly. Implement the `binary_search_recursive` function as described. Use the provided test cases to ensure your function works correctly.","solution":"def binary_search_recursive(arr: list, target: int, left: int = 0, right: int = None) -> int: Perform a binary search to find the index of the target element in a sorted list. Parameters: - arr (list): A sorted list of integers where the search is to be performed. - target (int): The integer value to search for in the list. - left (int): The starting index of the list segment to be searched. - right (int): The ending index of the list segment to be searched. Defaults to the last index of the list. Returns: - index (int): The index of the target element in the list if found. If not found, returns -1. if right is None: right = len(arr) - 1 if left > right: return -1 mid = left + (right - left) // 2 if arr[mid] == target: # To ensure we get the first occurrence, we continue searching in the left half if mid == left or arr[mid - 1] != target: return mid else: return binary_search_recursive(arr, target, left, mid - 1) elif arr[mid] > target: return binary_search_recursive(arr, target, left, mid - 1) else: return binary_search_recursive(arr, target, mid + 1, right)"},{"question":"# Constrained Random Integer Sum Scenario You are developing a feature for a gaming application that generates random sets of integers whose sum falls within a specific range. The purpose is to randomly generate scores for players but ensure they are within an acceptable threshold. To accomplish this, you need to implement a function that generates a list of random integers with a sum that falls within a defined range. The integers must also be constrained to a specific minimum and maximum value. Input and Output Requirements You need to implement the following function: 1. **`generate_random_sum(n: int, min_value: int, max_value: int, sum_range: tuple) -> list`**: * **Input**: - `n` (positive integer): Number of integers to generate. - `min_value` (integer): Minimum value of each generated integer (inclusive). - `max_value` (integer): Maximum value of each generated integer (inclusive). - `sum_range` (tuple of two integers): (min_sum, max_sum) defining the inclusive range for the sum of the generated integers. * **Output**: A list of `n` random integers that sum to a value within the `sum_range`. The function must validate that: - `n` is a positive integer. - `min_value` is less than or equal to `max_value`. - `sum_range` is a tuple of two integers where the first element (min_sum) is less than or equal to the second element (max_sum). - It is possible to generate `n` integers within the given `min_value`, `max_value` such that their sum is within the `sum_range`. Example Usage and Expected Results ```python print(generate_random_sum(5, 1, 10, (15, 25))) ``` Possible Output: `[3, 6, 5, 8, 2]` or `[4, 4, 4, 5, 4]` (but the sum should be within 15 to 25) ```python print(generate_random_sum(3, 2, 5, (10, 12))) ``` Possible Output: `[4, 3, 4]` or `[2, 5, 3]` (but the sum should be within 10 to 12) Constraints * `n > 0` * `min_value <= max_value` * `min_sum <= max_sum` * Ensure the function efficiently generates the required list even for large values of `n`. This assessment will test your ability to handle randomness, constraints and validation in your programming, focusing on accuracy and performance optimization.","solution":"import random def generate_random_sum(n: int, min_value: int, max_value: int, sum_range: tuple) -> list: Generates a list of `n` random integers such that their sum is within `sum_range`. Each integer is constrained to be between `min_value` (inclusive) and `max_value` (inclusive). if not isinstance(n, int) or n <= 0: raise ValueError(\\"`n` should be a positive integer.\\") if not isinstance(min_value, int) or not isinstance(max_value, int) or min_value > max_value: raise ValueError(\\"`min_value` should be less than or equal to `max_value`.\\") if ( not isinstance(sum_range, tuple) or len(sum_range) != 2 or not all(isinstance(i, int) for i in sum_range) or sum_range[0] > sum_range[1] ): raise ValueError(\\"`sum_range` should be a tuple of two integers (min_sum, max_sum) with min_sum <= max_sum.\\") min_sum, max_sum = sum_range min_possible_sum = n * min_value max_possible_sum = n * max_value if min_sum > max_possible_sum or max_sum < min_possible_sum: raise ValueError(\\"It\'s not possible to generate `n` integers with the given constraints to fit `sum_range`.\\") result = [] current_sum = 0 for _ in range(n): remaining_min_sum = (n - len(result) - 1) * min_value remaining_max_sum = (n - len(result) - 1) * max_value current_min_value = max(min_value, min_sum - current_sum - remaining_max_sum) current_max_value = min(max_value, max_sum - current_sum - remaining_min_sum) random_value = random.randint(current_min_value, current_max_value) result.append(random_value) current_sum += random_value return result"},{"question":"**Question**: Given a directed graph, implement a function to find all nodes with no incoming edges (i.e., zero in-degree) using an efficient graph traversal algorithm. # Details - **Input**: - `num_nodes`: An integer representing the number of nodes in the graph. - `edges`: A list of pairs of integers representing the directed edges in the graph. Each pair `(u, v)` indicates a directed edge from node `u` to node `v`. - **Output**: - A list of integers representing the nodes with no incoming edges. # Constraints: - `1 <= num_nodes <= 10^5` - `0 <= len(edges) <= 10^5` - The nodes are zero-indexed (i.e., nodes are numbered from 0 to `num_nodes - 1`). # Function Signature ```python def find_zero_in_degree_nodes(num_nodes: int, edges: list) -> list: pass ``` # Example ```python def test_find_zero_in_degree_nodes(): assert find_zero_in_degree_nodes(6, [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]) == [0] assert find_zero_in_degree_nodes(4, [(1, 2), (2, 3)]) == [0, 1] assert find_zero_in_degree_nodes(5, []) == [0, 1, 2, 3, 4] assert find_zero_in_degree_nodes(3, [(0, 1), (1, 2), (2, 0)]) == [] assert find_zero_in_degree_nodes(7, [(0, 1), (0, 2), (3, 2), (4, 5), (6, 5)]) == [0, 3, 4, 6] print(\\"All test cases pass\\") test_find_zero_in_degree_nodes() ``` **Requirements**: - Implement an efficient solution with time complexity approximately `O(num_nodes + len(edges))`. - Address edge cases such as nodes with no outgoing edges and graphs with cycles.","solution":"def find_zero_in_degree_nodes(num_nodes: int, edges: list) -> list: Function to find all nodes with zero in-degree in a directed graph. Parameters: num_nodes (int): number of nodes in the graph edges (list): list of pairs representing directed edges (u, v) Returns: list: list of nodes with zero in-degree # Initialize a list to keep track of in-degrees of all nodes in_degree = [0] * num_nodes # Iterate through edges and update the in-degree of destination nodes for u, v in edges: in_degree[v] += 1 # Collect all nodes with zero in-degree zero_in_degree_nodes = [node for node, degree in enumerate(in_degree) if degree == 0] return zero_in_degree_nodes"},{"question":"# Rotating Elements in an Array You are provided with an array of integers and a number indicating how many times the array should be rotated to the right. Implement a function `rotate_array()` that performs this operation and returns the rotated array. Function Signature ```python def rotate_array(arr: List[int], k: int) -> List[int]: ``` Input * `arr` (List[int]): A list of integers representing the array to be rotated. * `k` (int): The number of times to rotate the array to the right. Output * `List[int]`: The array after being rotated to the right `k` times. Constraints * The length of `arr` will be at least 1 and at most 1,000. * The elements of `arr` will be integers between -10^6 and 10^6. * `k` can be any non-negative integer. Example ```python arr = [1, 2, 3, 4, 5] k = 2 # Expected Output: [4, 5, 1, 2, 3] print(rotate_array(arr, k)) # [4, 5, 1, 2, 3] ``` Scenario Array rotation is a common operation used in various applications such as data analysis, cryptography, and game development. Implementing efficient rotation can enhance performance, especially when dealing with large datasets. This exercise will test your understanding of array manipulations and ability to optimize solutions for large-scale data operations.","solution":"from typing import List def rotate_array(arr: List[int], k: int) -> List[int]: Rotates the array to the right by k steps. Parameters: arr (List[int]): The array to rotate. k (int): The number of times to rotate the array to the right. Returns: List[int]: The rotated array. if not arr: return [] n = len(arr) k = k % n # Handle cases where k >= n return arr[-k:] + arr[:-k]"},{"question":"# Problem Statement You are given an integer array `nums` and an integer `target`. Your task is to implement a function that determines if there exist three distinct elements in `nums` whose sum is exactly equal to `target`. # Input and Output - **Input**: An integer array `nums` and an integer `target`. - **Output**: A boolean value `True` if there exist three distinct elements in `nums` whose sum equals `target`, otherwise `False`. # Constraints - The length of `nums` is between 3 and 1000. - Each element in `nums` is an integer between -10<sup>3</sup> and 10<sup>3</sup>. - The value of `target` is an integer between -10<sup>4</sup> and 10<sup>4</sup>. # Function Signature ```python def three_sum_to_target(nums: list[int], target: int) -> bool: pass ``` # Example ```python # Example 1 nums = [1, 2, 3, 4, 5] target = 9 print(three_sum_to_target(nums, target)) # Output should be True # Example 2 nums = [-1, 0, 1, 2] target = 2 print(three_sum_to_target(nums, target)) # Output should be True # Example 3 nums = [3, 7, 1, 9, 8] target = 10 print(three_sum_to_target(nums, target)) # Output should be False # Example 4 nums = [-2, -1, 0, 1, 2] target = 0 print(three_sum_to_target(nums, target)) # Output should be True ``` # Requirements 1. Implement the function using an efficient approach, ensuring a time complexity better than O(n^3). 2. Ensure the function handles edge cases such as arrays with all negative or all positive numbers. 3. The solution should not use the same element more than once within the sum.","solution":"def three_sum_to_target(nums: list[int], target: int) -> bool: nums.sort() n = len(nums) for i in range(n - 2): left = i + 1 right = n - 1 while left < right: total = nums[i] + nums[left] + nums[right] if total == target: return True elif total < target: left += 1 else: right -= 1 return False"},{"question":"# Convert Infix to Postfix Notation Using Shunting Yard Algorithm **Context**: In computer science, converting an arithmetic expression from infix notation to postfix notation (also known as Reverse Polish notation) can simplify the evaluation process. You need to implement an algorithm to convert a given arithmetic expression in infix notation to postfix notation using the Shunting Yard algorithm developed by Edsger Dijkstra. **Task**: Implement the function `infix_to_postfix(expression: str) -> str` that converts an arithmetic expression in infix notation to its equivalent postfix notation. **Function Signature**: ```python def infix_to_postfix(expression: str) -> str: ``` **Input**: - `expression` (str): A string representing an arithmetic expression in infix notation. The expression will contain: - Whole numbers (0-9) - Operators: `+`, `-`, `*`, `/` - Parentheses: `(`, `)` **Output**: - (str): A string representing the equivalent postfix notation of the given arithmetic expression. **Constraints**: - The input expression is guaranteed to be valid and contain only whole numbers and the specified operators and parentheses. - The input expression will not contain any spaces. **Examples**: ```python assert infix_to_postfix(\\"5 + 3\\") == \\"5 3 +\\" assert infix_to_postfix(\\"(9 - (2 + 9)) + (8 - 1)\\") == \\"9 2 9 + - 8 1 - +\\" assert infix_to_postfix(\\"((3 - 2) - (2 + 3)) + (2 - 4\\") == \\"3 2 - 2 3 + - 2 4 - +\\" ``` **Additional Notes**: 1. **Implement a custom Stack class** or use existing stack implementations from standard libraries, if allowed. 2. Ensure that your code handles nested parentheses and operator precedence correctly. 3. The implementation should handle operator associativity and precedence efficiently.","solution":"def infix_to_postfix(expression: str) -> str: precedence = {\'+\': 1, \'-\': 1, \'*\': 2, \'/\': 2} output = [] operators = [] def has_higher_precedence(op1, op2): return precedence[op1] > precedence.get(op2, 0) for char in expression: if char.isnumeric(): output.append(char) elif char == \'(\': operators.append(char) elif char == \')\': while operators and operators[-1] != \'(\': output.append(operators.pop()) operators.pop() # pop \'(\' else: while (operators and operators[-1] != \'(\' and not has_higher_precedence(char, operators[-1])): output.append(operators.pop()) operators.append(char) while operators: output.append(operators.pop()) return \' \'.join(output)"},{"question":"# Context The Fibonacci sequence is a series of numbers in which each number (after the first two) is the sum of the two preceding ones. The simplest Fibonacci sequence starts with 0 and 1, and continues as follows: 0, 1, 1, 2, 3, 5, 8, 13, 21, etc. # Problem Statement Using the provided `Node` class definition, you are required to implement a function `fibonacci_linked_list(n)` that constructs a singly linked list containing the first `n` Fibonacci numbers and returns the head of this linked list. # Function Signature ```python def fibonacci_linked_list(n: int) -> Node: pass ``` # Input and Output * **Input**: - `n` (int): The number of elements in the Fibonacci sequence to generate and store in the linked list. * **Output**: - `Node`: The head node of the linked list containing the first `n` Fibonacci numbers. # Constraints * `1 <= n <= 50` * Ensure the implementation is efficient in terms of both time and space complexity. # Example ```python # Suppose the Node class is defined as: class Node: def __init__(self, value=0, next=None): self.value = value self.next = next head = fibonacci_linked_list(5) # The resulting linked list should be Node(0) -> Node(1) -> Node(1) -> Node(2) -> Node(3) current = head while current: print(current.value) current = current.next # Expected output: # 0 # 1 # 1 # 2 # 3 ``` # Implementation Notes You will need to: 1. Create the `Node` class as shown above if not already provided. 2. Use a loop or iterative approach to calculate the Fibonacci numbers. 3. Create and link the nodes accordingly to reflect the Fibonacci sequence. Ensure that all nodes are correctly linked and handle edge cases such as `n = 1` properly.","solution":"class Node: def __init__(self, value=0, next=None): self.value = value self.next = next def fibonacci_linked_list(n): if n <= 0: return None # Initialize the first node head = Node(0) if n == 1: return head # Initialize the second node second = Node(1) head.next = second if n == 2: return head # Create the rest of the linked list prev = second current_value_minus_two = 0 current_value_minus_one = 1 for _ in range(2, n): current_value = current_value_minus_two + current_value_minus_one current_node = Node(current_value) prev.next = current_node prev = current_node current_value_minus_two = current_value_minus_one current_value_minus_one = current_value return head"},{"question":"# Problem Statement You are given a sorted list of integers. Write a function to find the starting and ending position of a given target value in the list. If the target is not found, return `[-1, -1]`. # Requirements: 1. Implement a function `search_range(nums: List[int], target: int) -> List[int]`. 2. The function should return the start and end indices of the target in the sorted list. Constraints: - `nums` will be a list of integers sorted in non-decreasing order. - The length of `nums` can be up to 10^5. - -10^9 ≤ nums[i], target ≤ 10^9 # Input: - A list of integers `nums` - An integer `target` # Output: - A list containing two integers indicating the start and end positions of the target value. # Example: ```python >>> search_range([5, 7, 7, 8, 8, 10], 8) [3, 4] >>> search_range([5, 7, 7, 8, 8, 10], 6) [-1, -1] >>> search_range([], 0) [-1, -1] >>> search_range([2, 2], 2) [0, 1] >>> search_range([1, 2, 3, 4, 5], 1) [0, 0] >>> search_range([1, 2, 3, 4, 5], 5) [4, 4] ``` # Performance Note: - The function should use an efficient approach with time complexity better than O(n). Binary search is recommended due to the sorted nature of the list. # Edge Cases to Consider: - An empty list `nums`. - The target is not in the list. - Multiple occurrences of the target in the list. - The target is at the beginning or end of the list.","solution":"from typing import List def search_range(nums: List[int], target: int) -> List[int]: Find the starting and ending position of a given target value in a sorted list of integers. If the target is not found, return [-1, -1]. def find_start(nums, target): Binary search to find the start index of the target. left, right = 0, len(nums) - 1 start = -1 while left <= right: mid = (left + right) // 2 if nums[mid] >= target: right = mid - 1 else: left = mid + 1 if nums[mid] == target: start = mid return start def find_end(nums, target): Binary search to find the end index of the target. left, right = 0, len(nums) - 1 end = -1 while left <= right: mid = (left + right) // 2 if nums[mid] <= target: left = mid + 1 else: right = mid - 1 if nums[mid] == target: end = mid return end start = find_start(nums, target) end = find_end(nums, target) return [start, end] if start != -1 and end != -1 else [-1, -1]"},{"question":"# Scenario You are developing a system to analyze strings and need to implement a function to check if a given string follows the rules of a \\"well-formed\\" parentheses sequence. A string is considered \\"well-formed\\" if every opening parenthesis has a corresponding closing parenthesis and the parentheses are properly nested. # Task Write a function `is_well_formed` to solve this problem. The function should determine if the given string of parentheses is well-formed. # Input/Output - **Input**: A single string `s` composed only of characters `(` and `)`. - **Output**: The function should return `True` if the string is well-formed, otherwise return `False`. # Constraints - The length of the string is between 1 and 10^4. - The string consists only of `(` and `)` characters. # Function Signature ```python def is_well_formed(s: str) -> bool: ``` # Example ```python print(is_well_formed(\\"()\\")) # Output: True print(is_well_formed(\\"(()))\\")) # Output: False print(is_well_formed(\\"()()\\")) # Output: True print(is_well_formed(\\"((())())\\")) # Output: True print(is_well_formed(\\")(\\")) # Output: False ``` # Notes Ensure that your solution efficiently handles the maximum input size and accurately checks for all possible cases of improper nesting and mismatched parentheses.","solution":"def is_well_formed(s: str) -> bool: This function checks if the given string of parentheses is well-formed. stack = [] for char in s: if char == \'(\': stack.append(char) elif char == \')\': if not stack: return False stack.pop() return len(stack) == 0"},{"question":"# Sentence Reverser **Context:** Manipulating strings is a common task in programming. One operation is reversing the order of words within a sentence, which is different from reversing individual characters. This is useful in various text-processing applications. **Task:** Write a function that takes a sentence as input and returns the sentence with the order of words reversed. The function should handle multiple spaces between words and trailing or leading spaces as well. **Function Signature:** ```python def reverse_sentence(sentence: str) -> str: ``` **Input:** - `sentence` (string): A sentence containing words separated by spaces. **Output:** - `str` : The sentence with the words in reverse order as a string. **Constraints:** - The input sentence can be up to 1000 characters in length. - Words are defined as contiguous sequences of non-space characters. **Example:** ```python >>> reverse_sentence(\\"the sky is blue\\") \\"blue is sky the\\" >>> reverse_sentence(\\" hello world \\") \\"world hello\\" ``` **Performance Requirements:** - The function should handle the string manipulation efficiently, without using large amounts of additional memory.","solution":"def reverse_sentence(sentence: str) -> str: Reverses the order of words in the given sentence. Args: sentence (str): A sentence containing words separated by spaces. Returns: str: The sentence with the words in reverse order. # Split the sentence based on spaces and filter out empty words words = [word for word in sentence.split(\' \') if word] # Reverse the list of words and join them with a single space reversed_sentence = \' \'.join(words[::-1]) return reversed_sentence"},{"question":"# Problem Statement You are given a string and an integer, k. Your task is to determine all unique permutations of the string of length k in lexicographical order. **Function Signature:** ```python def unique_permutations(s: str, k: int) -> List[str]: pass ``` # Inputs: 1. **s (str):** The input string. (1 ≤ len(s) ≤ 5) 2. **k (int):** The length of each permutation. (1 ≤ k ≤ len(s)) # Outputs: - **Returns (List[str]):** A sorted list of all unique permutations of length k in lexicographical order. # Constraints: - The input string may contain duplicate characters. - The input string will contain only lowercase English letters. - The solution must ensure that all permutations in the output list are unique and in lexicographical order. # Example: ```python print(unique_permutations(\\"aabc\\", 2)) # Output: [\'aa\', \'ab\', \'ac\', \'ba\', \'bc\', \'ca\', \'cb\'] print(unique_permutations(\\"abcd\\", 3)) # Output: [\'abc\', \'abd\', \'acd\', \'adb\', \'acd\', \'bca\', \'bcd\', \'cba\', \'cab\', \'cad\', \'dba\', \'dac\'] ``` Explanation: For the input string \\"aabc\\" and k=2, the function generates all unique 2-length permutations: \'aa\', \'ab\', \'ac\', \'ba\', \'bc\', \'ca\', \'cb\'. Notice how duplicated characters in the input string do not repeat in the output list. For the input string \\"abcd\\" and k=3, the function generates all unique 3-length permutations of distinct characters, also in lexicographical order.","solution":"from itertools import permutations from typing import List def unique_permutations(s: str, k: int) -> List[str]: Determine all unique permutations of the string of length k in lexicographical order. Args: s (str): The input string. k (int): The length of each permutation. Returns: List[str]: A sorted list of all unique permutations of length k in lexicographical order. # Generate all permutations of length k perm = permutations(s, k) # Convert to a set to remove duplicates perm_set = set(perm) # Convert back to a list and sort lexicographically unique_perm_list = sorted([\'\'.join(p) for p in perm_set]) return unique_perm_list"},{"question":"# Polynomial Differentiation Context In engineering and scientific calculations, differentiation of polynomial functions is frequently performed to determine the rate of change or to optimize functions. Your task is to automate the process of computing the derivative of a polynomial. Problem Statement You will write a function `polynomial_differentiation` which takes a list of coefficients representing a polynomial and returns a new list of coefficients representing the derivative of the polynomial. Input * `coefficients`: A list of integers or floats representing the coefficients of the polynomial. The index of each value in the list corresponds to the power of the corresponding term (i.e., the coefficient of x^i is at index i). Output * A list of integers or floats representing the coefficients of the derivative of the polynomial. Constraints 1. The input list will have at least one element. 2. The coefficients can be any real number. 3. The highest order of the polynomial is determined by the last non-zero coefficient. Example Usage ```python coefficients = [3, 0, 0, 2] # Represents the polynomial 3 + 2x^3 assert polynomial_differentiation(coefficients) == [0, 0, 6] # Represents the derivative 6x^2 coefficients = [5, 3] # Represents the polynomial 5 + 3x assert polynomial_differentiation(coefficients) == [3] # Represents the derivative 3 coefficients = [10] # Represents the polynomial 10 (a constant) assert polynomial_differentiation(coefficients) == [] # The derivative of a constant is 0 ``` Function Signature ```python def polynomial_differentiation(coefficients: List[Union[int, float]]) -> List[Union[int, float]]: pass ```","solution":"from typing import List, Union def polynomial_differentiation(coefficients: List[Union[int, float]]) -> List[Union[int, float]]: Returns the coefficients of the derivative of a polynomial. Args: coefficients: List of integers or floats representing the polynomial coefficients. Returns: List of integers or floats representing the derivative of the polynomial. derivative = [] for power, coeff in enumerate(coefficients): if power > 0: derivative.append(power * coeff) return derivative"},{"question":"# Coding Challenge: Implement Breadth-First Search for Graph Traversal Problem Statement: You are given an undirected graph represented by an adjacency list. Implement a function to perform a Breadth-First Search (BFS) starting from a given node. The function should return a list of nodes in the order they are visited. Function Signature: ```python def bfs_traversal(graph: dict, start_node: int) -> list: pass ``` Input: - `graph`: A dictionary where keys are node identifiers (integers) and values are lists of adjacent nodes. - `start_node`: An integer representing the node from which the BFS should start. Output: - A list of integers representing the nodes in the order they are visited. Constraints: - The graph will have at most 1000 nodes. - Each node identifier is a unique integer between 0 and 999. - There will be no self-loops. - The graph may be disconnected. - The graph can be empty (i.e., an empty dictionary). Example: ```python graph = { 0: [1, 2], 1: [0, 3, 4], 2: [0], 3: [1], 4: [1] } start_node = 0 print(bfs_traversal(graph, start_node)) # Output should be: # [0, 1, 2, 3, 4] ``` Hint: Use a queue to keep track of the nodes to be explored and a set to keep track of the visited nodes. Start by adding the start node to the queue and explore all adjacent nodes iteratively.","solution":"from collections import deque def bfs_traversal(graph: dict, start_node: int) -> list: Perform a Breadth-First Search (BFS) starting from a given node in an undirected graph. Parameters: graph : dict A dictionary representing the graph where keys are nodes and values are lists of adjacent nodes. start_node : int The node from which the BFS should start. Returns: list A list of nodes in the order they are visited. if not graph: return [] visited = set() queue = deque([start_node]) visited.add(start_node) traversal_order = [] while queue: node = queue.popleft() traversal_order.append(node) for neighbor in graph.get(node, []): if neighbor not in visited: visited.add(neighbor) queue.append(neighbor) return traversal_order"},{"question":"# Question: Implement a Simplified Mock File System You are tasked with creating a class that models a very simplified file system. This class should be able to handle creation of directories and files, and allow for reading and writing to the files. Requirements: * Implement a class named `MockFileSystem` with the following methods: * `mkdir(path: str) -> None`: * Creates a directory at the specified path. Nested directories should be created if they do not exist. * Example: `mkdir(\\"/a/b/c\\")` will create directories a, b, and c if they do not exist. * `addFile(path: str, content: str) -> None`: * Creates a file at the specified path with the given content. If the file already exists, it will overwrite the content. * Example: `addFile(\\"/a/b/d\\", \\"hello world\\")`. * `readFile(path: str) -> str`: * Returns the content of the file at the specified path. Raises a `FileNotFoundError` if the file does not exist. * Example: `readFile(\\"/a/b/d\\")` returns `\\"hello world\\"`. * `listDir(path: str) -> List[str]`: * Returns a list of all files and directories at the specified path. Raises a `FileNotFoundError` if the directory does not exist. * Example: `listDir(\\"/a/b\\")` returns `[\'c\', \'d\']`. * The class should: * Handle paths consistently using Unix-style forward slashes (`/`). * Raise appropriate exceptions with meaningful messages for invalid operations. * Have efficient time and space complexity, leveraging appropriate data structures for fast access and modification. Constraints: * All methods should assume the paths provided are absolute and valid. * The file system should be case-sensitive. * You may use any standard library data structures. Examples: ```python >>> fs = MockFileSystem() >>> fs.mkdir(\\"/a/b/c\\") >>> fs.addFile(\\"/a/b/d\\", \\"hello world\\") >>> fs.readFile(\\"/a/b/d\\") \'hello world\' >>> fs.listDir(\\"/a/b\\") [\'c\', \'d\'] >>> fs.readFile(\\"/a/b/e\\") Traceback (most recent call last): ... FileNotFoundError: File at path \'/a/b/e\' does not exist >>> fs.listDir(\\"/a/b/f\\") Traceback (most recent call last): ... FileNotFoundError: Directory at path \'/a/b/f\' does not exist ``` **Note**: Ensure your solution is robust and handles edge cases, such as deep nesting and large directories/files, efficiently.","solution":"class MockFileSystem: def __init__(self): self.fs = {} def mkdir(self, path: str) -> None: parts = path.strip(\'/\').split(\'/\') d = self.fs for part in parts: if part not in d: d[part] = {} d = d[part] def addFile(self, path: str, content: str) -> None: parts = path.strip(\'/\').split(\'/\') file_name = parts.pop() d = self.fs for part in parts: if part not in d: d[part] = {} d = d[part] d[file_name] = content def readFile(self, path: str) -> str: parts = path.strip(\'/\').split(\'/\') file_name = parts.pop() d = self.fs for part in parts: if part not in d: raise FileNotFoundError(f\\"File at path \'{path}\' does not exist\\") d = d[part] if file_name not in d: raise FileNotFoundError(f\\"File at path \'{path}\' does not exist\\") return d[file_name] def listDir(self, path: str) -> list: parts = path.strip(\'/\').split(\'/\') d = self.fs for part in parts: if part not in d: raise FileNotFoundError(f\\"Directory at path \'{path}\' does not exist\\") d = d[part] return list(d.keys())"},{"question":"# Knapsack Problem: Maximum Value Calculation Scenario You are tasked with solving the 0/1 Knapsack problem, a classic problem in combinatorial optimization. The problem asks, given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight does not exceed a given limit, and the total value is as large as possible. Problem Description Create a function `knapsack` that determines the maximum value that can be obtained from a collection of items, given the weight limitations of the knapsack. Input * `values` (List[int]): A list containing the values of each item. * `weights` (List[int]): A list containing the weights of each item. * `capacity` (int): Maximum weight capacity of the knapsack. Output * `max_value` (int): The maximum value that can be obtained under the given weight capacity. Constraints * The length of the `values` list and the `weights` list should be equal. * All values and weights are non-negative integers. * The capacity is a non-negative integer. Example ```python def knapsack(values: list[int], weights: list[int], capacity: int) -> int: # Your implementation here # Example usage: values = [60, 100, 120] weights = [10, 20, 30] capacity = 50 print(knapsack(values, weights, capacity)) # Expected: 220 ``` Ensure that your function efficiently calculates the maximum value the knapsack can hold without exceeding the weight capacity. Your solution should handle edge cases where the number of items is small or large, weights vary significantly, or the capacity is very limited.","solution":"def knapsack(values, weights, capacity): Determines the maximum value that can be obtained from a collection of items without exceeding the weight limit. :param values: List[int] - A list of values for the items :param weights: List[int] - A list of weights for the items :param capacity: int - Maximum weight capacity of the knapsack :return: int - The maximum value that can be obtained n = len(values) dp = [[0] * (capacity + 1) for _ in range(n + 1)] for i in range(1, n + 1): for w in range(capacity + 1): if weights[i-1] <= w: dp[i][w] = max(dp[i-1][w], dp[i-1][w-weights[i-1]] + values[i-1]) else: dp[i][w] = dp[i-1][w] return dp[n][capacity]"},{"question":"# Prime Divisors Sum Prime numbers are numbers greater than 1 that are only divisible by 1 and themselves. Given an integer n, find the sum of all its prime divisors. For example, for n = 28, its prime divisors are 2 and 7, and their sum is 9. Objective You need to write a function that computes the sum of all prime divisors of the given integer n. Function Signature ```python def prime_divisors_sum(n: int) -> int: pass ``` Input - An integer `n` where 2 <= n <= 10^9. The function should raise appropriate exceptions for invalid inputs. Output - The sum of all prime divisors of `n`. Constraints - The input `n` must be an integer. - The input `n` must be at least 2. Error Handling - If the input is not an integer, the function should raise a `TypeError` with a message \\"Input value of [number=<value>] must be an integer\\". - If the input is less than 2, the function should raise a `ValueError` with a message \\"Input must be an integer greater than or equal to 2\\". Example ```python >>> prime_divisors_sum(28) 9 >>> prime_divisors_sum(15) 8 >>> prime_divisors_sum(49) 7 >>> prime_divisors_sum(1) Traceback (most recent call last): ... ValueError: Input must be an integer greater than or equal to 2 >>> prime_divisors_sum(15.0) Traceback (most recent call last): ... TypeError: Input value of [number=15.0] must be an integer ``` # Task Implement the `prime_divisors_sum` function to meet the above requirements and handle all specified edge cases.","solution":"def prime_divisors_sum(n: int) -> int: if not isinstance(n, int): raise TypeError(f\\"Input value of [number={n}] must be an integer\\") if n < 2: raise ValueError(\\"Input must be an integer greater than or equal to 2\\") def is_prime(m): if m <= 1: return False if m <= 3: return True if m % 2 == 0 or m % 3 == 0: return False i = 5 while i * i <= m: if m % i == 0 or m % (i + 2) == 0: return False i += 6 return True prime_divisors = set() for i in range(2, int(n**0.5) + 1): if n % i == 0: if is_prime(i): prime_divisors.add(i) if is_prime(n // i): prime_divisors.add(n // i) # If n is prime itself, it should be included in the sum if is_prime(n): prime_divisors.add(n) return sum(prime_divisors)"},{"question":"# Implement a Simple Chatbot You are required to write a Python function that simulates a simple chatbot capable of responding to basic greetings and farewell messages. Function Signature ```python def chatbot_response(message: str) -> str: ``` Expected Input and Output - The function `chatbot_response()` receives one parameter: - `message` (string): The input message from the user. - The function will return a string containing the chatbot\'s response based on the input message. The possible chatbot responses should be: - If the input message is a greeting (e.g., \\"Hello\\", \\"Hi\\", \\"Hey\\"), the chatbot should respond with \\"Hello! How can I assist you today?\\" - If the input message is a farewell (e.g., \\"Goodbye\\", \\"Bye\\", \\"See you\\"), the chatbot should respond with \\"Goodbye! Have a great day!\\" - For any other message, the chatbot should respond with \\"I\'m sorry, I didn\'t understand that. Could you please rephrase?\\" Constraints - The comparison should be case-insensitive (e.g., \\"hello\\" and \\"Hello\\" should be treated the same). - Handle different variations of greetings and farewells. - Keep responses simple and direct, suitable for a basic chatbot. Performance Requirements - The function should be efficient and able to respond quickly even with multiple consecutive calls. - Minimal use of system resources. Example Usage ```python response = chatbot_response(\\"Hello\\") print(response) # Output: \\"Hello! How can I assist you today?\\" response = chatbot_response(\\"Bye\\") print(response) # Output: \\"Goodbye! Have a great day!\\" ``` Additional Considerations - You can expand the list of recognized greetings and farewells to enhance the chatbot\'s capabilities. - Ensure proper handling of unexpected or complex input messages in a user-friendly manner.","solution":"def chatbot_response(message: str) -> str: Responds to basic greetings and farewell messages. Parameters: - message (str): The input message from the user. Returns: - str: The chatbot\'s response. greetings = {\\"hello\\", \\"hi\\", \\"hey\\", \\"greetings\\"} farewells = {\\"goodbye\\", \\"bye\\", \\"see you\\", \\"farewell\\", \\"later\\"} message_lower = message.strip().lower() if message_lower in greetings: return \\"Hello! How can I assist you today?\\" elif message_lower in farewells: return \\"Goodbye! Have a great day!\\" else: return \\"I\'m sorry, I didn\'t understand that. Could you please rephrase?\\""},{"question":"# Problem Statement: A popular problem in computer science is finding the \\"word ladders\\" between two words. A word ladder is a sequence of words where each word in the sequence differs by exactly one character from the previous word. For example, \\"cot\\" -> \\"dot\\" -> \\"dog\\" is a word ladder. Given a dictionary of allowed words, write a function that finds the shortest transformation sequence from a starting word to a target word. You can only change one letter at a time, and each transformed word must exist in the dictionary. # Your Task: Implement a function: ```python def find_word_ladder(start: str, target: str, word_list: List[str]) -> List[str]: # Implement the function to find the shortest word ladder ``` # Specifications: 1. **Input Format:** * `start`: A string representing the start word. * `target`: A string representing the target word. * `word_list`: A list of strings representing the dictionary of allowed words. 2. **Output Format:** * A list of strings representing the shortest word ladder sequence from `start` to `target`. If no such sequence exists, return an empty list. 3. **Constraints:** * Both `start` and `target` are non-empty strings of the same length, consisting of lowercase alphabetic characters. * The `word_list` will contain words of the same length as `start` and `target`. * The `word_list` will contain at most 1000 words. 4. **Performance Consideration:** * The function should efficiently handle the given constraints by leveraging appropriate algorithms such as Breadth-First Search (BFS). # Example: ```python def find_word_ladder(start: str, target: str, word_list: List[str]) -> List[str]: # Implement the function to find the shortest word ladder # Example usage: start = \\"hit\\" target = \\"cog\\" word_list = [\\"hot\\", \\"dot\\", \\"dog\\", \\"lot\\", \\"log\\", \\"cog\\"] print(find_word_ladder(start, target, word_list)) # Expected output: [\\"hit\\", \\"hot\\", \\"dot\\", \\"dog\\", \\"cog\\"] start = \\"hit\\" target = \\"cog\\" word_list = [\\"hot\\", \\"dot\\", \\"dog\\", \\"lot\\", \\"log\\"] print(find_word_ladder(start, target, word_list)) # Expected output: [] ``` # Hints: * Consider using Breadth-First Search (BFS) to explore words level by level. * Use a queue to keep track of the current word and the path leading to it. * Utilize a set for the dictionary to allow for fast membership checking. * Ensure you handle cases where no transformation is possible. This problem will test your ability to implement classic graph search algorithms and handle edge cases effectively.","solution":"from collections import deque from typing import List def find_word_ladder(start: str, target: str, word_list: List[str]) -> List[str]: if target not in word_list or not start or not target or not word_list: return [] word_set = set(word_list) queue = deque([[start]]) visited = set() while queue: path = queue.popleft() current_word = path[-1] if current_word == target: return path for i in range(len(current_word)): for char in \'abcdefghijklmnopqrstuvwxyz\': next_word = current_word[:i] + char + current_word[i + 1:] if next_word in word_set and next_word not in visited: visited.add(next_word) queue.append(path + [next_word]) return []"},{"question":"# Coding Challenge: You are given a `root` of a Binary Search Tree (BST) and a target integer `k`. Your task is to write a function to determine if there exist two distinct elements in the BST whose sum is equal to `k`. **Function Signature**: ```python def find_target(root: Optional[TreeNode], k: int) -> bool: # Your code here ``` **Input**: - `root`: The root node of the Binary Search Tree (BST). Each node contains a `val` and pointers to left and right children. - `k`: An integer, the target sum. **Output**: - Returns `True` if there exist two elements in the BST whose sum is equal to `k`, otherwise `False`. **Constraints**: - The number of nodes in the tree is in the range `[1, 10000]`. - The `TreeNode` class is defined as: ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right ``` - The BST is valid and all node values are unique. - `-10^4 <= Node.val <= 10^4` - `-10^5 <= k <= 10^5` **Example Input and Output**: ```python # Define the BST: # 5 # / # 3 6 # / # 2 4 7 root = TreeNode(5) root.left = TreeNode(3) root.right = TreeNode(6) root.left.left = TreeNode(2) root.left.right = TreeNode(4) root.right.right = TreeNode(7) k = 9 print(find_target(root, k)) # Expected output -> True ``` **Explanation**: There are two elements in the BST (2 and 7) that sum up to 9. **Example Input and Output**: ```python # Define the BST: # 5 # / # 3 6 # / # 2 4 7 root = TreeNode(5) root.left = TreeNode(3) root.right = TreeNode(6) root.left.left = TreeNode(2) root.left.right = TreeNode(4) root.right.right = TreeNode(7) k = 28 print(find_target(root, k)) # Expected output -> False ``` **Explanation**: There are no two elements in the BST that sum up to 28. **Requirements**: - Implement the function efficiently to handle up to 10000 nodes. - Ensure the traversal makes the best use of the BST properties.","solution":"from typing import Optional class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def find_target(root: Optional[TreeNode], k: int) -> bool: def inorder(node, elements): if not node: return inorder(node.left, elements) elements.add(node.val) inorder(node.right, elements) elements = set() inorder(root, elements) for element in elements: if (k - element) in elements and (k - element) != element: return True return False"},{"question":"# Context: You are working as a software developer on a team that is developing a text processing library. One of the functionalities needed is to identify and highlight keywords in a given text. Your task is to implement a function that returns the text with specified keywords wrapped in asterisks (`*`). # Problem Statement: Implement the function `highlight_keywords` using the given skeleton code. The function should take as input a string and a list of keywords, and return the string with each keyword wrapped in asterisks. # Function Signature: ```python def highlight_keywords(text: str, keywords: List[str]) -> str: ``` # Input: * **text**: A string containing the text to be processed. * **keywords**: A list of strings where each string is a keyword that should be highlighted in the text. # Output: * **highlighted_text**: A string with each occurrence of the keywords in the text wrapped in asterisks. # Constraints: * Keywords will be case-insensitive. The highlight should preserve the original case of the text. * Only whole word matches should be highlighted (e.g., \\"apple\\" should not highlight a part of \\"pineapple\\"). * If a keyword appears multiple times in the text, all occurrences should be highlighted. * The function should handle edge cases gracefully (e.g., empty text, keywords not found). # Example: ```python # Example 1 text = \\"The quick brown fox jumps over the lazy dog.\\" keywords = [\\"fox\\", \\"dog\\"] highlighted_text = highlight_keywords(text, keywords) # Output: \\"The quick brown *fox* jumps over the lazy *dog*.\\" # Example 2 text = \\"Data science and machine learning are popular fields.\\" keywords = [\\"science\\", \\"machine\\"] highlighted_text = highlight_keywords(text, keywords) # Output: \\"Data *science* and *machine* learning are popular fields.\\" ``` # Notes: 1. The highlighting should be case-insensitive, but the original text\'s case should be preserved. 2. Use regular expressions to ensure efficient searching and replacement. 3. Consider edge cases such as overlapping keywords and punctuation. # Evaluation Criteria: * **Correctness**: The function should correctly identify and highlight all the specified keywords. * **Efficiency**: The implementation should handle large texts and lists of keywords efficiently. * **Code Quality**: The solution should be clean, readable, and properly commented. * **Edge Case Handling**: The function should appropriately handle edge cases like empty text, no keywords found, and keywords containing special characters.","solution":"import re from typing import List def highlight_keywords(text: str, keywords: List[str]) -> str: if not keywords: return text # Create a regular expression pattern that matches any of the keywords pattern = re.compile(r\'b(\' + \'|\'.join(map(re.escape, keywords)) + r\')b\', re.IGNORECASE) def substitute(match): # Wrap the matched keyword in asterisks return f\\"*{match.group(0)}*\\" # Substitute each match with the highlighted version highlighted_text = pattern.sub(substitute, text) return highlighted_text"},{"question":"# Problem Statement You are tasked with implementing a function that merges two sorted linked lists into one sorted linked list. This exercise aims to test your understanding of linked list manipulation and merging techniques. # Function to Implement Implement the function `merge_two_sorted_lists(l1: Optional[ListNode], l2: Optional[ListNode]) -> Optional[ListNode]` in Python, where: * `l1` and `l2` are the heads of two sorted linked lists. # Input and Output * **Input**: Two sorted linked lists represented by their head nodes: `l1` and `l2`. * **Output**: A single merged and sorted linked list. # Constraints 1. The length of each linked list will be between `0` and `10^5`. 2. Elements in each linked list are integers between `-10^9` and `10^9`. # Examples ```python # Example 1 # l1: 1 -> 2 -> 4 # l2: 1 -> 3 -> 4 # Output: 1 -> 1 -> 2 -> 3 -> 4 -> 4 # Example 2 # l1: [] # l2: [0] # Output: 0 # Example 3 # l1: [2] # l2: [1] # Output: 1 -> 2 # Example 4 # l1: [1, 2, 3] # l2: [] # Output: 1 -> 2 -> 3 # Example 5 # l1: [5, 6, 7] # l2: [1, 2, 3] # Output: 1 -> 2 -> 3 -> 5 -> 6 -> 7 ``` # Performance Requirements * Your solution should efficiently handle large linked lists with a time complexity of O(n + m), where `n` and `m` are the lengths of the two linked lists, respectively. * The space complexity should be O(1) (in-place merging). # Additional Notes Consider edge cases such as: * One or both linked lists being empty. * Handling negative values and large numbers properly within the constraints. * The linked lists having varying lengths. Implement a helper class if necessary for the ListNode and ensure your function correctly merges and returns a new sorted linked list. # Node Definition To help you with the implementation, the definition for a singly-linked list node is provided below: ```python class ListNode: def __init__(self, x: int = 0, next: Optional[\'ListNode\'] = None): self.val = x self.next = next ``` Implement your function to handle all edge cases effectively.","solution":"class ListNode: def __init__(self, x: int = 0, next: \'ListNode\' = None): self.val = x self.next = next def merge_two_sorted_lists(l1: ListNode, l2: ListNode) -> ListNode: # Creating a dummy node to start the merged list dummy = ListNode() current = dummy # Traverse both lists while l1 and l2: if l1.val < l2.val: current.next = l1 l1 = l1.next else: current.next = l2 l2 = l2.next current = current.next # If any elements are left in either list, link them directly if l1: current.next = l1 else: current.next = l2 # The merged linked list is pointed by dummy.next return dummy.next"},{"question":"# Coding Assessment Question Scenario: You are tasked with implementing an efficient function to calculate the Euler\'s Totient function, φ(n), for a given positive integer `n`. The Euler\'s Totient function is crucial in number theory and plays a pivotal role in topics such as modular arithmetic and the RSA algorithm. Problem Statement: Implement a Python function `euler_totient(n: int) -> int` that computes the Euler\'s Totient function value for a given integer `n`. Requirements: 1. The function should handle any positive integer input `n`. 2. Non-integer and non-positive inputs should raise a `ValueError`. 3. The function should efficiently compute the prime factors of `n` to apply the formula: - φ(n) = n * Π(1 - 1/p) for all distinct prime factors p of `n`. 4. The implementation should not rely on external libraries for prime factorization and should remain efficient. Input: - An integer `n`, where `n` is a positive integer. Output: - An integer representing the value of the Euler\'s Totient function for the given integer `n`. Constraints: - You must use an efficient prime factorization method. - Your solution should not exceed (O(sqrt{n})) for prime factorization. Function Signature: ```python def euler_totient(n: int) -> int: ``` Example Cases: ```python assert euler_totient(1) == 1 assert euler_totient(10) == 4 assert euler_totient(13) == 12 assert euler_totient(36) == 12 assert euler_totient(100) == 40 ``` Additional Information: - Utilize the provided helper functions `prime_factors` for implementation if necessary. - Consider integer overflow and edge cases as part of your solution. Implement the `euler_totient` function as per the outlined requirements.","solution":"def euler_totient(n: int) -> int: if not isinstance(n, int) or n <= 0: raise ValueError(\\"Input must be a positive integer\\") if n == 1: return 1 result = n p = 2 # Check for every number in [2, sqrt(n)] while p * p <= n: # Check if p is a prime factor if n % p == 0: # If it is a prime factor, then proceed with the formula while n % p == 0: n //= p result -= result // p p += 1 # If n is still greater than 1, then it\'s a prime number if n > 1: result -= result // n return result"},{"question":"# JSON Validation Assessment Create a function that validates whether a given JSON string adheres to a specified schema. The function should return `True` if the JSON string is valid according to the schema, and `False` otherwise. **Function Signature**: ```python def validate_json(json_str: str, schema: dict) -> bool: pass ``` # Constraints and Rules 1. **Basic Checks**: - The input JSON string must be a valid JSON format. - The JSON string must adhere to the provided schema. 2. **Schema Validations**: - The schema is a dictionary where keys represent the field names and values represent the expected types or nested schemas. - Valid types include `str`, `int`, `float`, `bool`, `list`, and `dict`. 3. **Type Matching**: - For each key in the schema, the corresponding value in the JSON must match the type specified by the schema. If the type is `list`, then the schema must further specify the type of items in the list. - For nested dictionaries, the schema should also be nested accordingly. # Expected Input and Output Formats **Input**: - A string `json_str` representing the JSON to be validated. - A dictionary `schema` representing the validation rules. **Output**: - A boolean value `True` if the JSON string is valid according to the schema, otherwise `False`. # Example ```python # Example 1: json_str = \'{\\"name\\": \\"Alice\\", \\"age\\": 30, \\"email\\": \\"alice@example.com\\"}\' schema = {\\"name\\": str, \\"age\\": int, \\"email\\": str} assert validate_json(json_str, schema) == True # Example 2: json_str = \'{\\"name\\": \\"Alice\\", \\"age\\": \\"30\\", \\"email\\": \\"alice@example.com\\"}\' schema = {\\"name\\": str, \\"age\\": int, \\"email\\": str} assert validate_json(json_str, schema) == False # Example 3: json_str = \'{\\"user\\": {\\"name\\": \\"Alice\\", \\"age\\": 30}, \\"active\\": true}\' schema = {\\"user\\": {\\"name\\": str, \\"age\\": int}, \\"active\\": bool} assert validate_json(json_str, schema) == True ``` Note: - Ensure that the function raises an appropriate exception if the input string is not a valid JSON. - The function should handle nested schemas and arrays in the input JSON.","solution":"import json def validate_json(json_str: str, schema: dict) -> bool: try: data = json.loads(json_str) except json.JSONDecodeError: return False return validate_schema(data, schema) def validate_schema(data, schema): if not isinstance(data, dict): return False for key, expected_type in schema.items(): if key not in data: return False value = data[key] if isinstance(expected_type, dict): if not validate_schema(value, expected_type): return False elif isinstance(expected_type, list): if not (isinstance(value, list) and all(isinstance(v, expected_type[0]) for v in value)): return False else: if not isinstance(value, expected_type): return False return True"},{"question":"Write a function `course_schedule(num_courses: int, prerequisites: List[Tuple[int, int]]) -> bool` that determines if it is possible to finish all courses given a list of prerequisite pairs. # Input - **Integer** `num_courses`: The total number of courses you need to take, labeled from `0` to `num_courses - 1`. - **List of Tuples** `prerequisites`: Each tuple `(a, b)` indicates that course `a` must be taken before course `b`. # Output - **Boolean** value: - `True` if it is possible to finish all courses. - `False` if it is not possible to finish all courses due to circular prerequisites. # Constraints 1. The number of courses (`num_courses`) ranges from (1) to (2000). 2. The number of prerequisite pairs (length of `prerequisites` list) ranges from (0) to (5000). # Example ```python num_courses_1 = 2 prerequisites_1 = [(1, 0)] print(course_schedule(num_courses_1, prerequisites_1)) # Output: True num_courses_2 = 2 prerequisites_2 = [(1, 0), (0, 1)] print(course_schedule(num_courses_2, prerequisites_2)) # Output: False ``` Implement the function `course_schedule(num_courses: int, prerequisites: List[Tuple[int, int]]) -> bool` by completing this task. Notes - Consider using a graph approach to model the courses and their prerequisites. - Detect cycles in the graph to determine if completing all courses is possible. - You might find Depth-First Search (DFS) or Breadth-First Search (BFS) helpful for detecting cycles in the graph.","solution":"from typing import List, Tuple def course_schedule(num_courses: int, prerequisites: List[Tuple[int, int]]) -> bool: from collections import defaultdict, deque # Create an adjacency list to represent the graph graph = defaultdict(list) indegree = defaultdict(int) for dest, src in prerequisites: graph[src].append(dest) indegree[dest] += 1 # Initialize a deque with courses that have no prerequisites zero_indegree_queue = deque([i for i in range(num_courses) if indegree[i] == 0]) count_of_visited_courses = 0 while zero_indegree_queue: course = zero_indegree_queue.popleft() count_of_visited_courses += 1 for neighbor in graph[course]: indegree[neighbor] -= 1 if indegree[neighbor] == 0: zero_indegree_queue.append(neighbor) return count_of_visited_courses == num_courses"},{"question":"# Scenario In this task, you will design a command-line tool that processes a log file and generates a summary report. The log file contains entries of different events, with each line consisting of a timestamp, a log level (INFO, WARNING, ERROR), and a message. # Objective Create a script that processes the log file to: 1. **Count Entries by Log Level**: Calculate the total number of entries for each log level (INFO, WARNING, ERROR). 2. **Identify Peak Hour**: Determine the hour of the day (0-23) when the highest number of log entries occurred. 3. **Filter by Date**: Generate a summary of log entries for a specified date. # Instructions 1. Ensure the function `process_log_file`: * Takes the path of the log file as input. * Returns a dictionary containing the counts of log levels and the peak hour. ```python def process_log_file(log_file_path): pass ``` 2. Ensure the function `filter_log_by_date`: * Takes the path of the log file and a date string (`YYYY-MM-DD`) as input. * Returns a summary string containing the count of log entries by level for the specified date and the peak hour for that date. ```python def filter_log_by_date(log_file_path, date_str): pass ``` 3. Log entries are in the format: `YYYY-MM-DD HH:MM:SS [LOG_LEVEL] Message`. # Expected Input and Output - **Input**: Path to a log file (`\\"system.log\\"`) and a date string (`\\"2023-05-14\\"`). - **Output**: A dictionary from `process_log_file` and a summary string from `filter_log_by_date`. # Constraints - Handle log files with up to 100,000 entries efficiently. - Ensure proper error handling for file reading and format parsing. # Example Log File (`example.log`) ``` 2023-05-14 10:15:32 [INFO] System started. 2023-05-14 11:17:45 [WARNING] Disk space low. 2023-05-14 11:18:37 [ERROR] Unable to connect to database. 2023-05-14 12:20:00 [INFO] User login successful. 2023-05-15 09:05:21 [INFO] System maintenance scheduled. 2023-05-15 09:10:29 [ERROR] Failed to load configuration. ``` # Example Usage ```python if __name__ == \\"__main__\\": log_file_path = \\"example.log\\" # Process the entire log file summary = process_log_file(log_file_path) print(summary) # Output: { \'INFO\': 3, \'WARNING\': 1, \'ERROR\': 2, \'peak_hour\': 11 } # Filter log entries by a specific date date_str = \\"2023-05-14\\" date_summary = filter_log_by_date(log_file_path, date_str) print(date_summary) # Output: \\"Date: 2023-05-14, INFO: 2, WARNING: 1, ERROR: 1, Peak Hour: 11\\" ``` # Performance Requirements - Ensure efficient file reading and processing to handle large log files. - Implement robust error handling for invalid entries and missing files. # Additional Notes - Remember to handle various edge cases, such as logs without entries for a specific date or malformed entries. - Use Python\'s built-in libraries for file I/O and datetime handling to simplify your implementation.","solution":"import re from collections import defaultdict, Counter from datetime import datetime LOG_PATTERN = re.compile( r\'(?P<date>d{4}-d{2}-d{2}) (?P<time>d{2}:d{2}:d{2}) [(?P<level>INFO|WARNING|ERROR)] (?P<message>.+)\' ) def process_log_file(log_file_path): level_counts = Counter() hourly_counts = Counter() with open(log_file_path, \'r\') as file: for line in file: match = LOG_PATTERN.match(line) if match: log_level = match.group(\'level\') log_hour = int(match.group(\'time\').split(\\":\\")[0]) level_counts[log_level] += 1 hourly_counts[log_hour] += 1 peak_hour = hourly_counts.most_common(1)[0][0] if hourly_counts else None result = { \'INFO\': level_counts[\'INFO\'], \'WARNING\': level_counts[\'WARNING\'], \'ERROR\': level_counts[\'ERROR\'], \'peak_hour\': peak_hour } return result def filter_log_by_date(log_file_path, date_str): level_counts = Counter() hourly_counts = Counter() with open(log_file_path, \'r\') as file: for line in file: match = LOG_PATTERN.match(line) if match: log_date = match.group(\'date\') if log_date == date_str: log_level = match.group(\'level\') log_hour = int(match.group(\'time\').split(\\":\\")[0]) level_counts[log_level] += 1 hourly_counts[log_hour] += 1 peak_hour = hourly_counts.most_common(1)[0][0] if hourly_counts else None summary = (f\\"Date: {date_str}, INFO: {level_counts[\'INFO\']}, \\" f\\"WARNING: {level_counts[\'WARNING\']}, ERROR: {level_counts[\'ERROR\']}, \\" f\\"Peak Hour: {peak_hour}\\") return summary"},{"question":"# Problem Statement Given a list of employees and their respective job titles, implement a function to count the number of employees for each unique job title. The function should return a dictionary where keys are the job titles and values are the counts of employees in each job title. **Function Signature**: ```python def count_job_titles(employees: List[Tuple[str, str]]) -> Dict[str, int]: pass ``` # Input * `employees`: A list of tuples, where each tuple contains two strings: - The first string is the employee\'s name. - The second string is the employee\'s job title. # Output * Returns a dictionary where the keys are unique job titles and the values are the count of employees holding each job title. # Constraints 1. The input list `employees` is non-empty. 2. Each job title will be a non-empty string. 3. Employee names may not be unique. # Example 1. ```python employees = [(\\"Alice\\", \\"Engineer\\"), (\\"Bob\\", \\"Analyst\\"), (\\"Charlie\\", \\"Engineer\\"), (\\"David\\", \\"Analyst\\"), (\\"Eve\\", \\"Manager\\")] print(count_job_titles(employees)) ``` Output: ``` {\\"Engineer\\": 2, \\"Analyst\\": 2, \\"Manager\\": 1} ``` 2. ```python employees = [(\\"Emily\\", \\"HR\\"), (\\"James\\", \\"HR\\"), (\\"Michael\\", \\"Developer\\"), (\\"Sarah\\", \\"Developer\\"), (\\"John\\", \\"HR\\")] print(count_job_titles(employees)) ``` Output: ``` {\\"HR\\": 3, \\"Developer\\": 2} ``` # Edge Cases: 1. All employees have the same job title. 2. Each employee has a unique job title. # Notes: Ensure proper handling of the input list and accurate counting of unique job titles.","solution":"from typing import List, Tuple, Dict def count_job_titles(employees: List[Tuple[str, str]]) -> Dict[str, int]: job_title_count = {} for name, job_title in employees: if job_title in job_title_count: job_title_count[job_title] += 1 else: job_title_count[job_title] = 1 return job_title_count"},{"question":"# Question: Log File Time Stamp Validator You are required to write a Python function to validate if the timestamps in a given log file are in a chronological order. The log file contains multiple entries in the format: `[YYYY-MM-DD HH:MM:SS] Some log message`. Requirements: 1. **Input**: - The function should read from a log file provided as a command-line argument. If the log file path is not provided, prompt the user to enter the path. 2. **Reading the File**: - Read the log file contents into memory. 3. **Parsing Timestamps**: - Extract the timestamps from each log entry. - Assume the log entries are well-formed and every line contains a valid timestamp in the format `[YYYY-MM-DD HH:MM:SS]`. 4. **Validation**: - Validate that the timestamps are in chronological order, i.e., each timestamp is equal to or later than the previous timestamp. 5. **Output**: - Print \\"All timestamps are in chronological order.\\" if the timestamps are sorted correctly. - Print \\"Timestamps are not in chronological order.\\" if any timestamp is out of order. 6. **Error Handling**: - Inform the user if the file does not exist or cannot be read. Implementation Details: 1. **Helper Functions**: - Implement helper functions where necessary to keep the code organized. 2. **Date and Time Handling**: - Use Python\'s `datetime` module to handle and compare timestamps. 3. **Logging**: - Log the progress of the read operation and any errors encountered. Constraints: - Python 3 must be used. - The log file can be large, but you can assume it fits into memory for simplicity. - The timestamps in the log file will be formatted correctly as per the specification `[YYYY-MM-DD HH:MM:SS]`. - The log entries will be on separate lines. Example Usage: ```bash python validate_log_timestamps.py /path/to/logfile.log ``` # Code Implementation: Implement your solution with the function signature given below: ```python def validate_log_timestamps(log_file_path: str): pass ``` # Example Log File: ``` [2023-01-01 00:00:01] Log entry 1 [2023-01-01 00:00:02] Log entry 2 [2023-01-01 00:00:03] Log entry 3 [2023-01-01 00:00:04] Log entry 4 ```","solution":"import os from datetime import datetime def validate_log_timestamps(log_file_path: str): try: if not os.path.isfile(log_file_path): print(f\\"The file {log_file_path} does not exist.\\") return with open(log_file_path, \'r\') as file: lines = file.readlines() last_timestamp = None for line in lines: timestamp_str = line.split(\']\')[0].strip(\'[\') timestamp = datetime.strptime(timestamp_str, \'%Y-%m-%d %H:%M:%S\') if last_timestamp and timestamp < last_timestamp: print(\\"Timestamps are not in chronological order.\\") return last_timestamp = timestamp print(\\"All timestamps are in chronological order.\\") except Exception as e: print(f\\"An error occurred while processing the file: {e}\\")"},{"question":"# Question You are tasked with creating a function that evaluates expressions in Reverse Polish Notation (RPN). The function will take a list of strings as input and return the evaluation result as a float. Requirements 1. The function should iterate through the list of strings and use a stack to evaluate the RPN expression. 2. Support the four basic arithmetic operations: addition (`+`), subtraction (`-`), multiplication (`*`), and division (`/`). 3. If the expression is invalid (e.g., insufficient operands for an operator), raise a ValueError. 4. If there is any division by zero, raise a ZeroDivisionError. 5. Add appropriate documentation and type hints to your function. Function Signature ```python def evaluate_rpn(expression: list[str]) -> float: Evaluate a given expression in Reverse Polish Notation (RPN). :param expression: List of strings representing an RPN expression. :return: The evaluation result as a float. :raises ValueError: If the RPN expression is invalid. :raises ZeroDivisionError: If division by zero occurs. pass ``` Input - `expression`: A list of strings representing an RPN expression containing numbers and operators. Output - Returns a float representing the evaluated result of the RPN expression. Constraints - The input expression will have at least one operation (i.e., an operator) and two operands. - Stack-based evaluation should be implemented efficiently. Example ```python expression = [\\"2\\", \\"1\\", \\"+\\", \\"3\\", \\"*\\"] result = evaluate_rpn(expression) # Output: 9.0 # Explanation: (2 + 1) * 3 = 9 expression = [\\"4\\", \\"13\\", \\"5\\", \\"/\\", \\"+\\"] result = evaluate_rpn(expression) # Output: 6.6 (approximately) # Explanation: 4 + (13 / 5) = 4 + 2.6 = 6.6 expression = [\\"2\\", \\"1\\", \\"+\\", \\"3\\", \\"*\\", \\"/\\"] # Raises ValueError due to invalid second operator expression = [\\"4\\", \\"0\\", \\"/\\"] # Raises ZeroDivisionError due to division by zero ``` Hints - RPN expressions are evaluated using a stack where operands are pushed onto the stack. - When an operator is encountered, the necessary number of operands is popped from the stack, the operation is performed, and the result is pushed back onto the stack. - Ensure to handle edge cases such as insufficient operands and division by zero properly.","solution":"def evaluate_rpn(expression: list[str]) -> float: Evaluate a given expression in Reverse Polish Notation (RPN). :param expression: List of strings representing an RPN expression. :return: The evaluation result as a float. :raises ValueError: If the RPN expression is invalid. :raises ZeroDivisionError: If division by zero occurs. stack = [] for token in expression: if token in \'+-*/\': if len(stack) < 2: raise ValueError(\\"Invalid RPN expression: insufficient operands for an operator.\\") b = stack.pop() a = stack.pop() if token == \'+\': result = a + b elif token == \'-\': result = a - b elif token == \'*\': result = a * b elif token == \'/\': if b == 0: raise ZeroDivisionError(\\"Division by zero.\\") result = a / b stack.append(result) else: try: stack.append(float(token)) except ValueError: raise ValueError(f\\"Invalid token \'{token}\' in RPN expression.\\") if len(stack) != 1: raise ValueError(\\"Invalid RPN expression: too many operands.\\") return stack[0]"},{"question":"# Merge Two Sorted Lists Problem Statement You are required to implement an algorithm that merges two sorted linked lists such that the resulting linked list is also sorted. The linked lists are comprised of nodes with integer values. Your implementation should maintain the original ordering of the elements from the two input lists. Function Signature ```python class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = next def merge_two_sorted_lists(l1: ListNode, l2: ListNode) -> ListNode: ``` Input - `l1: ListNode` - the head node of the first sorted linked list. - `l2: ListNode` - the head node of the second sorted linked list. Output - A `ListNode` which is the head of the merged sorted linked list. Example ```plaintext Input: l1 = 1 -> 3 -> 5, l2 = 2 -> 4 -> 6 Output: 1 -> 2 -> 3 -> 4 -> 5 -> 6 ``` Constraints - All nodes in the linked lists are sorted in non-decreasing order. - The number of nodes in both linked lists is in the range `[0, 10^4]`. - The values of the nodes in the linked lists are in the range `[-10^4, 10^4]`. Notes 1. Ensure that the merged list combines all elements from both input lists in a single sorted list. 2. Your solution should handle edge cases where one or both lists may be empty.","solution":"class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = next def merge_two_sorted_lists(l1: ListNode, l2: ListNode) -> ListNode: dummy = ListNode() current = dummy while l1 and l2: if l1.val < l2.val: current.next = l1 l1 = l1.next else: current.next = l2 l2 = l2.next current = current.next current.next = l1 if l1 else l2 return dummy.next"},{"question":"# Problem: Implement a Priority Queue using a Min-Heap You are required to implement a priority queue using the provided Min-Heap data structure. A priority queue ensures that elements are dequeued in order of their priority, with the minimum element having the highest priority. Requirements: 1. **Initialization**: - Initialize the priority queue with an empty Min-Heap. 2. **Insertions**: - Support insertion of elements with an associated priority. 3. **Deletions**: - Support extraction of the element with the highest priority (the minimum element). If the queue is empty, raise an IndexError. 4. **Peek**: - Provide a method to view the element with the highest priority without removal. 5. **Queue State**: - Provide a method to check if the queue is empty. Input: - A set of operations (insertions, deletions, and peeks) along with their data. Output: - After each operation, return the state of the priority queue or the result of the peek operation. Constraints: 1. Elements are associated with an integer priority. 2. The operations may vary in order and number but will fit within the available system limits. Performance Requirements: - Insertions should be handled in O(log n) time. - Deletions should be handled in O(log n) time. - Peek operation should be handled in O(1) time. - Queue state checks should be O(1) time. Example Scenario ```python # Initialize an empty priority queue pq = PriorityQueue() # Insert elements into the queue with priority pq.insert(5, 2) print(pq) # Expected Output: \\"[2:5]\\" pq.insert(9, 1) print(pq) # Expected Output: \\"[1:9, 2:5]\\" pq.insert(3, 3) print(pq) # Expected Output: \\"[1:9, 2:5, 3:3]\\" # Peek the element with the highest priority (minimum priority) print(pq.peek()) # Expected Output: \\"9\\" # Extract the element with the highest priority pq.delete() print(pq) # Expected Output: \\"[2:5, 3:3]\\" pq.delete() print(pq) # Expected Output: \\"[3:3]\\" pq.delete() print(pq) # Expected Output: \\"Priority queue is empty\\" ``` **Note**: You can reuse the provided `MinHeap` class for part of the implementation.","solution":"import heapq class PriorityQueue: def __init__(self): self.heap = [] def insert(self, element, priority): heapq.heappush(self.heap, (priority, element)) def delete(self): if self.is_empty(): raise IndexError(\\"The priority queue is empty\\") return heapq.heappop(self.heap)[1] def peek(self): if self.is_empty(): raise IndexError(\\"The priority queue is empty\\") return self.heap[0][1] def is_empty(self): return len(self.heap) == 0"},{"question":"# Question: Matrix Transposition with Memory Optimization Context Matrix transposition is a common operation in many mathematical, scientific, and computer graphics algorithms. In this task, you are required to write a function that transposes a given matrix while ensuring minimal memory usage. Problem Statement Implement a function `transpose_matrix_optimized` that transposes a given matrix in memory. The function should handle rectangular matrices and optimize memory usage where possible. # Function Signature ```python def transpose_matrix_optimized(matrix: List[List[int]]) -> List[List[int]]: Given a matrix represented as a list of lists, transpose the matrix. Parameters: - matrix (List[List[int]]): A 2D list representing the matrix with dimensions m x n. Returns: - List[List[int]]: A 2D list representing the transposed matrix with dimensions n x m. ``` # Constraints - The number of rows ( m ) and columns ( n ) are such that ( 1 leq m, n leq 10^3 ). - Each element in the matrix is an integer within the range ( -10^6 leq text{matrix}[i][j] leq 10^6 ). - The function should aim to use minimal additional memory. # Requirements 1. Transpose the matrix efficiently by switching the rows and columns. 2. Minimize additional memory usage where possible. 3. Ensure the solution works within reasonable time and space limits for the given constraints. # Examples ```python >>> transpose_matrix_optimized([[1, 2, 3], [4, 5, 6]]) [[1, 4], [2, 5], [3, 6]] >>> transpose_matrix_optimized([[7, 8], [9, 10], [11, 12]]) [[7, 9, 11], [8, 10, 12]] >>> transpose_matrix_optimized([[1]]) [[1]] ```","solution":"from typing import List def transpose_matrix_optimized(matrix: List[List[int]]) -> List[List[int]]: Given a matrix represented as a list of lists, transpose the matrix. Parameters: - matrix (List[List[int]]): A 2D list representing the matrix with dimensions m x n. Returns: - List[List[int]]: A 2D list representing the transposed matrix with dimensions n x m. if not matrix or not matrix[0]: return [] m, n = len(matrix), len(matrix[0]) transposed = [[0] * m for _ in range(n)] for i in range(m): for j in range(n): transposed[j][i] = matrix[i][j] return transposed"},{"question":"# Problem Statement: Prime Number Rotation A prime number is a natural number greater than 1 that cannot be formed by multiplying two smaller natural numbers. A number is considered to be a \\"rotatable prime\\" if each rotation of its digits forms a valid prime number. For example, 197 is a rotatable prime because rotations of its digits (197, 971, and 719) are all prime numbers. Your task is to write a function that checks if a given number is a rotatable prime. **Tasks**: 1. **Implement the function `is_rotatable_prime(number: int) -> bool`.** * The function should return `True` if the given number is a rotatable prime; otherwise, it should return `False`. * Ensure that the function handles edge cases where the input number is less than or equal to 1 correctly. **Example:** ```python >>> is_rotatable_prime(197) True >>> is_rotatable_prime(23) False >>> is_rotatable_prime(2) True >>> is_rotatable_prime(-5) False ``` **Input Constraints**: - The input number will be a positive integer (number) up to (10^6). **Assumptions**: - Rotations of the digits should consider the number in all cyclic permutations. - You may assume that standard libraries for basic numeric and list operations are available. Your implementation should be efficient, taking into account the potentially large size of the input number, and should handle edge cases such as single-digit primes and non-prime inputs appropriately.","solution":"def is_prime(n): Checks if a number is prime. if n <= 1: return False if n <= 3: return True if n % 2 == 0 or n % 3 == 0: return False i = 5 while i * i <= n: if n % i == 0 or n % (i + 2) == 0: return False i += 6 return True def get_rotations(number): Generate all rotations of the digits of a number rotations = [] s = str(number) for i in range(len(s)): rotation = s[i:] + s[:i] rotations.append(int(rotation)) return rotations def is_rotatable_prime(number): Checks if a given number is a rotatable prime. A number is considered to be a \'rotatable prime\' if each rotation of its digits forms a valid prime number. if number <= 1: return False rotations = get_rotations(number) return all(is_prime(rotation) for rotation in rotations)"},{"question":"# Meeting Room Booking Problem You are tasked with implementing a system to manage meeting room bookings. The system will maintain records for multiple meeting rooms and handle booking requests. Each room can be booked multiple times, provided there are no overlapping reservations. 1. **Book a Room**: Implement a method `book_room` with the signature `book_room(room_id: str, start_time: int, end_time: int) -> bool` that attempts to book a specific room for a given time interval. 2. **Find Available Rooms**: Implement a method `find_available_rooms` with the signature `find_available_rooms(start_time: int, end_time: int) -> List[str]` that returns a list of all rooms available for the given time interval. Input and Output Formats * **Input**: * For the `book_room` method: * `room_id` - a string representing the room identifier. * `start_time` and `end_time` - integers representing the start and end times of the booking. * For the `find_available_rooms` method: * `start_time` and `end_time` - integers representing the start and end times for the query. * **Output**: * For the `book_room` method: A boolean value indicating whether the booking was successful. * For the `find_available_rooms` method: A list of strings representing room IDs that are available during the specified interval. Constraints * `start_time` and `end_time` are integers and represent valid time intervals in minutes. * `room_id` is a non-empty string. * Bookings and queries are made with reasonable constraints for realistic scenarios in a workday (e.g., bookings do not exceed 24 hours). Performance Requirements * Ensure that booking and availability checking operations are efficient, with emphasis on handling multiple inquiries effectively. # Example ```python # Initialize the booking system booking_system = BookingSystem() # Attempt to book meeting rooms print(booking_system.book_room(\\"A\\", 540, 600)) # Output: True (9 AM to 10 AM booking in room A) print(booking_system.book_room(\\"A\\", 570, 630)) # Output: False (overlapping booking in room A) # Find available rooms print(booking_system.find_available_rooms(540, 600)) # Output: [\\"B\\", \\"C\\", \\"D\\", ...] (excluding room A) ``` # Implementation Enhance the provided `BookingSystem` class by implementing the `book_room` and `find_available_rooms` methods to manage meeting room bookings efficiently.","solution":"from typing import List, Dict class BookingSystem: def __init__(self): self.rooms: Dict[str, List[Tuple[int, int]]] = {} def book_room(self, room_id: str, start_time: int, end_time: int) -> bool: if start_time >= end_time: return False if room_id not in self.rooms: self.rooms[room_id] = [] # Check for overlapping bookings for booking in self.rooms[room_id]: if not (end_time <= booking[0] or start_time >= booking[1]): return False self.rooms[room_id].append((start_time, end_time)) return True def find_available_rooms(self, start_time: int, end_time: int) -> List[str]: available_rooms = [] for room_id, bookings in self.rooms.items(): is_available = True for booking in bookings: if not (end_time <= booking[0] or start_time >= booking[1]): is_available = False break if is_available: available_rooms.append(room_id) return available_rooms"},{"question":"# Coding Assessment Question **Problem Statement:** You are tasked with writing a function that calculates the total resistance of a series-parallel circuit. The circuit consists of three resistors ( R1 ), ( R2 ), and ( R3 ), where ( R1 ) and ( R2 ) are in parallel, and ( R3 ) is in series with the parallel combination of ( R1 ) and ( R2 ). Given three resistances ( R1 ), ( R2 ), and ( R3 ), you need to find the total resistance ( Rt ) using the following steps: 1. Calculate the equivalent resistance of ( R1 ) and ( R2 ) in parallel: [ R_{text{parallel}} = left(frac{R1 times R2}{R1 + R2}right) ] 2. Add ( R3 ) to the result to get the total resistance ( Rt ): [ Rt = R_{text{parallel}} + R3 ] Your function should validate the inputs to ensure that all resistance values are positive. If any resistance value is non-positive, the function should raise a `ValueError` with the message \\"All resistance values must be positive\\". **Function Signature:** ```python def series_parallel_resistance(resistance_1: float, resistance_2: float, resistance_3: float) -> float: pass ``` # Input: - `resistance_1`: A positive float representing the first resistance ( R1 ). - `resistance_2`: A positive float representing the second resistance ( R2 ). - `resistance_3`: A positive float representing the third resistance ( R3 ). # Output: - Returns a float, the total resistance ( Rt ). # Constraints: - All input resistances will be non-negative floating-point numbers. # Example Usage: ```python print(series_parallel_resistance(resistance_1=4, resistance_2=6, resistance_3=8)) # Output: 10.4 print(series_parallel_resistance(resistance_1=10, resistance_2=10, resistance_3=10)) # Output: 15.0 ``` # Edge Cases: - If any of `resistance_1`, `resistance_2`, or `resistance_3` are zero or negative, the function should raise a `ValueError`. **Test Cases:** 1. `series_parallel_resistance(4, 4, 4)` should return `6.0`. 2. `series_parallel_resistance(5, 10, 15)` should return `20.0`. 3. `series_parallel_resistance(1, 2, 3)` should return `3.67` (rounded to 2 decimal places). 4. `series_parallel_resistance(-1, 2, 3)` should raise `ValueError`. 5. `series_parallel_resistance(0, 5, 10)` should raise `ValueError`.","solution":"def series_parallel_resistance(resistance_1: float, resistance_2: float, resistance_3: float) -> float: Calculate the total resistance of a series-parallel circuit. :param resistance_1: A positive float representing the first resistance R1. :param resistance_2: A positive float representing the second resistance R2. :param resistance_3: A positive float representing the third resistance R3. :return: Total resistance Rt of the circuit. # Validate input resistances if resistance_1 <= 0 or resistance_2 <= 0 or resistance_3 <= 0: raise ValueError(\\"All resistance values must be positive\\") # Calculate the equivalent resistance of R1 and R2 in parallel r_parallel = (resistance_1 * resistance_2) / (resistance_1 + resistance_2) # Calculate the total resistance total_resistance = r_parallel + resistance_3 return total_resistance"},{"question":"# Question Context Efficient string manipulation and searching are essential tasks in software development, especially when working with large datasets or implementing search algorithms. Understanding how to manipulate and search within strings effectively is fundamental. Task Write a function `find_longest_word` that finds and returns the longest word from the given string. If there are multiple words of the same maximum length, return the one that appears first. Words are defined as sequences of alphabetic characters separated by non-alphabetic characters. Function Signature ```python def find_longest_word(s: str) -> str: ``` Input * `s` – A string. Output * Return the longest word found in the string `s`. Constraints * The string length does not exceed `10^6` characters. * The string may contain any ASCII character. Examples ```python assert find_longest_word(\\"The quick brown fox!\\") == \\"quick\\" assert find_longest_word(\\"Hello, world!\\") == \\"Hello\\" assert find_longest_word(\\"A journey of a thousand miles begins with a single step.\\") == \\"thousand\\" assert find_longest_word(\\"Lorem ipsum dolor sit amet.\\") == \\"Lorem\\" assert find_longest_word(\\"\\") == \\"\\" ``` Explanation * The function should identify sequences of alphabetic characters as words. * Non-alphabetic characters such as spaces, punctuation, and numbers act as delimiters. * The function should return the longest word based on its length. If the longest length is shared by multiple words, return the first one encountered.","solution":"def find_longest_word(s: str) -> str: Finds and returns the longest word from the given string. Words are sequences of alphabetic characters separated by non-alphabetic characters. import re # Extract words using regular expressions words = re.findall(r\'[a-zA-Z]+\', s) # Find the longest word if not words: return \\"\\" longest_word = max(words, key=len) return longest_word"},{"question":"# Question You are given a grid of characters where each cell contains a letter from the English alphabet. Your task is to write a function `find_words` that takes the grid and a list of words as input and returns a list of words that can be formed by traversing the grid. The words must be formed by sequentially adjacent cells, where \\"adjacent\\" cells are those horizontally or vertically neighboring. Each cell can be used only once per word, and the same word cannot be counted multiple times. Function Signature ```python def find_words(grid: List[List[str]], words: List[str]) -> List[str]: pass ``` Input - A 2D grid of characters, `grid` (1 <= len(grid), len(grid[0]) <= 100). - A list of words, `words` (1 <= len(words) <= 1000, 1 <= len(words[i]) <= 10). Output - A list of words that can be formed from the grid. The words must be in the same order as they appear in the input list. Constraints - Each word in the list appears only once. - Words can include duplicate letters. - All letters are lowercase English alphabets. Example ```python # Example 1 grid = [ [\'o\',\'a\',\'a\',\'n\'], [\'e\',\'t\',\'a\',\'e\'], [\'i\',\'h\',\'k\',\'r\'], [\'i\',\'f\',\'l\',\'v\'] ] words = [\\"oath\\", \\"pea\\", \\"eat\\", \\"rain\\"] print(find_words(grid, words)) # Output: [\\"oath\\", \\"eat\\"] # Example 2 grid = [ [\'a\',\'b\'], [\'c\',\'d\'] ] words = [\\"ab\\", \\"bc\\", \\"cd\\", \\"ad\\", \\"abc\\"] print(find_words(grid, words)) # Output: [\\"ab\\", \\"cd\\"] ``` Additional Notes - Ensure the function is optimized to handle the upper limits of the input sizes. - Consider edge cases such as grids with single cells or words that are longer than the dimensions of the grid. - Write clean and readable code with appropriate comments to explain your implementation. Hints - You may use Depth-First Search (DFS) to explore possible word formations in the grid. - Consider implementing a trie (prefix tree) to quickly check the presence of words in the list.","solution":"from typing import List, Set def find_words(grid: List[List[str]], words: List[str]) -> List[str]: def build_trie(words: List[str]): trie = {} for word in words: node = trie for char in word: if char not in node: node[char] = {} node = node[char] node[\'#\'] = word return trie def dfs(row: int, col: int, node, visited: Set): if (row < 0 or col < 0 or row >= len(grid) or col >= len(grid[0]) or (row, col) in visited or grid[row][col] not in node): return char = grid[row][col] next_node = node[char] visited.add((row, col)) if \'#\' in next_node: found_words.add(next_node[\'#\']) del next_node[\'#\'] for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]: dfs(row + dx, col + dy, next_node, visited) visited.remove((row, col)) # Build a trie from the list of words trie = build_trie(words) # Set of words found in the grid found_words = set() # Iterate through each starting point in the grid, perform DFS for row in range(len(grid)): for col in range(len(grid[0])): dfs(row, col, trie, set()) # Return the found words preserving the order from the input list return [word for word in words if word in found_words]"},{"question":"**Scenario**: You work for a software company that provides utility functions for string operations. One of the common utilities requested by users is the ability to find all unique substrings of a given length from a string. This task aims to demonstrate your understanding of string manipulation and the use of sets for ensuring uniqueness. **Task**: Write a function that finds all unique substrings of a given length from a provided string. Your function should be named `unique_substrings` and follow these specifications: 1. `unique_substrings(s: str, k: int) -> List[str]` The function should: - Take a string `s` and an integer `k` as input. - Return a list of unique substrings of length `k` found in `s`. # Constraints 1. The input string `s` will have a maximum length of 1000 characters. 2. The length `k` will be a positive integer less than or equal to the length of `s`. # Requirements 1. Ensure that the implementation handles edge cases, such as empty strings or when `k` is greater than the length of `s`. 2. Use appropriate data structures to maintain the uniqueness of substrings and maintain performance. # Expected Input and Output Format * **unique_substrings(s: str, k: int) -> List[str]** - **Input**: `s = \\"hellohello\\"`, `k = 3` - **Output**: `[\\"hel\\", \\"ell\\", \\"llo\\", \\"loh\\", \\"ohe\\", \\"hel\\"]` - **Input**: `s = \\"abcdef\\"`, `k = 2` - **Output**: `[\\"ab\\", \\"bc\\", \\"cd\\", \\"de\\", \\"ef\\"]` # Performance 1. The solution should be efficient, aiming for a linear time complexity relative to the input string length.","solution":"def unique_substrings(s: str, k: int) -> list: Finds all unique substrings of length k from the string s. Args: - s (str): the input string - k (int): the length of substrings Returns: - list: a list of unique substrings of length k if k > len(s) or k <= 0: return [] unique_subs = set() for i in range(len(s) - k + 1): unique_subs.add(s[i:i+k]) return list(unique_subs)"},{"question":"# Coding Question: Minimum Cost to Connect All Cities Background You are given a list of roads that connect different cities. Each road has a cost associated with it. Your task is to find the minimum cost required to connect all the cities such that there is a path between any two cities. Assume that all cities are connected initially and each pair of cities has at least one road connecting them directly or indirectly. Objective Write a function `min_cost(n: int, roads: List[Tuple[int, int, int]]) -> int` that calculates the minimum cost to connect all the cities. Input * An integer `n` representing the number of cities. * A list of tuples where each tuple contains three integers `[city1, city2, cost]` representing a road between `city1` and `city2` with the given `cost`. Output * Return an integer representing the minimum cost to connect all the cities. Constraints * `2 <= n <= 1000` (number of cities) * `1 <= len(roads) <= 10000` (number of roads) * Each tuple in the roads list consists of three integers representing two cities (1 <= city <= n) and the cost of the road (1 <= cost <= 1000). * There is guaranteed to be a way to connect all cities. Example ```python >>> min_cost(4, [(1, 2, 3), (2, 3, 4), (3, 4, 2), (1, 4, 1)]) 6 >>> min_cost(3, [(1, 2, 1), (2, 3, 2), (1, 3, 2)]) 3 ``` Notes * The use of Minimum Spanning Tree (MST) algorithms such as Kruskal\'s or Prim\'s is recommended to achieve an optimal solution. * Ensure to handle edge cases such as: * Multiple roads connecting the same pair of cities but with different costs. * Cases where the given input roads list represents a fully connected network with redundant paths. Edge Cases * If the number of cities is less than 2 or the roads list is empty, the function should raise appropriate error messages. Validation In addition to the above cases, your solution should efficiently handle the upper limit of inputs, ensuring scalability and performance.","solution":"def min_cost(n, roads): Returns the minimum cost required to connect all the cities. Parameters: n (int): The number of cities. roads (List[Tuple[int, int, int]]): A list of tuples where each tuple contains three integers (city1, city2, cost) representing a road between city1 and city2 with the given cost. Returns: int: The minimum cost to connect all cities. # Sort roads based on cost roads.sort(key=lambda x: x[2]) parent = list(range(n + 1)) def find(x): if parent[x] != x: parent[x] = find(parent[x]) return parent[x] def union(x, y): rootX = find(x) rootY = find(y) if rootX != rootY: parent[rootY] = rootX total_cost = 0 edges_used = 0 for u, v, cost in roads: if find(u) != find(v): union(u, v) total_cost += cost edges_used += 1 if edges_used == n - 1: break return total_cost"},{"question":"# Problem Statement Implement a function that takes a list of tasks with their durations and dependencies and returns the minimum total time required to complete all tasks. Each task must be completed before any tasks that depend on it can start. If there is a circular dependency, return `-1`. # Function Signature ```python def min_time_to_complete_tasks(tasks: dict, durations: dict) -> int: Calculates the minimum total time required to complete all tasks given their durations and dependencies. Args: tasks (dict): A dictionary where keys are task IDs and values are lists of task IDs that depend on the key task. durations (dict): A dictionary where keys are task IDs and values are the durations of the tasks. Returns: int: The minimum total time to complete all tasks or -1 if there is a circular dependency. pass ``` # Example Usage ```python tasks = { 1: [2, 3], 2: [4], 3: [4], 4: [] } durations = { 1: 3, 2: 5, 3: 8, 4: 6 } assert min_time_to_complete_tasks(tasks, durations) == 17 # Expected total time # A case with a circular dependency tasks_with_cycle = { 1: [2], 2: [3], 3: [1] } durations_with_cycle = { 1: 3, 2: 5, 3: 8 } assert min_time_to_complete_tasks(tasks_with_cycle, durations_with_cycle) == -1 ``` # Constraints * Tasks are represented by unique integers. * Durations are positive integers. * Dependencies are provided as a dictionary where each key (a task) points to a list of tasks that depend on it. * Ensure to handle edge cases like no dependencies, single task, and multiple levels of dependencies. * If there is a cycle in the dependencies, return `-1`. # Additional Information Consider edge cases such as: * No dependencies, where the total time is just the sum of the durations. * Multiple independent chains of dependencies. * Deep dependency chains. * Circular dependencies which must be detected and handled appropriately. Implement the function `min_time_to_complete_tasks` to return the correct minimum total time to complete all tasks or `-1` if there is a circular dependency.","solution":"def min_time_to_complete_tasks(tasks, durations): from collections import defaultdict, deque # Detecting circular dependencies using Kahn\'s algorithm (Topological Sort) indegree = {task: 0 for task in tasks} graph = defaultdict(list) for task in tasks: for dependent in tasks[task]: indegree[dependent] += 1 graph[task].append(dependent) # Queue for maintaining tasks with zero indegree zero_indegree_queue = deque([task for task in tasks if indegree[task] == 0]) topo_order = [] visited_count = 0 while zero_indegree_queue: current_task = zero_indegree_queue.popleft() topo_order.append(current_task) visited_count += 1 for dependent in graph[current_task]: indegree[dependent] -= 1 if indegree[dependent] == 0: zero_indegree_queue.append(dependent) # Check for a cycle (if there are unvisited tasks) if visited_count != len(tasks): return -1 # Calculate the minimum total time using the topological order completion_time = {task: 0 for task in tasks} for task in topo_order: task_duration = durations[task] # Update the completion time of dependents for dependent in tasks[task]: completion_time[dependent] = max(completion_time[dependent], completion_time[task] + task_duration) # The total time is the max completion time among all tasks total_time = max(completion_time[task] + durations[task] for task in tasks) return total_time"},{"question":"# Coding Assessment Question: Implement a Min-Heap with Update Key Functionality Objective: Design and implement a min-heap that supports insertion, extraction of the minimum element, and the ability to update the key of a specific element. Description: Create a class `MinHeap` that provides the following methods: * `__init__(self)`: Initializes an empty min-heap. * `insert(self, key, value)`: Inserts a key-value pair into the min-heap. * `extract_min(self)`: Removes and returns the key-value pair with the smallest key from the heap. * `update_key(self, current_key, new_key)`: Updates the key of an existing element to a new key, maintaining the heap property. Input/Output: * `__init__(self)`: Initializes an empty min-heap. * `insert(self, key, value)`: Inserts the key-value pair into the min-heap. * `extract_min(self)`: Removes and returns the smallest key-value pair. * `update_key(self, current_key, new_key)`: Updates the key of an existing element to the new key. Constraints: * You may assume the keys are unique and non-negative integers. * The heap should always satisfy the heap property after any operation. * Handle the scenario where the given `current_key` does not exist by raising an appropriate exception. Example: ```python # Example usage min_heap = MinHeap() min_heap.insert(10, \\"Value1\\") min_heap.insert(4, \\"Value2\\") min_heap.insert(15, \\"Value3\\") print(min_heap.extract_min()) # Output: (4, \\"Value2\\") min_heap.update_key(10, 2) print(min_heap.extract_min()) # Output: (2, \\"Value1\\") print(min_heap.extract_min()) # Output: (15, \\"Value3\\") ``` Requirements: * Implement methods to maintain the heap property for insertion and extraction. * Ensure the `update_key` method reorders the heap correctly after updating any key. * Provide necessary handling for edge cases like non-existing `current_key` and empty heap scenarios.","solution":"import heapq class MinHeap: def __init__(self): self.heap = [] self.entry_finder = {} # mapping of keys to entries self.REMOVED = \'<removed-item>\' # placeholder for a removed item self.counter = 0 def insert(self, key, value): \'Add a new key or update the value of an existing key\' if key in self.entry_finder: self.remove_entry(key) count = self.counter entry = [key, count, value] self.entry_finder[key] = entry heapq.heappush(self.heap, entry) self.counter += 1 def remove_entry(self, key): \'Mark an existing entry as REMOVED. Raise KeyError if not found.\' entry = self.entry_finder.pop(key) entry[-1] = self.REMOVED def extract_min(self): \'Remove and return the lowest key and value pair. Raise KeyError if empty.\' while self.heap: key, count, value = heapq.heappop(self.heap) if value is not self.REMOVED: del self.entry_finder[key] return (key, value) raise KeyError(\'pop from an empty priority queue\') def update_key(self, current_key, new_key): \'Update the key of an existing entry to a new key\' if current_key not in self.entry_finder: raise KeyError(\'Current key not found.\') value = self.entry_finder[current_key][2] self.remove_entry(current_key) self.insert(new_key, value)"},{"question":"# Problem Statement You are tasked with implementing a system that processes and analyzes logs generated from a server\'s activity over a period. The logs are recorded in a specific format, and your objective is to collect information about unique visitors and their activity sequences. # Task Write a function `analyze_logs` that takes in a list of log entries and processes this data to extract two pieces of information: 1. A dictionary mapping each unique visitor ID to a list of URLs they visited in the order they visited them. 2. A list of URLs sorted by the total number of visits in descending order. # Input * `logs` (list): A list of log entries, where each entry is a dictionary containing: * `visitor_id` (str): The unique identifier for the visitor. * `url` (str): The URL visited by the visitor. * `timestamp` (int): The Unix timestamp representing when the visit occurred. # Output * A tuple containing: * A dictionary with visitor IDs as keys and lists of visited URLs as values. * A list of URLs sorted by visit frequency in descending order. # Constraints * Assume each `visitor_id` is a unique string. * Assume URLs visited by different visitors can be repeated. * No two log entries for the same visitor can have the same timestamp. # Performance Requirements * The solution should efficiently process up to 10,000 log entries. * Use appropriate data structures to optimize for time and space complexity. # Example Function Signature ```python from typing import List, Tuple, Dict def analyze_logs(logs: List[dict]) -> Tuple[Dict[str, List[str]], List[str]]: visitor_activity = {} url_visit_count = {} for log in logs: visitor_id = log[\'visitor_id\'] url = log[\'url\'] # Maintain the visitor activity as ordered lists of URLs if visitor_id not in visitor_activity: visitor_activity[visitor_id] = [] visitor_activity[visitor_id].append(url) # Count visit frequency for URLs if url not in url_visit_count: url_visit_count[url] = 0 url_visit_count[url] += 1 # Sort URLs by visit count in descending order sorted_urls = sorted(url_visit_count.keys(), key=lambda x: url_visit_count[x], reverse=True) return visitor_activity, sorted_urls ``` # Example Usage ```python logs = [ {\'visitor_id\': \'abc123\', \'url\': \'/home\', \'timestamp\': 1609459200}, {\'visitor_id\': \'xyz789\', \'url\': \'/about\', \'timestamp\': 1609459260}, {\'visitor_id\': \'abc123\', \'url\': \'/contact\', \'timestamp\': 1609459320}, {\'visitor_id\': \'xyz789\', \'url\': \'/home\', \'timestamp\': 1609459380}, {\'visitor_id\': \'lmn456\', \'url\': \'/home\', \'timestamp\': 1609459440}, {\'visitor_id\': \'abc123\', \'url\': \'/about\', \'timestamp\': 1609459500}, ] activity, popular_urls = analyze_logs(logs) print(activity) # Output: {\'abc123\': [\'/home\', \'/contact\', \'/about\'], \'xyz789\': [\'/about\', \'/home\'], \'lmn456\': [\'/home\']} print(popular_urls) # Output: [\'/home\', \'/about\', \'/contact\'] ``` **Remember**: Your solution should handle various edge cases, such as missing log entries or malformed data, gracefully.","solution":"from typing import List, Tuple, Dict def analyze_logs(logs: List[dict]) -> Tuple[Dict[str, List[str]], List[str]]: visitor_activity = {} url_visit_count = {} for log in logs: visitor_id = log[\'visitor_id\'] url = log[\'url\'] # Maintain the visitor activity as ordered lists of URLs if visitor_id not in visitor_activity: visitor_activity[visitor_id] = [] visitor_activity[visitor_id].append(url) # Count visit frequency for URLs if url not in url_visit_count: url_visit_count[url] = 0 url_visit_count[url] += 1 # Sort URLs by visit count in descending order sorted_urls = sorted(url_visit_count.keys(), key=lambda x: url_visit_count[x], reverse=True) return visitor_activity, sorted_urls"},{"question":"# Problem Description You are given a Singly Linked List that supports basic operations like insertion and deletion. Your task is to enhance the existing code to support an additional feature: **Finding the Nth Node from the End**. This feature is useful in scenarios where you need to quickly access elements near the end of the list, without traversing the entire list multiple times. # Objective Implement a method in the `LinkedList` class called `find_nth_from_end` that takes an integer `n` and returns the value of the nth node from the end of the linked list. # Input * A `LinkedList` instance. * An integer `n`. # Output * The value of the nth node from the end of the linked list. # Constraints * The list consists of at most 1000 nodes. * The integer `n` will always be between 1 and the length of the list, inclusive. # Example Given the linked list built with the elements [10, 20, 30, 40, 50]: ```python ll = LinkedList() ll.insert_many([10, 20, 30, 40, 50]) ``` Calling `ll.find_nth_from_end(2)` should return: ``` 40 ``` # Implementation Notes 1. Utilize a two-pointer technique to find the nth node from the end efficiently. 2. Initialize two pointers, advance one pointer by `n` steps, and then move both pointers one step at a time until the advanced pointer reaches the end of the list. # Code Template ```python class ListNode: def __init__(self, value=0, next=None): self.value = value self.next = next class LinkedList: def __init__(self): self.head = None def insert_many(self, items): for item in items: self.insert(item) def insert(self, value): if not self.head: self.head = ListNode(value) else: current = self.head while current.next: current = current.next current.next = ListNode(value) def find_nth_from_end(self, n: int): Find the nth node from the end of the linked list. Args: n (int): the position from the end to find the node. Returns: int: value of the nth node from the end. # Your implementation here. pass # Example usage ll = LinkedList() ll.insert_many([10, 20, 30, 40, 50]) print(ll.find_nth_from_end(2)) # Output should be 40 ``` # Requirements * Ensure the function operates efficiently with the given constraints. * Handle edge cases appropriately, such as lists with minimal nodes.","solution":"class ListNode: def __init__(self, value=0, next=None): self.value = value self.next = next class LinkedList: def __init__(self): self.head = None def insert_many(self, items): for item in items: self.insert(item) def insert(self, value): if not self.head: self.head = ListNode(value) else: current = self.head while current.next: current = current.next current.next = ListNode(value) def find_nth_from_end(self, n: int): Find the nth node from the end of the linked list. Args: n (int): the position from the end to find the node. Returns: int: value of the nth node from the end. first = self.head second = self.head # Move first pointer n steps ahead for _ in range(n): if first: first = first.next # Move both pointers until first reaches end while first: first = first.next second = second.next # second should now point to the nth from the end node return second.value"},{"question":"# Coding Assessment Question **Scenario**: You are working on a keyword-based content recommendation engine for an ebook reader app. The app needs to respond quickly to user queries by searching for books based on keywords and returning relevant book details. **Task**: Implement a function `search_books_by_keyword` that searches for books containing a given keyword in their title or description and returns a list of dictionaries. Each dictionary should contain the book\'s title, author, and a shortened snippet from the description where the keyword appears. **Function Signature**: ```python def search_books_by_keyword(keyword: str) -> list: Searches for books containing the given keyword in their title or description and returns a list of dictionaries with the book title, author, and a snippet of the description. Args: keyword (str): The keyword to search for in book titles and descriptions. Returns: list: List of dictionaries where each dictionary has keys \'title\', \'author\', \'snippet\'. ``` **Example**: ```python results = search_books_by_keyword(\\"magic\\") for book in results: print(f\\"Title: {book[\'title\']}nAuthor: {book[\'author\']}nSnippet: {book[\'snippet\']}n\\") ``` **Constraints**: 1. Your function must: - Use the provided dataset `books_data` (a list of dictionaries where each dictionary represents a book with keys: \'title\', \'author\', \'description\'). - Ensure the keyword search is case-insensitive. - Return a snippet of up to 30 characters surrounding the first occurrence of the keyword in the description. - Handle cases where the keyword is not found in the description gracefully (e.g., exclude such entries from the results). 2. Optimize the function to handle datasets with up to 100,000 books efficiently. **Performance Boundaries**: - Ensure the function can respond within 1 second for datasets up to 100,000 books. **Additional Notes**: - Focus on making the search and snippet generation efficient. - Consider edge cases like very short descriptions, keywords at the start or end of descriptions, and overlapping keywords. - Document your function with appropriate comments for clarity. ```python # Sample books_data for testing books_data = [ {\\"title\\": \\"The Magic of Thinking Big\\", \\"author\\": \\"David Schwartz\\", \\"description\\": \\"This book explains the principles of thinking big, setting high goals, and achieving them through a series of practical steps.\\"}, {\\"title\\": \\"Fantasy Magic\\", \\"author\\": \\"John Doe\\", \\"description\\": \\"An epic tale of magic and adventure set in a mystical land with numerous challenges.\\"}, # More books... ] def search_books_by_keyword(keyword: str) -> list: Implementation here ```","solution":"# Sample books_data for testing books_data = [ {\\"title\\": \\"The Magic of Thinking Big\\", \\"author\\": \\"David Schwartz\\", \\"description\\": \\"This book explains the principles of thinking big, setting high goals, and achieving them through a series of practical steps.\\"}, {\\"title\\": \\"Fantasy Magic\\", \\"author\\": \\"John Doe\\", \\"description\\": \\"An epic tale of magic and adventure set in a mystical land with numerous challenges.\\"}, {\\"title\\": \\"Non-magic Book\\", \\"author\\": \\"Jane Roe\\", \\"description\\": \\"This book has nothing to do with magic, rather it is about science and facts.\\"}, # More books... ] def search_books_by_keyword(keyword: str) -> list: Searches for books containing the given keyword in their title or description and returns a list of dictionaries with the book title, author, and a snippet of the description. Args: keyword (str): The keyword to search for in book titles and descriptions. Returns: list: List of dictionaries where each dictionary has keys \'title\', \'author\', \'snippet\'. keyword = keyword.lower() results = [] for book in books_data: title = book[\'title\'] author = book[\'author\'] description = book[\'description\'] title_lower = title.lower() description_lower = description.lower() if keyword in title_lower or keyword in description_lower: if keyword in description_lower: start_idx = description_lower.find(keyword) snippet_start = max(0, start_idx - 15) snippet_end = min(len(description), start_idx + 15 + len(keyword)) snippet = description[snippet_start:snippet_end] else: snippet = \\"\\" results.append({ \'title\': title, \'author\': author, \'snippet\': snippet }) return results"},{"question":"# Sorting a Mixed List of Integers and Strings **Scenario**: In some applications, you might encounter lists that contain both integers and strings. Your goal is to sort such a list in a specific manner where all integers come first in ascending order, followed by all strings in lexicographical order. **Function to Implement**: ```python def mixed_sort(input_list: list) -> list: Sorts a mixed list of integers and strings with integers first in ascending order, followed by strings in lexicographical order. Args: input_list (list): A list containing both integers and strings. Returns: list: A new list with integers sorted in ascending order followed by strings in lexicographical order. Raises: TypeError: If the input_list contains elements that are neither integers nor strings. pass ``` **Requirements**: 1. Implement the `mixed_sort` function. 2. Handle lists containing integers, strings, or a mix of both. 3. Your function should raise a `TypeError` if the `input_list` contains elements that are neither integers nor strings. **Input**: - `input_list` (list): A list with elements that are either integers or strings. **Output**: - Returns a list where integers are sorted in ascending order, followed by strings sorted in lexicographical order. **Constraints**: - The list may contain up to `10^5` elements. - At least one element in the list is either an integer or a string. **Performance**: - Aim for `O(n log n)` time complexity due to sorting operations. **Hints**: 1. You can separate integers and strings into two different lists, sort them individually, and then concatenate the results. 2. Use Python\'s built-in sorting functions for simplicity and efficiency. **Example**: You can test your implementation with the following example: ```python input_list = [3, \\"apple\\", 1, \\"banana\\", 2, \\"cherry\\"] output = mixed_sort(input_list) # Expected output: [1, 2, 3, \\"apple\\", \\"banana\\", \\"cherry\\"] ```","solution":"def mixed_sort(input_list: list) -> list: Sorts a mixed list of integers and strings with integers first in ascending order, followed by strings in lexicographical order. Args: input_list (list): A list containing both integers and strings. Returns: list: A new list with integers sorted in ascending order followed by strings in lexicographical order. Raises: TypeError: If the input_list contains elements that are neither integers nor strings. integers = [] strings = [] for item in input_list: if isinstance(item, int): integers.append(item) elif isinstance(item, str): strings.append(item) else: raise TypeError(\\"The input_list contains elements that are neither integers nor strings.\\") integers.sort() strings.sort() return integers + strings"},{"question":"# Unique Character String Generator You need to implement a function that generates all possible unique strings of length `n` using a given set of characters. The output should be sorted in alphabetical order. Your function should: 1. Generate all possible unique strings of length `n`. 2. Return the result as a sorted list of strings. # Function Signature ```python def generate_unique_strings(characters: List[str], n: int) -> List[str]: ``` # Input - `characters` (List[str]): A list of characters to be used for generating strings. The characters are unique within the list and are given in random order. - `n` (int): The length of the strings to be generated. # Output - List of strings: A sorted list of all possible unique strings of length `n` using the given characters. # Constraints - `1 <= len(characters) <= 10` - `1 <= n <= 5` - Characters in the `characters` list are ASCII characters. # Example ```python # Example 1 characters1 = [\'a\', \'b\', \'c\'] n1 = 2 result1 = generate_unique_strings(characters1, n1) # Expected output: [\'aa\', \'ab\', \'ac\', \'ba\', \'bb\', \'bc\', \'ca\', \'cb\', \'cc\'] # Example 2 characters2 = [\'x\', \'y\'] n2 = 3 result2 = generate_unique_strings(characters2, n2) # Expected output: [\'xxx\', \'xxy\', \'xyx\', \'xyy\', \'yxx\', \'yxy\', \'yyx\', \'yyy\'] ``` # Explanation of Output Examples For `characters = [\'a\', \'b\', \'c\']` and `n = 2`, the function should generate all 2-letter combinations sorted alphabetically. As a result, we expect the list: - [\'aa\', \'ab\', \'ac\', \'ba\', \'bb\', \'bc\', \'ca\', \'cb\', \'cc\']. Similarly, for `characters = [\'x\', \'y\']` and `n = 3`, the function should generate: - [\'xxx\', \'xxy\', \'xyx\', \'xyy\', \'yxx\', \'yxy\', \'yyx\', \'yyy\']. Each combination should be unique and the list should be sorted alphabetically.","solution":"from itertools import product from typing import List def generate_unique_strings(characters: List[str], n: int) -> List[str]: Generate all possible unique strings of length n using the given set of characters. The result is returned as a sorted list of strings. all_combinations = product(characters, repeat=n) unique_strings = [\'\'.join(comb) for comb in all_combinations] unique_strings.sort() return unique_strings"},{"question":"Coding Question: Implementing and Testing a Genetic Algorithm for Function Maximization You are provided with a partial implementation of a Genetic Algorithm (GA) framework. Currently, the framework includes class definitions for `Individual` and `Population`, along with basic functionality for selection, crossover, and mutation operations. The objective of this task is to complete and test the Genetic Algorithm to optimize (maximize) a given mathematical function. The function to be maximized is: [ f(x, y) = sin(x) cdot cos(y) + cos(x) cdot sin(y) ] # Task 1. **Complete the Genetic Algorithm Implementation**: - Fill in the missing methods in the `GeneticAlgorithm` class, including: - A method for evaluating fitness. - Methods for performing selection, crossover, mutation, and generating new populations. 2. **Integrate & Test**: - Ensure the completed Genetic Algorithm works properly to optimize the provided function. - Test the Genetic Algorithm by running several iterations and outputting the best individual and its fitness score. 3. **Required Code Implementation**: - Implement the fitness evaluation function to calculate the fitness of an individual based on the function ( f(x, y) ). - Implement the GA operations methods. - Provide a test function to run the GA on the provided function ( f(x, y) ). # Function Signatures ```python import numpy as np class Individual: def __init__(self, x, y): self.x = x self.y = y self.fitness = None class Population: def __init__(self, size): self.individuals = [Individual(np.random.uniform(-10, 10), np.random.uniform(-10, 10)) for _ in range(size)] class GeneticAlgorithm: def __init__(self, population_size=50, generations=100, crossover_rate=0.7, mutation_rate=0.01): self.population = Population(population_size) self.generations = generations self.crossover_rate = crossover_rate self.mutation_rate = mutation_rate def fitness_function(self, individual): Calculate the fitness of an individual. :param individual: Individual, the individual whose fitness is to be calculated. :return: float, the fitness score. # Implement the fitness function here x, y = individual.x, individual.y return np.sin(x) * np.cos(y) + np.cos(x) * np.sin(y) def selection(self): Select individuals from the population based on their fitness. :return: List of Individuals selected. # Implement selection logic here def crossover(self, parent1, parent2): Perform crossover between two parents to produce an offspring. :param parent1: Individual, the first parent. :param parent2: Individual, the second parent. :return: Individual, the offspring. # Implement crossover logic here def mutate(self, individual): Perform mutation on an individual. :param individual: Individual, the individual to be mutated. # Implement mutation logic here def generate_new_population(self): Generate a new population using selection, crossover, and mutation. # Implement new population generation logic here def run(self): Run the genetic algorithm for the specified number of generations. for _ in range(self.generations): self.generate_new_population() best_individual = max(self.population.individuals, key=self.fitness_function) return best_individual def test_genetic_algorithm(): Test function for Genetic Algorithm. ga = GeneticAlgorithm() best_individual = ga.run() print(f\\"Best Individual: x = {best_individual.x}, y = {best_individual.y}, fitness = {best_individual.fitness}\\") # Uncomment to test # test_genetic_algorithm() ``` # Constraints: 1. Ensure a minimum population size of 20 individuals. 2. Use a minimal crossover rate of 0.6 and a mutation rate of 0.01. 3. Display results including parameters of the best individual and its fitness score. # Sample Input: No specific input is needed as parameters for individuals and population are randomly initialized. # Sample Output: ``` Best Individual: x = 2.34, y = 1.57, fitness = 1.0 ``` A plot can also be displayed showing the convergence of the GA over generations, with the fitness of the best individual.","solution":"import numpy as np class Individual: def __init__(self, x, y): self.x = x self.y = y self.fitness = None class Population: def __init__(self, size): self.individuals = [Individual(np.random.uniform(-10, 10), np.random.uniform(-10, 10)) for _ in range(size)] class GeneticAlgorithm: def __init__(self, population_size=50, generations=100, crossover_rate=0.7, mutation_rate=0.01): self.population = Population(population_size) self.generations = generations self.crossover_rate = crossover_rate self.mutation_rate = mutation_rate def fitness_function(self, individual): Calculate the fitness of an individual. :param individual: Individual, the individual whose fitness is to be calculated. :return: float, the fitness score. x, y = individual.x, individual.y return np.sin(x) * np.cos(y) + np.cos(x) * np.sin(y) def selection(self): Select individuals from the population based on their fitness. :return: List of Individuals selected. sorted_individuals = sorted(self.population.individuals, key=self.fitness_function, reverse=True) return sorted_individuals[:len(sorted_individuals)//2] def crossover(self, parent1, parent2): Perform crossover between two parents to produce an offspring. :param parent1: Individual, the first parent. :param parent2: Individual, the second parent. :return: Individual, the offspring. if np.random.rand() > self.crossover_rate: return parent1 alpha = np.random.rand() x = alpha * parent1.x + (1 - alpha) * parent2.x y = alpha * parent1.y + (1 - alpha) * parent2.y return Individual(x, y) def mutate(self, individual): Perform mutation on an individual. :param individual: Individual, the individual to be mutated. if np.random.rand() < self.mutation_rate: individual.x += np.random.normal() individual.y += np.random.normal() def generate_new_population(self): Generate a new population using selection, crossover, and mutation. new_population = [] selected_individuals = self.selection() while len(new_population) < len(self.population.individuals): parent1, parent2 = np.random.choice(selected_individuals, 2) offspring = self.crossover(parent1, parent2) self.mutate(offspring) new_population.append(offspring) self.population.individuals = new_population def run(self): Run the genetic algorithm for the specified number of generations. for _ in range(self.generations): self.generate_new_population() best_individual = max(self.population.individuals, key=self.fitness_function) best_individual.fitness = self.fitness_function(best_individual) return best_individual def test_genetic_algorithm(): Test function for Genetic Algorithm. ga = GeneticAlgorithm() best_individual = ga.run() print(f\\"Best Individual: x = {best_individual.x}, y = {best_individual.y}, fitness = {best_individual.fitness}\\") # Uncomment to test # test_genetic_algorithm()"},{"question":"# Unique Users per Device ID Logging You are tasked with creating a function that processes a log file containing user interactions within a mobile app. Each log entry records a user’s activity identified by a unique `user_id` and the device used identified by a `device_id`. Your function should implement the following requirements: 1. Read the log data from a given text file. 2. Extract the `user_id` and `device_id` from each log entry. 3. Calculate the number of unique `user_ids` associated with each `device_id`. 4. Return a dictionary where the keys are `device_ids` and the values are the counts of unique `user_ids` per `device_id`. The function signature should be: ```python def unique_users_per_device(log_file: str) -> dict[str, int]: Returns a dictionary where keys are device IDs and values are the counts of unique user IDs per device ID. ``` Input: - `log_file` (str): The path to the log file. Each line in the log file is formatted as `\\"timestamp user_id device_id\\"`. Output: - Dictionary (dict): A dictionary with `device_id` as keys and the number of unique `user_id`s as values. Constraints: - The log file entries are well-formed and contain no missing data. - Each `user_id` and `device_id` are alphanumeric strings. - The log file can potentially be large, so the implementation should be efficient in terms of memory usage. Example: If the log file contains the following lines: ``` 2023-01-01T12:00:00 user1 deviceA 2023-01-01T12:10:00 user2 deviceA 2023-01-01T12:20:00 user1 deviceA 2023-01-01T12:30:00 user3 deviceB 2023-01-01T12:40:00 user3 deviceB 2023-01-01T12:50:00 user4 deviceA ``` Then, the function output should be: ``` { \\"deviceA\\": 3, \\"deviceB\\": 1 } ``` Here\'s an example to get you started: ```python def unique_users_per_device(log_file: str) -> dict[str, int]: Returns a dictionary where keys are device IDs and values are the counts of unique user IDs per device ID. from collections import defaultdict device_users = defaultdict(set) with open(log_file, \'r\') as file: for line in file: _, user_id, device_id = line.strip().split() device_users[device_id].add(user_id) return {device_id: len(users) for device_id, users in device_users.items()} # Example of use log_file_path = \\"path/to/logfile.log\\" print(unique_users_per_device(log_file_path)) ``` Make sure to test your function for various log files to ensure correctness and efficiency.","solution":"def unique_users_per_device(log_file: str) -> dict[str, int]: Returns a dictionary where keys are device IDs and values are the counts of unique user IDs per device ID. from collections import defaultdict device_users = defaultdict(set) with open(log_file, \'r\') as file: for line in file: _, user_id, device_id = line.strip().split() device_users[device_id].add(user_id) return {device_id: len(users) for device_id, users in device_users.items()}"},{"question":"# Task Description Implement a function to calculate the maximum sum of non-adjacent numbers in a list using dynamic programming. The goal is to maximize the sum without selecting two consecutive elements from the list. # Function Signature ```python def max_sum_non_adjacent(nums: List[int]) -> int: pass ``` # Input - A list of integers `nums` where 0 ≤ len(nums) ≤ 10^5 and -10^4 ≤ nums[i] ≤ 10^4. # Output - Return an integer representing the maximum sum of non-adjacent numbers. # Constraints - You need to find the maximum sum such that no two selected numbers are adjacent in the list. - Your solution should handle large inputs efficiently, preferably in O(n) time complexity and O(1) space complexity. # Example ```python assert max_sum_non_adjacent([3, 2, 5, 10, 7]) == 15 # 3 + 10 + 7 assert max_sum_non_adjacent([3, 2, 7, 10]) == 13 # 3 + 10 assert max_sum_non_adjacent([5, 5, 10, 100, 10, 5]) == 110 # 5 + 100 + 5 assert max_sum_non_adjacent([5, 1, 1, 5]) == 10 # 5 + 5 assert max_sum_non_adjacent([]) == 0 assert max_sum_non_adjacent([1, 2, 9, 4, 5, 0, 4, 11, 6]) == 26 # 1 + 9 + 5 + 11 } ``` # Special Note - Aim to use an iterative approach to avoid excessive recursion stack depth. - Consider carefully the base cases where the list may be empty or contain only one or two elements.","solution":"from typing import List def max_sum_non_adjacent(nums: List[int]) -> int: if not nums: return 0 if len(nums) == 1: return max(0, nums[0]) # Initial values for the sums prev1, prev2 = max(0, nums[0]), 0 for num in nums[1:]: current = max(prev1, prev2 + num) prev2, prev1 = prev1, current return prev1"},{"question":"# Coding Assessment Question Scenario You have been hired to work on a financial analysis tool that helps investment firms analyze stock data for better decision-making. As part of the tool, you need to implement a feature that identifies profitable stock investments based on historical data. Task Implement a function `max_profit_days` that receives a list of stock prices where each element represents the stock price on a given day. The function should return a tuple containing the best days to buy and sell the stock to achieve the maximum profit. If no profit is possible, return (-1, -1). Function Signature ```python def max_profit_days(prices: list) -> tuple: Identifies the best days to buy and sell stock for maximum profit. Args: prices (list): List of stock prices where each price represents the stock price on a given day. Returns: tuple: A tuple (buy_day, sell_day) indicating the day to buy and the day to sell for maximum profit. If no profit can be made, returns (-1, -1). ``` Example ```python prices = [7, 1, 5, 3, 6, 4] result = max_profit_days(prices) print(result) # Output: (1, 4) prices = [7, 6, 4, 3, 1] result = max_profit_days(prices) print(result) # Output: (-1, -1) ``` Constraints 1. Your function must: - Analyze the input list and determine the days that yield the maximum profit. - If there are multiple answers (like multiple days with the same profit), return any one of them. 2. Implement the function efficiently, with a time complexity of O(n). Performance Boundaries - Ensure that your function can handle input lists of up to 10^6 elements within a reasonable time frame. Additional Notes - Day 0 corresponds to the first element in the list, Day 1 to the second, and so forth. - Consider edge cases where the input list is empty or contains only one element.","solution":"def max_profit_days(prices: list) -> tuple: Identifies the best days to buy and sell stock for maximum profit. Args: prices (list): List of stock prices where each price represents the stock price on a given day. Returns: tuple: A tuple (buy_day, sell_day) indicating the day to buy and the day to sell for maximum profit. If no profit can be made, returns (-1, -1). if not prices or len(prices) < 2: return (-1, -1) min_price = prices[0] min_day = 0 max_profit = 0 buy_day = -1 sell_day = -1 for i in range(1, len(prices)): profit = prices[i] - min_price if profit > max_profit: max_profit = profit buy_day = min_day sell_day = i if prices[i] < min_price: min_price = prices[i] min_day = i if max_profit == 0: return (-1, -1) return (buy_day, sell_day)"},{"question":"# Question Given a list of integers, write a function `critical_connections` that finds all the critical connections in a network represented by an undirected graph. A connection is critical if removing it causes the network to be disconnected. The graph is connected and has no cycles. **Function Signature**: ```python def critical_connections(n: int, connections: List[List[int]]) -> List[List[int]]: ``` # Input - `n`: an integer representing the number of nodes in the graph (1 <= n <= 10^5). - `connections`: a list where each element is a list of two integers representing an undirected edge between two nodes. There are `n-1` connections in total. # Output - A list of lists, where each sublist represents a critical connection. The order of the connections in the output does not matter. # Constraints - The connections list represents a graph that is connected and acyclic (i.e., a tree). - There is exactly one unique path between any two nodes. - The nodes are numbered from 0 to n-1. # Examples ```python # Example 1 n = 5 connections = [[0,1], [1,2], [2,3], [3,4]] print(critical_connections(n, connections)) # Expected Output: [[0,1], [1,2], [2,3], [3,4]] # Example 2 n = 4 connections = [[0,1], [1,2], [2,3]] print(critical_connections(n, connections)) # Expected Output: [[0,1], [1,2], [2,3]] ``` # Notes - This problem can be approached by understanding that all the edges in a tree are critical connections because removing any one of them will disconnect the tree. - Consider advanced graph algorithms such as Depth-First Search (DFS) to efficiently identify and handle potential critical connections.","solution":"from typing import List def critical_connections(n: int, connections: List[List[int]]) -> List[List[int]]: Since the network is a tree (acyclic connected graph), every single edge is a critical connection. Therefore, the result should simply be the input list of connections. return connections"},{"question":"# Stock Price Tracker You are provided with a class, `StockPriceTracker`, that maintains stock prices and supports various operations on it. Your task is to implement one additional method for this class: `is_stable`. This method will determine if the stock price has been stable over a given window of days. A stock price is considered stable if the absolute difference between the highest and lowest prices within the window does not exceed a specified threshold. Function Signature ```python def is_stable(self, window: int, threshold: float) -> bool: ``` Input - `window` (int): The number of recent days to consider for checking stability. - `threshold` (float): The maximum allowed difference between the highest and lowest stock prices within the window. Output - Returns `True` if the stock price has been stable over the given window of days. Otherwise, returns `False`. Constraints - You can assume that there is sufficient data to cover the window size. - Prices are floating-point numbers. - `window` is a positive integer. Example ```python s = StockPriceTracker() s.record_price(100.0) s.record_price(101.5) s.record_price(102.0) s.record_price(103.5) s.record_price(104.0) assert s.is_stable(3, 2.0) == True # The prices in the most recent 3 days are [102.0, 103.5, 104.0], difference is 2.0 (104.0 - 102.0 <= 2.0) assert s.is_stable(3, 1.0) == False # The prices in the most recent 3 days are [102.0, 103.5, 104.0], difference is 2.0 (104.0 - 102.0 > 1.0) ```","solution":"class StockPriceTracker: def __init__(self): self.prices = [] def record_price(self, price: float): self.prices.append(price) def is_stable(self, window: int, threshold: float) -> bool: if len(self.prices) < window: raise ValueError(\\"Insufficient data to cover the window size.\\") recent_prices = self.prices[-window:] max_price = max(recent_prices) min_price = min(recent_prices) return (max_price - min_price) <= threshold"},{"question":"# Given Problem Write a function for computing the factorial of a given positive integer using a recursive approach. # Requirements 1. **Function Name**: `recursive_factorial` 2. **Arguments**: - `n` (int), a positive integer. 3. **Output**: Return the factorial of integer `n`. 4. **Constraints**: `n` must be a non-negative integer. Raise a `ValueError` if `n` is negative. # Examples ```python # Factorial of 5 recursive_factorial(5) # Output: 120 # Factorial of 0 recursive_factorial(0) # Output: 1 # Factorial of 7 recursive_factorial(7) # Output: 5040 # Factorial of 1 recursive_factorial(1) # Output: 1 ``` # Implementation Write the function `recursive_factorial` to meet the above requirements. **Function Signature**: ```python def recursive_factorial(n: int) -> int: pass ``` **Notes**: - Ensure the function handles base cases correctly. - The function should call itself recursively for factorial computation.","solution":"def recursive_factorial(n: int) -> int: Computes the factorial of a given positive integer using a recursive approach. Parameters: n (int): A non-negative integer to compute the factorial of. Returns: int: Factorial of the given number. Raises: ValueError: If n is a negative integer. if n < 0: raise ValueError(\\"Input must be a non-negative integer.\\") if n == 0: return 1 return n * recursive_factorial(n - 1)"},{"question":"# Binary Tree Upside-Down Conversion You are tasked with implementing a function that converts a given Binary Tree into its Upside-Down form. In an Upside-Down Binary Tree, the original left child becomes the new root, the original root becomes the new right child, and the original right child becomes the new left child if the original root has a left child. Write a function `upside_down_binary_tree(root: TreeNode) -> TreeNode` that takes the root of a binary tree and returns the new root after converting the tree to its Upside-Down form. Definition for a Binary Tree Node: ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right ``` Constraints: 1. The Binary Tree should be a full binary tree (every node has 0 or 2 children). 2. The node values will be integers in the range of [-1000, 1000]. 3. The depth of the tree will not exceed 10. Expected Input/Output: - Input: ``` python root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) ``` - Output: ``` python new_root = TreeNode(4) new_root.left = TreeNode(5) new_root.right = TreeNode(2) new_root.right.left = TreeNode(3) new_root.right.right = TreeNode(1) ``` Example: ``` python # Example binary tree: # 1 # / # 2 3 # / # 4 5 root = TreeNode(1) root.left = TreeNode(2) root.right = TreeNode(3) root.left.left = TreeNode(4) root.left.right = TreeNode(5) # After conversion, the tree will look like: # 4 # / # 5 2 # / # 3 1 print_tree(upside_down_binary_tree(root)) # Output: # TreeNode( # val=4, # left=TreeNode( # val=5, # left=None, # right=None # ), # right=TreeNode( # val=2, # left=TreeNode( # val=3, # left=None, # right=None # ), # right=TreeNode( # val=1, # left=None, # right=None # ) # ) # ) ``` Notes: 1. Ensure your function properly handles null inputs and returns null if the input is null. 2. Focus on the iterative process and tree manipulation skills. 3. You may use helper functions if necessary to achieve a clean and organized solution.","solution":"class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def upside_down_binary_tree(root: TreeNode) -> TreeNode: if not root or not root.left: return root new_root = upside_down_binary_tree(root.left) root.left.left = root.right root.left.right = root root.left = None root.right = None return new_root"},{"question":"**Question 2]: **Maze Path Finder** You are given a 2D grid that represents a maze, where `0` indicates open space and `1` indicates walls. Your task is to determine the shortest path from the top-left corner to the bottom-right corner, given that you can only move up, down, left, or right. **Function Signature**: ```python def find_shortest_path(maze: list[list[int]]) -> int: pass ``` **Input**: - `maze`: A 2D list where each element is either `0` (open space) or `1` (wall). Assume the maze is rectangular and will not be empty. **Output**: - An integer representing the number of steps in the shortest path from the top-left to the bottom-right corner. If there\'s no valid path, return `-1`. **Constraints**: - The maze dimensions are between 1x1 and 100x100. - The top-left corner of the maze (maze[0][0]) and the bottom-right corner (maze[-1][-1]) will always be `0`. **Example**: ```python >>> find_shortest_path([ [0, 1, 1, 0, 0], [0, 1, 1, 1, 0], [0, 0, 0, 1, 0], [1, 1, 0, 1, 0], [0, 0, 0, 0, 0] ]) 7 >>> find_shortest_path([ [0, 1], [1, 0] ]) -1 ``` **Explanation**: 1. For the first example: - The shortest path can be described as (without walls): Start at (0,0), move to (1,0), (2,0), (2,1), (2,2), (3,2), (4,2), ending at (4,4) which results in 7 steps. 2. For the second example: - There is no possible way to navigate through the maze to reach the end, hence the output is `-1`. **Performance Requirements**: - Your solution should be optimized to handle large grids efficiently. - Consider using BFS (Breadth-First Search) for finding shortest paths in unweighted grids. **Scenarios**: The context of this task could be real-world applications like navigating through robotic paths, game development, or even GPS systems plotting the shortest path in a grid-based city map.","solution":"from collections import deque def find_shortest_path(maze): Determine the shortest path from the top-left corner to the bottom-right corner of the maze. Parameters: maze (list of list of int): 2D grid where 0 indicates open space and 1 indicates walls. Returns: int: Number of steps in the shortest path, or -1 if no valid path exists. rows, cols = len(maze), len(maze[0]) if maze[0][0] == 1 or maze[rows-1][cols-1] == 1: return -1 directions = [(0, 1), (1, 0), (0, -1), (-1, 0)] # Queue stores the position (row, col) and the distance traveled to reach that position queue = deque([(0, 0, 1)]) visited = set((0, 0)) while queue: row, col, dist = queue.popleft() if row == rows - 1 and col == cols - 1: return dist for dr, dc in directions: r, c = row + dr, col + dc if 0 <= r < rows and 0 <= c < cols and maze[r][c] == 0 and (r, c) not in visited: visited.add((r, c)) queue.append((r, c, dist + 1)) return -1"},{"question":"# Question: Find Height of a Binary Tree You are provided with a binary tree data structure. Your task is to calculate the height of the tree using a depth-first search technique. The height of a binary tree is the number of edges between the tree\'s root and its farthest leaf. # Function Signature ```python def height_of_tree(root: Node) -> int: Calculate the height of the binary tree rooted at `root`. Args: root (Node): The root node of the binary tree. Returns: int: The height of the tree. ``` # Input - `root`: A `Node` object representing the root of the binary tree. The Node class is defined as: ```python class Node: def __init__(self, value: int) -> None: self.value = value self.left: Node | None = None self.right: Node | None = None ``` # Output - An integer representing the height of the tree. If the tree is empty (i.e., `root` is `None`), the height is `-1`. # Constraints - The number of nodes in the tree will be in the range `[0, 10^4]`. # Example ```python # Define the tree root = Node(10) root.left = Node(5) root.right = Node(-3) root.left.left = Node(12) root.right.left = Node(8) root.right.right = Node(0) # Calculate the height result = height_of_tree(root) # Output should be 2 ``` # Edge Cases to Consider - Tree with only one node (height should be 0). - Empty tree (should return -1). - Tree with large depth. - Tree with unbalanced structure (e.g., all nodes only on the left or right). Please implement the `height_of_tree` function accordingly.","solution":"class Node: def __init__(self, value: int) -> None: self.value = value self.left = None self.right = None def height_of_tree(root: Node) -> int: Calculate the height of the binary tree rooted at `root`. Args: root (Node): The root node of the binary tree. Returns: int: The height of the tree. if not root: return -1 left_height = height_of_tree(root.left) right_height = height_of_tree(root.right) return max(left_height, right_height) + 1"},{"question":"**Question: Create a Customizable Sorting Algorithm for Complex Data Structures** # Objective Develop a sorting algorithm that can handle complex data objects using customizable sorting criteria. Your implementation should focus on flexibility, performance, and correctness. # Requirements 1. **Data Structure**: * Implement a class to define complex data objects. * Each object should contain multiple attributes (e.g., `id`, `name`, `value`, etc.). 2. **Sorting Logic**: * Allow sorting on any combination of attributes. * Support ascending and descending order per attribute. 3. **Custom Comparators**: * Implement custom comparator functions to handle sorting based on specific attributes or combination of attributes. * Ensure comparators can handle data of various types (e.g., strings, integers, floats). 4. **Main Sorting Function**: * Implement a function to perform the sorting using the defined comparators. * Ensure the sorting algorithm is efficient and handles large datasets effectively. 5. **Stability**: * Ensure the sorting algorithm is stable—i.e., preserves the relative order of records with equal keys. # Input/Output Specification 1. **Input**: * `data`: A list of complex data objects. * `criteria`: A list of tuples, where each tuple contains an attribute name and the order (\'asc\' for ascending or \'desc\' for descending). 2. **Output**: * A sorted list of complex data objects based on the given criteria. # Constraints * The algorithm should be efficient with at least O(n log n) time complexity. * Custom comparator functions should be correctly implemented and seamlessly integrated. * Ensure compatibility with diverse data types within the data objects. # Example ```python class DataObject: def __init__(self, id, name, value): self.id = id self.name = name self.value = value def custom_sort(data, criteria): # Implement sorting logic here pass # Sample data data = [ DataObject(1, \'Alice\', 23.5), DataObject(2, \'Bob\', 17.8), DataObject(3, \'Charlie\', 23.5) ] # Sort criteria: First by \'value\' in ascending order, then by \'name\' in descending order criteria = [(\'value\', \'asc\'), (\'name\', \'desc\')] sorted_data = custom_sort(data, criteria) # Expected Output: [DataObject(2, \'Bob\', 17.8), DataObject(1, \'Alice\', 23.5), DataObject(3, \'Charlie\', 23.5)] for obj in sorted_data: print(obj.id, obj.name, obj.value) ``` # Submission * Implement the `DataObject` class for complex data definitions. * Implement the `custom_sort` function to sort the data objects. * Provide complete and functional code to demonstrate sorting with example data. **Note:** Ensure your code is well-documented and modular to facilitate future extensions.","solution":"from functools import cmp_to_key class DataObject: def __init__(self, id, name, value): self.id = id self.name = name self.value = value def custom_sort(data, criteria): def comparator(a, b): for (attr, order) in criteria: a_attr = getattr(a, attr) b_attr = getattr(b, attr) if a_attr != b_attr: if order == \'asc\': return -1 if a_attr < b_attr else 1 else: # \'desc\' return -1 if a_attr > b_attr else 1 return 0 return sorted(data, key=cmp_to_key(comparator))"},{"question":"# Question You are tasked with implementing a function to solve the \\"job scheduling with deadlines\\" problem. Given an array of jobs where each job has a deadline and a profit, your goal is to schedule the jobs in such a way that maximizes the total profit. Assume each job takes one unit of time to complete, and a job can only be completed if its entire duration falls within its deadline window. Write a function `job_scheduling(jobs: List[Dict[str, int]]) -> List[int]` that schedules the jobs to maximize the total profit and returns the list of job IDs (in any order) that are included in the optimal schedule. # Input and Output Formats Inputs: - `jobs`: A list of dictionaries where each dictionary represents a job with the following keys: - `id`: An integer representing the job\'s identifier. - `deadline`: An integer representing the deadline by which the job must be completed. - `profit`: An integer representing the profit earned by completing the job. Output: - A list of integers representing the job IDs included in the optimal schedule that maximizes the total profit. The order of job IDs in the output list does not matter. # Constraints - Each input list will have at least one job and at most 100 jobs. - Each job can only be completed within its deadline. - Each job contributes positively to the profit if completed on time. # Example ```python # Example Input jobs = [ {\\"id\\": 1, \\"deadline\\": 4, \\"profit\\": 20}, {\\"id\\": 2, \\"deadline\\": 1, \\"profit\\": 10}, {\\"id\\": 3, \\"deadline\\": 1, \\"profit\\": 40}, {\\"id\\": 4, \\"deadline\\": 1, \\"profit\\": 30}, ] # Example Function Call print(job_scheduling(jobs)) # Expected Output (one possible optimal schedule) [3, 1] ``` In this example, the optimal schedule that maximizes profit is achieved by completing jobs with IDs 3 and 1, yielding a total profit of 60. Note that this is just one possible solution, and the order of job IDs in the output list may vary.","solution":"from typing import List, Dict def job_scheduling(jobs: List[Dict[str, int]]) -> List[int]: Schedules jobs to maximize total profit. Parameters: jobs (List[Dict[str, int]]): A list of jobs, where each job is a dictionary with \'id\', \'deadline\', and \'profit\'. Returns: List[int]: A list of job IDs included in the optimal schedule. # Sort jobs based on profit in descending order sorted_jobs = sorted(jobs, key=lambda x: x[\'profit\'], reverse=True) max_deadline = max(job[\'deadline\'] for job in jobs) time_slots = [False] * max_deadline # Time slots, initially all free job_sequence = [-1] * max_deadline # Job IDs for scheduled jobs for job in sorted_jobs: # Find a time slot for this job (starting from the last slot before the deadline) for time_slot in range(min(job[\'deadline\'], max_deadline) - 1, -1, -1): if not time_slots[time_slot]: time_slots[time_slot] = True job_sequence[time_slot] = job[\'id\'] break # Filter out unassigned slots return [job_id for job_id in job_sequence if job_id != -1] # Example usage jobs_example = [ {\\"id\\": 1, \\"deadline\\": 4, \\"profit\\": 20}, {\\"id\\": 2, \\"deadline\\": 1, \\"profit\\": 10}, {\\"id\\": 3, \\"deadline\\": 1, \\"profit\\": 40}, {\\"id\\": 4, \\"deadline\\": 1, \\"profit\\": 30}, ] print(job_scheduling(jobs_example))"},{"question":"# Implementing a Priority Queue using a Heap You are required to implement a priority queue using a binary heap. The priority queue should support insertion of elements along with their priority values, as well as extracting the element with the highest priority. # Instructions: 1. Implement a class `PriorityQueue` that supports the following methods: * `__init__()`: Initializes an empty priority queue. * `insert(element, priority)`: Inserts an element with the given priority. * `extract_max()`: Removes and returns the element with the highest priority. If two elements have the same priority, return the one which was inserted earlier. 2. Use a binary heap to manage the storage of elements and their priorities. 3. Handle edge cases, such as extracting from an empty queue by returning `None`. # Input: * A sequence of operations to insert and extract elements from the priority queue. # Output: * The results of the `extract_max` operations. # Constraints: * Use a list to store the heap elements. * The priority values are positive integers. * The maximum number of elements in the queue will not exceed 1000. # Example: ```python pq = PriorityQueue() pq.insert(\'task1\', 3) pq.insert(\'task2\', 2) pq.insert(\'task3\', 5) print(pq.extract_max()) # Should return \'task3\' print(pq.extract_max()) # Should return \'task1\' print(pq.extract_max()) # Should return \'task2\' print(pq.extract_max()) # Should return `None` ``` # Function Signature: ```python class PriorityQueue: def __init__(self): pass def insert(self, element: Any, priority: int): pass def extract_max(self) -> Optional[Any]: pass # Usage Example pq = PriorityQueue() pq.insert(\'task1\', 3) pq.insert(\'task2\', 2) pq.insert(\'task3\', 5) print(pq.extract_max()) # Should return \'task3\' print(pq.extract_max()) # Should return \'task1\' print(pq.extract_max()) # Should return \'task2\' print(pq.extract_max()) # Should return `None` ```","solution":"import heapq class PriorityQueue: def __init__(self): self.heap = [] self.counter = 0 # To handle elements with the same priority by order of insertion def insert(self, element, priority): # Use negative priority since heapq is a min-heap but we need a max-heap heapq.heappush(self.heap, (-priority, self.counter, element)) self.counter += 1 def extract_max(self): if not self.heap: return None # Return the element part of the tuple return heapq.heappop(self.heap)[2]"},{"question":"# Problem Statement You are required to implement functions that check if a string is a palindrome ignoring whitespaces, punctuation, and case, and to find the longest palindrome subsequence within a given string. These operations are foundational in text processing and have applications in areas such as natural language processing and data validation. # Function Definitions 1. `is_palindrome(s: str) -> bool` - **Input**: A string `s`. - **Output**: `True` if the string is a palindrome ignoring whitespaces, punctuation, and case; `False` otherwise. - **Constraints**: - Ignore case sensitivity (e.g., \'A\' is considered equal to \'a\'). - Ignore non-alphanumeric characters (e.g., spaces, punctuation). 2. `longest_palindrome_subsequence(s: str) -> str` - **Input**: A string `s`. - **Output**: The longest palindromic subsequence in the string `s` as a new string. - **Constraints**: - In case of multiple subsequences with the same maximum length, return any one of them. - The function should be efficient considering the string size can be relatively large. # Example ```python assert is_palindrome(\\"A man, a plan, a canal: Panama\\") == True assert is_palindrome(\\"race a car\\") == False assert longest_palindrome_subsequence(\\"character\\") == \\"carac\\" assert longest_palindrome_subsequence(\\"noon\\") == \\"noon\\" ``` # Note - Utilize efficient algorithms to ensure scalability such as dynamic programming for finding the longest palindromic subsequence. - Ensure to handle various edge cases, including empty strings and strings with no alphanumeric characters.","solution":"import re def is_palindrome(s: str) -> bool: Checks if the given string is a palindrome ignoring whitespaces, punctuation and case sensitivity. # Filter out non-alphanumeric characters and convert to lower case filtered_s = re.sub(r\'[^A-Za-z0-9]\', \'\', s).lower() # Check if it is equal to its reverse return filtered_s == filtered_s[::-1] def longest_palindrome_subsequence(s: str) -> str: Finds the longest palindromic subsequence within the given string. n = len(s) if n == 0: return \\"\\" # Create a 2D array to store the length of longest palindromic subsequence dp = [[0] * n for _ in range(n)] # Every single character is a palindrome of length 1 for i in range(n): dp[i][i] = 1 # Build the dp array for cl in range(2, n + 1): for i in range(n - cl + 1): j = i + cl - 1 if s[i] == s[j] and cl == 2: dp[i][j] = 2 elif s[i] == s[j]: dp[i][j] = dp[i + 1][j - 1] + 2 else: dp[i][j] = max(dp[i][j - 1], dp[i + 1][j]) # Store the result string result = [\'\'] * dp[0][n - 1] start, end = 0, dp[0][n - 1] - 1 i, j = 0, n - 1 while start <= end: if s[i] == s[j]: result[start] = s[i] result[end] = s[j] start += 1 end -= 1 i += 1 j -= 1 elif dp[i][j - 1] > dp[i + 1][j]: j -= 1 else: i += 1 return \'\'.join(result)"},{"question":"# Problem: Sum of Digit Factorials Consider the sum of the factorial of the digits of a number ( n ). For example, the sum of the factorial of the digits of 145 is ( 1! + 4! + 5! = 1 + 24 + 120 = 145 ). Your task is to write a function `is_sum_of_digit_factorials(n: int) -> bool` that determines if a given number ( n ) is equal to the sum of the factorial of its digits. # Input * `n`: an integer (0 leq n leq 1,000,000). # Output * Returns a boolean `True` if ( n ) is equal to the sum of the factorial of its digits, and `False` otherwise. # Example ```python is_sum_of_digit_factorials(145) # returns True is_sum_of_digit_factorials(123) # returns False ``` # Constraints * The solution should be optimized for both time and space complexity. * Precompute the factorials of digits from 0 to 9 to improve performance. * Handle edge cases effectively, such as single-digit numbers. ```python def is_sum_of_digit_factorials(n: int) -> bool: # Define a list of factorials for digits 0-9 factorials = [1] for i in range(1, 10): factorials.append(factorials[-1] * i) # Sum the factorials of the digits of n original_n = n sum_factorials = 0 while n > 0: digit = n % 10 sum_factorials += factorials[digit] n //= 10 # Check if the sum of factorials is equal to the original number return sum_factorials == original_n # Example Usage print(is_sum_of_digit_factorials(145)) # True print(is_sum_of_digit_factorials(123)) # False ```","solution":"def is_sum_of_digit_factorials(n: int) -> bool: Returns True if n is equal to the sum of the factorials of its digits, otherwise False. # Define a list of factorials for digits 0-9 factorials = [1] for i in range(1, 10): factorials.append(factorials[-1] * i) # Sum the factorials of the digits of n original_n = n sum_factorials = 0 while n > 0: digit = n % 10 sum_factorials += factorials[digit] n //= 10 # Check if the sum of factorials is equal to the original number return sum_factorials == original_n"},{"question":"# Problem Statement You are given a list of integers `nums` and an integer `k`. Your task is to implement a function to rotate the list to the right by `k` steps, where `k` is non-negative. A single rotation step moves the last element of the list to the first position. # Function Signature ```python def rotate_list(nums: list[int], k: int) -> list[int]: ``` # Input - `nums` (list[int]): A list of integers. Constraints: 0 <= len(nums) <= 10^5, -10^9 <= nums[i] <= 10^9 - `k` (int): An integer representing the number of steps to rotate the list. Constraints: 0 <= k <= 10^5 # Output - The function should return the rotated list as a new list of integers. # Example ```python assert rotate_list([1,2,3,4,5], 2) == [4,5,1,2,3] assert rotate_list([1,2,3,4,5], 0) == [1,2,3,4,5] assert rotate_list([1,2,3,4,5], 5) == [1,2,3,4,5] assert rotate_list([1,2,3,4,5], 7) == [4,5,1,2,3] assert rotate_list([], 3) == [] ``` # Constraints - You must perform the rotation in-place or return a new list without making a copy of the input list. - Focus on writing clean and efficient code that can handle large lists and large rotation values. # Performance Requirements - The rotation should be performed in O(n) time complexity, where n is the length of the list. - The space complexity should be O(1) if done in-place, or O(n) if returning a new list.","solution":"def rotate_list(nums: list[int], k: int) -> list[int]: Rotates the list to the right by k steps. Args: nums (list[int]): A list of integers. k (int): Number of steps to rotate the list. Returns: list[int]: Rotated list. n = len(nums) if n == 0: return [] k = k % n # handle cases where k > n return nums[-k:] + nums[:-k]"},{"question":"# Fibonacci Subsequence Checker Context Fibonacci sequences are well-known in computational contexts due to their recursive definition and interesting properties. The Fibonacci sequence starts with 0 and 1, and each subsequent number is the sum of the previous two. Given the importance of recognizing patterns and sequences in various coding problems, it is useful to be able to verify if an array is a subsequence of the Fibonacci sequence. Problem Statement Create a function `is_fibonacci_subsequence` which checks whether a given list of integers forms a subsequence of the Fibonacci sequence. The function should handle input validation and return an appropriate response. Function Signature ```python def is_fibonacci_subsequence(arr: list[int]) -> bool: ``` Input - `arr`: (list of int) A list of integers to be checked. Output - Returns a boolean value indicating whether the list `arr` is a subsequence of the Fibonacci sequence. Constraints - Elements in `arr` should be non-negative integers. - The input list can be empty, which should return `True`. Error Handling Raise a `ValueError` in case of: - Any element in `arr` being negative. Examples ```python >>> is_fibonacci_subsequence([1, 2, 3, 5, 8]) True >>> is_fibonacci_subsequence([8, 2, 3, 1]) False >>> is_fibonacci_subsequence([13, 21, 34, 55]) True >>> is_fibonacci_subsequence([0, 1, 4, 5, 9]) False >>> is_fibonacci_subsequence([]) # An empty list is trivially a subsequence True >>> is_fibonacci_subsequence([8, -1, 13]) ValueError: Elements in the input list must be non-negative ``` Explanation 1. **When all elements form a subsequence in the same order**: The function should return `True`. 2. **When elements do not follow the Fibonacci sequence order**: The function should return `False`. 3. **Handle the error case for negative elements**: Raise a `ValueError` if any element in the list is negative. 4. **Empty list**: An empty list should always return `True`. This problem tests the candidate\'s ability to understand and work with sequences, handle input validation, and implement algorithmic checks efficiently.","solution":"def is_fibonacci_subsequence(arr: list[int]) -> bool: if any(x < 0 for x in arr): raise ValueError(\\"Elements in the input list must be non-negative\\") if not arr: return True fib_set = set() a, b = 0, 1 while b <= max(arr): fib_set.add(b) a, b = b, a + b fib_set.add(0) # explicitly add 0 to handle the start of the sequence index = 0 for num in arr: if num in fib_set and (index == 0 or num >= arr[index - 1]): index += 1 else: return False return True"},{"question":"# Coding Assessment Question Context In computational geometry, points with integer coordinates on a plane can form various geometric shapes. One common problem is finding the maximum number of points that lie on a single straight line. We will assess your understanding of algorithms and data structures through the computation of collinear points. Task You need to write a function `max_points_on_line` that takes in a list of points and returns the maximum number of points that lie on a single straight line. Input - `points` (List[Tuple[int, int]]): A list of points where each point is represented as a tuple of two integers (x, y). (0 <= len(points) <= 300, -10^4 <= x, y <= 10^4). Output - An integer representing the maximum number of points that lie on a single straight line. # Function Signature ```python def max_points_on_line(points: List[Tuple[int, int]]) -> int: pass ``` # Example ```python >>> max_points_on_line([(1, 1), (2, 2), (3, 3)]) 3 >>> max_points_on_line([(1, 1), (3, 2), (5, 3), (4, 1), (2, 3), (1, 4)]) 4 >>> max_points_on_line([(0, 0), (1, 1), (1, -1)]) 2 ``` # Notes - Ensure efficient computation, as the number of points can be large. - Consider edge cases where all points might be identical or no points are provided. - Implement a strategy to handle floating-point precision issues arising from slope calculations.","solution":"from collections import defaultdict from typing import List, Tuple def max_points_on_line(points: List[Tuple[int, int]]) -> int: if not points: return 0 def gcd(a, b): while b: a, b = b, a % b return a def get_slope(p1, p2): delta_x = p2[0] - p1[0] delta_y = p2[1] - p1[1] if delta_x == 0: return (\'inf\', p1[0]) if delta_y == 0: return (0, p1[1]) gcd_val = gcd(delta_x, delta_y) return (delta_y // gcd_val, delta_x // gcd_val) max_points = 1 for i in range(len(points)): lines = defaultdict(int) duplicates = 1 for j in range(i + 1, len(points)): if points[i] == points[j]: duplicates += 1 else: slope = get_slope(points[i], points[j]) lines[slope] += 1 max_points = max(max_points, duplicates + max(lines.values(), default=0)) return max_points"},{"question":"# Median Maintenance System You are required to develop a **Median Maintenance System** that keeps track of the median of a stream of integers. The system needs to support efficient insertion of integers and median retrieval. **Function Signature:** ```python class MedianMaintainer: def __init__(self) -> None: Initialize your data structure here. pass def insert(self, number: int) -> None: Inserts a number into the MedianMaintainer system. Args: - number (int): The integer to be inserted. Example: maintainer.insert(10) pass def get_median(self) -> float: Returns the median of all integers inserted so far. Returns: - float: The median of the numbers. Example: median = maintainer.get_median() pass ``` # Requirements 1. **`__init__` Method**: Sets up any necessary data structures to keep track of the numbers. 2. **`insert` Method**: Accepts an integer and inserts it efficiently into the data structure. 3. **`get_median` Method**: Returns the median of all inserted integers. If the count of numbers is even, the median is the average of the two middle numbers. # Constraints - The number of integers inserted is between 1 and 10^5. - All integers inserted are within the range -10^6 to 10^6. - Ensuring efficient insertion and quick median retrieval is crucial. Aim for O(log n) insertion and O(1) median retrieval time. # Example ```python maintainer = MedianMaintainer() maintainer.insert(10) assert maintainer.get_median() == 10 maintainer.insert(20) assert maintainer.get_median() == 15.0 # (10 + 20) / 2 maintainer.insert(30) assert maintainer.get_median() == 20 maintainer.insert(5) assert maintainer.get_median() == 15.0 # (10 + 20) / 2 maintainer.insert(25) assert maintainer.get_median() == 20 ``` Implement these methods to ensure the median can be efficiently maintained and retrieved.","solution":"import heapq class MedianMaintainer: def __init__(self) -> None: Initialize your data structure here. self.lower_half = [] # Max heap self.upper_half = [] # Min heap def insert(self, number: int) -> None: Inserts a number into the MedianMaintainer system. Args: - number (int): The integer to be inserted. # Insert into max heap (lower half) heapq.heappush(self.lower_half, -number) # Balance the heaps by ensuring that max of lower_half is <= min of upper_half if self.lower_half and self.upper_half and (-self.lower_half[0] > self.upper_half[0]): heapq.heappush(self.upper_half, -heapq.heappop(self.lower_half)) # Balance lengths if necessary if len(self.lower_half) > len(self.upper_half) + 1: heapq.heappush(self.upper_half, -heapq.heappop(self.lower_half)) elif len(self.upper_half) > len(self.lower_half): heapq.heappush(self.lower_half, -heapq.heappop(self.upper_half)) def get_median(self) -> float: Returns the median of all integers inserted so far. Returns: - float: The median of the numbers. if len(self.lower_half) > len(self.upper_half): return -self.lower_half[0] else: return (-self.lower_half[0] + self.upper_half[0]) / 2"},{"question":"# Dynamic Programming for Coin Change Problem Given a function `coin_change`, implement the function to compute the minimum number of coins required to make a given amount from a set of coin denominations. If the amount cannot be formed by any combination of the given coins, return -1. # Function Signature ```python def coin_change(coins: List[int], amount: int) -> int: pass ``` # Input - `coins`: A list of integers representing the available coin denominations. - `amount`: An integer representing the target amount of money. # Output - Return the minimum number of coins needed to make up the `amount`. - Return `-1` if it is not possible to make up that amount with the given coins. # Example Scenario Consider the following input: ```python coins = [1, 2, 5] amount = 11 ``` The function should return `3` since the minimum number of coins to make `11` would be `[5, 5, 1]`. # Constraints - `1 <= coins.length <= 12` - `1 <= coins[i] <= 231 - 1` - `0 <= amount <= 104` # Sample Test Case ```python assert coin_change([1, 2, 5], 11) == 3 assert coin_change([2], 3) == -1 assert coin_change([1], 0) == 0 assert coin_change([1], 2) == 2 ``` # Tips - Utilize a dynamic programming approach to minimize the complexity. - Create an array `dp` of length `amount + 1` where `dp[i]` represents the minimum number of coins needed to make the amount `i`. - Initialize `dp[0]` to `0`, as no coins are needed to make amount 0. - For each amount from `1` to `amount`, find the minimum coins required by checking all coin denominations. - Carefully handle the edge cases such as `amount` being `0` or any denomination being greater than `amount`. Implement this function to dynamically compute the solution based on the given constraints and input sizes.","solution":"from typing import List def coin_change(coins: List[int], amount: int) -> int: # Initialize the dp array with amount+1, which is an impossible high number of coins dp = [float(\'inf\')] * (amount + 1) # Base case: No coins needed to make amount 0 dp[0] = 0 # Update the dp array for coin in coins: for x in range(coin, amount + 1): dp[x] = min(dp[x], dp[x - coin] + 1) # If dp[amount] is still infinity, it means it\'s not possible to make that amount with given coins return dp[amount] if dp[amount] != float(\'inf\') else -1"},{"question":"# Coding Assessment Question Problem Statement You are given a binary tree, where each node contains a unique integer value. Your task is to write a function that finds the longest consecutive sequence of nodes, where each consecutive node has a value of one greater than the node before it. The sequence can be from parent to child (left or right), and can start at any node in the tree. The function should return the length of this longest sequence. Function Signature ```python class TreeNode: def __init__(self, value: int): self.val = value self.left = None self.right = None def longest_consecutive_sequence(root: TreeNode) -> int: Find the length of the longest consecutive sequence in a binary tree. Parameters ---------- root: TreeNode The root node of the binary tree. Returns ------- int The length of the longest consecutive sequence. ``` Detailed Requirements 1. **Input and Output**: - **Input**: - `root`: A TreeNode representing the root of the binary tree. - **Output**: - Return an integer indicating the length of the longest consecutive sequence in the binary tree. 2. **Constraints**: - The tree can be any binary tree, not necessarily balanced. - Each node in the binary tree contains a unique integer value. 3. **Performance Requirements**: - The function should efficiently traverse the tree to find the longest consecutive sequence. - Solution should be optimized to handle large trees with several thousand nodes. 4. **Scenario**: - Validate the correctness of the implementation against various binary trees with different structures and values. Example ```python class TreeNode: def __init__(self, value: int): self.val = value self.left = None self.right = None def longest_consecutive_sequence(root: TreeNode) -> int: def dfs(node: TreeNode, parent_val: int, length: int) -> int: if not node: return length current_length = length + 1 if node.val == parent_val + 1 else 1 left_length = dfs(node.left, node.val, current_length) right_length = dfs(node.right, node.val, current_length) return max(current_length, left_length, right_length) return dfs(root, float(\'-inf\'), 0) # Example usage root = TreeNode(1) root.right = TreeNode(3) root.right.left = TreeNode(2) root.right.right = TreeNode(4) root.right.right.right = TreeNode(5) print(longest_consecutive_sequence(root)) # Should print: 3 root2 = TreeNode(2) root2.left = TreeNode(3) root2.left.left = TreeNode(4) print(longest_consecutive_sequence(root2)) # Should print: 3 ```","solution":"class TreeNode: def __init__(self, value: int): self.val = value self.left = None self.right = None def longest_consecutive_sequence(root: TreeNode) -> int: def dfs(node: TreeNode, parent_val: int, length: int) -> int: if not node: return length current_length = length + 1 if node.val == parent_val + 1 else 1 left_length = dfs(node.left, node.val, current_length) right_length = dfs(node.right, node.val, current_length) return max(current_length, left_length, right_length) return dfs(root, float(\'-inf\'), 0)"},{"question":"Context: You are presented with a class **StringEditor** that provides basic string manipulation methods. Your task is to enhance this class by adding methods that allow for more complex operations, commonly needed in text processing applications. This will test your understanding of string manipulation techniques and your ability to implement efficient algorithms for text handling. # Task: 1. Implement a method `remove_vowels(self) -> None` that removes all vowels (\'a\', \'e\', \'i\', \'o\', \'u\', both uppercase and lowercase) from the string stored in the class. 2. Implement an `is_palindrome(self) -> bool` method that checks if the current string is a palindrome, considering only alphanumeric characters and ignoring cases. It should return `True` if the string is a palindrome, `False` otherwise. 3. Implement a method `reverse_words(self) -> None` that reverses the order of the words in the string. Words are defined as sequences of non-space characters. # Function Signature: ```python def remove_vowels(self) -> None: Removes all vowels from the string. def is_palindrome(self) -> bool: Checks if the string is a palindrome. def reverse_words(self) -> None: Reverses the order of words in the string. ``` # Input & Output Formats: * The `remove_vowels` method takes no arguments and returns `None`. It modifies the string in place. * The `is_palindrome` method takes no arguments and returns a boolean (`True` or `False`). * The `reverse_words` method takes no arguments and returns `None`. It modifies the string in place. # Constraints: * The input string can be empty, and methods should handle this gracefully. * The `remove_vowels` method should only target the vowels in the English alphabet. * The `is_palindrome` method should ignore non-alphanumeric characters and be case-insensitive. * The `reverse_words` method should preserve spacing between words but not retain leading or trailing whitespace. # Example: ```python # Initialize StringEditor se = StringEditor(\\"hello world\\") # Remove vowels se.remove_vowels() print(se) # Expected Output: \\"hll wrld\\" # Check palindrome se_pal = StringEditor(\\"A man, a plan, a canal, Panama\\") print(se_pal.is_palindrome()) # Expected Output: True # Reverse words se_rev = StringEditor(\\"This is an example\\") se_rev.reverse_words() print(se_rev) # Expected Output: \\"example an is This\\" ``` Make sure your implementations handle edge cases and are efficient in terms of space and time complexity.","solution":"import re class StringEditor: def __init__(self, s: str): self.s = s def __str__(self): return self.s def remove_vowels(self) -> None: vowels = \\"aeiouAEIOU\\" self.s = \'\'.join([char for char in self.s if char not in vowels]) def is_palindrome(self) -> bool: stripped_str = re.sub(r\'[^A-Za-z0-9]\', \'\', self.s).lower() return stripped_str == stripped_str[::-1] def reverse_words(self) -> None: self.s = \' \'.join(self.s.split()[::-1])"},{"question":"# Question: Find the Missing Number in a Consecutive Sequence You are given an array of consecutive integers starting from 1 up to n, inclusive, with exactly one number missing. The numbers are provided in no specific order. Your task is to find the missing number from the sequence. - **Input**: The input is a list of integers, `arr`, which is the sequence without one number. - **Output**: Return the missing integer. Constraints: * The length of the array will be at least 1 and at most 10^5. * The array will contain integers ranging from 1 to n where exactly one number from this range is missing. # Example ```python def find_missing_number(arr: List[int]) -> int: pass # The function call should return the integer 3 print(find_missing_number([1, 2, 4, 5])) # The function call should return the integer 1 print(find_missing_number([2])) ``` # Notes: 1. Consider using a mathematical approach to find the missing number efficiently. 2. Ensure your solution handles large lists within acceptable time limits.","solution":"def find_missing_number(arr): Finds the missing number in a consecutive sequence starting from 1 up to n. Params: - arr (List[int]): List of integers from 1 to n with one missing element. Returns: - int: The missing number. n = len(arr) + 1 total_sum = n * (n + 1) // 2 # Sum of numbers from 1 to n array_sum = sum(arr) return total_sum - array_sum"},{"question":"# Problem Description: You are tasked with implementing a simple file system that supports file creation, deletion, and reading files. The file system should also support creation of directories, listing the contents of a directory, and navigating between directories. Implement a `FileSystem` class with the following operations: 1. **Creation of a file**: Create a new file with content in the current directory. 2. **Deletion of a file**: Delete an existing file in the current directory. 3. **Reading a file**: Read and return the content of a file in the current directory. 4. **Creation of a directory**: Create a new directory. 5. **Listing contents**: List all files and subdirectories in the current directory. 6. **Changing directory**: Change to a different directory (e.g., navigate to a subdirectory or parent directory). # Requirements: - **Input Format**: - For creating a file, the method signature should be: ```python def create_file(self, filename: str, content: str) -> None ``` - For deleting a file, the method signature should be: ```python def delete_file(self, filename: str) -> None ``` - For reading a file, the method signature should be: ```python def read_file(self, filename: str) -> str ``` - For creating a directory, the method signature should be: ```python def create_directory(self, dirname: str) -> None ``` - For listing contents, the method signature should be: ```python def list_contents(self) -> list[str] ``` - For changing directories, the method signature should be: ```python def change_directory(self, path: str) -> None ``` - **Performance Constraints**: Each operation should be optimized for average use cases. - **Assumptions**: - File and directory names are unique in each directory. - An initial structure contains a root directory \'/\'. # Example Usage: ```python filesystem = FileSystem() filesystem.create_file(\\"file1.txt\\", \\"Content of file1\\") filesystem.create_directory(\\"docs\\") filesystem.change_directory(\\"docs\\") filesystem.create_file(\\"file2.txt\\", \\"Content of file2\\") print(filesystem.read_file(\\"file2.txt\\")) # Output: \\"Content of file2\\" filesystem.change_directory(\\"..\\") print(filesystem.list_contents()) # Output: [\\"file1.txt\\", \\"docs\\"] filesystem.delete_file(\\"file1.txt\\") print(filesystem.list_contents()) # Output: [\\"docs\\"] filesystem.change_directory(\\"docs\\") print(filesystem.list_contents()) # Output: [\\"file2.txt\\"] ``` # Notes: - `change_directory` method can accept relative paths (e.g., \\"subdir\\") or parent directory (e.g., \\"..\\"). - You can assume a standard hierarchical file system structure. - Ensure your implementation handles edge cases such as navigating to a non-existent directory or file, and trying to read or delete files that do not exist. - Pay attention to edge cases and proper error handling.","solution":"class FileSystem: def __init__(self): self.root = {\'/\': {}} self.current_path = [\'/\'] def _get_current_dict(self): curr = self.root for dir in self.current_path: curr = curr[dir] return curr def create_file(self, filename: str, content: str) -> None: curr = self._get_current_dict() if filename in curr: raise FileExistsError(\\"File already exists\\") curr[filename] = content def delete_file(self, filename: str) -> None: curr = self._get_current_dict() if filename not in curr or isinstance(curr[filename], dict): raise FileNotFoundError(\\"File not found\\") del curr[filename] def read_file(self, filename: str) -> str: curr = self._get_current_dict() if filename not in curr or isinstance(curr[filename], dict): raise FileNotFoundError(\\"File not found\\") return curr[filename] def create_directory(self, dirname: str) -> None: curr = self._get_current_dict() if dirname in curr: raise FileExistsError(\\"Directory already exists\\") curr[dirname] = {} def list_contents(self) -> list[str]: curr = self._get_current_dict() return list(curr.keys()) def change_directory(self, path: str) -> None: if path == \\"..\\": if len(self.current_path) > 1: self.current_path.pop() return path_parts = path.split(\'/\') curr = self._get_current_dict() for part in path_parts: if part not in curr or not isinstance(curr[part], dict): raise NotADirectoryError(f\\"{part} is not a directory or does not exist\\") curr = curr[part] self.current_path.append(path)"},{"question":"# Problem Statement: You are tasked with implementing a function to determine if a given word can be formed by rearranging the letters of another word, commonly known as finding an anagram. This function is critical in various text-processing applications, such as spell checkers, word games, and data validation. # Your Task: Implement the function: 1. `is_anagram(word1: str, word2: str) -> bool`: This function takes two words as input and returns `True` if one word is an anagram of the other, and `False` otherwise. # Specifications: 1. **Input Format:** * Each word is represented as a string containing only lowercase alphabetic characters (a-z). 2. **Output Format:** * The function `is_anagram` should return a boolean value: `True` if the words are anagrams, and `False` otherwise. 3. **Constraints:** * The input strings will have a length between 1 and 1000 characters. * Consider the performance for long strings and multiple function calls. 4. **Performance Consideration:** * The function should handle multiple calls efficiently. # Example: ```python def is_anagram(word1: str, word2: str) -> bool: # implement function to check if word1 and word2 are anagrams. # Example usage: word1 = \\"listen\\" word2 = \\"silent\\" print(is_anagram(word1, word2)) # Expected output: True word1 = \\"hello\\" word2 = \\"world\\" print(is_anagram(word1, word2)) # Expected output: False ``` # Hints: * Consider sorting the letters of both words and comparing the results. * You can also use frequency counting of the letters to determine if they match. * Think about edge cases like empty strings or strings with different lengths.","solution":"def is_anagram(word1: str, word2: str) -> bool: Returns True if word1 is an anagram of word2, False otherwise. # Anagrams must have the same length if len(word1) != len(word2): return False # Create frequency dictionaries for both words freq1 = {} freq2 = {} for char in word1: if char in freq1: freq1[char] += 1 else: freq1[char] = 1 for char in word2: if char in freq2: freq2[char] += 1 else: freq2[char] = 1 # Compare the frequency dictionaries return freq1 == freq2"},{"question":"# K-Means Clustering and Elbow Method Implementation In this assessment, you are required to implement functions for K-Means Clustering and the Elbow Method. Your implementation should include appropriate error handling and optimizations as outlined. The functions should strictly follow the operational steps and requirements of the respective algorithms. Objectives: 1. Design and implement a function for **K-Means Clustering**. 2. Design and implement a function for **Elbow Method** to determine the optimal number of clusters. 3. Implement error handling, including assertion errors for invalid inputs. Input * For K-Means Clustering: - A feature matrix (numpy array) with dimensions m x n. - Number of clusters (k). * For Elbow Method: - A feature matrix (numpy array) with dimensions m x n. - Maximum number of clusters to test. Output * Transformed feature matrix with assigned cluster labels (numpy array) for K-Means. * An array of distortions for each cluster size tested for the Elbow Method. Constraints * The feature matrix will have at least one row and column. * For K-Means, the number of clusters k should be a positive integer less than the number of datapoints. * Use numpy and scipy as necessary for matrix operations and calculations. Function Signature ```python def k_means_clustering(features: np.ndarray, clusters: int) -> np.ndarray: K-Means Clustering. Parameters: * features: The features extracted from the dataset * clusters: Number of clusters to form Returns: Array of cluster labels for each data point def elbow_method(features: np.ndarray, max_clusters: int) -> np.ndarray: Elbow Method for determining the optimal number of clusters. Parameters: * features: The features extracted from the dataset * max_clusters: The maximum number of clusters to test against Returns: Array of distortions for each cluster size tested ``` Example Usage ```python import numpy as np from sklearn.datasets import load_iris # Loading sample dataset data = load_iris() features = data[\'data\'] # K-Means Clustering Implementation cluster_labels = k_means_clustering(features, 3) print(np.unique(cluster_labels, return_counts=True)) # Elbow Method Implementation distortions = elbow_method(features, 10) print(distortions) ``` Notes * Ensure that you include appropriate assertion checks within your functions. * Use the provided examples for testing your functions. * Aim for clean and readable code along with documentation where necessary. * Visualize the elbow plot (not required but recommended for better analysis).","solution":"import numpy as np from scipy.spatial.distance import cdist from sklearn.cluster import KMeans from typing import Union def k_means_clustering(features: np.ndarray, clusters: int) -> np.ndarray: K-Means Clustering. Parameters: * features: The features extracted from the dataset (numpy array) * clusters: Number of clusters to form (positive int less than the number of data points) Returns: Array of cluster labels for each data point (numpy array) assert isinstance(features, np.ndarray), \\"Features should be a numpy array\\" assert isinstance(clusters, int), \\"Number of clusters should be an integer\\" assert clusters > 0, \\"Number of clusters should be greater than 0\\" assert clusters < len(features), \\"Number of clusters should be less than the number of data points\\" kmeans = KMeans(n_clusters=clusters, random_state=42) kmeans.fit(features) return kmeans.labels_ def elbow_method(features: np.ndarray, max_clusters: int) -> np.ndarray: Elbow Method for determining the optimal number of clusters. Parameters: * features: The features extracted from the dataset (numpy array) * max_clusters: The maximum number of clusters to test against (positive int greater than 1) Returns: Array of distortions for each cluster size tested (numpy array) assert isinstance(features, np.ndarray), \\"Features should be a numpy array\\" assert isinstance(max_clusters, int), \\"Max clusters should be an integer\\" assert max_clusters > 1, \\"Max clusters should be greater than 1\\" assert max_clusters < len(features), \\"Max clusters should be less than the number of data points\\" distortions = [] for k in range(1, max_clusters + 1): kmeans = KMeans(n_clusters=k, random_state=42) kmeans.fit(features) distortions.append(sum(np.min(cdist(features, kmeans.cluster_centers_, \'euclidean\'), axis=1)) / features.shape[0]) return np.array(distortions)"},{"question":"Scenario Graph algorithms are fundamental in computer science, and proficiency in implementing them demonstrates a strong grasp of both theory and practical problem-solving. In this task, you\'ll leverage your understanding of graph traversal techniques and data structures to solve a classic problem. Problem Statement Given a connected and undirected graph represented as an adjacency list, implement the function `is_cyclic(graph: dict) -> bool`, which checks if the graph contains any cycles. Input - `graph` (dictionary): A dictionary where keys represent graph vertices, and the values are lists of adjacent vertices. Output - Returns a boolean value indicating whether the graph contains a cycle (True) or not (False). Function Signature ```python def is_cyclic(graph: dict) -> bool: pass ``` Example ```python >>> graph1 = { 0: [1, 2], 1: [0, 2], 2: [0, 1, 3], 3: [2, 4], 4: [3] } >>> is_cyclic(graph1) True >>> graph2 = { 0: [1], 1: [0, 2], 2: [1, 3], 3: [2, 4], 4: [3] } >>> is_cyclic(graph2) False ``` Constraints - The graph is connected and undirected. - The number of vertices V in the graph is such that 1 ≤ V ≤ 1000. - The number of edges E in the graph is such that 0 ≤ E ≤ 10000. Note - Utilize Depth-First Search (DFS) or Breadth-First Search (BFS) effectively to detect cycles. - Ensure to account for the possibility of revisiting nodes in the graph during the traversal process. - Consider implementing a union-find data structure to enhance cycle detection if relevant.","solution":"def is_cyclic(graph: dict) -> bool: def dfs(node, parent): visited.add(node) for neighbor in graph[node]: if neighbor not in visited: if dfs(neighbor, node): return True elif neighbor != parent: return True return False visited = set() for node in graph: if node not in visited: if dfs(node, -1): return True return False"},{"question":"# Matrix Diagonal Sum In linear algebra, the diagonal sum of a matrix is the sum of the elements along the main diagonal (from the top-left to the bottom-right corner) of a square matrix. Task Write a function `diagonal_sum(matrix: list[list[int]]) -> int` which returns the sum of the primary diagonal elements of the given square matrix. # Details 1. **Matrix Validity**: Ensure that the input is a valid square matrix. 2. **Sum Calculation**: Traverse through the matrix and sum up the elements on the main diagonal. Input * A list of lists `matrix` where each sub-list represents a row in the square matrix (1 ≤ len(matrix) ≤ 1000 and 1 ≤ len(matrix[i]) ≤ 1000, for 0 ≤ i < len(matrix)) Output * An integer representing the sum of the primary diagonal elements. Constraints * The matrix will always be a square matrix. * The elements of the matrix are integers within the range -10^5 to 10^5. Example ```python >>> diagonal_sum([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) 15 >>> diagonal_sum([[2, 5], [3, 4]]) 6 >>> diagonal_sum([[100]]) 100 ``` # Scenario Imagine you are developing a feature for a data analysis tool where you need to extract specific metrics from a dataset represented as a matrix. One such metric is the sum of the main diagonal elements, which provides a quick insight into the trends or patterns in the dataset. Implementing the function `diagonal_sum` will help you achieve this efficiently.","solution":"def diagonal_sum(matrix): Returns the sum of the primary diagonal elements of the given square matrix. return sum(matrix[i][i] for i in range(len(matrix)))"},{"question":"# Matrix Rotation by 90 Degrees Problem Statement You are given a `n x n` matrix represented as a 2D list in Python. Your task is to write a function to rotate the matrix by 90 degrees clockwise. Requirements Implement the following method: ```python def rotate_matrix(matrix: List[List[int]]) -> None: Rotate the given n x n matrix by 90 degrees clockwise in-place. Parameters: matrix (List[List[int]]): 2D list representing the n x n matrix. Example: >>> matrix = [ ... [1, 2, 3], ... [4, 5, 6], ... [7, 8, 9] ... ] >>> rotate_matrix(matrix) >>> print(matrix) [[7, 4, 1], [8, 5, 2], [9, 6, 3]] >>> matrix = [ ... [5, 1, 9, 11], ... [2, 4, 8, 10], ... [13, 3, 6, 7], ... [15, 14, 12, 16] ... ] >>> rotate_matrix(matrix) >>> print(matrix) [[15, 13, 2, 5], [14, 3, 4, 1], [12, 6, 8, 9], [16, 7, 10, 11]] ``` Your implementation must: - Rotate the matrix in-place, meaning you should not use any additional 2D lists. - Follow the optimal approach with O(1) space complexity, merely modifying the existing matrix. Input and Output - **Input**: A 2D list `matrix` representing the n x n matrix to be rotated. - **Output**: The matrix should be modified in-place. Constraints - The matrix will have dimensions n x n where 1 ≤ n ≤ 300. - The matrix will contain integer values. Performance Requirements - The function should handle large matrices efficiently within the given constraints. Example ```python >>> matrix = [ ... [1, 2, 3], ... [4, 5, 6], ... [7, 8, 9] ... ] >>> rotate_matrix(matrix) >>> print(matrix) [[7, 4, 1], [8, 5, 2], [9, 6, 3]] >>> matrix = [ ... [5, 1, 9, 11], ... [2, 4, 8, 10], ... [13, 3, 6, 7], ... [15, 14, 12, 16] ... ] >>> rotate_matrix(matrix) >>> print(matrix) [[15, 13, 2, 5], [14, 3, 4, 1], [12, 6, 8, 9], [16, 7, 10, 11]] ```","solution":"from typing import List def rotate_matrix(matrix: List[List[int]]) -> None: Rotate the given n x n matrix by 90 degrees clockwise in-place. Parameters: matrix (List[List[int]]): 2D list representing the n x n matrix. n = len(matrix) # Transpose the matrix for i in range(n): for j in range(i, n): matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j] # Reverse each row for i in range(n): matrix[i].reverse()"},{"question":"# Merging Sorted Lists Exercise **Scenario**: You have been tasked with implementing a function that merges two separately sorted lists of integers into a single sorted list. This is a common operation in various algorithms, such as the merge step in the merge sort algorithm. Your function should handle typical edge cases, ensuring that invalid inputs are appropriately managed. **Function Signature**: ```python def merge_sorted_lists(list1: list, list2: list) -> list: pass ``` **Input**: - `list1` (list): A list of integers sorted in non-decreasing order. - `list2` (list): Another list of integers sorted in non-decreasing order. **Output**: - Returns a single list which is the result of merging the two input lists while maintaining the sorted order. **Constraints**: - Elements within each input list are sorted in non-decreasing order. - Inputs must be lists containing integers. - The function should raise `ValueError` if any element within any input list is not an integer. - The function should raise `TypeError` if inputs are not lists. **Performance Requirements**: - The function should handle the merging operation efficiently, with a time complexity of O(n + m), where n and m are the lengths of `list1` and `list2` respectively. **Example**: ```python >>> merge_sorted_lists([1, 3, 5], [2, 4, 6]) [1, 2, 3, 4, 5, 6] >>> merge_sorted_lists([1, 2, 3], [4, 5, 6]) [1, 2, 3, 4, 5, 6] >>> merge_sorted_lists([-5, 0, 2], [-2, 1, 3]) [-5, -2, 0, 1, 2, 3] >>> merge_sorted_lists([], [1, 2, 3]) [1, 2, 3] >>> merge_sorted_lists([1, 2, 3], []) [1, 2, 3] >>> merge_sorted_lists([], []) [] >>> merge_sorted_lists([1, 2], [3, \\"4\\", 5]) Traceback (most recent call last): ... ValueError: all elements within each list must be integers >>> merge_sorted_lists(\\"123\\", [1, 2, 3]) Traceback (most recent call last): ... TypeError: inputs must be lists ``` **Additional Notes**: - Implement the function ensuring it adheres strictly to the type and value constraints. - Consider edge cases such as empty lists, and handle them accordingly. - Ensure the function maintains the efficiency requirement and is capable of handling large lists.","solution":"def merge_sorted_lists(list1, list2): Merges two separately sorted lists of integers into a single sorted list. :param list1: First sorted list of integers :param list2: Second sorted list of integers :return: A single sorted list if not isinstance(list1, list) or not isinstance(list2, list): raise TypeError(\\"inputs must be lists\\") if not all(isinstance(x, int) for x in list1) or not all(isinstance(x, int) for x in list2): raise ValueError(\\"all elements within each list must be integers\\") merged_list = [] i, j = 0, 0 while i < len(list1) and j < len(list2): if list1[i] < list2[j]: merged_list.append(list1[i]) i += 1 else: merged_list.append(list2[j]) j += 1 while i < len(list1): merged_list.append(list1[i]) i += 1 while j < len(list2): merged_list.append(list2[j]) j += 1 return merged_list"},{"question":"# Question: You are a data analyst tasked with designing an application to aggregate and summarize user data to get insights into user behavior on a website. Your application should be able to compute the average session duration for each user and identify the top N users with the highest average session duration. Write a function `top_n_users(session_data: List[Tuple[int, int, int]], N: int) -> List[int]` that takes a list of tuples representing user sessions and an integer `N`, and returns a list of user IDs with the highest average session duration, ordered from highest to lowest. Each tuple in the input list contains: - `user_id` (int): The unique identifier for a user. - `session_id` (int): The unique identifier for a session. - `duration` (int): Duration of the session in seconds. # Input: - `session_data`: A list of tuples. Each tuple contains three integers representing `user_id`, `session_id`, and `duration`. - `N`: An integer representing the number of users with the highest average session duration to return. # Output: A list of integers representing user IDs. The list should contain exactly `N` user IDs sorted by their average session duration in descending order. If there are fewer than `N` users, return the IDs of all users sorted by their average session duration in descending order. # Constraints: - The list `session_data` will not be empty and will contain at least one entry. - The value of `N` will always be a positive integer. - There will be no duplicate sessions for a user. # Examples: 1. Given the following session data and N = 2: ```python session_data = [(1, 1, 300), (2, 2, 200), (1, 3, 600), (3, 4, 150), (2, 5, 600), (3, 6, 400)] top_n_users(session_data, 2) ``` Should return [1, 3] because: - User 1 has average duration: (300 + 600) / 2 = 450 seconds - User 3 has average duration: (150 + 400) / 2 = 275 seconds 2. Given the following session data and N = 1: ```python session_data = [(1, 1, 100), (2, 2, 200), (3, 3, 300)] top_n_users(session_data, 1) ``` Should return [3] because: - User 3 has the highest average duration: 300 seconds # Additional Notes: - Implement robust error checking for the input values. - Use appropriate data structures to ensure efficient computation. - Include test cases to verify the correctness of your implementation.","solution":"from typing import List, Tuple from collections import defaultdict def top_n_users(session_data: List[Tuple[int, int, int]], N: int) -> List[int]: Function to find the top N users with the highest average session duration. Parameters: - session_data: List of tuples, where each tuple contains user_id, session_id, and duration. - N: The number of top users to return based on average session duration. Returns: - List of user IDs with the highest average session duration. # Dictionary to accumulate total duration and count of sessions for each user. user_sessions = defaultdict(lambda: {\'total_duration\': 0, \'session_count\': 0}) for user_id, session_id, duration in session_data: user_sessions[user_id][\'total_duration\'] += duration user_sessions[user_id][\'session_count\'] += 1 # Calculate the average session duration for each user. average_durations = { user_id: data[\'total_duration\'] / data[\'session_count\'] for user_id, data in user_sessions.items() } # Sort users by average duration in descending order and pick top N users. top_users = sorted(average_durations, key=average_durations.get, reverse=True)[:N] return top_users"},{"question":"# Coding Assessment Question Substring Search Optimization with Rolling Hash You have been provided with a basic implementation of substring search within a string using rolling hash. The task is to enhance the functionality to better handle large datasets and efficiently find all occurrences of a pattern within a given text. # Problem Statement Function: optimized_substring_search Write a function `optimized_substring_search` that: - Takes as input a string `text`, a string `pattern`. - Returns a list of starting indices where `pattern` is found in `text`. Constraints: 1. The length of `text` will be up to 10^6 characters. 2. The length of `pattern` will be up to 10^3 characters. Rolling Hash Considerations: - Employ a rolling hash technique to achieve efficient substring matching. - Use appropriate hash functions to minimize collisions and ensure performance. Specifications: - Input: Strings `text`, `pattern`. - Output: List of integers representing starting indices of matched patterns. Example Scenario Given `text = \\"abracadabra\\"`, `pattern = \\"abra\\"`: ```python text = \\"abracadabra\\" pattern = \\"abra\\" indices = optimized_substring_search(text, pattern) print(indices) # Output should be [0, 7] ``` The function should find that \\"abra\\" occurs at indices 0 and 7 in the given text. # Note: Handle edge cases where: - The `pattern` is longer than the `text`. - Ensure that the rolling hash implementation efficiently handles large text data. - Consider the impact of character set diversity on the hashing strategy. Write your implementation in a function `optimized_substring_search` using the principles of rolling hash to achieve the desired functionality.","solution":"def optimized_substring_search(text, pattern): Returns a list of starting indices where pattern is found in text. Uses a rolling hash technique for efficient substring matching. if not text or not pattern or len(pattern) > len(text): return [] # Base values for rolling hash base = 256 mod = 10**9 + 7 pattern_length = len(pattern) text_length = len(text) # Precompute the highest power of base needed highest_base = 1 for _ in range(pattern_length - 1): highest_base = (highest_base * base) % mod # Initial hash values for pattern and first window of text pattern_hash = 0 window_hash = 0 for i in range(pattern_length): pattern_hash = (pattern_hash * base + ord(pattern[i])) % mod window_hash = (window_hash * base + ord(text[i])) % mod # List to store the starting indices of matching substrings result = [] # Slide the pattern over text one character at a time for i in range(text_length - pattern_length + 1): if pattern_hash == window_hash: # If the hash values match, check the actual substrings to avoid false positives due to collisions if text[i:i+pattern_length] == pattern: result.append(i) # Compute the hash for the next window if i < text_length - pattern_length: window_hash = (window_hash - ord(text[i]) * highest_base) % mod window_hash = (window_hash * base + ord(text[i + pattern_length])) % mod # Handle negative values of window_hash if window_hash < 0: window_hash += mod return result"},{"question":"Finding the Dominant Element **Scenario**: You are working with a dataset where certain elements appear more frequently than others. Your task is to identify the element that appears more than half the time in the list. **Problem**: Given a list of integers, write a function to determine the element that appears more than half the time in the list. If no such element exists, return `-1`. **Function Signature**: ```python def find_dominant_element(data: List[int]) -> int: Function to find the dominant element in a list. Args: data (List[int]): A list of integers. Returns: int: The element that appears more than half the time, or -1 if no such element exists. ``` **Input**: - `data`: A list of integers. **Output**: - An integer representing the dominant element or `-1` if no element appears more than half the time. **Constraints**: - The length of the data list will not exceed 10^5. - All integers in `data` are within the range 1 to 10^6. **Examples**: ```python >>> find_dominant_element([3, 3, 4, 2, 4, 4, 2, 4, 4]) 4 >>> find_dominant_element([3, 3, 4, 2, 4, 4, 2, 4]) -1 >>> find_dominant_element([1]) 1 ``` **Hint**: Consider using an efficient algorithm such as the Boyer-Moore Voting Algorithm to handle the constraint on list size.","solution":"from typing import List def find_dominant_element(data: List[int]) -> int: Function to find the dominant element in a list. Args: data (List[int]): A list of integers. Returns: int: The element that appears more than half the time, or -1 if no such element exists. if not data: return -1 # Boyer-Moore Voting Algorithm candidate = None count = 0 for num in data: if count == 0: candidate = num count = 1 elif num == candidate: count += 1 else: count -= 1 # Verify candidate if data.count(candidate) > len(data) // 2: return candidate else: return -1"},{"question":"# Data Clustering with K-Means Problem Statement Implement the K-Means clustering algorithm to classify a set of data points into clusters. Given a list of two-dimensional data points and the number of clusters ( k ), your task is to assign each data point to one of the ( k ) clusters such that the within-cluster sum of squares is minimized. Function to Implement Implement the function `k_means_clustering` which takes the following parameters: 1. **data_points**: A list of tuples, where each tuple represents a point in 2D space (x, y). 2. **k**: An integer representing the number of clusters. The function should return a dictionary with the following keys: - **\\"clusters\\"**: A list of lists, where each inner list contains the points that belong to that specific cluster. - **\\"centroids\\"**: A list of tuples representing the centroids of each cluster after convergence. Example Input ```python data_points = [(1, 1), (1, 2), (4, 4), (5, 5), (10, 10)] k = 2 ``` Example Output ```python { \\"clusters\\": [ [(1, 1), (1, 2)], [(4, 4), (5, 5), (10, 10)] ], \\"centroids\\": [ (1, 1.5), (6.3333, 6.3333) ] } ``` Constraints - The number of data points will be between 2 and 1000. - The value of ( k ) will be between 1 and the number of data points. - All coordinates of the data points will be non-negative integers. Additional Information You may assume that the initial centroids can be chosen randomly from the given data points. Use the Euclidean distance metric for measuring distances between points. ```python def k_means_clustering(data_points, k): Perform K-Means clustering on the given data points. :param data_points: List of tuples representing points in 2D space :param k: Integer representing the number of clusters :return: Dictionary with clusters and centroids # Your implementation here pass ``` Notes - Implement the core steps of the K-Means algorithm: initialization, assignment, update, and convergence check. - Handle edge cases such as points equidistant from multiple centroids and empty clusters gracefully.","solution":"import random import numpy as np def k_means_clustering(data_points, k): Perform K-Means clustering on the given data points. :param data_points: List of tuples representing points in 2D space :param k: Integer representing the number of clusters :return: Dictionary with clusters and centroids # Convert data points to numpy array for easier mathematical operations data_points_arr = np.array(data_points) # Randomly initialize centroids by selecting k unique data points centroids = data_points_arr[random.sample(range(len(data_points)), k)] # Initialize variables old_centroids = np.zeros(centroids.shape) clusters = [[] for _ in range(k)] # Function to calculate Euclidean distance def euclidean_distance(a, b): return np.linalg.norm(a - b) # Loop until centroids do not change while not np.array_equal(centroids, old_centroids): old_centroids = centroids.copy() # Clear the clusters clusters = [[] for _ in range(k)] # Assign each data point to the nearest centroid for point in data_points_arr: distances = [euclidean_distance(point, centroid) for centroid in centroids] cluster_index = np.argmin(distances) clusters[cluster_index].append(point) # Update the centroids by calculating the mean of the points in each cluster for i in range(k): if clusters[i]: # Avoid division by zero centroids[i] = np.mean(clusters[i], axis=0) # Convert centroids back to list of tuples and clusters to list of lists of tuples centroids_tuples = [tuple(centroid) for centroid in centroids] clusters_tuples = [[tuple(point) for point in cluster] for cluster in clusters] return {\\"clusters\\": clusters_tuples, \\"centroids\\": centroids_tuples}"},{"question":"# Binary Tree Leaf Sum Calculation Objective: Your task is to implement a method in the `BinaryTree` class to calculate the sum of all leaf nodes\' values. Requirements: 1. Implement a new method `leaf_sum` in the `BinaryTree` class. 2. Ensure the method correctly identifies and sums values of leaf nodes (nodes with no children). Class Definition: ```python class Node: def __init__(self, value=None, left=None, right=None): self.value = value self.left = left self.right = right class BinaryTree: def __init__(self): self.root = None def insert(self, value): if self.root is None: self.root = Node(value) else: self._insert_recursive(self.root, value) def _insert_recursive(self, current, value): if value < current.value: if current.left is None: current.left = Node(value) else: self._insert_recursive(current.left, value) else: if current.right is None: current.right = Node(value) else: self._insert_recursive(current.right, value) def leaf_sum(self): return self._leaf_sum_recursive(self.root) def _leaf_sum_recursive(self, current): if current is None: return 0 if current.left is None and current.right is None: return current.value return self._leaf_sum_recursive(current.left) + self._leaf_sum_recursive(current.right) ``` Testing: - Create multiple test cases to validate behavior: 1. Binary tree with several nodes where some nodes are leaves. 2. Trees with no leaves (e.g., empty tree). 3. Trees with only one node (the root). Example: ```python tree = BinaryTree() tree.insert(10) tree.insert(5) tree.insert(15) tree.insert(3) tree.insert(7) print(tree.leaf_sum()) # 3 + 7 + 15 = 25 empty_tree = BinaryTree() print(empty_tree.leaf_sum()) # 0 single_node_tree = BinaryTree() single_node_tree.insert(8) print(single_node_tree.leaf_sum()) # 8 ``` **Output**: ```shell 25 0 8 ``` Ensure to handle edge cases and make sure the sum calculation is thorough and correct.","solution":"class Node: def __init__(self, value=None, left=None, right=None): self.value = value self.left = left self.right = right class BinaryTree: def __init__(self): self.root = None def insert(self, value): if self.root is None: self.root = Node(value) else: self._insert_recursive(self.root, value) def _insert_recursive(self, current, value): if value < current.value: if current.left is None: current.left = Node(value) else: self._insert_recursive(current.left, value) else: if current.right is None: current.right = Node(value) else: self._insert_recursive(current.right, value) def leaf_sum(self): return self._leaf_sum_recursive(self.root) def _leaf_sum_recursive(self, current): if current is None: return 0 if current.left is None and current.right is None: return current.value return self._leaf_sum_recursive(current.left) + self._leaf_sum_recursive(current.right)"},{"question":"# **Finding the Intersection of Two Arrays** Background You have been given two arrays of integers and need to determine their intersection. The intersection of two arrays consists of common elements that appear in both arrays. Task Write a Python function `array_intersection(arr1: List[int], arr2: List[int]) -> List[int]` that takes two lists of integers as input and returns a list of their intersection. Each element in the result should be unique and the order of the elements in the result is not important. Details: 1. **Input Format**: Two lists of integers `arr1` and `arr2`. 2. **Output Format**: A list of integers representing the intersection of the two arrays. Constraints: - The input arrays can be of different lengths. - The integers in the arrays can be negative, zero or positive. - The function should raise a `TypeError` if the inputs are not lists of integers. Examples: ``` array_intersection([1, 2, 2, 1], [2, 2]) # Output: [2] array_intersection([4, 9, 5], [9, 4, 9, 8, 4]) # Output: [4, 9] array_intersection([1, 3, 5, 7], [2, 4, 6, 8]) # Output: [] array_intersection([-1, -2, 3], [1, 2, -2, -1]) # Output: [-1, -2] array_intersection(\'abc\', [2, 3]) # Raises TypeError array_intersection([1, 2, 3], \'xyz\') # Raises TypeError array_intersection([1, 2, 3], [2.0, 3.0, 1.0]) # Raises TypeError ``` Notes: 1. Leverage Python\'s set operations to efficiently find the intersection of two arrays. 2. Ensure to convert the inputs to sets to remove any duplicate elements within each array. 3. Validate your input before finding the intersection. 4. Write appropriate test cases to handle various input scenarios, including edge cases.","solution":"from typing import List def array_intersection(arr1: List[int], arr2: List[int]) -> List[int]: Returns the intersection of two integer arrays as a list of unique elements. :param arr1: List[int] - First input array. :param arr2: List[int] - Second input array. :return: List[int] - Intersection of arr1 and arr2, containing unique elements. if not isinstance(arr1, list) or not isinstance(arr2, list): raise TypeError(\\"Both inputs must be lists.\\") if not all(isinstance(i, int) for i in arr1) or not all(isinstance(i, int) for i in arr2): raise TypeError(\\"All elements in the input lists must be integers.\\") # Utilize set to find intersection set1, set2 = set(arr1), set(arr2) intersection = set1 & set2 # set intersection return list(intersection)"},{"question":"# Coding Assessment Question **Context:** You are to implement a software component that processes a large log of timestamped events. The events are ordered chronologically based on their timestamps. Your task is to design a function that consolidates consecutive events occurring within a specified time window. **Function Specification:** - **Function Name**: `merge_events` - **Input**: - `events` (List[Tuple[str, str]]): A list of tuples, where each tuple contains an event timestamp in the format `YYYY-MM-DD HH:MM:SS` and an event description. - `time_window` (int): The maximum number of seconds between consecutive events for them to be considered part of the same consolidated event. - **Output**: - A list of lists, where each inner list contains tuples of merged consecutive events within the given time window. Each tuple includes the original timestamp and event description from the input. **Input Constraints**: - Event timestamps are in the correct format and properly ordered. - The `time_window` is a positive integer. **Performance Requirements**: - Efficiently handle the merging based on the time window. **Edge Cases to Consider**: - Empty `events` list. - `time_window` is zero. - Large values for `time_window` that encompass all events in one merge. **Examples**: ```python >>> merge_events( events=[ (\\"2023-10-01 12:00:00\\", \\"Event A\\"), (\\"2023-10-01 12:00:10\\", \\"Event B\\"), (\\"2023-10-01 12:01:00\\", \\"Event C\\"), (\\"2023-10-01 13:00:00\\", \\"Event D\\") ], time_window=30 ) [ [(\\"2023-10-01 12:00:00\\", \\"Event A\\"), (\\"2023-10-01 12:00:10\\", \\"Event B\\")], [(\\"2023-10-01 12:01:00\\", \\"Event C\\")], [(\\"2023-10-01 13:00:00\\", \\"Event D\\")] ] >>> merge_events( events=[ (\\"2023-10-01 12:00:00\\", \\"Event A\\"), (\\"2023-10-01 12:00:10\\", \\"Event B\\"), (\\"2023-10-01 12:01:00\\", \\"Event C\\"), (\\"2023-10-01 13:00:00\\", \\"Event D\\") ], time_window=3600 ) [ [ (\\"2023-10-01 12:00:00\\", \\"Event A\\"), (\\"2023-10-01 12:00:10\\", \\"Event B\\"), (\\"2023-10-01 12:01:00\\", \\"Event C\\"), (\\"2023-10-01 13:00:00\\", \\"Event D\\") ] ] ``` **Implementation Notes**: - Utilize the `datetime` module for managing and comparing timestamps. - Consider edge cases where the time window may be too small to merge any events or large enough to merge all events into one. - Your solution should efficiently handle edge cases and invalid inputs gracefully.","solution":"from datetime import datetime, timedelta from typing import List, Tuple def merge_events(events: List[Tuple[str, str]], time_window: int) -> List[List[Tuple[str, str]]]: if not events: return [] merged_events = [] current_group = [events[0]] for i in range(1, len(events)): current_timestamp = datetime.strptime(events[i][0], \\"%Y-%m-%d %H:%M:%S\\") last_timestamp = datetime.strptime(events[i - 1][0], \\"%Y-%m-%d %H:%M:%S\\") if (current_timestamp - last_timestamp).total_seconds() <= time_window: current_group.append(events[i]) else: merged_events.append(current_group) current_group = [events[i]] merged_events.append(current_group) return merged_events"},{"question":"# Problem Statement You are tasked to create a function that takes a list of strings and returns a dictionary. The keys in this dictionary should be the lengths of the strings, and the values should be lists of strings of that length. This operation can be useful in scenarios such as categorizing words by their length. **Function Signature:** ```python def categorize_by_length(words: List[str]) -> Dict[int, List[str]]: pass ``` # Input * A list of `n` strings. * ( 1 leq n leq 10^5 ) * Each string `s` can contain between `1` and `100` characters. # Output * A dictionary where each key is an integer representing a string length, and each value is a list of strings of that length. # Constraints * Ensure that your solution handles large lists efficiently and appropriately categorizes the strings by their lengths. # Example ```python def categorize_by_length(words: List[str]) -> Dict[int, List[str]]: Categorizes a list of words by their lengths. Parameters: words (List[str]): list of words. Returns: Dict[int, List[str]]: Dictionary with lengths as keys and lists of words as values. length_dict = {} for word in words: length = len(word) if length not in length_dict: length_dict[length] = [] length_dict[length].append(word) return length_dict if __name__ == \\"__main__\\": # Example 1 words = [\\"apple\\", \\"bat\\", \\"ball\\", \\"cat\\", \\"dog\\", \\"elephant\\"] print(categorize_by_length(words)) # Expected Output : {5: [\'apple\'], 3: [\'bat\', \'cat\', \'dog\'], 4: [\'ball\'], 8: [\'elephant\']} # Example 2 words = [\\"\\", \\"a\\", \\"ab\\", \\"abc\\", \\"abcd\\", \\"abcde\\", \\"abcdef\\"] print(categorize_by_length(words)) # Expected Output : {0: [\'\'], 1: [\'a\'], 2: [\'ab\'], 3: [\'abc\'], 4: [\'abcd\'], 5: [\'abcde\'], 6: [\'abcdef\']} ``` # Notes * Ensure that the lengths of strings are accurately calculated. * Consider edge cases, such as when the list contains strings of only one length or multiple strings of the same length.","solution":"from typing import List, Dict def categorize_by_length(words: List[str]) -> Dict[int, List[str]]: Categorizes a list of words by their lengths. Parameters: words (List[str]): list of words. Returns: Dict[int, List[str]]: Dictionary with lengths as keys and lists of words as values. length_dict = {} for word in words: length = len(word) if length not in length_dict: length_dict[length] = [] length_dict[length].append(word) return length_dict"},{"question":"# Binary Search Implementation and Analysis You are tasked with implementing a binary search algorithm to find the position of a target value within a sorted input list. After implementing the search algorithm, you will also need to analyze and return the number of iterations the algorithm took to find the target. Function Signature ```python def binary_search(arr: List[int], target: int) -> Tuple[int, int]: pass ``` Requirements 1. **Binary Search Algorithm**: - The function should accept a list of sorted integers (`arr`) and an integer (`target`) as its inputs. - The function should perform a binary search to find and return the index of the `target` within the list. - If the `target` value is not found, return -1 as the index. 2. **Iteration Count**: - Keep track of and return the number of iterations (or steps) the algorithm took to find the `target`. 3. **Output**: - The function should return a tuple containing the index position of the `target` and the number of iterations. Example ```python # Example input list sorted_list = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21] # Example target target_value = 7 # Expected output: (3, 3) # Explanation: The target 7 is found at index 3, and it took 3 iterations to locate it. print(binary_search(sorted_list, target_value)) ``` Notes - Ensure that the function handles edge cases, such as an empty list or a list where the target is not present. - The list is guaranteed to be sorted in ascending order. - Utilize dividing the list in half to maximize search efficiency and minimize the number of iterations. Example Usage ```python # Sample tests for the binary_search function # Test case 1: Target is present arr = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20] target = 14 # Expected output: (6, 4) print(binary_search(arr, target)) # Test case 2: Target is not present arr = [1, 3, 5, 7, 9, 11] target = 2 # Expected output: (-1, 3) print(binary_search(arr, target)) # Test case 3: Empty array arr = [] target = 5 # Expected output: (-1, 0) print(binary_search(arr, target)) # Test case 4: Target is the first element arr = [10, 20, 30, 40, 50] target = 10 # Expected output: (0, 2) print(binary_search(arr, target)) # Test case 5: Target is the last element arr = [3, 6, 9, 12, 15] target = 15 # Expected output: (4, 3) print(binary_search(arr, target)) ```","solution":"from typing import List, Tuple def binary_search(arr: List[int], target: int) -> Tuple[int, int]: Performs a binary search to find the index of the target value in the sorted list. Also returns the number of iterations it took to find the target. left, right = 0, len(arr) - 1 iterations = 0 while left <= right: iterations += 1 mid = (left + right) // 2 if arr[mid] == target: return (mid, iterations) elif arr[mid] < target: left = mid + 1 else: right = mid - 1 return (-1, iterations)"},{"question":"# Coding Assessment Question Context: Merge Sort is another highly efficient, comparison-based sorting algorithm which uses the divide-and-conquer approach. It is an important concept in computer science, as it ensures sorting in O(n log n) time complexity in any case. Understanding and implementing Merge Sort with both recursive and iterative approaches is key for grasping sorting algorithms comprehensively. Task: Implement a function `merge_sort_iterative(nums: list) -> list` that sorts a list of integers using an iterative (non-recursive) Merge Sort algorithm. Focus on breaking down the problem iteratively rather than using recursive calls, and merge subarrays in a bottom-up manner. Function Signature: ```python def merge_sort_iterative(nums: list) -> list: pass ``` Input: - `nums` (list): A list of integers that needs to be sorted. Output: - A new list containing the sorted elements in ascending order. Constraints: - The list should be sorted in ascending order. - You must not use any built-in `sort` functions. Examples: ```python >>> nums1 = [38, 27, 43, 3, 9, 82, 10] >>> merge_sort_iterative(nums1) [3, 9, 10, 27, 38, 43, 82] >>> nums2 = [5, 1, 3, 8, 7, 2] >>> merge_sort_iterative(nums2) [1, 2, 3, 5, 7, 8] >>> nums3 = [] >>> merge_sort_iterative(nums3) [] ``` Notes: - You may create helper functions within `merge_sort_iterative`. - Ensure no recursion is used and manage the merging of subarrays iteratively.","solution":"def merge_sort_iterative(nums: list) -> list: def merge(left, right): merged = [] i = j = 0 # Merge the two arrays while i < len(left) and j < len(right): if left[i] < right[j]: merged.append(left[i]) i += 1 else: merged.append(right[j]) j += 1 # If there are remaining elements in left half while i < len(left): merged.append(left[i]) i += 1 # If there are remaining elements in right half while j < len(right): merged.append(right[j]) j += 1 return merged width = 1 n = len(nums) result = nums[:] while width < n: for i in range(0, n, 2 * width): left = result[i:i+width] right = result[i+width:i+2*width] result[i:i+2*width] = merge(left, right) width *= 2 return result"},{"question":"# Question: Implement a Concurrent HashMap You are tasked with implementing a thread-safe `ConcurrentHashMap` in Python. This `ConcurrentHashMap` should support the following functionalities: 1. **Thread-safe Put**: A method to insert or update a key-value pair in the map. 2. **Thread-safe Get**: A method to retrieve the value associated with a given key. 3. **Thread-safe Remove**: A method to remove a key-value pair from the map. 4. **Thread-safe containsKey**: A method to check if a key is present in the map. Function Specifications: 1. **Put**: * Function Name: `put` * Input: A key and its associated value. * Output: None 2. **Get**: * Function Name: `get` * Input: A key. * Output: The value associated with the key, or None if the key does not exist. 3. **Remove**: * Function Name: `remove` * Input: A key. * Output: None 4. **ContainsKey**: * Function Name: `contains_key` * Input: A key. * Output: A boolean indicating if the key exists in the map. You are required to implement these methods in a given `ConcurrentHashMap` class. The class should use locks or any other synchronization techniques to ensure thread-safety. Constraints: - Assume unique keys. - Ensure all provided methods are thread-safe. - The `ConcurrentHashMap` should support average time complexity of O(1) for basic operations under lock contention. Example Usage: ```python import threading # Initialize concurrent hash map concurrent_map = ConcurrentHashMap() # Insert elements concurrent_map.put(\\"key1\\", \\"value1\\") concurrent_map.put(\\"key2\\", \\"value2\\") # Retrieve elements print(concurrent_map.get(\\"key1\\")) # Expected Output: \\"value1\\" # Check if key exists print(concurrent_map.contains_key(\\"key2\\")) # Expected Output: True # Remove element concurrent_map.remove(\\"key1\\") print(concurrent_map.get(\\"key1\\")) # Expected Output: None ``` Example with Multiple Threads: ```python import threading import time def write_to_map(concurrent_map, key, value): for _ in range(100): concurrent_map.put(key, value) time.sleep(0.01) def read_from_map(concurrent_map, key): for _ in range(100): print(concurrent_map.get(key)) time.sleep(0.01) # Create threads thread1 = threading.Thread(target=write_to_map, args=(concurrent_map, \\"key1\\", \\"value1\\")) thread2 = threading.Thread(target=read_from_map, args=(concurrent_map, \\"key1\\")) # Start threads thread1.start() thread2.start() # Wait for threads to finish thread1.join() thread2.join() ```","solution":"import threading class ConcurrentHashMap: def __init__(self): self.map = {} self.lock = threading.Lock() def put(self, key, value): with self.lock: self.map[key] = value def get(self, key): with self.lock: return self.map.get(key, None) def remove(self, key): with self.lock: if key in self.map: del self.map[key] def contains_key(self, key): with self.lock: return key in self.map"},{"question":"# Knapsack Problem Variant Problem Statement Implement a function `maximum_value` that calculates the maximum value that can be obtained by selecting items with given weight and value constraints to fit into a knapsack of a specified capacity. The function should solve the problem using a dynamic programming approach. Function Signature ```python def maximum_value(weights: List[int], values: List[int], capacity: int) -> int: pass ``` Input - `weights`: A list of integers where each integer represents the weight of an item (0 <= len(weights) <= 1000, 1 <= weights[i] <= 1000). - `values`: A list of integers where each integer represents the value of an item (0 <= len(values) <= 1000, 1 <= values[i] <= 1000). - `capacity`: An integer representing the maximum weight capacity of the knapsack (0 <= capacity <= 1000). Output - Returns an integer representing the maximum value obtainable with the given constraints. Constraints - The `weights` and `values` lists have the same length. - The problem can be solved using 0/1 Knapsack approach. Example ```python assert maximum_value([1, 3, 4, 5], [1, 4, 5, 7], 7) == 9 # Select items with weights 3 and 4 assert maximum_value([1, 2, 3], [10, 20, 30], 5) == 50 # Select items with weights 2 and 3 assert maximum_value([10, 20, 30], [60, 100, 120], 50) == 220 # Select items with weights 20 and 30 assert maximum_value([1, 4, 5, 7], [1, 3, 4, 5], 0) == 0 # Knapsack capacity is 0, hence max value is 0 assert maximum_value([], [], 10) == 0 # No items available ``` Detailed Explanation 1. Use a 2D Dynamic Programming table `dp` where `dp[i][w]` represents the maximum value that can be achieved using the first `i` items and a knapsack of capacity `w`. 2. Initialize a DP table with `0`s as the base condition stating that with `0` capacity the value is `0`. 3. Populate the DP table: - If including the i-th item exceeds the current capacity `w`, the value from the previous item is carried forward (`dp[i][w] = dp[i-1][w]`). - Otherwise, consider two scenarios: including the item or excluding it, and choose the maximum value between them (`dp[i][w] = max(dp[i-1][w], values[i-1] + dp[i-1][w-weights[i-1]])`). Implement the `maximum_value` function based on the described logic.","solution":"from typing import List def maximum_value(weights: List[int], values: List[int], capacity: int) -> int: # Number of items n = len(weights) # Initialize a DP array dp = [[0] * (capacity + 1) for _ in range(n + 1)] # Populate the DP array for i in range(1, n + 1): for w in range(capacity + 1): if weights[i - 1] <= w: dp[i][w] = max(dp[i - 1][w], values[i - 1] + dp[i - 1][w - weights[i - 1]]) else: dp[i][w] = dp[i - 1][w] return dp[n][capacity]"},{"question":"# Coding Question: Efficient File Line Reader **Scenario**: You are tasked with optimizing an application that processes large log files. The current implementation reads the entire file into memory, which is inefficient and can lead to performance issues when handling very large files. Your goal is to refactor the file reading method to be more memory-efficient by processing the log file line by line. **Requirements**: 1. Implement a function `process_log_file(file_path: str) -> List[str]` that reads a log file line by line. 2. The function should return a list of lines that contain the keyword \\"ERROR\\". 3. It should handle potential file I/O errors gracefully by catching exceptions and printing an appropriate error message. **Input**: * `file_path` - The path to the log file (a valid file path string). **Output**: * A list of strings, each representing a line from the file that contains the keyword \\"ERROR\\". **Constraints**: * The log file size can be very large, so it\'s not practical to read the entire file into memory at once. * Each line in the file will be a valid string of text. **Example**: ```python def process_log_file(file_path: str) -> List[str]: error_lines = [] try: with open(file_path, \'r\') as file: for line in file: if \\"ERROR\\" in line: error_lines.append(line.strip()) except IOError as e: print(f\\"An error occurred while reading the file: {e}\\") return error_lines # Example use case log_errors = process_log_file(\\"system.log\\") for error in log_errors: print(error) ``` **Hints**: * Use the `open` function with a context manager (`with` statement) to handle file operations. * Use a try-except block to catch file I/O errors and handle them gracefully.","solution":"def process_log_file(file_path): Reads a log file line by line and returns a list of lines that contain the keyword \'ERROR\'. Args: file_path (str): The path to the log file. Returns: List[str]: A list of lines containing \'ERROR\'. error_lines = [] try: with open(file_path, \'r\') as file: for line in file: if \\"ERROR\\" in line: error_lines.append(line.strip()) except IOError as e: print(f\\"An error occurred while reading the file: {e}\\") return error_lines"},{"question":"**Problem Statement**: You need to create a function to calculate the total number of ways to climb a staircase with `n` steps, where you can either take 1 step, 2 steps, or 3 steps at a time. Your challenge is to implement the following function: 1. `count_ways(n: int) -> int`: Determines the number of ways to climb the staircase with `n` steps. **Function Specifications**: 1. `count_ways(n: int) -> int`: - **Input**: An integer `n`. - **Output**: Returns the total number of distinct ways to climb a staircase of `n` steps. - **Constraints**: `n` will be a non-negative integer. - **Error Handling**: Raise a `ValueError` if `n` is less than 0, or a `TypeError` if `n` is not an integer or castable to an integer. **Example Cases**: ```python >>> count_ways(0) 1 >>> count_ways(1) 1 >>> count_ways(2) 2 >>> count_ways(3) 4 >>> count_ways(4) 7 >>> count_ways(5) 13 # Error Handling >>> count_ways(-1) Traceback (most recent call last): ... ValueError: Parameter n must be non-negative. >>> count_ways(\\"4\\") Traceback (most recent call last): ... TypeError: Parameter n must be int or castable to int. ``` **Detailed Explanation**: - For 0 steps, there is only 1 way (doing nothing). - For 1 step, there is 1 way (1 step). - For 2 steps, there are 2 ways (1+1, 2). - For 3 steps, there are 4 ways (1+1+1, 1+2, 2+1, 3). - For 4 steps, there are 7 ways (1+1+1+1, 1+1+2, 1+2+1, 2+1+1, 2+2, 1+3, 3+1). - For 5 steps, there are 13 ways (computed similarly by adding all possible combinations using 1, 2, and 3 steps). Use dynamic programming to efficiently compute the number of ways for larger step counts and verify the solution against the provided examples. **Assessment Criteria**: - Correctness: Ensure the function returns the correct number of ways for various test cases. - Efficiency: Implement an optimal solution to handle larger values of `n` effectively. - Robustness: Appropriately handle invalid inputs and edge cases.","solution":"def count_ways(n): Calculate the number of distinct ways to climb a staircase with n steps, where a person can take 1 step, 2 steps, or 3 steps at a time. if not isinstance(n, int) or isinstance(n, bool): raise TypeError(\\"Parameter n must be int or castable to int.\\") if n < 0: raise ValueError(\\"Parameter n must be non-negative.\\") # Base cases if n == 0: return 1 elif n == 1: return 1 elif n == 2: return 2 # Dynamic programming to store results of sub-problems ways = [0] * (n + 1) ways[0], ways[1], ways[2] = 1, 1, 2 for i in range(3, n + 1): ways[i] = ways[i - 1] + ways[i - 2] + ways[i - 3] return ways[n]"},{"question":"# Coding Question: Implement a Genetic Algorithm for the Traveling Salesman Problem (TSP) **Context**: The Traveling Salesman Problem (TSP) is a well-known combinatorial optimization problem where the objective is to find the shortest possible route that visits a set of cities and returns to the origin city. A genetic algorithm (GA) is a search heuristic that mimics the process of natural evolution to generate high-quality solutions to optimization and search problems. **Challenge**: Your task is to implement a `GeneticAlgorithmTSP` class to solve the TSP using a genetic algorithm. This implementation should include functionalities such as initialization, selection, crossover, mutation, and evolution. **Function Signature**: ```python import random from typing import List, Tuple class GeneticAlgorithmTSP: def __init__(self, cities: List[Tuple[int, int]], population_size: int, mutation_rate: float, generations: int) -> None: pass def initialize_population(self) -> List[List[int]]: pass def evaluate_fitness(self, population: List[List[int]]) -> List[float]: pass def select_parents(self, population: List[List[int]], fitness: List[float]) -> List[List[int]]: pass def crossover(self, parent1: List[int], parent2: List[int]) -> List[int]: pass def mutate(self, individual: List[int]) -> List[int]: pass def evolve(self) -> List[int]: pass ``` **Detailed Requirements**: 1. **Initialization**: The constructor should accept the following parameters: - `cities`: A list of tuples where each tuple represents the coordinates (x, y) of a city. - `population_size`: The number of routes in the population. - `mutation_rate`: The probability of a mutation occurring in an individual. - `generations`: The number of generations to run the algorithm. 2. **Initialization of Population**: - Implement the `initialize_population` method to create an initial population of random routes. - Each route should be a permutation of city indices. 3. **Evaluate Fitness**: - Implement the `evaluate_fitness` method to calculate the fitness of each route in the population. - Fitness can be inversely proportional to the total distance of the route. 4. **Selection**: - Implement the `select_parents` method to select pairs of parent routes based on their fitness. - You can use stochastic methods like tournament selection. 5. **Crossover**: - Implement the `crossover` method to combine two parent routes to produce a child route. - Use ordered crossover (OX) or another appropriate crossover technique. 6. **Mutation**: - Implement the `mutate` method to randomly alter a route. - Mutation can involve swapping cities in the route. 7. **Evolution**: - Implement the `evolve` method to execute the genetic algorithm for the given number of generations. - The method should return the best route found during the evolution process. **Constraints**: - The number of cities will be between 5 and 50. - Coordinates of cities are integers ranging from 0 to 1000. - Population size will be between 20 and 100. - Mutation rate will be a float between 0 and 1. - The number of generations will be between 50 and 1000. **Performance Requirements**: - The `evolve` method should execute within a reasonable time for up to the maximum number of cities and generations. - Memory usage should be optimized to handle the population and operations effectively. **Example**: ```python >>> cities = [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4)] >>> ga_tsp = GeneticAlgorithmTSP(cities, population_size=50, mutation_rate=0.05, generations=100) >>> best_route = ga_tsp.evolve() >>> print(best_route) [0, 1, 2, 3, 4] # Example output (the order may vary) ```","solution":"import random from typing import List, Tuple import numpy as np class GeneticAlgorithmTSP: def __init__(self, cities: List[Tuple[int, int]], population_size: int, mutation_rate: float, generations: int) -> None: self.cities = cities self.population_size = population_size self.mutation_rate = mutation_rate self.generations = generations def initialize_population(self) -> List[List[int]]: population = [] city_indices = list(range(len(self.cities))) for _ in range(self.population_size): random.shuffle(city_indices) population.append(city_indices[:]) return population def evaluate_fitness(self, population: List[List[int]]) -> List[float]: fitness = [] for individual in population: total_distance = 0 for i in range(len(individual)): current_city = self.cities[individual[i]] next_city = self.cities[individual[(i + 1) % len(individual)]] total_distance += np.linalg.norm(np.array(current_city) - np.array(next_city)) fitness.append(1 / total_distance) return fitness def select_parents(self, population: List[List[int]], fitness: List[float]) -> List[List[int]]: selected_parents = [] for _ in range(self.population_size // 2): # Tournament selection tournament = random.sample(list(zip(population, fitness)), k=5) parents = sorted(tournament, key=lambda x: x[1], reverse=True)[:2] selected_parents.extend([parents[0][0], parents[1][0]]) return selected_parents def crossover(self, parent1: List[int], parent2: List[int]) -> List[int]: size = len(parent1) start, end = sorted(random.sample(range(size), 2)) child_p1 = parent1[start:end+1] child_p2 = [item for item in parent2 if item not in child_p1] return child_p2[:start] + child_p1 + child_p2[start:] def mutate(self, individual: List[int]) -> List[int]: if random.random() < self.mutation_rate: idx1, idx2 = random.sample(range(len(individual)), 2) individual[idx1], individual[idx2] = individual[idx2], individual[idx1] return individual def evolve(self) -> List[int]: population = self.initialize_population() for generation in range(self.generations): fitness = self.evaluate_fitness(population) parents = self.select_parents(population, fitness) next_generation = [] for i in range(0, len(parents), 2): parent1, parent2 = parents[i], parents[i + 1] child1 = self.mutate(self.crossover(parent1, parent2)) child2 = self.mutate(self.crossover(parent2, parent1)) next_generation.extend([child1, child2]) population = next_generation fitness = self.evaluate_fitness(population) best_individual_index = fitness.index(max(fitness)) return population[best_individual_index]"},{"question":"# Image Compression Using K-Means Clustering Problem Description: You are tasked with implementing a function that utilizes K-Means clustering to compress an image. The function should reduce the number of colors in the image to `k` colors and save the compressed image to a file. Additionally, you should implement a function that reads the compressed image, reconstructs it using the K-Means centroids, and optionally displays it. Function Signatures: ```python def compress_image(input_image_filename: str, output_image_filename: str, k: int) -> None: Compresses an image using K-Means clustering algorithm and saves it to a file with reduced colors. Args: - input_image_filename (str): The name of the file containing the input image. - output_image_filename (str): The name of the file to save the compressed image. - k (int): The number of clusters (colors) to reduce the image to. Returns: - None pass def decompress_image(compressed_image_filename: str, show_image: bool = False) -> \'ndarray\': Reads a compressed image and reconstructs it using K-Means centroids. Optionally displays the decompressed image. Args: - compressed_image_filename (str): The name of the file containing the compressed image. - show_image (bool, optional): Whether to display the decompressed image. Default is False. Returns: - ndarray: The decompressed image as a NumPy array. pass ``` Input: - For `compress_image`: - `input_image_filename`: A string representing the name of the file containing the input image. - `output_image_filename`: A string representing the name of the file to save the compressed image. - `k`: An integer representing the number of clusters (colors) to reduce the image to. - For `decompress_image`: - `compressed_image_filename`: A string representing the name of the file containing the compressed image. - `show_image`: An optional boolean indicating whether to display the decompressed image (default is False). Output: - For `compress_image`: None. The compressed image is saved to the specified file. - For `decompress_image`: A NumPy array representing the decompressed image. Constraints: - The input image must be a valid image file (e.g., PNG, JPEG). - `k` should be a positive integer value, typically between 2 and 256. - The compressed image should maintain the same dimensions as the original image but with reduced colors. Performance Requirements: - The functions should handle high-resolution images efficiently. - Aim to minimize processing time and memory usage while preserving image quality. Example: ```python # Example usage of the functions. input_image = \\"input_image.jpg\\" compressed_image = \\"compressed_image.png\\" k = 16 # Compress and write to file compress_image(input_image, compressed_image, k) # Read from file and decompress decompressed_image_data = decompress_image(compressed_image, show_image=True) ```","solution":"import numpy as np from sklearn.cluster import KMeans from PIL import Image def compress_image(input_image_filename: str, output_image_filename: str, k: int) -> None: Compresses an image using K-Means clustering algorithm and saves it to a file with reduced colors. Args: - input_image_filename (str): The name of the file containing the input image. - output_image_filename (str): The name of the file to save the compressed image. - k (int): The number of clusters (colors) to reduce the image to. Returns: - None # Load image image = Image.open(input_image_filename) image_np = np.array(image) original_shape = image_np.shape # Reshape image array pixels = image_np.reshape(-1, 3) # Apply KMeans clustering kmeans = KMeans(n_clusters=k, random_state=0).fit(pixels) new_colors = kmeans.cluster_centers_.astype(\'uint8\') new_pixels = new_colors[kmeans.labels_] # Reshape pixels back to original image shape compressed_image_np = new_pixels.reshape(original_shape) # Save compressed image compressed_image = Image.fromarray(compressed_image_np) compressed_image.save(output_image_filename) def decompress_image(compressed_image_filename: str, show_image: bool = False) -> np.ndarray: Reads a compressed image and reconstructs it using K-Means centroids. Optionally displays the decompressed image. Args: - compressed_image_filename (str): The name of the file containing the compressed image. - show_image (bool, optional): Whether to display the decompressed image. Default is False. Returns: - ndarray: The decompressed image as a NumPy array. # Load the compressed image compressed_image = Image.open(compressed_image_filename) compressed_image_np = np.array(compressed_image) if show_image: compressed_image.show() return compressed_image_np"},{"question":"# Problem: Counting Island Perimeters in a Grid You are tasked with calculating the total perimeter of the connected island cells in a grid. # Function Signature ```python def island_perimeters(grid: list[list[int]]) -> int: Parameters: - grid : list of lists of integers : a 2D list representing the grid, where each cell is either water (0) or land (1) Returns: - int : the total perimeter of all islands ``` # Input Format - `grid`: A 2D list consisting of 0s and 1s where: - 0 represents water, - 1 represents land. # Output Format - An integer representing the total perimeter of the islands in the grid. # Constraints - The grid has dimensions (m x n) where `1 <= m, n <= 1000`. - The grid is surrounded by water, i.e., there are no land cells on the boundary of the grid. - There can be multiple separate islands, each formed by horizontally or vertically connected land cells without any land touching the border. # Performance Requirements - The solution should efficiently traverse the grid to account for the fact that the number of cells can be as large as 1,000,000 (1,000 x 1,000). # Scenario Imagine you are given a top-down view of a geographical region represented as a grid where land is represented by 1 and water is represented by 0. Islands are formed by adjacent lands (connected horizontally or vertically). Your task is to calculate the total perimeter of these islands. The perimeter of a land cell is considered to be the length of the grid cell boundary that is adjacent to water. # Example ```python grid = [ [0, 1, 0, 0], [1, 1, 1, 0], [0, 1, 0, 0], [1, 1, 0, 0] ] # Expected output: # 16 ``` Implement the function to solve the problem described.","solution":"def island_perimeters(grid: list[list[int]]) -> int: Calculates the total perimeter of islands in the given grid. Parameters: - grid: list of lists of integers, where 0 represents water and 1 represents land Returns: - int: the total perimeter of all islands def is_water(i, j): return i < 0 or i >= len(grid) or j < 0 or j >= len(grid[0]) or grid[i][j] == 0 perimeter = 0 for i in range(len(grid)): for j in range(len(grid[0])): if grid[i][j] == 1: # Check all four sides if is_water(i-1, j): # Check top perimeter += 1 if is_water(i+1, j): # Check bottom perimeter += 1 if is_water(i, j-1): # Check left perimeter += 1 if is_water(i, j+1): # Check right perimeter += 1 return perimeter"},{"question":"# Coding Question on Algorithm Optimization and Dynamic Programming Context In computer science and operations research, the knapsack problem is a well-known problem that focuses on the selection of items with given weights and values to maximize the total value without exceeding the weight capacity of the knapsack. Problem Design a function `knapsack(max_weight, weights, values)` that solves the 0/1 knapsack problem. Given a set of items, each with a weight and a value, determine the maximum value that can be achieved by selecting items such that the total weight does not exceed `max_weight`. Requirements To achieve this: 1. Utilize dynamic programming to efficiently solve the problem. 2. Develop a table where the entry `[i][w]` represents the maximum value that can be achieved with the first `i` items and a maximum weight capacity of `w`. 3. Use this table to determine the optimal subset of items to include. Input and Output * **Input**: - An integer `max_weight` representing the maximum weight capacity of the knapsack. - A list `weights` of integers where `weights[i]` represents the weight of the `i-th` item. - A list `values` of integers where `values[i]` represents the value of the `i-th` item. * **Output**: - An integer representing the maximum value that can be achieved with the given constraints. Implementation Constraints * Ensure the algorithm runs efficiently for the given constraints using dynamic programming techniques. * Assume the number of items and the maximum weight will be within reasonably large limits that allow for practical computation. Example ```python def knapsack(max_weight, weights, values): # Your code here # Example: max_weight = 50 weights = [10, 20, 30] values = [60, 100, 120] print(knapsack(max_weight, weights, values)) # Expected output: 220 ``` You are required to provide a function definition for `knapsack(max_weight, weights, values)` and ensure it accurately produces the expected output for the given example case. Use dynamic programming to solve the problem efficiently.","solution":"def knapsack(max_weight, weights, values): n = len(weights) dp = [[0 for _ in range(max_weight + 1)] for _ in range(n + 1)] for i in range(1, n + 1): for w in range(max_weight + 1): if weights[i - 1] <= w: dp[i][w] = max(dp[i - 1][w], dp[i - 1][w - weights[i - 1]] + values[i - 1]) else: dp[i][w] = dp[i - 1][w] return dp[n][max_weight]"},{"question":"# Coding Challenge: Implement Merge and Extract Minimum Operations on Fibonacci Heap Context A Fibonacci Heap is an advanced data structure that supports a broader spectrum of efficient heap operations compared to binary or binomial heaps. While the core functions include insertion, merging, and extracting the minimum element, certain operations like deletion and key change are also very efficient. Task You need to extend a Fibonacci Heap implementation with two additional functions: 1. **Merge**: This operation merges another Fibonacci Heap into the current heap. 2. **Extract Minimum**: This operation extracts and returns the minimum element from the heap while restructuring it to preserve the Fibonacci heap properties. Specifications **Operation 1: Merge** - **Function Signature**: `def merge(self, other_heap):` - **Input**: `other_heap` - Another Fibonacci Heap instance to be merged with the current heap. - **Output**: It does not return anything but modifies the current heap to include elements from `other_heap`. **Operation 2: Extract Minimum** - **Function Signature**: `def extract_min(self):` - **Input**: None. - **Output**: It returns the minimum value from the heap while maintaining the heap properties. Additional Requirements - Ensure the heap properties are intact after performing these operations. - Handle cases where the heap is empty gracefully. - Adhere to the typical time complexity of Fibonacci heap operations. # Example Usage ```python # Initialize Fibonacci heaps heap1 = FibonacciHeap() heap2 = FibonacciHeap() # Insert elements into heap1 heap1.insert(10) heap1.insert(20) heap1.insert(30) # Insert elements into heap2 heap2.insert(5) heap2.insert(25) # Merge heap2 into heap1 heap1.merge(heap2) # Extract minimum from the merged heap print(heap1.extract_min()) # Should print 5 # Check the new minimum print(heap1.find_min()) # Should print 10 or the smallest remaining element ``` # Constraints - Do not use additional data structures beyond what is required for the operations. - Ensure all heaps involved in these operations maintain their structural properties. - Implement thorough error handling for edge cases like empty heaps. - Performance requirements must adhere to the standard complexities of Fibonacci heap operations. **Nota Bene**: Modify the `FibonacciHeap` and `Node` classes as necessary to implement the new functionalities.","solution":"class Node: def __init__(self, key): self.key = key self.degree = 0 self.parent = None self.child = None self.mark = False self.left = self self.right = self class FibonacciHeap: def __init__(self): self.min_node = None self.total_nodes = 0 def _link(self, node1, node2): node1.left.right = node1.right node1.right.left = node1.left node1.parent = node2 if node2.child is None: node2.child = node1 node1.right = node1 node1.left = node1 else: node1.left = node2.child node1.right = node2.child.right node2.child.right = node1 node1.right.left = node1 node2.degree += 1 node1.mark = False def insert(self, key): node = Node(key) if self.min_node is None: self.min_node = node else: node.right = self.min_node node.left = self.min_node.left self.min_node.left.right = node self.min_node.left = node if key < self.min_node.key: self.min_node = node self.total_nodes += 1 def merge(self, other_heap): if other_heap.min_node is None: return if self.min_node is None: self.min_node = other_heap.min_node self.total_nodes = other_heap.total_nodes else: min_right = self.min_node.right min_other_left = other_heap.min_node.left self.min_node.right = other_heap.min_node other_heap.min_node.left = self.min_node min_right.left = min_other_left min_other_left.right = min_right if other_heap.min_node.key < self.min_node.key: self.min_node = other_heap.min_node self.total_nodes += other_heap.total_nodes def extract_min(self): z = self.min_node if z is not None: if z.child is not None: children = [x for x in self._iterate(z.child)] for x in children: x.left.right = x.right x.right.left = x.left x.left = self.min_node x.right = self.min_node.right self.min_node.right = x x.right.left = x x.parent = None z.left.right = z.right z.right.left = z.left if z == z.right: self.min_node = None else: self.min_node = z.right self._consolidate() self.total_nodes -= 1 return z.key if z else None def _iterate(self, head): node = head stop = head flag = False while True: if node == stop and flag: break elif node == stop: flag = True yield node node = node.right def _consolidate(self): a = [None] * (self.total_nodes + 1) nodes = [w for w in self._iterate(self.min_node)] for w in nodes: x = w d = x.degree while a[d] is not None: y = a[d] if x.key > y.key: x, y = y, x self._link(y, x) a[d] = None d += 1 a[d] = x self.min_node = None for i in range(len(a)): if a[i] is not None: if self.min_node is None: self.min_node = a[i] else: a[i].right = self.min_node a[i].left = self.min_node.left self.min_node.left.right = a[i] self.min_node.left = a[i] if a[i].key < self.min_node.key: self.min_node = a[i] def find_min(self): return self.min_node.key if self.min_node else None"},{"question":"# Question You are tasked with developing a function for a text-based game that manages player actions based on game state. Players can perform various actions like \\"attack\\", \\"defend\\", \\"heal\\", and \\"run\\". Each player\'s action affects their state and the state of their opponent. Your function, `process_actions`, should: 1. Receive the game state as a dictionary, which includes player states and action commands. 2. Modify the states accordingly based on player actions. 3. Return the updated game state. **Player Actions:** - \\"attack\\": Reduces the opponent\'s HP by the player\'s attack power. - \\"defend\\": Reduces incoming damage by half for the next round. - \\"heal\\": Increases player\'s HP by a fixed amount if they have potions. - \\"run\\": Ends the game in favor of the opponent. **Function Signature:** ```python def process_actions(game_state: dict) -> dict: pass ``` # Input: - `game_state`: A dictionary containing the following details: - `players`: - `player1`: - `hp`: Current HP. - `attack_power`: Attack power for \\"attack\\". - `defense`: Boolean flag for current round defense. - `potions`: Number of potions available for \\"heal\\". - `player2`: - Same structure as `player1`. - `actions`: - `player1`: Action string for player1\'s action (\\"attack\\", \\"defend\\", \\"heal\\", \\"run\\"). - `player2`: Action string for player2\'s action (\\"attack\\", \\"defend\\", \\"heal\\", \\"run\\"). # Output: - Returns an updated `game_state` dictionary reflecting the changes after processing the actions. # Constraints: - Players can only perform one action per round. - HP (hit points) should not fall below zero. - A player cannot heal if no potions are left. # Example: ```python # Example game state input: game_state = { \\"players\\": { \\"player1\\": { \\"hp\\": 100, \\"attack_power\\": 20, \\"defense\\": False, \\"potions\\": 1 }, \\"player2\\": { \\"hp\\": 80, \\"attack_power\\": 15, \\"defense\\": False, \\"potions\\": 0 }, }, \\"actions\\": { \\"player1\\": \\"attack\\", \\"player2\\": \\"heal\\" } } ``` **Example Output**: ```python # After processing actions: updated_state = { \\"players\\": { \\"player1\\": { \\"hp\\": 100, \\"attack_power\\": 20, \\"defense\\": False, \\"potions\\": 1 }, \\"player2\\": { \\"hp\\": 60, # Updated after attack (80 - 20) \\"attack_power\\": 15, \\"defense\\": False, \\"potions\\": 0 # No potion used as there were none }, }, \\"actions\\": {} } ``` In this case, player1 attacks, and player2\'s heal action fails due to having no potions left. Player2\'s HP reduces by 20 (player1\'s attack power).","solution":"def process_actions(game_state: dict) -> dict: players = game_state[\\"players\\"] actions = game_state[\\"actions\\"] player1 = players[\\"player1\\"] player2 = players[\\"player2\\"] action1 = actions[\\"player1\\"] action2 = actions[\\"player2\\"] if action1 == \\"attack\\": if action2 == \\"defend\\": player2[\\"hp\\"] -= player1[\\"attack_power\\"] // 2 else: player2[\\"hp\\"] -= player1[\\"attack_power\\"] if action2 == \\"attack\\": if action1 == \\"defend\\": player1[\\"hp\\"] -= player2[\\"attack_power\\"] // 2 else: player1[\\"hp\\"] -= player2[\\"attack_power\\"] if action1 == \\"heal\\" and player1[\\"potions\\"] > 0: player1[\\"hp\\"] += 20 # fixed amount for heal player1[\\"potions\\"] -= 1 if action2 == \\"heal\\" and player2[\\"potions\\"] > 0: player2[\\"hp\\"] += 20 # fixed amount for heal player2[\\"potions\\"] -= 1 if action1 == \\"run\\": player1[\\"hp\\"] = 0 # Ends the game in favor of opponent if action2 == \\"run\\": player2[\\"hp\\"] = 0 # Ends the game in favor of opponent # Ensure HP does not fall below zero player1[\\"hp\\"] = max(player1[\\"hp\\"], 0) player2[\\"hp\\"] = max(player2[\\"hp\\"], 0) # Reset actions after processing game_state[\\"actions\\"] = {} return game_state"},{"question":"Data Interchange Challenge **Problem Statement:** You are given a JSON file named `movies.json` containing data about various movies. Each movie is represented as a dictionary with keys such as \\"title\\", \\"director\\", \\"year\\", \\"genres\\", and \\"ratings\\". The task is to write a function that reads the JSON file, processes the data, groups the movies by genre, and outputs the genre with the highest average rating. If multiple genres have the same average rating, return the one that comes first alphabetically. Each movie\'s \\"ratings\\" is a list of integers ranging from 1 to 10. Your function should handle the file reading, data processing, and calculating the average ratings efficiently. **Input:** - A JSON file `movies.json` where each movie has the following structure: ```json { \\"title\\": \\"Movie Title\\", \\"director\\": \\"Director Name\\", \\"year\\": 2000, \\"genres\\": [\\"Genre1\\", \\"Genre2\\"], \\"ratings\\": [5, 8, 7] } ``` **Output:** - A string representing the genre with the highest average rating. **Constraints:** - The file contains at least one movie. - Each movie has at least one genre. - Ratings lists contain at least one rating. - Genres, movie titles, and director names are non-empty strings. **Performance Requirements:** - Efficient processing of JSON data. - Accurate calculation and comparison of average ratings. **Example:** Consider the following small example: ```json [ { \\"title\\": \\"Inception\\", \\"director\\": \\"Christopher Nolan\\", \\"year\\": 2010, \\"genres\\": [\\"Sci-Fi\\", \\"Thriller\\"], \\"ratings\\": [9, 10, 10, 8, 9] }, { \\"title\\": \\"The Matrix\\", \\"director\\": \\"The Wachowskis\\", \\"year\\": 1999, \\"genres\\": [\\"Sci-Fi\\", \\"Action\\"], \\"ratings\\": [8, 9, 10, 7, 8] }, { \\"title\\": \\"The Godfather\\", \\"director\\": \\"Francis Ford Coppola\\", \\"year\\": 1972, \\"genres\\": [\\"Crime\\", \\"Drama\\"], \\"ratings\\": [10, 9, 10, 10, 9, 8] } ] ``` Your function should return \\"Crime\\" as it is one of the genres with the highest average rating and comes first alphabetically among those. **Function Signature:** ```python def highest_avg_rating_genre(file_path: str) -> str: pass ``` **Implementation:** Implement the function `highest_avg_rating_genre` which reads the movies data from `movies.json`, processes it to find the genre with the highest average rating using Python\'s JSON handling and efficient data processing methods. **Example Execution:** ```python >>> highest_avg_rating_genre(\\"movies.json\\") \'Crime\' ``` **Note:** - Ensure you have Python\'s JSON library available for parsing the input file. - Be sure to handle potential edge cases such as ties in average ratings alphabetically.","solution":"import json from collections import defaultdict def highest_avg_rating_genre(file_path: str) -> str: with open(file_path, \'r\') as file: movies = json.load(file) genre_ratings = defaultdict(list) for movie in movies: for genre in movie[\'genres\']: genre_ratings[genre].extend(movie[\'ratings\']) highest_avg = -float(\'inf\') highest_avg_genre = None for genre, ratings in genre_ratings.items(): avg_rating = sum(ratings) / len(ratings) if avg_rating > highest_avg or (avg_rating == highest_avg and genre < highest_avg_genre): highest_avg = avg_rating highest_avg_genre = genre return highest_avg_genre"},{"question":"Problem: Generate Permutations of a String Write a function that generates all possible permutations of a given string. # Input 1. A string **s** (1 <= |s| <= 8) containing unique characters. # Output 1. A list of strings, where each string is a unique permutation of the input string **s**. # Function Signature ```python def generate_permutations(s: str) -> List[str]: pass ``` # Examples Example 1: ```python s = \\"ABC\\" print(generate_permutations(s)) # Output: [\'ABC\', \'ACB\', \'BAC\', \'BCA\', \'CAB\', \'CBA\'] ``` Example 2: ```python s = \\"A1B\\" print(generate_permutations(s)) # Output: [\'A1B\', \'AB1\', \'1AB\', \'1BA\', \'BA1\', \'B1A\'] ``` # Notes 1. The permutations should be returned in lexicographical order. 2. You can use recursion or iterative methods to generate permutations. 3. Ensure that the function handles both uppercase letters, lowercase letters, and digits in the input string. # Implementation Tips - Consider using itertools.permutations to simplify the generation of permutations. - Sort the input string initially to guarantee lexicographical order of permutations.","solution":"from typing import List from itertools import permutations def generate_permutations(s: str) -> List[str]: Generates all possible permutations of a given string. Parameters: s (str): Input string of unique characters (length 1 to 8) Returns: List[str]: List of all unique permutations of the input string in lexicographical order perms = [\'\'.join(p) for p in permutations(sorted(s))] return perms"},{"question":"# LRU Cache Implementation Background: Least Recently Used (LRU) Cache is a popular caching strategy where the least recently accessed items are the first to be evicted when the cache reaches its capacity. Your task is to implement an LRU cache using a combination of a dictionary and a double-ended queue (deque). Task: Implement an LRU cache that supports the following operations: `get` and `put`. Requirements: 1. **Initialization**: - Initialize the cache with a fixed capacity. 2. **Get Operation**: - Returns the value of the key if the key exists in the cache; otherwise, return -1. - Update the cache to reflect this access as the most recent. 3. **Put Operation**: - Inserts or updates the value of the key. - If inserting, ensure the cache does not exceed the specified capacity; evict the least recently used item if necessary. Class Definition: ```python class LRUCache: def __init__(self, capacity: int): Initialize the LRU cache with given capacity. :param capacity: int self.capacity = capacity self.cache = {} self.order = deque() def get(self, key: int) -> int: Retrieve item from cache if it exists. :param key: int :return: int if key in self.cache: self.order.remove(key) self.order.appendleft(key) return self.cache[key] return -1 def put(self, key: int, value: int) -> None: Insert or update the value of the key. :param key: int :param value: int if key in self.cache: self.order.remove(key) elif len(self.cache) >= self.capacity: lru_key = self.order.pop() del self.cache[lru_key] self.cache[key] = value self.order.appendleft(key) ``` Example Usage: ```python lru_cache = LRUCache(2) lru_cache.put(1, 1) lru_cache.put(2, 2) assert lru_cache.get(1) == 1 # Returns 1 lru_cache.put(3, 3) # Evicts key 2 assert lru_cache.get(2) == -1 # Returns -1 (not found) lru_cache.put(4, 4) # Evicts key 1 assert lru_cache.get(1) == -1 # Returns -1 (not found) assert lru_cache.get(3) == 3 # Returns 3 assert lru_cache.get(4) == 4 # Returns 4 ``` Constraints: - The number of operations performed can be up to 10^4. - 1 <= capacity <= 3000 - 0 <= key, value <= 10^4 Performance Requirements: - The `get` and `put` operations should each run in O(1) average-time complexity.","solution":"from collections import deque class LRUCache: def __init__(self, capacity: int): Initialize the LRU cache with given capacity. :param capacity: int self.capacity = capacity self.cache = {} self.order = deque() def get(self, key: int) -> int: Retrieve item from cache if it exists. :param key: int :return: int if key in self.cache: self.order.remove(key) self.order.appendleft(key) return self.cache[key] return -1 def put(self, key: int, value: int) -> None: Insert or update the value of the key. :param key: int :param value: int if key in self.cache: self.order.remove(key) elif len(self.cache) >= self.capacity: lru_key = self.order.pop() del self.cache[lru_key] self.cache[key] = value self.order.appendleft(key)"},{"question":"# Title Case Conversion Imagine that you are given a string that needs to be converted to \\"title case\\". In title case, the first letter of each word is capitalized, and all subsequent letters in the word are in lowercase. Spaces and punctuation marks should be retained. **Your task** is to implement the `to_title_case` function in Python, which takes a string and converts it to title case while preserving spaces and punctuation. Function Definition: ```python def to_title_case(text: str) -> str: ``` - `text`: A string that needs to be converted to title case. Constraints: - The function should handle empty strings. - The function should treat sequences of non-alphabetical characters (punctuation, digits, etc.) as word boundaries, but otherwise leave them unchanged. - The function should avoid modifying spaces or punctuation marks. Examples: ```python assert to_title_case(\\"hello world\\") == \\"Hello World\\" assert to_title_case(\\"a quick brown fox\\") == \\"A Quick Brown Fox\\" assert to_title_case(\\"HELLO WORLD\\") == \\"Hello World\\" assert to_title_case(\\"123 abc &^* xyz\\") == \\"123 Abc &^* Xyz\\" assert to_title_case(\\"\\") == \\"\\" assert to_title_case(\\"title using: punctuation!\\") == \\"Title Using: Punctuation!\\" ``` **Notes**: - The primary challenge is to accurately identify word boundaries and apply the correct transformation while keeping all other characters intact. - Ensure that your implementation is efficient and handles both typical and edge case scenarios gracefully.","solution":"def to_title_case(text: str) -> str: Convert a given string to title case. def capitalize(word): if word: return word[0].upper() + word[1:].lower() return word words = text.split(\' \') return \' \'.join(capitalize(word) for word in words)"},{"question":"Matrix Transpose Optimization Context: Transposing a matrix is a fundamental operation where rows of the original matrix become columns in the new matrix and vice versa. This operation is commonly used in various algorithms, especially in numerical linear algebra and graphics. To optimize matrix operations, you will implement an efficient transpose function that minimizes memory usage and leverages in-place operations where feasible. Task: Write a Python function to transpose a given matrix. Optimize for performance, especially considering larger matrices. Ensure that the function handles both square and rectangular matrices effectively. Requirements: 1. **Input**: A 2D list `matrix` representing the matrix to transpose. 2. **Output**: A 2D list representing the transposed matrix. Input Constraints: * The matrix is non-empty and can have varying dimensions. * The elements of the matrix can be any valid numeric or string values. Implementation: Your solution should: 1. Transpose the matrix such that the rows and columns are interchanged. 2. Optimize any in-place operations where possible, ensuring it\'s efficient for large matrices. Function Signature: ```python def transpose_matrix(matrix: list) -> list: pass ``` # Example: ```python >>> transpose_matrix([[1, 2, 3], [4, 5, 6]]) [[1, 4], [2, 5], [3, 6]] >>> transpose_matrix([[\'a\', \'b\'], [\'c\', \'d\'], [\'e\', \'f\']]) [[\'a\', \'c\', \'e\'], [\'b\', \'d\', \'f\']] >>> transpose_matrix([[1]]) [[1]] >>> transpose_matrix([[1, 2], [3, 4], [5, 6], [7, 8]]) [[1, 3, 5, 7], [2, 4, 6, 8]] ```","solution":"def transpose_matrix(matrix: list) -> list: Transposes the given 2D matrix. Args: matrix (list): A 2D list representing the matrix. Returns: list: The transposed matrix. if not matrix or not matrix[0]: return [] rows, cols = len(matrix), len(matrix[0]) transposed = [[None] * rows for _ in range(cols)] for i in range(rows): for j in range(cols): transposed[j][i] = matrix[i][j] return transposed"},{"question":"# Graph Processing Challenge: Shortest Path Navigation You are tasked with implementing a feature for a navigation system that finds the shortest path in a city represented by a graph. Each location in the city is represented by a node, and roads between locations are represented by edges with weights corresponding to the travel time. Your solution must efficiently compute the shortest path from a starting location to the destination. # Problem Statement Write a function `find_shortest_path` that computes the shortest travel time between two locations in a city. You will implement Dijkstra\'s algorithm to solve this problem. # Function Signature ```python def find_shortest_path(n: int, roads: List[Tuple[int, int, int]], start: int, destination: int) -> int: ``` # Input - `n`: Integer, representing the number of locations (nodes) in the city. - `roads`: List of tuples, where each tuple `(u, v, w)` represents a bidirectional road between locations `u` and `v` with travel time `w`. - `start`: Integer, representing the starting location. - `destination`: Integer, representing the destination location. # Output - An integer representing the shortest travel time between the start and destination. If there is no path, return -1. # Constraints 1. `1 <= n <= 1000` 2. `1 <= len(roads) <= 10000` 3. `1 <= u, v <= n` 4. `1 <= w <= 1000` # Requirements 1. **Graph Representation**: Represent the city as an adjacency list. 2. **Algorithm**: Implement Dijkstra\'s algorithm to find the shortest path. 3. **Edge Cases**: Handle cases where the start and destination are the same, and where paths do not exist. # Example ```python # Number of locations n = 5 # Roads as a list of (u, v, w) tuples roads = [ (1, 2, 10), (1, 3, 3), (2, 3, 1), (2, 4, 2), (3, 4, 8), (3, 5, 2), (4, 5, 5) ] # Start and destination locations start = 1 destination = 5 # Find shortest path shortest_time = find_shortest_path(n, roads, start, destination) print(shortest_time) ``` # Expected Output ```python 5 ``` # Notes 1. Your implementation should handle graphs with a large number of nodes and edges efficiently. 2. Consider edge cases such as no available path, isolated nodes, or when the start and destination are the same. 3. Ensure your function handles different inputs robustly and adheres to the constraints.","solution":"import heapq from typing import List, Tuple def find_shortest_path(n: int, roads: List[Tuple[int, int, int]], start: int, destination: int) -> int: Computes the shortest travel time between two locations in a city using Dijkstra\'s algorithm. :param n: Integer, the number of locations (nodes) in the city. :param roads: List of tuples, where each tuple (u, v, w) represents a road between locations u and v with travel time w. :param start: Integer, the starting location. :param destination: Integer, the destination location. :return: Integer, the shortest travel time between the start and destination, or -1 if no path exists. # Construct adjacency list adj_list = {i: [] for i in range(1, n + 1)} for u, v, w in roads: adj_list[u].append((v, w)) adj_list[v].append((u, w)) # Dijkstra\'s algorithm pq = [(0, start)] # Priority queue as (distance, node) distances = {i: float(\'inf\') for i in range(1, n + 1)} distances[start] = 0 while pq: current_distance, current_node = heapq.heappop(pq) if current_node == destination: return current_distance if current_distance > distances[current_node]: continue for neighbor, weight in adj_list[current_node]: distance = current_distance + weight if distance < distances[neighbor]: distances[neighbor] = distance heapq.heappush(pq, (distance, neighbor)) return -1 if distances[destination] == float(\'inf\') else distances[destination]"},{"question":"# Context You are tasked with developing a function that efficiently finds the shortest path in a directed acyclic graph (DAG) using depth-first search (DFS) and dynamic programming techniques. The graph is represented using an adjacency list. # Requirements Implement a function `shortest_path_dag` that computes the shortest path from a given starting node to a target node in a DAG, taking into account edge weights. # Function Specification ```python def shortest_path_dag(graph: dict, start: int, target: int) -> (list, float): Compute the shortest path in a DAG. :param graph: dict, adjacency list representing the graph where each key is a node, and each value is a list of tuples (neighbor, weight) indicating the outgoing edges and their weights. :param start: int, the starting node. :param target: int, the target node. :return: tuple, containing a list of nodes representing the shortest path and the total weight of that path. pass ``` # Input - `graph` - A dictionary representing the adjacency list of the directed acyclic graph. Each key is a node and the value is a list of tuples `(neighbor, weight)` representing the edges and their weights. - `start` - Integer representing the starting node. - `target` - Integer representing the target node. # Output - Returns a tuple containing: - A list of nodes representing the shortest path from the start node to the target node. - The total weight of the shortest path. # Example ```python # Example graph (represented as adjacency list) graph = { 0: [(1, 2), (2, 4)], 1: [(2, 1), (3, 7)], 2: [(3, 3)], 3: [] } # Running the algorithm path, distance = shortest_path_dag(graph, start=0, target=3) print(path, distance) # Example Output: [0, 1, 2, 3], 6.0 ``` # Constraints - Ensure that the graph is a directed acyclic graph (DAG). - The graph contains no negative weight cycles. - Nodes in the graph are represented by non-negative integers. - Implement the shortest path finding using DFS and dynamic programming for efficient processing. # Notes - You may use topological sorting to aid in processing the nodes in a linearized order. - Utilize memoization techniques to store the shortest paths to subproblems for dynamic programming. - Handle edge cases where the start or target node is not in the graph or if no path exists from the start to the target node.","solution":"def shortest_path_dag(graph: dict, start: int, target: int) -> (list, float): Compute the shortest path in a DAG. :param graph: dict, adjacency list representing the graph where each key is a node, and each value is a list of tuples (neighbor, weight) indicating the outgoing edges and their weights. :param start: int, the starting node. :param target: int, the target node. :return: tuple, containing a list of nodes representing the shortest path and the total weight of that path. from collections import deque import math # Topological Sort def topological_sort(graph): in_degree = {u: 0 for u in graph} # Initialize in-degrees of all nodes to 0 for u in graph: for v, _ in graph[u]: in_degree[v] += 1 # Increment in-degree for each outgoing edge queue = deque([u for u in graph if in_degree[u] == 0]) # Nodes with in-degree 0 top_order = [] while queue: node = queue.popleft() top_order.append(node) for neighbor, _ in graph[node]: in_degree[neighbor] -= 1 if in_degree[neighbor] == 0: queue.append(neighbor) return top_order # Initialize distances and paths dist = {u: float(\'inf\') for u in graph} dist[start] = 0 path = {u: [] for u in graph} path[start] = [start] top_order = topological_sort(graph) for u in top_order: if dist[u] != float(\'inf\'): for v, weight in graph[u]: if dist[u] + weight < dist[v]: dist[v] = dist[u] + weight path[v] = path[u] + [v] # If the target is unreachable if dist[target] == float(\'inf\'): return ([], float(\'inf\')) return (path[target], dist[target])"},{"question":"# Problem Statement: Implement a Python class `SimpleCardGame` that simulates a very basic card game where players can draw cards from a deck. The goal is to determine the winner based on the highest card drawn. The game will have the following steps: 1. Initialize a deck of cards. 2. Allow each player to draw a card. 3. Identify the winner based on the highest card drawn. # Detailed Requirements: 1. Create a class `SimpleCardGame` with the following methods: * `__init__(self, players: int)`: Initializes the game with the specified number of players and a shuffled deck of cards. The deck should contain 52 cards, with ranks from 2 to 10, and 11 for Jack, 12 for Queen, 13 for King, and 14 for Ace. Suits are not considered in this game. * `draw_card(self) -> dict`: Each player draws a card from the deck. Returns a dictionary with player indices as keys and the drawn card values as values. * `find_winner(self) -> int`: Determines the winner based on the highest card drawn. Returns the index of the winning player. If there is a tie, return the smallest index among them. 2. Constraints: * The number of players `players` will be between 2 and 5. * Assume the deck is properly shuffled and contains unique cards. * Ensure that no additional cards can be drawn if the deck runs out (handle this gracefully). 3. Input and Output formats: * The methods will receive and return data as specified above. * Sample input: `game = SimpleCardGame(3)`, `cards = game.draw_card()`, `winner = game.find_winner()` * Sample output: `{0: 7, 1: 13, 2: 9}`, `1` # Example: ```python # Sample usage of the SimpleCardGame class game = SimpleCardGame(3) # Players draw cards cards = game.draw_card() print(cards) # Possible output: {0: 7, 1: 13, 2: 9} # Determine the winner winner = game.find_winner() print(winner) # Output: 1 ``` # Performance: * Both `draw_card` and `find_winner` methods should have linear time complexity O(1) for `draw_card` and O(n) for `find_winner` where n is the number of players. * Memory usage should be proportional to the number of players.","solution":"import random class SimpleCardGame: def __init__(self, players: int): Initialize the game with the specified number of players and a shuffled deck of cards. The deck contains 52 cards with ranks from 2 to 14 (where 11 for Jack, 12 for Queen, 13 for King, 14 for Ace). self.players = players self.deck = list(range(2, 15)) * 4 # 4 suits, hence each rank appears 4 times random.shuffle(self.deck) self.hands = {} def draw_card(self) -> dict: Each player draws a card from the deck. Returns a dictionary with player indices as keys and the drawn card values as values. self.hands = {} # Reset hands before drawing new cards for player in range(self.players): if self.deck: # Check if deck still has cards self.hands[player] = self.deck.pop() return self.hands def find_winner(self) -> int: Determine the winner based on the highest card drawn. Returns the index of the winning player. In case of a tie, return the smallest index among them. if not self.hands: return None # No cards drawn winner = max(self.hands, key=lambda player: (self.hands[player], -player)) return winner"},{"question":"# Context You are given a binary search tree (BST) implementation in Python, and you need to augment its functionality with an additional operation. The BST class already provides methods for insertion, deletion, and search. # Task Implement a function `find_kth_smallest(self, k: int) -> int` within the `BinarySearchTree` class that returns the k-th smallest element in the BST. Assume that `k` is always a valid input. # Function Signature ```python class BinarySearchTree: def find_kth_smallest(self, k: int) -> int: # Your code here ``` # Input * An integer `k` representing the k-th position (1-based index) of the smallest element to find in the BST. # Output * Return the k-th smallest element as an integer. # Constraints * `k` is always valid, i.e., 1 <= `k` <= n, where `n` is the number of nodes in the BST. * The number of nodes in the BST (n) is in the range [1, 1,000]. # Example ```python >>> bst = BinarySearchTree([20, 8, 22, 4, 12, 10, 14]) >>> bst.find_kth_smallest(3) 10 >>> bst.find_kth_smallest(1) 4 >>> bst.find_kth_smallest(7) 22 ``` # Notes * Implement an in-order traversal of the BST to find the k-th smallest element. * The BST class assumes that all values are unique, and no duplicate exists.","solution":"class Node: def __init__(self, key): self.data = key self.left = None self.right = None class BinarySearchTree: def __init__(self, elements=None): self.root = None if elements: for elem in elements: self.insert(elem) def insert(self, key): if self.root is None: self.root = Node(key) else: self._insert(self.root, key) def _insert(self, root, key): if key < root.data: if root.left is None: root.left = Node(key) else: self._insert(root.left, key) else: if root.right is None: root.right = Node(key) else: self._insert(root.right, key) def find_kth_smallest(self, k): def in_order_traversal(node): if not node: return [] return in_order_traversal(node.left) + [node.data] + in_order_traversal(node.right) sorted_elements = in_order_traversal(self.root) return sorted_elements[k - 1]"},{"question":"# Matrix Shift Problem **Problem Statement:** You need to write a function `cyclically_shift_matrix` that cyclically shifts the elements of a given matrix counterclockwise by one position. This means that every element moves to the position of the previous element in counterclockwise order within the bounds of the matrix. The matrix is represented as a 2D list of integers, and the dimensions of the matrix are `m` (rows) by `n` (columns). Here\'s how a 3x3 matrix looks before and after a counterclockwise shift: ``` Before: [[1, 2, 3], [4, 5, 6], [7, 8, 9]] After: [[2, 3, 6], [1, 5, 9], [4, 7, 8]] ``` **Function Signature:** ```python def cyclically_shift_matrix(matrix: List[List[int]]) -> List[List[int]]: ``` **Input:** * `matrix`: A 2D list of integers with dimensions `m` x `n` (`1 ≤ m, n ≤ 100`). **Output:** * Return the modified matrix after a single counterclockwise shift. **Constraints:** 1. The dimensions of the matrix will always be valid (i.e., `m` and `n` are at least 1). 2. You should not use any additional matrix for storing the results of the shifts (in-place shifting is preferred). **Example Usage:** ```python cyclically_shift_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) -> [[2, 3, 6], [1, 5, 9], [4, 7, 8]] cyclically_shift_matrix([[1, 1, 1], [0, 0, 0], [2, 2, 2]]) -> [[1, 1, 1], [1, 0, 2], [0, 2, 2]] ``` **Note:** * Focus on implementing the integer shifts within the matrix in-place to minimize memory usage. * Consider edge cases where `m` or `n` is 1, and ensure your function behaves as expected. * You may find it helpful to visualize the movement of elements in smaller matrices before scaling up to larger examples.","solution":"def cyclically_shift_matrix(matrix): m = len(matrix) n = len(matrix[0]) if m == 1 and n == 1: return matrix # No change for 1x1 matrix # Extract the outer layer into a list in counterclockwise order outer_layer = [] # Top row from left to right for j in range(n): outer_layer.append(matrix[0][j]) # Right column from top to bottom (excluding the first entry) for i in range(1, m): outer_layer.append(matrix[i][n-1]) # Bottom row from right to left (excluding the first entry) if m > 1: for j in range(n-2, -1, -1): outer_layer.append(matrix[m-1][j]) # Left column from bottom to top (excluding the first and last entries) if n > 1: for i in range(m-2, 0, -1): outer_layer.append(matrix[i][0]) # Rotate the outer layer by one position if outer_layer: outer_layer = outer_layer[1:] + outer_layer[:1] # Place the rotated layer back into the matrix idx = 0 for j in range(n): matrix[0][j] = outer_layer[idx] idx += 1 for i in range(1, m): matrix[i][n-1] = outer_layer[idx] idx += 1 if m > 1: for j in range(n-2, -1, -1): matrix[m-1][j] = outer_layer[idx] idx += 1 if n > 1: for i in range(m-2, 0, -1): matrix[i][0] = outer_layer[idx] idx += 1 return matrix"},{"question":"# Problem Description You are given a list of integers representing the weights of various books in a library. You need to organize these books into the smallest possible number of bins, where each bin can hold books with a combined weight of up to a given limit. Your task is to implement the First-Fit Decreasing method for bin packing and return the number of bins used. # Function to Implement ```python def number_of_bins(weights: List[int], limit: int) -> int: pass ``` # Input - `weights`: A list of integers, where 1 <= len(weights) <= 1000 and 1 <= weights[i] <= 10000. - `limit`: An integer, representing the maximum weight that any bin can hold, 1 <= limit <= 10000. # Output - An integer representing the number of bins required to pack all the books using the First-Fit Decreasing method. # Example ```python assert number_of_bins([4, 8, 1, 4, 2, 1], 10) == 2 assert number_of_bins([9, 8, 2, 2, 5, 4], 10) == 4 assert number_of_bins([3, 3, 3, 3, 3, 3], 6) == 3 ``` # Instructions 1. Sort the list of weights in descending order. 2. Iterate through the list and place each book in the first bin that has enough remaining capacity. 3. If no bin can accommodate the current book, create a new bin. 4. Return the total number of bins used. # Constraints - The First-Fit Decreasing method should be implemented accurately. - Optimize your solution to handle up to the maximum constraints efficiently.","solution":"def number_of_bins(weights, limit): # Sort weights in descending order weights.sort(reverse=True) bins = [] for weight in weights: placed = False # Try to place the book in one of the existing bins for bin_index in range(len(bins)): if bins[bin_index] + weight <= limit: bins[bin_index] += weight placed = True break # If no suitable bin is found, create a new bin if not placed: bins.append(weight) return len(bins)"},{"question":"# Coding Assessment Question Context You have been given a utility function `merge_intervals` that merges a list of overlapping intervals and returns a new list of the merged intervals. Your task is to use this function effectively to create new functionality for scheduling resources. Task Write a function `schedule_resources(tasks: list[tuple[int, int]], maintenance: tuple[int, int]) -> list[tuple[int, int]]` that: 1. Merges overlapping intervals in both the `tasks` list and the maintenance interval. 2. Identifies and returns the list of time slots when resources are available. Input - `tasks`: List of tuples representing the intervals during which tasks are scheduled. Each tuple contains two integer values representing the start and end times. - `maintenance`: A tuple representing the interval during which maintenance is scheduled, with two integer values for the start and end times. Output - A list of tuples representing the intervals during which resources are available. These intervals should not overlap with any of the scheduled tasks or the maintenance interval. Constraints - All values representing times are integers. - Intervals within `tasks` may overlap and need to be merged. - The `maintenance` interval may partially overlap with some tasks\' intervals. - Assume well-formed input data. Performance Requirements - Ensure the function handles up to 10⁶ intervals efficiently. Example ```python tasks = [(1, 5), (3, 7), (8, 12)] maintenance = (6, 10) result = schedule_resources(tasks, maintenance) print(result) # Expected output: A list of tuples containing the intervals during which resources are available # For instance [(0, 1), (7, 8), (12, inf)] indicating before the first task, between merged tasks and maintenance, and after the last task. ``` Note - The function `merge_intervals` is already provided in your working environment. - You may assume that time starts from 0 and there may be slots available before the first task or after the last task. - Consider edge cases where tasks or maintenance cover the entire timeline or where there are significant gaps between intervals.","solution":"def merge_intervals(intervals): Merges overlapping intervals. if not intervals: return [] intervals.sort(key=lambda x: x[0]) merged = [intervals[0]] for current in intervals[1:]: last = merged[-1] if current[0] <= last[1]: # Overlap merged[-1] = (last[0], max(last[1], current[1])) else: merged.append(current) return merged def subtract_intervals(from_intervals, subtract_interval): Subtract one interval from a list of intervals. result = [] for start, end in from_intervals: if end <= subtract_interval[0] or start >= subtract_interval[1]: result.append((start, end)) else: if start < subtract_interval[0]: result.append((start, subtract_interval[0])) if end > subtract_interval[1]: result.append((subtract_interval[1], end)) return result def schedule_resources(tasks, maintenance): all_intervals = tasks + [maintenance] merged_intervals = merge_intervals(all_intervals) available_intervals = [] current_time = 0 for start, end in merged_intervals: if current_time < start: available_intervals.append((current_time, start)) current_time = max(current_time, end) if current_time < float(\'inf\'): available_intervals.append((current_time, float(\'inf\'))) return available_intervals"},{"question":"# Objective Create a function that checks whether it is possible to partition an array into three parts with equal sums. # Problem Description Write a function `can_partition_into_three_parts(arr: List[int]) -> bool` that: 1. Accepts a list of integers `arr`. 2. Returns `True` if the array can be partitioned into three non-empty contiguous subarrays such that the sum of the elements in each subarray is the same; otherwise, returns `False`. # Constraints * The length of `arr` is between 3 and 5000, inclusive. * Each element in `arr` is between `-10^4` and `10^4`. *Performance Requirement*: Your solution should consider both time and space limitations. # Function Signature ```python def can_partition_into_three_parts(arr: List[int]) -> bool: pass ``` # Example ```python # Example 1 arr = [0, 2, 1, -6, 6, -7, 9, 1, 2, 0, 1] # The array can be partitioned as [0, 2, 1], [-6, 6, -7, 9], [1, 2, 0, 1] assert can_partition_into_three_parts(arr) == True # Example 2 arr = [0, 2, 1, -6, 6, 7, -9, 1, 2, 0, 1] # There is no way to partition the array into three parts with equal sum. assert can_partition_into_three_parts(arr) == False # Example 3 arr = [1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1] # The array can be partitioned into three parts: [1, -1, 1, -1, 1, -1, 1, -1], [1, -1, 1, -1, 1, -1], [1, -1] assert can_partition_into_three_parts(arr) == True ``` # Scenario Context Consider you are developing software for financial analysis, and part of this involves checking if certain transactions (represented as an array of integers) can be split evenly three ways to balance out investments or expenses. Write a function to determine whether such a partition is possible, ensuring it operates efficiently given potential large datasets.","solution":"from typing import List def can_partition_into_three_parts(arr: List[int]) -> bool: total_sum = sum(arr) if total_sum % 3 != 0: return False target_sum = total_sum // 3 current_sum, count = 0, 0 for num in arr: current_sum += num if current_sum == target_sum: count += 1 current_sum = 0 if count == 3: return True return False"},{"question":"**Problem Statement**: You are given an array of integers and a target integer. Your task is to determine whether there exist two distinct indices `i` and `j` in the array such that the absolute difference between the elements at these indices is equal to the target value, i.e., `|arr[i] - arr[j]| = target`. Write a function `find_pair_with_difference(arr: list[int], target: int) -> bool` that takes an array of integers and a target integer, and returns a boolean value indicating whether such a pair exists. **Function Signature**: ```python def find_pair_with_difference(arr: list[int], target: int) -> bool: pass ``` **Input**: * `arr`: A list of integers, which could be of any length (0 <= len(arr) <= 10^5). * `target`: An integer representing the target difference (target >= 0). **Output**: * `True` if there exist distinct indices `i` and `j` such that `|arr[i] - arr[j]| = target`, otherwise `False`. **Examples**: ```python # Example 1 arr = [1, 5, 3, 4, 2] target = 3 print(find_pair_with_difference(arr, target)) # Output: True (|5-2|=3 or |4-1|=3) # Example 2 arr = [8, 12, 16, 4, 0, 20] target = 4 print(find_pair_with_difference(arr, target)) # Output: True (|8-12|=4 or |16-12|=4) # Example 3 arr = [1, 3, 5, 7] target = 10 print(find_pair_with_difference(arr, target)) # Output: False # Example 4 arr = [] target = 5 print(find_pair_with_difference(arr, target)) # Output: False # Example 5 arr = [2, 2, 2, 2] target = 0 print(find_pair_with_difference(arr, target)) # Output: True (|2-2|=0) ``` **Constraints**: * The input array `arr` can contain duplicate values. * The target value will always be a non-negative integer. * The function should aim to have a time complexity better than O(n^2), ideally O(n log n) or O(n). **Notes**: * The function should handle cases where the array is empty or has only one element by returning `False`. * Take into account that the difference should be checked in absolute terms, i.e., `|arr[i] - arr[j]| = target` rather than `arr[i] - arr[j] = target`.","solution":"def find_pair_with_difference(arr: list[int], target: int) -> bool: Determines if there are two distinct indices i and j in the array such that the absolute difference between the elements at these indices is equal to the target value. if target < 0 or len(arr) < 2: return False value_set = set() for value in arr: if (value + target) in value_set or (value - target) in value_set: return True value_set.add(value) return False"},{"question":"# Coding Problem: Volleyball Points Tracker Context: In a volleyball game, teams score points using a basic set of rules. A point is scored whenever a team wins a rally. Your task is to track the points and determine the winner based on the number of points scored by each team. Task: Write a function `track_volleyball_points(rallies: List[str], team_a: str, team_b: str)` that: 1. Takes in a list of rally results and two team names. 2. Returns the final scores of both teams and determines the winner. **Functions to Implement**: 1. **compute_scores**: This function iterates through the list of rallies and updates the scores of the teams accordingly. 2. **determine_winner**: This function receives the final scores and determines the winner. 3. **track_volleyball_points**: This function integrates the computation and decision steps to produce the final output. # Example: ```python from typing import List, Tuple def track_volleyball_points(rallies: List[str], team_a: str, team_b: str) -> Tuple[int, int, str]: # Write your implementation here. pass ``` Given: ```python rallies = [\\"A\\", \\"B\\", \\"A\\", \\"A\\", \\"B\\", \\"A\\"] team_a = \\"TeamA\\" team_b = \\"TeamB\\" ``` For the input: ```python track_volleyball_points(rallies, team_a, team_b) ``` Expected Output: ```python (4, 2, \'TeamA\') ``` Constraints: * The list of rallies (0 ≤ length ≤ 1000). * The names of the teams will be unique and non-empty. * Each rally result in the list is either \'A\' or \'B\' indicating the winner of that rally. Performance Requirements: - Ensure the solution performs efficiently with a linear time complexity for computing scores. - Handle edge cases where the rallies list might be empty. Implementation Notes: - Use simple iteration to count the scores for each team. - Implement a clear and accurate method for determining the winner based on the final scores. - The solution should return a tuple consisting of the scores for both teams and the name of the winning team. If scores are tied, return a message indicating a tie.","solution":"from typing import List, Tuple def compute_scores(rallies: List[str]) -> Tuple[int, int]: score_a = 0 score_b = 0 for rally in rallies: if rally == \'A\': score_a += 1 elif rally == \'B\': score_b += 1 return score_a, score_b def determine_winner(score_a: int, score_b: int, team_a: str, team_b: str) -> str: if score_a > score_b: return team_a elif score_b > score_a: return team_b else: return \\"Tie\\" def track_volleyball_points(rallies: List[str], team_a: str, team_b: str) -> Tuple[int, int, str]: score_a, score_b = compute_scores(rallies) winner = determine_winner(score_a, score_b, team_a, team_b) return score_a, score_b, winner"},{"question":"# Question: Implementing a Directory Traversal and File Analysis System You are tasked with creating a system to traverse a directory structure, analyze files, and retrieve specific information based on file types and contents. The system should include functionalities for filtering, counting, and extracting data from files. **Features to Implement**: 1. **Directory Traversal**: Recursively traverse through a given directory and its subdirectories. 2. **File Type Filtering**: Filter and process files based on their extensions (e.g., `.txt`, `.csv`, `.log`). 3. **Content Counting**: Count occurrences of specified keywords within the text files. 4. **Data Extraction**: Extract certain pieces of data (e.g., email addresses, phone numbers) from the text files. # Function Definitions: ```python import os from typing import List, Dict import re class DirectoryAnalyzer: def __init__(self, directory_path: str) -> None: \'\'\' Initialize the DirectoryAnalyzer with the given root directory path. Args: directory_path (str): Path to the root directory to be analyzed. \'\'\' self.directory_path = directory_path def traverse_directory(self) -> List[str]: \'\'\' Traverse the directory and gather all file paths. Returns: List[str]: A list of file paths. \'\'\' pass def filter_files_by_extension(self, file_paths: List[str], extensions: List[str]) -> List[str]: \'\'\' Filter files by their extensions. Args: file_paths (List[str]): A list of file paths. extensions (List[str]): List of file extensions to filter by (e.g., [\'.txt\', \'.csv\']). Returns: List[str]: A list of file paths that match the given extensions. \'\'\' pass def count_keyword_occurrences(self, file_paths: List[str], keyword: str) -> Dict[str, int]: \'\'\' Count occurrences of a specified keyword in each file. Args: file_paths (List[str]): A list of file paths. keyword (str): The keyword to count occurrences of. Returns: Dict[str, int]: Dictionary containing file path as key and count of keyword occurrences as value. \'\'\' pass def extract_data(self, file_paths: List[str], pattern: str) -> Dict[str, List[str]]: \'\'\' Extract data matching a specific pattern (e.g., email addresses, phone numbers) from each file. Args: file_paths (List[str]): A list of file paths. pattern (str): The regex pattern to match data. Returns: Dict[str, List[str]]: Dictionary with file path as key and list of matched data as value. \'\'\' pass ``` Input Format: 1. For `__init__`: A string representing the directory path. 2. For `filter_files_by_extension`: A list of file paths and a list of file extensions. 3. For `count_keyword_occurrences`: A list of file paths and a string keyword. 4. For `extract_data`: A list of file paths and a string regex pattern. Output Format: 1. For `traverse_directory`: Returns a list of file paths. 2. For `filter_files_by_extension`: Returns a list of file paths that match the given extensions. 3. For `count_keyword_occurrences`: Returns a dictionary with file paths as keys and keyword occurrence counts as values. 4. For `extract_data`: Returns a dictionary with file paths as keys and a list of extracted data as values. Constraints: - Handle large directory structures efficiently. - Ensure regex patterns are optimized for data extraction. - Filter, count, and extract operations should have minimal performance impact even on large files. Example Usage: ```python # Creating an instance of DirectoryAnalyzer for a given directory path analyzer = DirectoryAnalyzer(\\"/path/to/directory\\") # Traversing directory all_files = analyzer.traverse_directory() # Filtering files by .txt and .log extensions text_and_log_files = analyzer.filter_files_by_extension(all_files, [\\".txt\\", \\".log\\"]) # Counting keyword occurrences keyword_counts = analyzer.count_keyword_occurrences(text_and_log_files, \\"error\\") # Extracting email addresses emails = analyzer.extract_data(text_and_log_files, r\\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+.[a-zA-Z]{2,}\\") print(all_files) # Output: List of all file paths print(text_and_log_files) # Output: List of .txt and .log files print(keyword_counts) # Output: {\'/path/to/file1.txt\': 3, \'/path/to/file2.log\': 5} print(emails) # Output: {\'/path/to/file1.txt\': [\'email@example.com\'], \'/path/to/file2.log\': [\'user@example.org\']} ```","solution":"import os from typing import List, Dict import re class DirectoryAnalyzer: def __init__(self, directory_path: str) -> None: \'\'\' Initialize the DirectoryAnalyzer with the given root directory path. Args: directory_path (str): Path to the root directory to be analyzed. \'\'\' self.directory_path = directory_path def traverse_directory(self) -> List[str]: \'\'\' Traverse the directory and gather all file paths. Returns: List[str]: A list of file paths. \'\'\' file_paths = [] for root, dirs, files in os.walk(self.directory_path): for file in files: file_paths.append(os.path.join(root, file)) return file_paths def filter_files_by_extension(self, file_paths: List[str], extensions: List[str]) -> List[str]: \'\'\' Filter files by their extensions. Args: file_paths (List[str]): A list of file paths. extensions (List[str]): List of file extensions to filter by (e.g., [\'.txt\', \'.csv\']). Returns: List[str]: A list of file paths that match the given extensions. \'\'\' return [file_path for file_path in file_paths if any(file_path.endswith(ext) for ext in extensions)] def count_keyword_occurrences(self, file_paths: List[str], keyword: str) -> Dict[str, int]: \'\'\' Count occurrences of a specified keyword in each file. Args: file_paths (List[str]): A list of file paths. keyword (str): The keyword to count occurrences of. Returns: Dict[str, int]: Dictionary containing file path as key and count of keyword occurrences as value. \'\'\' keyword_counts = {} for file_path in file_paths: with open(file_path, \'r\', encoding=\'utf-8\', errors=\'ignore\') as file: content = file.read() keyword_counts[file_path] = content.count(keyword) return keyword_counts def extract_data(self, file_paths: List[str], pattern: str) -> Dict[str, List[str]]: \'\'\' Extract data matching a specific pattern (e.g., email addresses, phone numbers) from each file. Args: file_paths (List[str]): A list of file paths. pattern (str): The regex pattern to match data. Returns: Dict[str, List[str]]: Dictionary with file path as key and list of matched data as value. \'\'\' extracted_data = {} regex = re.compile(pattern) for file_path in file_paths: with open(file_path, \'r\', encoding=\'utf-8\', errors=\'ignore\') as file: content = file.read() matches = regex.findall(content) extracted_data[file_path] = matches return extracted_data"},{"question":"# Warehouse Inventory Management You are responsible for managing the inventory of a warehouse. The warehouse inventory includes a list of items, each with a specified quantity. Periodically, you receive shipment records indicating the items to be added or removed from the inventory. Write a function to update the inventory based on these shipment records and calculate the current inventory with respect to the initial quantities. Function Signature ```python def update_inventory(inventory: dict, shipments: list) -> dict: Args: - inventory (dict): A dictionary where keys are item names (str) and values are their respective quantities (int). - shipments (list): A list of tuples where each tuple contains: - item (str): The name of the item. - change (int): A positive integer if items are added to the inventory or a negative integer if items are removed. Returns: - dict: Updated inventory where keys are item names and values are their current quantities. ``` Input * `inventory`: A dictionary where: * Keys are strings representing item names. * Values are integers representing the quantity of each item initially available. * `shipments`: A list of tuples, where each tuple contains: * `item` (str): The name of the item being added or removed. * `change` (int): The quantity of the item being added (positive value) or removed (negative value). Output * A dictionary representing the updated inventory after processing all the shipment records. Constraints * 1 ≤ len(inventory) ≤ 1000 * Each item name is a non-empty string with a maximum length of 100 characters. * The change (int) in shipments can be between -1000 to 1000. * The inventory quantity can be negative if more items are removed than present. Example ```python >>> update_inventory({\'apple\': 50, \'orange\': 100}, [(\'apple\', -10), (\'orange\', 20), (\'banana\', 5)]) {\'apple\': 40, \'orange\': 120, \'banana\': 5} >>> update_inventory({\'pen\': 200, \'notebook\': 150}, [(\'pen\', -50), (\'notebook\', -100), (\'eraser\', 10)]) {\'pen\': 150, \'notebook\': 50, \'eraser\': 10} ``` # Expectations 1. **Correctness**: Ensure the function correctly processes each shipment and updates the inventory accurately. 2. **Edge Cases**: Handle edge cases such as items not initially in the inventory or items being removed leading to negative quantities. 3. **Efficiency**: The function should perform efficiently with respect to the constraints. Implement your function `update_inventory` based on the above specifications. You can test your solution with the provided examples.","solution":"def update_inventory(inventory: dict, shipments: list) -> dict: Updates the inventory based on the shipment records provided. Args: - inventory (dict): A dictionary where keys are item names (str) and values are their respective quantities (int). - shipments (list): A list of tuples where each tuple contains: - item (str): The name of the item. - change (int): A positive integer if items are added to the inventory or a negative integer if items are removed. Returns: - dict: Updated inventory where keys are item names and values are their current quantities. for item, change in shipments: if item in inventory: inventory[item] += change else: inventory[item] = change return inventory"},{"question":"# Merge K Sorted Lists **Scenario**: Given a list of `k` sorted linked lists, you want to merge them into a single sorted linked list. This is a common problem in linked lists, heaps, and divide-and-conquer strategies. **Problem Statement**: Write a function `merge_k_sorted_lists(lists: List[Optional[ListNode]]) -> Optional[ListNode]` that merges all the given `k` sorted linked lists into one single sorted linked list and returns its head. **Input**: - A list `lists` where each element is the head of a sorted linked list (0 <= len(lists) <= 100). - Each linked list node contains an integer value (-10^4 <= node.val <= 10^4) and a reference to the next node or `null`. **Output**: - Returns the head of the merged sorted linked list. **Constraints**: - The total number of nodes across all lists is within the range `0` to `10^4`. **Function Signature**: ```python def merge_k_sorted_lists(lists: List[Optional[ListNode]]) -> Optional[ListNode]: pass ``` **Example**: ```python # Given the following k=3 sorted linked lists: # 1 -> 4 -> 5, # 1 -> 3 -> 4, # 2 -> 6 # The merged sorted linked list would be: # 1 -> 1 -> 2 -> 3 -> 4 -> 4 -> 5 -> 6 list1 = ListNode(1, ListNode(4, ListNode(5))) list2 = ListNode(1, ListNode(3, ListNode(4))) list3 = ListNode(2, ListNode(6)) print(merge_k_sorted_lists([list1, list2, list3])) # Output: 1 -> 1 -> 2 -> 3 -> 4 -> 4 -> 5 -> 6 ``` **Notes**: - You can choose to solve this problem using different approaches such as a min heap (priority queue) to ensure the solution is optimized, especially for larger values of `k` and greater number of nodes.","solution":"from typing import List, Optional import heapq class ListNode: def __init__(self, x=0, next=None): self.val = x self.next = next def merge_k_sorted_lists(lists: List[Optional[ListNode]]) -> Optional[ListNode]: min_heap = [] # Initialize the heap for idx, node in enumerate(lists): if node: heapq.heappush(min_heap, (node.val, idx, node)) dummy = ListNode(0) current = dummy # Process the heap while min_heap: val, idx, node = heapq.heappop(min_heap) current.next = ListNode(val) current = current.next if node.next: heapq.heappush(min_heap, (node.next.val, idx, node.next)) return dummy.next"},{"question":"# Coding Assessment Question Scenario You are working as a software engineer for a machine learning company. One part of your job involves data preprocessing, including correcting outliers in numerical datasets. As part of this, you need to implement a function to smooth data points based on their neighboring values. Task Write a function `smooth_data(points, window_size)` that takes a list of numerical data points and an integer window size, and returns a new list where each data point is replaced with the average of itself and its neighbors within the specified window size. The window size determines the number of neighboring points to consider on either side of the current point. Function Signature ```python def smooth_data(points: list[float], window_size: int) -> list[float]: ``` Input - `points` (list of float): A list of numerical data points. - `window_size` (int): The number of neighboring points to consider on each side of the current point. Must be a non-negative integer. Output - (list of float): A new list of the same length as `points`, where each point is the average of itself and its neighboring points within the specified window size. Constraints - Handle edge cases where the window size is larger than or equal to the number of points. - Raise a `ValueError` if `window_size` is negative. - If any input is not a list of floats or an integer, raise an appropriate error message. Example ```python >>> smooth_data([1.0, 2.0, 3.0, 4.0, 5.0], 1) [1.5, 2.0, 3.0, 4.0, 4.5] >>> smooth_data([10.0, 20.0, 30.0, 40.0, 50.0], 2) [20.0, 25.0, 30.0, 35.0, 40.0] >>> smooth_data([1.0, 2.0, 3.0], 3) [2.0, 2.0, 2.0] >>> smooth_data([1.0, 2.0, 3.0], -1) Traceback (most recent call last): ... ValueError: window_size must be non-negative >>> smooth_data([1.0, \\"a\\", 3.0], 1) Traceback (most recent call last): ... ValueError: points must be a list of floats >>> smooth_data(123, 1) Traceback (most recent call last): ... ValueError: points must be a list of floats >>> smooth_data([1.0, 2.0, 3.0], \\"a\\") Traceback (most recent call last): ... ValueError: window_size must be an integer ``` Ensure that your implementation handles invalid inputs and edge cases as shown in the examples.","solution":"def smooth_data(points, window_size): Returns a list where each data point is replaced with the average of itself and its neighbors within the specified window size. Parameters: points (list of float): A list of numerical data points. window_size (int): The number of neighboring points to consider on each side of the current point. Returns: list of float: A smoothed list of the same length as `points`. if not isinstance(points, list) or not all(isinstance(x, (float, int)) for x in points): raise ValueError(\\"points must be a list of floats\\") if not isinstance(window_size, int): raise ValueError(\\"window_size must be an integer\\") if window_size < 0: raise ValueError(\\"window_size must be non-negative\\") n = len(points) smoothed_points = [] for i in range(n): start = max(0, i - window_size) end = min(n, i + window_size + 1) window = points[start:end] smoothed_points.append(sum(window) / len(window)) return smoothed_points"},{"question":"# Coding Question Scenario You have been tasked with developing a text processing tool as part of a larger document management system. One of the requirements is to extract and summarize key insights from blocks of text. The initial step in this process is to accurately count the frequency of words in a given piece of text, ignoring common English stop words and punctuation. Problem Statement Write a function called `word_frequency` that takes a string and returns a dictionary with the word frequencies, excluding specified stop words and punctuation. Implementation - The function `word_frequency` should accept: - A string `text` containing a block of text. - The function should return a dictionary with words as keys and their frequencies as values. - Ignore case, punctuation, and stop words. Input - `text`: A string containing the text to process. Output - A dictionary where the keys are words (lowercased) and the values are the number of times each word appears in the text. Constraints - The input text can have a length of up to 100,000 characters. - Ignore the following list of common English stop words: - \\"a\\", \\"the\\", \\"is\\", \\"in\\", \\"at\\", \\"of\\", \\"and\\", \\"to\\", \\"or\\", \\"that\\", \\"this\\", \\"with\\", \\"for\\", \\"on\\", \\"as\\", \\"by\\", \\"an\\", \\"it\\", \\"from\\", \\"but\\", \\"which\\", \\"be\\", \\"are\\". - Ignore punctuation (.,!?:;-\\"\'). Example ```python def word_frequency(text): # implementation here text = \\"The quick brown fox jumps over the lazy dog. The dog was not amused.\\" print(word_frequency(text)) # Output: {\'quick\': 1, \'brown\': 1, \'fox\': 1, \'jumps\': 1, \'over\': 1, \'lazy\': 1, \'dog\': 2, \'was\': 1, \'not\': 1, \'amused\': 1} ``` # Notes - Use Python\'s `string` module for handling punctuation. - Ensure the implementation efficiently handles large input texts and edge cases where text contains no valid words after filtering.","solution":"import string def word_frequency(text): stop_words = set([ \\"a\\", \\"the\\", \\"is\\", \\"in\\", \\"at\\", \\"of\\", \\"and\\", \\"to\\", \\"or\\", \\"that\\", \\"this\\", \\"with\\", \\"for\\", \\"on\\", \\"as\\", \\"by\\", \\"an\\", \\"it\\", \\"from\\", \\"but\\", \\"which\\", \\"be\\", \\"are\\" ]) # Convert text to lowercase text = text.lower() # Remove punctuation text = text.translate(str.maketrans(\\"\\", \\"\\", string.punctuation)) # Split text into words words = text.split() # Count frequencies, ignoring stop words word_count = {} for word in words: if word not in stop_words: if word in word_count: word_count[word] += 1 else: word_count[word] = 1 return word_count"},{"question":"# Coding Question Context In a game of battleships, a player can record the result of each shot in a grid. The grid is of size n x n, where n is an odd number. The battleship is represented by a single cell that the player is trying to hit. The game keeps track of each shot as either a miss (marked by an \'M\') or a hit (marked by an \'H\'). We want to determine if the location of the hit can be uniquely identified based on the given results and if the player has \\"won\\" the game by exactly hitting the battleship once. A unique identification of the hit means there is only one \'H\' cell in the entire grid. Task Implement a function that checks if the player has won the game by hitting the battleship exactly once and makes sure there is only one \'H\' cell in the grid. Function Signature ```python def is_winning_move(grid: List[List[str]]) -> bool: pass ``` Input * `grid` (List[List[str]]): A 2D list of size n x n containing \'M\' for a miss, and \'H\' for a hit. Output * Returns a boolean indicating whether the player has won (True) or not (False). Examples ```python assert is_winning_move([[\'M\', \'M\', \'M\'], [\'M\', \'H\', \'M\'], [\'M\', \'M\', \'M\']]) == True assert is_winning_move([[\'M\', \'M\', \'M\'], [\'M\', \'M\', \'M\'], [\'M\', \'M\', \'M\']]) == False assert is_winning_move([[\'M\', \'M\', \'M\'], [\'H\', \'H\', \'M\'], [\'M\', \'M\', \'M\']]) == False ``` Constraints * The size of the grid `n` is an odd integer where `1 ≤ n ≤ 99`. * The grid initially contains only \'M\'s, and might change to contain at most one \'H\' after each shot. * The battleship is represented by a single cell, and there can be only one \'H\' in the grid for the player to win. Note Ensure the implementation checks for the uniqueness of the \'H\' cell in the entire grid to determine the winning condition.","solution":"from typing import List def is_winning_move(grid: List[List[str]]) -> bool: Checks if the player has won the battleship game by hitting the battleship exactly once. :param grid: List[List[str]] - 2D list of size n x n containing \'M\' for miss and \'H\' for hit. :return: bool - True if there is exactly one \'H\' in the grid, False otherwise. hit_count = 0 for row in grid: hit_count += row.count(\'H\') if hit_count > 1: return False return hit_count == 1"},{"question":"# Coding Assessment Question Objective You are tasked with developing a function that computes all possible unique permutations of a string where no two adjacent characters are the same. Problem Statement Write a Python function `unique_permutations(s: str) -> List[str]` that takes a string `s` and returns a list of all possible unique permutations of the string, ensuring that no two adjacent characters in each permutation are the same. # Input * `s`: A string (1 <= len(s) <= 8) consisting of lowercase alphabets. # Output * A list of strings representing all possible unique permutations of the input string where no two adjacent characters are the same. # Constraints * You can assume the input string contains only lowercase English letters. * The output list should not contain any duplicate permutations. # Example ```python def unique_permutations(s: str) -> List[str]: from itertools import permutations unique_perm = set(permutations(s)) valid_perm = [\'\'.join(p) for p in unique_perm if all(p[i] != p[i + 1] for i in range(len(p) - 1))] return list(valid_perm) # Example Usage print(unique_permutations(\\"aab\\")) # Output: [\'aba\'] print(unique_permutations(\\"aaab\\")) # Output: [] print(unique_permutations(\\"abc\\")) # Output: [\'abc\', \'acb\', \'bac\', \'bca\', \'cab\', \'cba\'] ``` # Requirements 1. The function should handle edge cases where the input string length is minimal (1 character) or maximal (8 characters). 2. Handle cases where it is impossible to generate a permutation that satisfies the condition (return an empty list in such cases). Notes: * Ensure your code is optimized given the constraints. * Conduct comprehensive testing with edge cases and various input scenarios to validate correctness and efficiency.","solution":"from typing import List from itertools import permutations def unique_permutations(s: str) -> List[str]: unique_perm = set(permutations(s)) valid_perm = [\'\'.join(p) for p in unique_perm if all(p[i] != p[i + 1] for i in range(len(p) - 1))] return list(valid_perm)"},{"question":"# Task Write a function that identifies the largest prime palindrome less than a given integer `n`. A palindrome is a number that reads the same forward and backward, and a prime number is only divisible by 1 and itself. # Input and Output * **Function Signature**: ```python def largest_prime_palindrome(n: int) -> int: ``` * **Input**: * An integer `n` where `1 <= n <= 10^6`. * **Output**: * An integer that represents the largest prime palindrome less than `n`. # Constraints 1. The function should handle general cases efficiently within the given constraints. 2. Only standard modules may be used. # Example For instance, calling the function with: ```python largest_prime_palindrome(1000) # returns 929 ``` # Expectations * Use efficient prime checking and palindrome detection algorithms to ensure reasonable execution time. * Avoid recomputing checks unnecessarily to optimize performance. # Assumptions * You can assume that `n` will always be an integer within the specified range. * Handling very large numbers and performance optimizations should be appropriately considered, given the constraint.","solution":"def is_prime(num): if num <= 1: return False if num <= 3: return True if num % 2 == 0 or num % 3 == 0: return False i = 5 while i * i <= num: if num % i == 0 or num % (i + 2) == 0: return False i += 6 return True def is_palindrome(num): return str(num) == str(num)[::-1] def largest_prime_palindrome(n): for num in range(n - 1, 1, -1): if is_palindrome(num) and is_prime(num): return num return -1"},{"question":"# Hash Table Collision Resolution using Open Addressing **Background**: Hash tables are a fundamental data structure used to implement an associative array, a structure that can map keys to values. Collisions in hash tables are inevitable and must be handled properly. One common technique is open addressing, which uses probing methods to find the next available slot. In this exercise, you will implement linear probing for collision resolution in a hash table. **Objective**: Complete the implementation for a hash table that resolves collisions using linear probing. **Task**: 1. Complete the `HashTable` class with necessary methods to handle insertions and searches. 2. Write a function `put` to insert a key-value pair into the hash table and handle collisions using linear probing. 3. Write a function `get` to retrieve the value associated with a given key. **Function Signature**: ```python class HashTable: def __init__(self, size: int): self.size = size self.table = [None] * size def put(self, key: int, value: any) -> None: pass def get(self, key: int) -> any: pass ``` **Input**: - `key`: An integer representing the key to be inserted or retrieved. - `value`: The value to be associated with the key. **Behavior**: - If a collision occurs, use linear probing (i.e., try the next slot in the table) to find an available slot. - If the `put` method needs to find a slot, it should continuously probe until it finds an empty slot or the same key. **Output**: - For `put`, there is no return value. The method should insert the key-value pair in the appropriate slot. - For `get`, the method should return the value associated with the provided key or `None` if the key is not found. **Constraints**: - The hash table size `n` is such that `1 <= n <= 1000`. - The number of different keys to be inserted will not exceed the size of the table. **Example**: ```python hash_table = HashTable(size=10) hash_table.put(1, \'value1\') hash_table.put(11, \'value11\') hash_table.put(21, \'value21\') assert hash_table.get(1) == \'value1\' assert hash_table.get(11) == \'value11\' assert hash_table.get(21) == \'value21\' assert hash_table.get(2) == None # key 2 is not in the table ``` You can start by implementing a basic hash function within the `put` and `get` methods and then handle collisions with linear probing. **Example Implementation**: ```python class HashTable: def __init__(self, size: int): self.size = size self.table = [None] * size def hash_function(self, key: int) -> int: return key % self.size def put(self, key: int, value: any) -> None: idx = self.hash_function(key) while self.table[idx] is not None: if self.table[idx][0] == key: self.table[idx] = (key, value) return idx = (idx + 1) % self.size self.table[idx] = (key, value) def get(self, key: int) -> any: idx = self.hash_function(key) while self.table[idx] is not None: if self.table[idx][0] == key: return self.table[idx][1] idx = (idx + 1) % self.size return None ``` Integrate and build upon the provided implementation to ensure correct behavior for insertion and retrieval of key-value pairs in the hash table using linear probing for collision handling.","solution":"class HashTable: def __init__(self, size: int): self.size = size self.table = [None] * size def hash_function(self, key: int) -> int: Simple hash function to compute the initial index. return key % self.size def put(self, key: int, value: any) -> None: Insert the key-value pair into the hash table using linear probing for collision resolution. idx = self.hash_function(key) while self.table[idx] is not None: if self.table[idx][0] == key: self.table[idx] = (key, value) return idx = (idx + 1) % self.size self.table[idx] = (key, value) def get(self, key: int) -> any: Retrieve the value associated with the key using linear probing to resolve collisions. idx = self.hash_function(key) while self.table[idx] is not None: if self.table[idx][0] == key: return self.table[idx][1] idx = (idx + 1) % self.size return None"},{"question":"# URL Shortener Service Objective Design and implement a URL shortener service. The service should be able to shorten a given long URL and retrieve the original long URL when provided with the shortened version. Implement both encoding and decoding functionalities. Problem Statement You are required to create a class `URLShortener` that provides the following methods: 1. **encode(long_url: str) -> str**: This method will take a long URL as input and return a shortened version of the URL. 2. **decode(short_url: str) -> str**: This method will take a shortened URL as input and return the original long URL. The shortened URL can be created using a base62 encoding scheme (consisting of alphanumeric characters). One way to do this is by using an incremental ID for each long URL and converting this ID to a base62 string. Function Specifications 1. **encode(long_url: str) -> str**: This function will take a string `long_url` and return a shortened URL. 2. **decode(short_url: str) -> str**: This function will take a string `short_url` and return the original long URL. Example ```python # Create a new URLShortener instance shortener = URLShortener() # Encode long URLs short_url1 = shortener.encode(\\"https://www.example.com\\") short_url2 = shortener.encode(\\"https://www.anotherexample.com\\") print(short_url1) # Example output: \'b\' print(short_url2) # Example output: \'c\' # Decode short URLs print(shortener.decode(short_url1)) # Output: \'https://www.example.com\' print(shortener.decode(short_url2)) # Output: \'https://www.anotherexample.com\' ``` Constraints - The length of `long_url` may not exceed 10^3 characters. - Each `short_url` is unique and correctly maps to the original `long_url`. - Implement efficient solutions with respect to time and space complexity. - You can assume the service handles maximum 10^5 URLs. This new question should align well with the existing set, focusing on core programming concepts such as data structures, hash maps, encoding schemes, and unique identification. The level of detail and the clear structure of tasks maintain consistency with the provided example.","solution":"import string class URLShortener: def __init__(self): self.url_to_id = {} self.id_to_url = {} self.counter = 1 self.alphabet = string.ascii_letters + string.digits def _encode_id(self, id): Encodes an integer ID to a base62 string. base62 = [] while id > 0: base62.append(self.alphabet[id % 62]) id //= 62 return \'\'.join(reversed(base62)) def _decode_id(self, short_url): Decodes a base62 string to an integer ID. id = 0 for char in short_url: id = id * 62 + self.alphabet.index(char) return id def encode(self, long_url: str) -> str: Encodes a long URL to a shortened URL. if long_url in self.url_to_id: id = self.url_to_id[long_url] else: id = self.counter self.url_to_id[long_url] = id self.id_to_url[id] = long_url self.counter += 1 return self._encode_id(id) def decode(self, short_url: str) -> str: Decodes a shortened URL to its original long URL. id = self._decode_id(short_url) return self.id_to_url.get(id, \\"\\")"},{"question":"# Directory Size Calculation You are tasked with building a function to calculate the total size of files within a directory structure, taking into account the nested subdirectories. The function should traverse the entire directory tree and sum the sizes of all files. **Function Signature**: ```python def calculate_directory_size(directory: dict) -> int: ``` # Input * `directory` (dict): A nested dictionary where each key is the name of a file or subdirectory, and each value is either an integer (representing the size of a file in bytes) or another dictionary (representing a subdirectory). # Output * Returns the total size of all files within the directory and its subdirectories as an integer. # Constraints * Each file size will be a non-negative integer. * Directory names and file names are unique within their immediate containing directory. # Example ```python example_directory = { \'file1.txt\': 100, \'file2.txt\': 200, \'subdir1\': { \'file3.txt\': 300, \'file4.txt\': 400, \'subdir2\': { \'file5.txt\': 500, \'file6.txt\': 600, } }, \'subdir3\': { \'file7.txt\': 700 } } >>> calculate_directory_size(example_directory) 2800 ``` # Additional Information The function should be able to handle deeply nested structures and correctly sum the sizes of all files at various levels of the directory tree. The directory structure might be complex and large, so ensure the function is efficient and handles nesting correctly.","solution":"def calculate_directory_size(directory: dict) -> int: total_size = 0 def traverse_directory(sub_directory): nonlocal total_size for key, value in sub_directory.items(): if isinstance(value, dict): traverse_directory(value) else: total_size += value traverse_directory(directory) return total_size"},{"question":"**Efficient Graph Coloring** You need to implement an efficient algorithm to determine the minimum number of colors required to color a given undirected graph such that no two adjacent vertices share the same color. Additionally, your implementation should be able to provide the coloring of the graph. # Input: - An integer `num_nodes` representing the number of vertices in the graph. - A list of tuples `edges`, where each tuple contains two integers `u` and `v` representing an edge between vertex `u` and vertex `v`. # Output: - An integer representing the minimum number of colors required to color the graph. - A list of integers where the `i`-th element represents the color assigned to the `i`-th vertex (0-indexed). # Constraints: - `1 <= num_nodes <= 1000` - `0 <= len(edges) <= 5000` - There are no self-loops or multiple edges between the same pair of vertices. # Performance Requirements: - Your algorithm should aim for an efficient solution, preferably with a time complexity of (O(V^2 + E)), suitable for the given constraints. # Function Signature: ```python def graph_coloring(num_nodes: int, edges: list[tuple[int, int]]) -> tuple[int, list[int]]: ``` # Example: ```python >>> graph_coloring(4, [(0, 1), (1, 2), (2, 3), (3, 0), (0, 2)]) (3, [0, 1, 2, 1]) >>> graph_coloring(3, [(0, 1), (1, 2), (2, 0)]) (3, [0, 1, 2]) >>> graph_coloring(5, [(0, 1), (1, 2), (2, 3), (3, 4), (4, 0)]) (3, [0, 1, 2, 1, 0]) ``` **Note**: Implement the function such that it efficiently determines the chromatic number of the graph and assigns colors to each vertex to meet the problem requirements.","solution":"def graph_coloring(num_nodes, edges): def greedy_coloring(num_nodes, adj_list): result = [-1] * num_nodes available = [False] * num_nodes result[0] = 0 for u in range(1, num_nodes): for i in adj_list[u]: if result[i] != -1: available[result[i]] = True cr = 0 while cr < num_nodes and available[cr]: cr += 1 result[u] = cr for i in adj_list[u]: if result[i] != -1: available[result[i]] = False return result adj_list = [[] for _ in range(num_nodes)] for u, v in edges: adj_list[u].append(v) adj_list[v].append(u) coloring = greedy_coloring(num_nodes, adj_list) num_colors = max(coloring) + 1 return num_colors, coloring"},{"question":"# Coding Assessment Question Scenario You are developing a system for an e-commerce platform to manage orders efficiently. Each order contains multiple items, and you need to implement functionality to calculate the total cost of an order while applying various discounts based on the total cost or the number of items in the order. Task Implement a function `calculate_total_cost` that calculates the total cost of an order after applying applicable discounts. The order is represented as a list of tuples, where each tuple contains the item price and quantity. Additionally, you are given a list of discount rules that define various discount thresholds and the corresponding discount percentages. Function Signature ```python def calculate_total_cost(order: List[Tuple[float, int]], discounts: List[Tuple[float, float]]) -> float: ``` Input * `order (List[Tuple[float, int]])`: A list of tuples where each tuple contains the price of an item (float) and its quantity (int). * `discounts (List[Tuple[float, float]])`: A list of tuples where each tuple contains a cost threshold (float) and a discount percentage (float). Output * Returns the total cost (float) of the order after applying the highest applicable discount. Constraints * The order list contains at least one item. * The prices and quantities of items are always positive numbers. * Discount percentages are always between 0 and 100 (inclusive). * If multiple discounts apply, only the highest discount should be applied to the total cost. Example ```python You have the following order: - Item 1: 10.0, quantity: 2 - Item 2: 5.0, quantity: 5 The total cost without any discount is 45.0. The following discounts are available: - If the total cost is 20.0 or more, apply a 10% discount. - If the total cost is 40.0 or more, apply a 20% discount. In this case, the highest applicable discount is 20%, so the final cost should be 36.0. order = [(10.0, 2), (5.0, 5)] discounts = [(20.0, 10.0), (40.0, 20.0)] total_cost = calculate_total_cost(order, discounts) print(total_cost) # Output should be 36.0 ``` Notes * Make sure to account for the possibility of multiple discount thresholds. * Ensure the solution is clear and easy to understand, focusing on readability and correctness.","solution":"from typing import List, Tuple def calculate_total_cost(order: List[Tuple[float, int]], discounts: List[Tuple[float, float]]) -> float: Returns the total cost of an order after applying the highest applicable discount. :param order: List of tuples where each tuple contains the price of an item and its quantity. :param discounts: List of discount rules where each rule is a tuple with a cost threshold and a discount percentage. :return: The total cost after applying the highest applicable discount. # Calculate the total cost without any discounts total_cost = sum(price * quantity for price, quantity in order) # Determine the highest applicable discount applicable_discount = 0.0 for threshold, discount in discounts: if total_cost >= threshold: applicable_discount = max(applicable_discount, discount) # Apply the highest discount final_cost = total_cost * (1 - applicable_discount / 100) return final_cost"},{"question":"# Scenario: You are tasked with developing a library management system that can efficiently handle book checkouts and read requests. The system should ensure books can only be checked out once, support priority access to books based on member roles, and accurately track book availability. # Task: Implement a library management system with the following requirements in mind: # Requirements: 1. **Initialization**: * Initialize the library with a given list of books and members. 2. **Methods**: * `checkout_book(member_id, book_title)`: Allows a member to check out a book, if available. Should handle priority access based on member roles (e.g., VIP members get higher priority). * `return_book(member_id, book_title)`: Allows a member to return a checked-out book. * `available_books()`: Returns a list of available books for checkout. * `member_books(member_id)`: Returns a list of books currently checked out by the member. 3. **Constraints**: * Each book can only be checked out by one member at a time. * Members can only check out up to a certain number of books at a time based on their role. * Handle different member roles with different priorities (e.g., VIP vs. Regular). * Ensure accurate tracking of book availability and handle edge cases gracefully (e.g., attempting to check out unavailable books). # Input Format: - Initialization parameters: * `books`: List of available book titles. * `members`: List of dictionaries with each member\'s ID, name, and role (`\\"VIP\\"` or `\\"Regular\\"`). - Methods: * For `checkout_book`: * `member_id`: Unique identifier of the member. * `book_title`: Title of the book to be checked out. * For `return_book`: * `member_id`: Unique identifier of the member. * `book_title`: Title of the book to be returned. # Output Format: - `available_books`: List of strings representing the titles of available books. - `member_books`: List of strings representing the titles of books checked out by the member. - `checkout_book`: Boolean indicating success or failure of the operation. - `return_book`: Boolean indicating success or failure of the operation. # Example: ```python books = [\\"Book1\\", \\"Book2\\", \\"Book3\\"] members = [ {\\"id\\": 1, \\"name\\": \\"Alice\\", \\"role\\": \\"VIP\\"}, {\\"id\\": 2, \\"name\\": \\"Bob\\", \\"role\\": \\"Regular\\"} ] # Initializing the library library = LibraryManagementSystem(books, members) # Check out books print(library.checkout_book(1, \\"Book1\\")) # True, VIP member Alice checked out Book1 print(library.checkout_book(2, \\"Book1\\")) # False, Book1 already checked out # Return book print(library.return_book(1, \\"Book1\\")) # True, Alice returned Book1 # Get available books print(library.available_books()) # [\\"Book1\\", \\"Book2\\", \\"Book3\\"] # Get member\'s books print(library.member_books(1)) # [] (Alice has no books checked out) ``` Implement the `LibraryManagementSystem` class in Python with the above specifications.","solution":"class LibraryManagementSystem: def __init__(self, books, members): Initialize the library with a list of books and members. self.books = set(books) self.available_books_hw = set(books) self.checked_out_books = {} self.members = {member[\\"id\\"]: member for member in members} self.member_books_hw = {member[\\"id\\"]: set() for member in members} self.roles_limit = {\\"VIP\\": 10, \\"Regular\\": 5} def checkout_book(self, member_id, book_title): Allows a member to check out a book, if available. Should handle priority access based on member roles. if book_title not in self.available_books_hw: return False member_role = self.members[member_id][\\"role\\"] max_books = self.roles_limit[member_role] if len(self.member_books_hw[member_id]) >= max_books: return False self.available_books_hw.remove(book_title) self.checked_out_books[book_title] = member_id self.member_books_hw[member_id].add(book_title) return True def return_book(self, member_id, book_title): Allows a member to return a checked-out book. if book_title not in self.checked_out_books: return False if self.checked_out_books[book_title] != member_id: return False self.available_books_hw.add(book_title) del self.checked_out_books[book_title] self.member_books_hw[member_id].remove(book_title) return True def available_books(self): Returns a list of available books for checkout. return list(self.available_books_hw) def member_books(self, member_id): Returns a list of books currently checked out by the member. return list(self.member_books_hw[member_id])"},{"question":"Largest Prime Factor Calculation **Background**: In number theory, the prime factors of a positive integer are the prime numbers that divide that integer exactly. The largest prime factor of an integer is the largest of these prime factors. **Task**: Write a function `largest_prime_factor` that takes an integer `n` and returns the largest prime factor of `n`. Function Signature: ```python def largest_prime_factor(n: int) -> int: pass ``` Input: * An integer `n` (2 <= n <= 10^12) Output: * An integer representing the largest prime factor of `n`. Examples: ```python largest_prime_factor(13195) -> 29 largest_prime_factor(600851475143) -> 6857 largest_prime_factor(37) -> 37 largest_prime_factor(49) -> 7 ``` # Constraints: * The function should efficiently compute the largest prime factor considering the large range of the input size. * Handle edge cases where `n` itself is a prime number. # Scenario: Imagine you are tasked with optimizing a cryptographic algorithm that relies on prime factorization. This function would be critical in such applications, where performance and correctness are pivotal. Ensure your implementation considers the efficiency for very large inputs.","solution":"import math def largest_prime_factor(n: int) -> int: Returns the largest prime factor of a given integer n. # Initialize the largest factor as the smallest prime number largest_factor = 1 # Remove the factors of 2 while n % 2 == 0: largest_factor = 2 n = n // 2 # At this point, n must be odd. Start loop from 3 and increment by 2 (odd numbers only) for i in range(3, int(math.sqrt(n)) + 1, 2): while (n % i == 0): largest_factor = i n = n // i # This condition is to check if n is a prime number greater than 2 if n > 2: largest_factor = n return largest_factor"},{"question":"# Problem Description Design a function to compute the dot product of two sparse vectors. The vectors will be represented as lists of tuples where each tuple contains an index and a value. The length of the two input vectors will always be the same. # Input and Output **Function Signature**: ```python def sparse_vector_dot_product(vector_a: List[Tuple[int, float]], vector_b: List[Tuple[int, float]]) -> float: pass ``` **Inputs**: * `vector_a` (List[Tuple[int, float]]): A list of tuples where each tuple contains an index and value for the first sparse vector. * `vector_b` (List[Tuple[int, float]]): A list of tuples where each tuple contains an index and value for the second sparse vector. **Outputs**: * Returns a float which is the dot product of the two sparse vectors. # Constraints * Both vectors are of the same length and the indices are unique within a vector. * If an index is present in one vector but not the other, it should be considered as having a value of 0 in the other vector. # Example ```python vector_a = [(0, 3.0), (2, 4.0), (4, 5.0)] vector_b = [(0, 2.0), (2, 1.0), (3, 7.0)] result = sparse_vector_dot_product(vector_a, vector_b) print(result) # Output should be 3.0 * 2.0 + 4.0 * 1.0 = 10.0 ``` # Task Implement the `sparse_vector_dot_product` function to calculate the dot product of two given sparse vectors correctly, ensuring proper validation and handling of edge cases discussed.","solution":"def sparse_vector_dot_product(vector_a, vector_b): Computes the dot product of two sparse vectors. Args: vector_a: List[Tuple[int, float]] - The first sparse vector. vector_b: List[Tuple[int, float]] - The second sparse vector. Returns: float - The dot product of the two sparse vectors. dict_a = {index: value for index, value in vector_a} dict_b = {index: value for index, value in vector_b} dot_product = 0.0 for index, value in dict_a.items(): if index in dict_b: dot_product += value * dict_b[index] return dot_product"},{"question":"# Coding Assessment Question You are required to design a function that processes earthquake data from an external API and filters the results based on magnitude and date range. The function should handle possible errors gracefully and provide options to cache results for improved performance. Function Specification **Function Name**: `fetch_earthquake_data` **Input Parameters**: 1. `min_magnitude`: (float) Minimum magnitude of earthquakes to be considered. 2. `start_date`: (str) Start date in `YYYY-MM-DD` format. 3. `end_date`: (str) End date in `YYYY-MM-DD` format. 4. `use_cache`: (bool) Optional parameter to indicate if the function should use cached data when available. Default is `True`. **Output**: - If successful, returns a list of dictionaries where each dictionary contains the date, time, location, and magnitude of each earthquake. - In the case of failures, returns an appropriate error message or an empty list. **Constraints**: - The `start_date` should not be after the `end_date`. - Only dates within the API\'s available data range should be considered. - Manage and implement caching mechanisms to store responses for previously fetched date ranges. Example Usage ```python def fetch_earthquake_data(min_magnitude: float, start_date: str, end_date: str, use_cache=True) -> list: # Your implementation here pass # Example call results = fetch_earthquake_data(5.0, \\"2021-01-01\\", \\"2021-01-31\\") for event in results: print(event) ``` # Requirements: 1. **Error Handling**: Your implementation should gracefully handle API errors, invalid date ranges, and empty responses. 2. **Caching**: Implement a simple caching mechanism to save previous responses in memory and allow re-use when `use_cache` is `True`. 3. **Efficiency**: Ensure that the solution efficiently handles large date ranges without significant performance degradation. 4. **Clear Documentation and Code**: Provide meaningful function and variable names, and ensure your code is well-documented. You have 2 hours to complete this task. Good luck!","solution":"import requests import datetime from dateutil.parser import parse class Cache: def __init__(self): self.data = {} def get(self, key): return self.data.get(key, None) def set(self, key, value): self.data[key] = value cache = Cache() def fetch_earthquake_data(min_magnitude: float, start_date: str, end_date: str, use_cache=True) -> list: Fetches earthquake data from an external API and filters based on given criteria. :param min_magnitude: (float) Minimum magnitude of earthquakes to be considered. :param start_date: (str) Start date in `YYYY-MM-DD` format. :param end_date: (str) End date in `YYYY-MM-DD` format. :param use_cache: (bool) Optional parameter to indicate if the function should use cached data when available. :return: A list of dictionaries with date, time, location, and magnitude of each earthquake. # Validate date strings try: start_date = parse(start_date).date() end_date = parse(end_date).date() except ValueError: return \\"Invalid date format. Please use YYYY-MM-DD.\\" if start_date > end_date: return \\"Start date should not be after end date.\\" # Prepare the cache key cache_key = f\\"{min_magnitude}_{start_date}_{end_date}\\" if use_cache: cached_result = cache.get(cache_key) if cached_result is not None: return cached_result # URL and parameters for the API (example using USGS earthquake data API) url = \\"https://earthquake.usgs.gov/fdsnws/event/1/query\\" params = { \\"format\\": \\"geojson\\", \\"starttime\\": start_date.isoformat(), \\"endtime\\": end_date.isoformat(), \\"minmagnitude\\": min_magnitude } try: response = requests.get(url, params=params) response.raise_for_status() except requests.RequestException as e: return f\\"API request failed: {e}\\" # Parse the response try: data = response.json() except ValueError: return \\"Invalid response received from API.\\" if \'features\' not in data: return [] # Process the data earthquakes = [] for feature in data[\'features\']: properties = feature[\'properties\'] event = { \\"date\\": datetime.datetime.utcfromtimestamp(properties[\'time\'] / 1000).strftime(\'%Y-%m-%d\'), \\"time\\": datetime.datetime.utcfromtimestamp(properties[\'time\'] / 1000).strftime(\'%H:%M:%S\'), \\"location\\": properties[\'place\'], \\"magnitude\\": properties[\'mag\'] } earthquakes.append(event) # Cache the result cache.set(cache_key, earthquakes) return earthquakes"},{"question":"# Tower of Hanoi Solver You are asked to implement a function that solves the Tower of Hanoi problem. The function should print out the sequence of moves needed to transfer the disks from the source peg to the destination peg, following the rules of the game. **Function Signature:** ```python def tower_of_hanoi(n: int, source: str, target: str, auxiliary: str) -> None: ``` **Input:** - `n` - The number of disks. - `source` - The name of the source peg. - `target` - The name of the target peg. - `auxiliary` - The name of the auxiliary peg. **Output:** - The function should print out the moves required to solve the Tower of Hanoi problem. **Constraints:** - The value of `n` will be between 1 and 10. - The names of the pegs are arbitrary strings that will be passed to the function. **Scenario:** The Tower of Hanoi is a classic problem that illustrates the concept of recursion. You need to demonstrate your understanding of recursion by implementing this function, which will be used in a tutorial for demonstrating recursive problem-solving techniques. **Example:** ```python >>> tower_of_hanoi(3, \'A\', \'C\', \'B\') Move disk 1 from A to C Move disk 2 from A to B Move disk 1 from C to B Move disk 3 from A to C Move disk 1 from B to A Move disk 2 from B to C Move disk 1 from A to C ``` **Note:** The function should directly print each move as shown in the example. Each move should follow the format: ``` Move disk X from Y to Z ``` where X is the disk number, Y is the source peg, and Z is the target peg. Here\'s a starting point for you to implement the solution: ```python def tower_of_hanoi(n: int, source: str, target: str, auxiliary: str) -> None: if n == 1: print(f\\"Move disk 1 from {source} to {target}\\") return tower_of_hanoi(n-1, source, auxiliary, target) print(f\\"Move disk {n} from {source} to {target}\\") tower_of_hanoi(n-1, auxiliary, target, source) ```","solution":"def tower_of_hanoi(n: int, source: str, target: str, auxiliary: str) -> None: Solves the Tower of Hanoi problem and prints the sequence of moves. Args: n (int): Number of disks. source (str): The name of the source peg. target (str): The name of the target peg. auxiliary (str): The name of the auxiliary peg. Returns: None if n == 1: print(f\\"Move disk 1 from {source} to {target}\\") return tower_of_hanoi(n-1, source, auxiliary, target) print(f\\"Move disk {n} from {source} to {target}\\") tower_of_hanoi(n-1, auxiliary, target, source)"},{"question":"# Implement a K-Nearest Neighbors Classifier Your task is to implement a K-Nearest Neighbors (KNN) algorithm from scratch. You will need to provide an implementation for the classification process using KNN. # Function Descriptions 1. **euclidean_distance(point1: np.ndarray, point2: np.ndarray) -> float** * This function computes the Euclidean distance between two points. 2. **get_neighbors(x_train: np.ndarray, test_point: np.ndarray, k: int) -> np.ndarray** * This function finds the `k` nearest neighbors of a given `test_point` from the training set `x_train`. 3. **knn_classify(x_train: np.ndarray, y_train: np.ndarray, test_set: np.ndarray, k: int) -> np.ndarray** * This function uses the k-nearest neighbors algorithm to classify each point in the `test_set`. # Requirements * Implement the `euclidean_distance`, `get_neighbors`, and `knn_classify` functions as described. * The input `x_train` is a 2D numpy array where each row is a training sample. * The input `y_train` is a 1D numpy array containing the target class labels for each row in `x_train`. * The input `test_set` is a 2D numpy array where each row is a new sample to classify. * The input `k` is an integer representing the number of nearest neighbors to use for classification. # Constraints * Assume that `x_train` and `y_train` are non-empty with consistent dimensions. * Ensure that `k` is a positive integer and not greater than the number of training samples. * Manage the time complexity effectively, so the solution is efficient for a feasible number of training samples (up to 1000 samples). # Example ```python import numpy as np def euclidean_distance(point1: np.ndarray, point2: np.ndarray) -> float: return np.sqrt(np.sum((point1 - point2)**2)) def get_neighbors(x_train: np.ndarray, test_point: np.ndarray, k: int) -> np.ndarray: distances = np.array([euclidean_distance(test_point, x) for x in x_train]) neighbors_idx = np.argsort(distances)[:k] return neighbors_idx def knn_classify(x_train: np.ndarray, y_train: np.ndarray, test_set: np.ndarray, k: int) -> np.ndarray: predictions = [] for test_point in test_set: neighbors_idx = get_neighbors(x_train, test_point, k) neighbor_labels = y_train[neighbors_idx] prediction = np.bincount(neighbor_labels).argmax() predictions.append(prediction) return np.array(predictions) # Test data x_train = np.array([[1.2, 3.1], [2.4, 1.6], [3.6, 3.2], [4.8, 1.2]]) y_train = np.array([0, 1, 0, 1]) test_set = np.array([[1.5, 3.0], [4.0, 2.0]]) k = 3 # Expected Output: [0, 1] print(knn_classify(x_train, y_train, test_set, k)) ``` Your solution should pass the above test case and additional edge cases derived from the context of the problem. Ensure proper handling of ties in the nearest neighbor voting process.","solution":"import numpy as np def euclidean_distance(point1: np.ndarray, point2: np.ndarray) -> float: Computes the Euclidean distance between two points. Args: point1 (np.ndarray): First point. point2 (np.ndarray): Second point. Returns: float: Euclidean distance. return np.sqrt(np.sum((point1 - point2)**2)) def get_neighbors(x_train: np.ndarray, test_point: np.ndarray, k: int) -> np.ndarray: Finds the k nearest neighbors of a test point from the training set. Args: x_train (np.ndarray): Training data. test_point (np.ndarray): Point to find neighbors for. k (int): Number of neighbors to find. Returns: np.ndarray: Indices of the k nearest neighbors. distances = np.array([euclidean_distance(test_point, x) for x in x_train]) neighbors_idx = np.argsort(distances)[:k] return neighbors_idx def knn_classify(x_train: np.ndarray, y_train: np.ndarray, test_set: np.ndarray, k: int) -> np.ndarray: Classifies each point in the test set using the k-nearest neighbors algorithm. Args: x_train (np.ndarray): Training data. y_train (np.ndarray): Training labels. test_set (np.ndarray): Test data. k (int): Number of neighbors to consider. Returns: np.ndarray: Predicted labels for the test data. predictions = [] for test_point in test_set: neighbors_idx = get_neighbors(x_train, test_point, k) neighbor_labels = y_train[neighbors_idx] prediction = np.bincount(neighbor_labels).argmax() predictions.append(prediction) return np.array(predictions)"},{"question":"# Scenario You have been assigned to manage a distributed system where tasks are constantly distributed across multiple nodes. To optimize the system\'s performance and ensure efficient load balancing, you decide to use a consistent hashing mechanism. # Task Implement a consistent hashing system that supports adding, removing, and locating nodes dynamically. Given a set of operations, your task is to simulate the consistent hashing process and respond to the queries accordingly. # Specifications 1. **Input:** * **Commands:** A list of tuples where each tuple represents a command type and its parameters. 2. **Output:** * A list of results corresponding to each `locate` command in the order they are given. 3. **Command Types:** * **Add Node:** `(\\"add\\", node_id)` - adds a node with a unique identifier `node_id` to the hashing ring. * **Remove Node:** `(\\"remove\\", node_id)` - removes the node with the identifier `node_id` from the hashing ring. * **Locate:** `(\\"locate\\", key)` - returns the identifier of the node to which the given `key` is mapped in the current configuration. # Constraints * The number of commands is at most 100,000. * 1 ≤ len(node_id) ≤ 100 (node_id is a string). * 1 ≤ key ≤ 1,000,000,000 (key is an integer). # Requirements 1. Implement a consistent hashing mechanism that allows for the dynamic addition, removal, and location of nodes. 2. Ensure that the distribution of keys to nodes is balanced and that the system handles the high concurrency of operations efficiently. 3. Your implementation should prioritize minimal re-distribution of keys when nodes are added or removed. # Example ```python commands = [ (\\"add\\", \\"node1\\"), (\\"add\\", \\"node2\\"), (\\"locate\\", 10), (\\"add\\", \\"node3\\"), (\\"locate\\", 50), (\\"remove\\", \\"node2\\"), (\\"locate\\", 10) ] results = consistent_hashing(commands) print(results) # Output should correspond to the locations of keys as per the commands ``` # Note Ensure that your solution handles the dynamic nature of node management and provides correct and efficient key-to-node mappings.","solution":"import bisect import hashlib class ConsistentHashing: def __init__(self): self.ring = {} self.sorted_keys = [] def _hash(self, key): return int(hashlib.sha256(key.encode()).hexdigest(), 16) % (2**32) def add_node(self, node_id): hashed_node = self._hash(node_id) if hashed_node not in self.ring: bisect.insort(self.sorted_keys, hashed_node) self.ring[hashed_node] = node_id def remove_node(self, node_id): hashed_node = self._hash(node_id) if hashed_node in self.ring: self.sorted_keys.remove(hashed_node) del self.ring[hashed_node] def locate(self, key): if not self.ring: return None hashed_key = self._hash(str(key)) idx = bisect.bisect_left(self.sorted_keys, hashed_key) if idx == len(self.sorted_keys): idx = 0 return self.ring[self.sorted_keys[idx]] def consistent_hashing(commands): ch = ConsistentHashing() results = [] for command in commands: if command[0] == \\"add\\": ch.add_node(command[1]) elif command[0] == \\"remove\\": ch.remove_node(command[1]) elif command[0] == \\"locate\\": results.append(ch.locate(command[1])) return results"},{"question":"# Simulate a Traffic Light System Overview You have been assigned the task of simulating a traffic light system at a four-way intersection. The traffic light can be in one of three states: Red, Yellow, and Green. The transition between these states follows a specific pattern to ensure safety and smooth flow of vehicles. Problem Statement Write a class `TrafficLight` that simulates the behavior of a traffic light. The class should have methods to transition between states and to report the current state. You should also implement an additional function `simulate_traffic_light` that initializes a traffic light and transitions it through its states in a specified number of steps. Input - `steps`: An integer indicating the number of state changes to simulate. Output - A list of strings, each representing the state of the traffic light after each transition. Traffic Light State Logic 1. **Red:** The light should stay red for 3 steps. 2. **Green:** The light should stay green for 4 steps. 3. **Yellow:** The light should stay yellow for 1 step. The sequence should continuously cycle through Red -> Green -> Yellow. Constraints - `steps` will be greater than 0 and less than or equal to 100. Example ```python class TrafficLight: def __init__(self): self.states = [\\"Red\\", \\"Green\\", \\"Yellow\\"] self.durations = [3, 4, 1] self.current_state_index = 0 self.current_step = 0 def transition(self): Advances the traffic light to the next state if necessary, otherwise stays in the current state. self.current_step += 1 if self.current_step >= self.durations[self.current_state_index]: self.current_state_index = (self.current_state_index + 1) % len(self.states) self.current_step = 0 def current_state(self) -> str: Returns the current state of the traffic light. return self.states[self.current_state_index] def simulate_traffic_light(steps: int) -> list[str]: traffic_light = TrafficLight() results = [] for _ in range(steps): traffic_light.transition() results.append(traffic_light.current_state()) return results # Example Test Case assert simulate_traffic_light(10) == [\'Red\', \'Red\', \'Red\', \'Green\', \'Green\', \'Green\', \'Green\', \'Yellow\', \'Red\', \'Red\'] ``` Implement the `TrafficLight` class and `simulate_traffic_light` function to ensure that the given test case passes and accurately simulates the traffic light transitions.","solution":"class TrafficLight: def __init__(self): self.states = [\\"Red\\", \\"Green\\", \\"Yellow\\"] self.durations = [3, 4, 1] self.current_state_index = 0 self.current_step = 0 def transition(self): Advances the traffic light to the next state if necessary, otherwise stays in the current state. self.current_step += 1 if self.current_step >= self.durations[self.current_state_index]: self.current_state_index = (self.current_state_index + 1) % len(self.states) self.current_step = 0 def current_state(self) -> str: Returns the current state of the traffic light. return self.states[self.current_state_index] def simulate_traffic_light(steps: int) -> list[str]: traffic_light = TrafficLight() results = [] for _ in range(steps): results.append(traffic_light.current_state()) traffic_light.transition() return results"},{"question":"# Problem Statement You are given an array of integers that represents the heights of buildings. Your task is to determine the maximum amount of water that can be trapped between the buildings when it rains. The problem is to find the total amount of water trapped between the buildings during a rainstorm. The amount of water trapped on the top of each building is determined by finding the maximum height to the left and right of each building and taking the difference between the minimum of those two heights and the height of the building. The sum of all such differences is the total amount of water trapped. # Function Signature ```python def trap_rainwater(heights: List[int]) -> int: pass ``` # Inputs * `heights` (List[int]): A list of non-negative integers representing the heights of buildings. # Outputs * Returns (int): The total amount of water trapped between the buildings. # Constraints - The length of `heights` is at most (10^5). - Each element in `heights` is a non-negative integer and at most (10^4). # Examples 1. `trap_rainwater([0,1,0,2,1,0,1,3,2,1,2,1])` -> `6` Explanation: Here, 6 units of water are trapped. 2. `trap_rainwater([4,2,0,3,2,5])` -> `9` Explanation: Here, 9 units of water are trapped. # Scenario You are tasked with solving a problem related to rainwater trapped between buildings. Given an array of integers where each integer represents the height of a building, you need to compute the maximum amount of rainwater that can be trapped between buildings once a heavy rain has passed, using an efficient algorithm that avoids excessive time complexity. This problem relates to dynamically calculating maximum heights and directly applying the water trapping logic to determine the solution. Utilize an optimal approach to handle the constraints efficiently.","solution":"from typing import List def trap_rainwater(heights: List[int]) -> int: if not heights: return 0 n = len(heights) left_max = [0] * n right_max = [0] * n water_trapped = 0 # Fill left_max array left_max[0] = heights[0] for i in range(1, n): left_max[i] = max(left_max[i - 1], heights[i]) # Fill right_max array right_max[n - 1] = heights[n - 1] for i in range(n - 2, -1, -1): right_max[i] = max(right_max[i + 1], heights[i]) # Calculate the water trapped for i in range(1, n - 1): water_trapped += min(left_max[i], right_max[i]) - heights[i] return water_trapped"},{"question":"Coding Assessment Question # Objective Create a function to aid in text analysis by efficiently generating word frequency distributions and handling edge cases such as punctuation and case sensitivity. # Scenario You work for a company that specializes in text analytics. The team needs a robust solution for generating word frequency distributions from large documents. The function should handle various edge cases and ensure the results are consistent and accurate. # Task Implement the function `generate_word_frequency_distribution` with the following requirements: 1. **Input**: * A string representing a block of text. 2. **Output**: * A dictionary where keys are words (in lowercase and without punctuation) and values are the frequency of each word. 3. **Constraints**: * Ignore case (e.g., \'Word\' and \'word\' should be counted as the same word). * Remove all punctuation from the words. 4. **Performance Requirements**: * Optimize for performance to handle very large texts efficiently. * Include error handling for edge cases such as empty strings or non-string inputs. # Constraints: * The input text can be up to 1,000,000 characters long. * Should use Python\'s standard library for text processing. * Ensure the solution handles large text inputs efficiently and provides accurate word counts. # Function Signature ```python def generate_word_frequency_distribution(text: str) -> dict: ``` # Example ```python text = \\"Hello, world! Hello. HELLO?\\" word_freq = generate_word_frequency_distribution(text) print(word_freq) # Output: {\'hello\': 3, \'world\': 1} ``` # Additional Task * Write a test script that validates your function with various edge cases, including empty strings, strings with only punctuation, and large text inputs. Ensure the function behaves correctly and efficiently across these scenarios.","solution":"import re from collections import defaultdict def generate_word_frequency_distribution(text: str) -> dict: Generates a word frequency distribution from the given text. Converts all words to lowercase and removes punctuation. Args: text (str): The input text. Returns: dict: Dictionary with words as keys and their frequencies as values. # Error handling for non-string input if not isinstance(text, str): raise ValueError(\\"Input must be a string\\") # Using regex to remove punctuation and split text into words words = re.findall(r\'bw+b\', text.lower()) # Use defaultdict to count the frequency of words word_freq = defaultdict(int) for word in words: word_freq[word] += 1 return dict(word_freq)"},{"question":"# Sum of Unique Elements Given a list of integers, write a function `sum_of_unique_elements(nums: List[int]) -> int` that returns the sum of all elements that appear exactly once in the list. Input - A list of integers `nums` where `1 <= len(nums) <= 10^5` and `-10^5 <= nums[i] <= 10^5`. Output - An integer representing the sum of elements which appear only once in the list. Constraints - The list may contain both positive and negative integers. - Your solution should be efficient to handle the upper limit of the constraints. Example ```python assert sum_of_unique_elements([1, 2, 3, 2]) == 4 assert sum_of_unique_elements([4, 4, 2, 3, 3, 1]) == 3 assert sum_of_unique_elements([1]) == 1 assert sum_of_unique_elements([]) == 0 ``` # Context You are developing a feature for a data analytics tool that requires summarizing data by aggregating unique entries. This function ensures that duplicated entries do not skew the aggregate statistics. # Notes Consider edge cases such as: - Lists with all elements the same. - Lists with no repeating elements. - An empty list. - Lists containing negative numbers. Implement an efficient solution to handle large input sizes within the given constraints.","solution":"def sum_of_unique_elements(nums): Returns the sum of all elements that appear exactly once in the list. from collections import Counter # Count the frequency of each element in the list element_count = Counter(nums) # Sum elements that appear exactly once return sum(element for element, count in element_count.items() if count == 1)"},{"question":"# Encoding and Decoding of Run-Length Encoding (RLE) Strings You are tasked with implementing the Run-Length Encoding (RLE) algorithm for both encoding and decoding functionality. Run-Length Encoding is a simple form of data compression in which runs of data (that is, sequences in which the same data value occurs in many consecutive data elements) are represented as a single data value and a count. Function 1: `my_rle_encode(data: str) -> str` This function should accept a string and return its RLE encoded string. Function 2: `my_rle_decode(data: str) -> str` This function should accept an RLE encoded string and return the original string before encoding. # Input & Output Format 1. **Input for `my_rle_encode`**: A string to be encoded. 2. **Output for `my_rle_encode`**: An RLE encoded string. 3. **Input for `my_rle_decode`**: An RLE encoded string. 4. **Output for `my_rle_decode`**: The original string before encoding. # Constraints * The input string for `my_rle_encode` will have a maximum length of 1000 characters. * The input RLE encoded string for `my_rle_decode` will have a maximum length of 1000 characters. * The encoded string must accurately compress sequences of characters while retaining the same characters for non-repeated sequences. * Edge cases such as empty inputs should be handled correctly. # Requirements * You should maintain the sequence integrity during encoding and decoding. * Ensure that your implementation avoids unnecessary performance bottlenecks. * Handle both lowercase and uppercase letters, digits, and basic punctuation. * Properly manage single character sequences in encoded outputs to avoid incorrect decoding. # Example ```python assert my_rle_encode(\\"\\") == \'\' assert my_rle_encode(\\"aaaabbbcc\\") == \'a4b3c2\' assert my_rle_encode(\\"a\\") == \'a1\' assert my_rle_encode(\\"abbbccccdef\\") == \'a1b3c4d1e1f1\' assert my_rle_decode(\\"\\") == \'\' assert my_rle_decode(\\"a4b3c2\\") == \'aaaabbbcc\' assert my_rle_decode(\\"a1\\") == \'a\' assert my_rle_decode(\\"a1b3c4d1e1f1\\") == \'abbbccccdef\' ``` These example tests indicate what the expected output for given inputs should be. Ensure your implementation passes these checks and handles other potential scenarios well, including single and mixed character sequences.","solution":"def my_rle_encode(data: str) -> str: if not data: return \'\' encoded = [] current_char = data[0] count = 1 for char in data[1:]: if char == current_char: count += 1 else: encoded.append(f\\"{current_char}{count}\\") current_char = char count = 1 encoded.append(f\\"{current_char}{count}\\") return \'\'.join(encoded) def my_rle_decode(data: str) -> str: if not data: return \'\' decoded = [] i = 0 while i < len(data): char = data[i] j = i + 1 count = 0 while j < len(data) and data[j].isdigit(): count = count * 10 + int(data[j]) j += 1 decoded.append(char * count) i = j return \'\'.join(decoded)"},{"question":"# Question You are tasked with implementing a dynamic interval tree to efficiently manage and query intervals. The goal is to provide a structure that supports fast insertion, deletion, and querying of intervals. Objectives - Implement an `IntervalTree` class that supports inserting and removing intervals. - Implement a method to query all intervals that overlap with a given interval. Input - A list of intervals: `List[Tuple[int, int]]` representing the intervals to be managed by the interval tree. - Queries for intervals that overlap with a given interval: `Tuple[int, int]`. Output - For each query, output a list of intervals from the tree that overlap with the given interval. Constraints - The intervals list can contain up to 10^5 intervals. - Each interval is represented by a start and end point where 0 <= start < end <= 10^9. - The number of queries can be up to 10^5. Example ```python # Sample usage intervals = [(1, 5), (10, 15), (20, 25), (30, 35)] queries = [(0, 6), (10, 14), (20, 30)] tree = IntervalTree() for interval in intervals: tree.insert(interval) results = [tree.query(q) for q in queries] print(results) # Expected: [[(1, 5)], [(10, 15)], [(20, 25), (30, 35)]] tree.remove((10, 15)) results = [tree.query(q) for q in queries] print(results) # Expected: [[(1, 5)], [], [(20, 25), (30, 35)]] ``` Requirements 1. Complete the implementation of the `IntervalTree` class. 2. The `insert` method should add an interval to the tree. 3. The `remove` method should remove an interval from the tree. 4. The `query` method should return a list of all intervals in the tree that overlap with the specified interval. 5. Ensure the implementation is efficient in terms of both time and space complexity.","solution":"import bisect class IntervalTree: def __init__(self): # Store start and end points separately for efficient querying self.start_points = [] self.end_points = [] self.intervals = [] def insert(self, interval): # Use binary search for efficient insertion bisect.insort_left(self.start_points, interval[0]) bisect.insort_left(self.end_points, interval[1]) self.intervals.append(interval) def remove(self, interval): # Remove by interval identity if interval in self.intervals: self.intervals.remove(interval) # Remove from sorted lists self.start_points.remove(interval[0]) self.end_points.remove(interval[1]) def query(self, query_interval): start, end = query_interval result = [] for interval in self.intervals: if not (interval[1] < start or interval[0] > end): result.append(interval) return result"},{"question":"# Problem Statement You are given a string that may contain various characters, including letters, digits, and special characters. Your task is to implement a function that reformats this string in a specific manner: 1. Remove all special characters (anything that is not a letter or digit). 2. Convert all characters to lowercase. 3. Split the string into a list of strings, each containing exactly 3 characters. If the last group has fewer than 3 characters, it should be filled with the character \'z\' to make it exactly 3 characters long. # Function Signature ```python def reformat_string(s: str) -> List[str]: ... ``` # Input - `s`: A string containing letters, digits, and special characters. # Output A list of strings, each of 3 characters in length, with any necessary filling done using the character \'z\'. # Constraints - The input string can be of any length (0 <= len(s) <= 10**6). - Ensure that special characters are removed and lowercase conversion is efficiently handled. - Handle edge cases such as empty strings. # Example ```python >>> reformat_string(\\"aBc!@123DEF...ghij?\\") [\'abc\', \'123\', \'def\', \'ghi\', \'jzz\'] >>> reformat_string(\\"XYZ\\") [\'xyz\'] >>> reformat_string(\\"\\") [] >>> reformat_string(\\"123456789\\") [\'123\', \'456\', \'789\'] >>> reformat_string(\\"A!@B\\") [\'abz\'] ``` # Note - For the string \\"aBc!@123DEF...ghij?\\", the special characters and case conversions result in the intermediate string \\"abc123defghij\\". Splitting into groups of 3, we get [\\"abc\\", \\"123\\", \\"def\\", \\"ghi\\"]. Since \\"j\\" needs to be 3 characters, it becomes \\"jzz\\". - Handle large inputs efficiently and ensure no unnecessary errors or performance issues due to string manipulations.","solution":"from typing import List import re def reformat_string(s: str) -> List[str]: Reformats the input string by removing special characters, converting to lowercase, and splitting into chunks of 3, filling up the last chunk with \'z\' if necessary. # Remove special characters and convert to lowercase cleaned_s = re.sub(r\'[^a-zA-Z0-9]\', \'\', s).lower() # Split the cleaned string into chunks of 3 characters n = len(cleaned_s) chunks = [cleaned_s[i:i+3] for i in range(0, n, 3)] # If the last chunk is shorter than 3 characters, fill up with \'z\' if chunks and len(chunks[-1]) < 3: chunks[-1] = chunks[-1].ljust(3, \'z\') return chunks"},{"question":"# Fibonacci Sequence Checker Objective Implement a function `is_fibonacci` that determines if a given number is a part of the Fibonacci sequence. Function Signature ```python def is_fibonacci(num: int) -> bool: ``` Input Parameters * `num` (int): The number to be checked if it belongs to the Fibonacci sequence. Output * Return `True` if the input number is a Fibonacci number, otherwise return `False`. Constraints * `num` should be a non-negative integer. Example ```python >>> is_fibonacci(8) True >>> is_fibonacci(4) False >>> is_fibonacci(21) True >>> is_fibonacci(0) True ``` Explanation * The first example returns `True` because 8 is part of the Fibonacci sequence. * The second example returns `False` because 4 is not part of the Fibonacci sequence. * The third example returns `True` because 21 is part of the Fibonacci sequence. * The fourth example returns `True` because 0 is part of the Fibonacci sequence (the sequence starts with 0, 1, 1, 2, 3, ...). Notes * Fibonacci sequence starts with 0 and 1, each subsequent number is the sum of the previous two numbers. * The function should efficiently handle numbers that are not overly large to avoid performance issues. * Consider edge cases where the number is very small (e.g., 0 or 1).","solution":"def is_fibonacci(num: int) -> bool: Determines if a given number is part of the Fibonacci sequence. :param num: The number to be checked. :return: True if num is a Fibonacci number, else False. if num < 0: return False # Two checks based on Fibonacci property def is_perfect_square(x): s = int(x**0.5) return s * s == x return is_perfect_square(5*num*num + 4) or is_perfect_square(5*num*num - 4)"},{"question":"# Next Greater Element Given a list of integers `nums`, you need to find the next greater element for each element in the array. The next greater element for an element `x` is the first greater element on its right side in the list. If no such element exists, output `-1` for that position. Write a function `next_greater_element(nums: List[int]) -> List[int]` to solve the problem. # Requirements: 1. Implement the function to return a list of integers representing the next greater element for each position in the input list. 2. The input list will only contain integers. # Constraints: - Length of `nums` is less than or equal to `10^4`. - Elements in `nums` are within the range `[-10^5, 10^5]`. # Example: ```python # Example 1 nums = [4, 5, 2, 25] next_greater_element(nums) => [5, 25, 25, -1] # Example 2 nums = [13, 7, 6, 12] next_greater_element(nums) => [-1, 12, 12, -1] # Example 3 nums = [8, 6, 11, 4] next_greater_element(nums) => [11, 11, -1, -1] # Example 4 nums = [] next_greater_element(nums) => [] ``` # Edge Cases: - The list `nums` can be empty, and in that case, the output should be an empty list. - The list may contain negative, zero, or large positive numbers. # Performance Consideration: - Aim for an O(n) complexity solution leveraging a stack for efficient lookups to determine the next greater elements. # Function Signature: ```python def next_greater_element(nums: List[int]) -> List[int]: pass ``` # Implementation Note: - Ensure to handle large input sizes within time constraints by utilizing an efficient algorithm. Prepare for common pitfalls such as handling duplicates and ensuring the correct index mapping from original list positions.","solution":"from typing import List def next_greater_element(nums: List[int]) -> List[int]: Finds the next greater element for each element in the array. If no such element exists, outputs -1 for that position. result = [-1] * len(nums) stack = [] for i, num in enumerate(nums): while stack and nums[stack[-1]] < num: index = stack.pop() result[index] = num stack.append(i) return result"},{"question":"# Problem Statement You are tasked with finding the number of unique binary search trees (BSTs) that can be built with `n` distinct nodes labeled from `1` to `n`. A Binary Search Tree (BST) is a tree in which for each node: - The value of all the nodes in the left subtree is less than the value of the node. - The value of all the nodes in the right subtree is greater than or equal to the value of the node. Let this number be represented as `G(n)`. For example: - `G(1) = 1` because there is only one tree with a single node. - `G(2) = 2` because there are two trees with two nodes: ``` 1 2 / 2 1 ``` Given an integer `n`, implement the function `num_trees(n: int) -> int` that returns the number of unique BSTs that can be built with `n` nodes. # Function Signature ```python def num_trees(n: int) -> int: pass ``` # Input - `n` (1 ≤ n ≤ 19): An integer representing the number of nodes. # Output - An integer representing the number of unique BSTs that can be constructed with `n` nodes. # Constraints - Your solution should run efficiently for all values up to the maximum constraint of `n`. # Example ```python assert num_trees(1) == 1 assert num_trees(2) == 2 assert num_trees(3) == 5 assert num_trees(4) == 14 assert num_trees(5) == 42 ``` **Note**: Consider using dynamic programming or other efficient techniques to solve this problem effectively, especially for the upper range of `n`.","solution":"def num_trees(n: int) -> int: Function to calculate the number of unique BSTs that can be built with `n` distinct nodes. # Base case for 0 and 1 nodes if n == 0 or n == 1: return 1 # DP array to store the number of unique BSTs for each count of nodes dp = [0] * (n + 1) dp[0] = 1 # empty tree dp[1] = 1 # single node tree # Fill the dp array for nodes in range(2, n + 1): for root in range(1, nodes + 1): dp[nodes] += dp[root - 1] * dp[nodes - root] return dp[n]"},{"question":"# Context: A social media platform is implementing a reputation system where each user can upvote or downvote posts. To properly incentivize quality content, the platform wants to calculate a \\"weighted score\\" for each post based on the total number of upvotes and downvotes. # Problem Statement: Implement a function `weighted_score` that calculates the weighted score of a post given the number of upvotes and downvotes. The score should be calculated using the formula: [ text{score} = frac{text{upvotes} - text{downvotes}}{text{upvotes} + text{downvotes} + 1} ] The result should be rounded to two decimal places. # Function Signature: ```python def weighted_score(upvotes: int, downvotes: int) -> float: pass ``` # Input: * `upvotes` (int): The number of upvotes a post has received (0 <= upvotes <= 10^6). * `downvotes` (int): The number of downvotes a post has received (0 <= downvotes <= 10^6). # Output: * Returns a float representing the weighted score of the post, rounded to two decimal places. # Constraints: * Both numbers will be non-negative. * Ensure the calculation is done in such a way that it handles large numbers efficiently. # Examples: ```python assert weighted_score(100, 50) == 0.33 assert weighted_score(50, 100) == -0.33 assert weighted_score(0, 0) == 0.0 assert weighted_score(10, 0) == 0.91 assert weighted_score(0, 10) == -0.91 ``` # Additional Notes: * Consider numerical precision and rounding behavior when dealing with floating-point arithmetic. * Properly handle edge cases such as when the sum of upvotes and downvotes is zero to avoid division by zero errors. * You may use Python’s built-in functions for rounding to ensure the accuracy of your results. # Evaluation: Your solution will be evaluated based on: * Correctness * Efficiency * Clarity and readability of the code * Handling of edge cases","solution":"def weighted_score(upvotes: int, downvotes: int) -> float: Calculates the weighted score of a post. Args: upvotes (int): The number of upvotes a post has received. downvotes (int): The number of downvotes a post has received. Returns: float: The weighted score rounded to two decimal places. score = (upvotes - downvotes) / (upvotes + downvotes + 1) return round(score, 2)"},{"question":"# Question: Implement a Circular Buffer with Fixed Capacity Background A circular buffer (also called a ring buffer) is a data structure that uses a single, fixed-size buffer as if it were connected end-to-end. This structure is useful for buffering data streams where the total size of the data is unknown ahead of time, but a maximum size (capacity) is. The buffer has two pointers, one for writing and one for reading, which wrap around to the beginning once they reach the end of the buffer. Task Create a `CircularBuffer` class that supports the following operations: - `enqueue(data)`: Adds an element to the end of the buffer. If the buffer is full, it should overwrite the oldest element. - `dequeue()`: Removes and returns the oldest element from the buffer. If the buffer is empty, return `None`. - `peek()`: Returns the oldest element without removing it. If the buffer is empty, return `None`. - `is_full()`: Returns `True` if the buffer is full, else `False`. - `is_empty()` : Returns `True` if the buffer is empty, else `False`. Function Signature The class should be implemented as: ```python class CircularBuffer: def __init__(self, capacity: int): self.capacity = capacity self.buffer = [None] * capacity self.head = 0 self.tail = 0 self.size = 0 def enqueue(self, data: int) -> None: pass def dequeue(self) -> int: pass def peek(self) -> int: pass def is_full(self) -> bool: pass def is_empty(self) -> bool: pass ``` Expected Input and Output 1. **Input**: * A series of operations to be performed on the circular buffer. 2. **Output**: * The state of the buffer or the result of the operations performed. Constraints * Assume all data to be enqueued are non-negative integers. * The capacity of the buffer will always be a positive integer greater than 0. Example 1. **Input**: ```python cb = CircularBuffer(3) cb.enqueue(1) cb.enqueue(2) cb.enqueue(3) print(cb.dequeue()) # Output: 1 cb.enqueue(4) print(cb.peek()) # Output: 2 print(cb.is_full()) # Output: True print(cb.is_empty()) # Output: False ``` **Output**: ```python 1 2 True False ``` 2. **Input**: ```python cb = CircularBuffer(2) cb.enqueue(5) cb.enqueue(6) cb.enqueue(7) print(cb.dequeue()) # Output: 6 print(cb.dequeue()) # Output: 7 print(cb.dequeue()) # Output: None ``` **Output**: ```python 6 7 None ``` Notes * Ensure the class handles wrap-around correctly when the end of the buffer is reached. * The `enqueue` method should overwrite the oldest data if the buffer is full, maintaining the fixed capacity. * Provide error handling for inappropriate operations, such as dequeuing from an empty buffer or enqueuing invalid data types.","solution":"class CircularBuffer: def __init__(self, capacity: int): self.capacity = capacity self.buffer = [None] * capacity self.head = 0 self.tail = 0 self.size = 0 def enqueue(self, data: int) -> None: if self.is_full(): self.head = (self.head + 1) % self.capacity self.buffer[self.tail] = data self.tail = (self.tail + 1) % self.capacity if not self.is_full(): self.size += 1 def dequeue(self) -> int: if self.is_empty(): return None data = self.buffer[self.head] self.buffer[self.head] = None self.head = (self.head + 1) % self.capacity self.size -= 1 return data def peek(self) -> int: if self.is_empty(): return None return self.buffer[self.head] def is_full(self) -> bool: return self.size == self.capacity def is_empty(self) -> bool: return self.size == 0"},{"question":"# Unique String Combinations Task Scenario You are developing a utility for a text-processing application. One of the features involves generating unique string combinations based on a set of given characters. This feature needs to be robust and efficient to handle user inputs of varying complexity and sizes. Your task is to write a function that generates all possible unique combinations of the input characters. Requirements Implement a function `generate_combinations()` that generates all possible unique combinations of characters from an input string. 1. **Combination Generation**: * Generate combinations of all possible lengths from 1 to the length of the input string. 2. **Handling Duplicates**: * Ensure that the combinations are unique, even if the input string contains duplicate characters. 3. **Ordered Output**: * The output should be a list of combinations sorted in lexicographical order. Function Signature ```python def generate_combinations(characters: str) -> list: pass ``` Input * `characters` (str): A string containing the set of characters to generate combinations from. Output * Returns a list of unique combinations, sorted lexicographically, of all possible lengths. Constraints * The input string can contain duplicate characters. * All characters are in lowercase alphabets. Test Case Example Input: ```python characters = \\"abc\\" ``` Expected Output: ```python [ \'a\', \'ab\', \'abc\', \'ac\', \'b\', \'bc\', \'c\' ] ``` Input: ```python characters = \\"aabb\\" ``` Expected Output: ```python [ \'a\', \'aa\', \'aab\', \'aabb\', \'ab\', \'abb\', \'b\', \'bb\' ] ``` In this task, you will need to ensure that the function can handle the generation of unique combinations efficiently, even for input strings with repetitive characters. Your output should be carefully ordered and free of duplicates, adhering to the described requirements.","solution":"from itertools import combinations def generate_combinations(characters: str) -> list: Generates all possible unique combinations of characters from an input string. Params: characters (str): A string containing the set of characters to generate combinations from. Returns: list: A list of unique combinations sorted lexicographically. unique_combinations = set() for r in range(1, len(characters) + 1): for combo in combinations(sorted(characters), r): unique_combinations.add(\'\'.join(combo)) return sorted(unique_combinations)"},{"question":"# Coding Challenge: Shortest Path in Weighted Graph Scenario: You are tasked with developing a routing system for a delivery company. The system must calculate the shortest route for a delivery truck to travel from a distribution center to various delivery locations. The road network can be represented as a weighted directed graph, where nodes represent locations, directed edges represent roads, and weights on the edges represent travel times. Task: Implement a function `shortest_path` that takes the number of locations (nodes), the road segments (edges) with their travel times, the starting point (source), and the delivery points (targets). The function should return the shortest travel time from the source to each of the targets. Function Signature: ```python def shortest_path(n: int, edges: list[tuple[int, int, int]], source: int, targets: list[int]) -> list[int]: ``` Input: - `n` (int): The number of locations (nodes) in the graph. - `edges` (list of tuples of int): Each tuple (u, v, w) represents a directed edge from location u to location v with travel time w. - `source` (int): The starting location (source node). - `targets` (list of int): The delivery locations (target nodes). Output: - `list of int`: The shortest travel times from the source to each of the targets in the same order as given in the `targets` list. Constraints: - `1 <= n <= 5000` (number of nodes) - `0 <= len(edges) <= 20000` (number of edges) - Each travel time `w` is a positive integer. - Location IDs (nodes) are numbered from 0 to n-1. - The `targets` list will not contain duplicate locations. Example: ```python n = 5 edges = [(0, 1, 2), (1, 2, 4), (0, 2, 8), (0, 3, 15), (3, 4, 10), (2, 4, 3)] source = 0 targets = [2, 4] print(shortest_path(n, edges, source, targets)) # Expected Output: [6, 9] ``` Requirements: - Use Dijkstra\'s algorithm to compute the shortest paths. - Ensure that your function runs efficiently given the constraints. - Write additional helper functions if necessary. Notes: - Consider edge cases such as an empty graph (n = 0, edges = []), locations that are unreachable from the source, and multiple disjoint subgraphs. - The output should be in the same order as the target locations provided.","solution":"import heapq def shortest_path(n: int, edges: list[tuple[int, int, int]], source: int, targets: list[int]) -> list[int]: Calculates the shortest travel time from the source to each of the targets. Uses Dijkstra\'s algorithm to compute the shortest paths. Parameters: n (int): Number of nodes in the graph. edges (list of tuples): List of edges where each tuple (u, v, w) represents an edge from node u to node v with weight w. source (int): The starting node. targets (list of int): List of target nodes to find the shortest paths to. Returns: list[int]: The shortest travel times from the source to each of the targets. # Create adjacency list for the graph graph = [[] for _ in range(n)] for u, v, w in edges: graph[u].append((v, w)) # Dijkstra\'s algorithm to find the shortest path from source to all other nodes pq = [(0, source)] distances = {i: float(\'inf\') for i in range(n)} distances[source] = 0 while pq: current_distance, current_node = heapq.heappop(pq) if current_distance > distances[current_node]: continue for neighbor, weight in graph[current_node]: distance = current_distance + weight if distance < distances[neighbor]: distances[neighbor] = distance heapq.heappush(pq, (distance, neighbor)) return [distances[target] if distances[target] != float(\'inf\') else -1 for target in targets]"},{"question":"Problem Statement: You are given a list `courses` where each element is a tuple representing a course and its respective prerequisite. Your task is to write a function `can_finish_courses(numCourses: int, courses: List[Tuple[int, int]]) -> bool` that determines if it is possible to finish all courses given their prerequisites. # Requirements: 1. Implement a topological sort using Kahn\'s Algorithm (BFS) to detect if there\'s a cycle in the course schedule. 2. Your function should return `True` if it is possible to finish all courses, otherwise return `False`. # Constraints: - The number of courses `numCourses` is at most `1000`. - The list `courses` contains tuples where each tuple (a, b) indicates that course `a` requires course `b` to be taken first. - The number of prerequisites is at most `5000`. # Input: - `numCourses`: An integer representing the total number of courses. - `courses`: A list of tuples representing the courses and their prerequisites. # Output: - A boolean value (`True` or `False`). # Example: **Input**: ```python numCourses = 4 courses = [(1, 0), (2, 1), (3, 2)] ``` **Output**: ```python True ``` **Input**: ```python numCourses = 2 courses = [(1, 0), (0, 1)] ``` **Output**: ```python False ``` **Input**: ```python numCourses = 3 courses = [] ``` **Output**: ```python True ``` # Notes: Consider edge cases where there are no prerequisites or a self-dependent course that directly leads to a cycle. Use an efficient approach to handle large input sizes within the constraints given.","solution":"from typing import List, Tuple from collections import deque, defaultdict def can_finish_courses(numCourses: int, courses: List[Tuple[int, int]]) -> bool: if numCourses <= 0: return False # Initialize graph and indegree list graph = defaultdict(list) indegree = [0] * numCourses # Build the graph and fill the indegree array for dest, src in courses: graph[src].append(dest) indegree[dest] += 1 # Initialize queue and enqueue all courses with indegree 0 queue = deque([i for i in range(numCourses) if indegree[i] == 0]) visited = 0 # Process nodes in topological sorted order while queue: current = queue.popleft() visited += 1 for neighbor in graph[current]: indegree[neighbor] -= 1 if indegree[neighbor] == 0: queue.append(neighbor) # If we have visited all nodes, it means no cycle return visited == numCourses"},{"question":"# List Rotation Checker In this task, you are required to implement the method `is_rotated_version` on a provided list class `RotatableList`. A list `B` is a rotation of another list `A` if both lists contain the same elements and `B` can be obtained by rotating `A` any number of times. For example, `[1, 2, 3, 4]` and `[3, 4, 1, 2]` are rotations of each other. ```python class RotatableList: elements: List[int] def is_rotated_version(self, other: List[int]) -> bool: This method should return True if the provided list \'other\' is a rotation of the list in \'self.elements\', otherwise False. Args: other (List[int]): Another list to compare against. Returns: bool: True if \'other\' is a rotation of \'self.elements\', False otherwise. # Your code here pass ``` Input Format: - You will be given the elements of the list through the class property `elements`. - You will be given the other list as an argument to the method `is_rotated_version`. Output Format: - Return a boolean value, `True` or `False`, indicating whether the other list is a rotated version of the original list. Constraints: 1. Each element in the list is represented as an integer. 2. The length of each list can range from 1 to 1000 elements. Example: Consider these lists: - Original list `elements`: `[1, 2, 3, 4, 5]` - Other list `other`: `[3, 4, 5, 1, 2]` - In this case, calling `is_rotated_version(other)` on the `RotatableList` with the given `elements` returns `True`. To validate your solution, ensure you cover various edge cases such as: - Single element lists. - Lists that are not rotations but have the same elements. - Properly handling empty lists and lists with duplicates.","solution":"class RotatableList: def __init__(self, elements): self.elements = elements def is_rotated_version(self, other): This method should return True if the provided list \'other\' is a rotation of the list in \'self.elements\', otherwise False. Args: other (List[int]): Another list to compare against. Returns: bool: True if \'other\' is a rotation of \'self.elements\', False otherwise. if len(self.elements) != len(other): return False if not self.elements: return True # two empty lists are considered rotations # Create a concatenated version: self.elements + self.elements double_elements = self.elements + self.elements # Check if \'other\' is a substring of the concatenated version return str(other)[1:-1] in str(double_elements)[1:-1] # remove brackets # Example usage: # rotatable_list = RotatableList([1, 2, 3, 4, 5]) # print(rotatable_list.is_rotated_version([3, 4, 5, 1, 2])) # Should return True # print(rotatable_list.is_rotated_version([4, 5, 1, 2, 3])) # Should return True # print(rotatable_list.is_rotated_version([1, 2, 3, 5, 4])) # Should return False"},{"question":"# Context You are developing a feature that processes data from a sequence of monetary transactions. To ensure accurate financial reporting, you need to determine the k-th largest transaction from a list of transactions. # Objective Implement an efficient function to find the k-th largest transaction from a list of amounts. Your solution should handle large lists of transactions and return the correct result even in edge cases. # Function Signature ```python def kth_largest_transaction(transactions: list[float], k: int) -> float: Find the k-th largest monetary transaction from the list :param transactions: List of transaction amounts (list of floats) :param k: Integer representing the k-th position to find the largest transaction :return: The k-th largest transaction amount Example: >>> kth_largest_transaction([100.5, 83.1, 99.9, 120.0, 200.75], 2) 120.0 >>> kth_largest_transaction([55.5, 33.3, 77.7, 5.5, 150.6], 4) 33.3 ``` # Constraints and Requirements 1. The `transactions` list will always contain at least `k` elements. 2. The list might contain zero or negative values, but `k` will always be a positive integer (`k > 0`). 3. A non-positive `k` should raise a `ValueError`. # Performance 1. Ensure the algorithm runs efficiently for large lists of transactions. 2. Aim for a time complexity of (O(n log k)) using a suitable selection algorithm like a heap or quickselect. # Examples - Input: `[100.5, 83.1, 99.9, 120.0, 200.75], 2` Output: `120.0` - Input: `[55.5, 33.3, 77.7, 5.5, 150.6], 4` Output: `33.3` - Input: `[1.1, -2.3, 3.4, -4.5, 0.0], 3` Output: `0.0` # Notes Handle edge cases where the transaction amounts can be negative or zero. Verify your implementation with a variety of test cases, ensuring accuracy and efficiency. Consider discussing potential edge cases and any improvements for performance when `k` is large relative to the list size.","solution":"import heapq def kth_largest_transaction(transactions, k): Find the k-th largest monetary transaction from the list :param transactions: List of transaction amounts (list of floats) :param k: Integer representing the k-th position to find the largest transaction :return: The k-th largest transaction amount if k <= 0: raise ValueError(\\"k must be a positive integer\\") if k > len(transactions): raise ValueError(\\"k exceeds the number of transactions\\") # Use a min-heap of size k to find the k-th largest transaction. min_heap = transactions[:k] heapq.heapify(min_heap) for transaction in transactions[k:]: if transaction > min_heap[0]: heapq.heapreplace(min_heap, transaction) return min_heap[0]"},{"question":"# Coding Question Problem Statement You are given an array of integers, where each element represents the maximum jump length from that position. Your task is to implement a function `canReachEnd(arr: List[int]) -> bool` to determine if you can reach the last index of the array starting from the first index. You should return `True` if it is possible to reach the last index, and `False` otherwise. # Input and Output Formats * **Input Format**: * `arr`: A List of integers `arr` where `1 <= len(arr) <= 10^5` and `0 <= arr[i] <= 10^5`. * **Output Format**: * Return a boolean value, `True` if you can reach the last index, `False` otherwise. # Constraints * `1 ≤ len(arr) ≤ 10^5` * `0 ≤ arr[i] ≤ 10^5` for all valid `i` # Performance Requirements * Your solution should have a time complexity of (O(n)). # Example Input ```python arr = [2, 3, 1, 1, 4] ``` Output ```python True ``` Explanation Starting at index 0, you can jump to index 1 (using the value `2`), then from index 1, you can jump to index 4 (using the value `3`), thus reaching the end of the array. Input ```python arr = [3, 2, 1, 0, 4] ``` Output ```python False ``` Explanation Starting at index 0, you can jump to index 1, 2, or 3, but from index 3, you can only jump to index 3 (since the value is `0`), and you cannot move further, thus it is impossible to reach the end of the array. # Hints * You can maintain a variable to track the farthest index that can be reached while iterating through the array. Here\'s the function signature: ```python from typing import List def canReachEnd(arr: List[int]) -> bool: pass ```","solution":"from typing import List def canReachEnd(arr: List[int]) -> bool: max_reachable = 0 n = len(arr) for i in range(n): if i > max_reachable: return False max_reachable = max(max_reachable, i + arr[i]) return max_reachable >= n - 1"},{"question":"# Problem Statement Write a function that finds the longest word in a given string of text where the word may contain only alphabetic letters. If there are multiple words of the same maximum length, return the first one found. The returned word should be in lowercase. # Input - A single string of text which may contain letters, spaces, punctuation marks, and other non-alphabetic characters. Words are separated by one or more spaces, punctuation, or other non-alphabetic characters. # Output - A single string which is the longest word in the input text in lowercase. # Constraints - The input string length will not exceed (10^6) characters. # Performance Requirements - The function should efficiently handle the input size. # Function Signature ```python def find_longest_word(text: str) -> str: pass ``` # Example Your implementation should produce the following output: ```python print(find_longest_word(\\"Hello there! Isn\'t this a great day?\\")) ``` Expected Output: ```python \\"hello\\" ``` # Explanation - After processing the input string \\"Hello there! Isn\'t this a great day?\\", the longest word found is \\"Hello\\" (ignoring punctuation and converting to lowercase). Thus, the output is \\"hello\\". If there were another word of the same length, the first occurrence in the text would be returned. # Hint Consider using regular expressions to split the text into words containing only alphabetic characters and then finding the longest one.","solution":"import re def find_longest_word(text: str) -> str: Finds the longest word containing only alphabetic characters in the given text. Parameters: text (str): The input text containing letters, spaces, punctuation, etc. Returns: str: The longest word in lowercase. words = re.findall(r\'b[a-zA-Z]+b\', text) longest_word = max(words, key=len).lower() if words else \'\' return longest_word"},{"question":"# Question: Matrix Pathfinding with Obstacles You are given a class `Grid` that represents a 2D grid where each cell has a specific cost associated with entering it. The grid contains obstacles that cannot be entered, marked with a value of `-1`. # Task 1. Extend the `Grid` class to find the minimum-cost path from the top-left corner (0, 0) to the bottom-right corner (n-1, m-1) of the grid while avoiding obstacles. # Requirements 1. **Implement** the following methods in the `Grid` class: - `min_cost_path`: to compute and return the minimum cost path, avoiding obstacles. - `add_obstacle`: to mark a cell as an obstacle by setting its cost to `-1`. - `clear_path`: to remove an obstacle from a cell by setting its cost to a valid integer value. 2. **Ensure** that the method `min_cost_path` recalculates the minimum cost path efficiently after any grid update. # Input: - A grid, represented as a 2D list of integers where each integer denotes the cost of entering a cell (a value of `-1` denotes an obstacle). - Series of updates through adding or removing obstacles. # Output: - Minimum cost to traverse from the top-left corner to the bottom-right corner after each modification. # Constraints: - All costs are non-negative integers, except obstacles which are denoted by `-1`. - The grid is always rectangular with at least one cell. # Example: ```python grid = Grid([ [1, 2, 3], [4, -1, 6], [7, 8, 9] ]) print(grid.min_cost_path()) # Output should give the minimum cost path from (0, 0) to (2, 2). # Adding an obstacle and recalculating grid.add_obstacle(2, 1) print(grid.min_cost_path()) # Output should reflect the updated minimum cost path. # Removing an obstacle and recalculating grid.clear_path(1, 1, 5) print(grid.min_cost_path()) # Output should reflect the updated minimum cost path. ``` # Function Signatures: 1. `def min_cost_path(self) -> int:` 2. `def add_obstacle(self, x: int, y: int) -> None:` 3. `def clear_path(self, x: int, y: int, cost: int) -> None:`","solution":"from heapq import heappop, heappush from typing import List class Grid: def __init__(self, grid: List[List[int]]): self.grid = grid self.rows = len(grid) self.cols = len(grid[0]) def min_cost_path(self) -> int: if not self.grid or self.grid[0][0] == -1 or self.grid[self.rows-1][self.cols-1] == -1: return -1 dirs = [(0, 1), (1, 0)] heap = [(self.grid[0][0], 0, 0)] costs = {(0, 0): self.grid[0][0]} while heap: current_cost, x, y = heappop(heap) if (x, y) == (self.rows - 1, self.cols - 1): return current_cost for dx, dy in dirs: nx, ny = x + dx, y + dy if 0 <= nx < self.rows and 0 <= ny < self.cols and self.grid[nx][ny] != -1: new_cost = current_cost + self.grid[nx][ny] if (nx, ny) not in costs or new_cost < costs[(nx, ny)]: costs[(nx, ny)] = new_cost heappush(heap, (new_cost, nx, ny)) return -1 def add_obstacle(self, x: int, y: int) -> None: if 0 <= x < self.rows and 0 <= y < self.cols: self.grid[x][y] = -1 def clear_path(self, x: int, y: int, cost: int) -> None: if 0 <= x < self.rows and 0 <= y < self.cols: self.grid[x][y] = cost"},{"question":"# Tree Traversal and Validation Implement a function to determine if a given sequence of numbers represents a valid post-order traversal of a Binary Search Tree (BST). Recall that in a post-order traversal, the nodes are recursively visited in the following order: left subtree, right subtree, and then the root node. Input: * A list `nums` of integers representing the post-order traversal of a BST. Output: * Return `True` if the list represents a valid post-order traversal of a BST, otherwise return `False`. Constraints: * The length of `nums` will be between 1 and 1000. * The values in `nums` will be unique and between -10^4 and 10^4. # Function Signature: ```python def validate_postorder(nums: List[int]) -> bool: pass ``` # Example: ```python assert validate_postorder([1, 3, 2, 6, 5, 7, 4]) == True assert validate_postorder([7, 4, 6, 5]) == False assert validate_postorder([5, 9, 12, 10, 8]) == True assert validate_postorder([1, 2, 3, 4, 5, 6]) == True ``` # Additional Information: * Make sure to handle base cases effectively, such as sequences with one or two elements. * Ensure your solution captures edge cases like descending or ascending sequences of numbers.","solution":"def validate_postorder(nums): Returns True if the given nums is a valid post-order traversal of a BST, otherwise False. def helper(arr, low, high): if low >= high: return True root = arr[high] split = low while split < high and arr[split] < root: split += 1 for i in range(split, high): if arr[i] < root: return False return helper(arr, low, split - 1) and helper(arr, split, high - 1) return helper(nums, 0, len(nums) - 1)"},{"question":"Question: Operations on Sparse Matrices # Scenario In numerical computing, sparse matrices are matrices in which most of the elements are zero. Efficient storage and operations on sparse matrices can significantly enhance performance. You need to implement functions that operate on sparse matrices, represented in a custom format. # Implementation Requirements - Implement a function `add_sparse_matrices(matrix1: dict, matrix2: dict) -> dict` that takes as input two sparse matrices and returns their sum as a sparse matrix. - Implement a function `transpose_sparse_matrix(matrix: dict) -> dict` that computes the transpose of a given sparse matrix. # Input - Sparse matrices will be represented as dictionaries where keys are tuples representing the position (row, column) of non-zero elements and values are the non-zero elements. ```python matrix = { (0, 1): 2, (2, 3): 5 } ``` # Output - `add_sparse_matrices` should return a dictionary representing the sum of the input matrices. - `transpose_sparse_matrix` should return a dictionary representing the transpose of the input matrix. # Constraints - The input dictionaries should only contain tuples with non-negative integers and numeric values. - Ensure that input matrices can be of different sizes. - If the sum of corresponding non-zero elements results in zero, that entry should not appear in the output dictionary. # Example ```python matrix1 = { (0, 1): 3, (1, 0): 4, (2, 3): 1 } matrix2 = { (0, 1): 3, (1, 0): -4, (2, 3): 2 } # Adding two sparse matrices print(add_sparse_matrices(matrix1, matrix2)) # Output: {(0, 1): 6, (2, 3): 3} # Transposing a sparse matrix print(transpose_sparse_matrix(matrix1)) # Output: {(1, 0): 3, (0, 1): 4, (3, 2): 1} ``` # Edge Cases - If both input matrices for `add_sparse_matrices` are empty, the function should return an empty dictionary. - If the input matrix for `transpose_sparse_matrix` is empty, the function should return an empty dictionary. - Ensure the functions handle matrices with only one non-zero element correctly. - If a resulting dictionary entry has a value of zero, it should not be included in the final output.","solution":"def add_sparse_matrices(matrix1: dict, matrix2: dict) -> dict: Adds two sparse matrices and returns the resulting sparse matrix. :param matrix1: First sparse matrix :param matrix2: Second sparse matrix :return: Sum of matrix1 and matrix2 as a sparse matrix result = {} # Add elements of matrix1 to result for key, value in matrix1.items(): result[key] = value # Add elements of matrix2 to result, sum up if key already exists for key, value in matrix2.items(): if key in result: result[key] += value else: result[key] = value # Remove entries where the sum is zero result = {key: value for key, value in result.items() if value != 0} return result def transpose_sparse_matrix(matrix: dict) -> dict: Computes the transpose of a sparse matrix. :param matrix: The sparse matrix to transpose :return: The transposed sparse matrix transposed = {} for (row, col), value in matrix.items(): transposed[(col, row)] = value return transposed"},{"question":"**Scenario**: As part of your responsibilities as a backend developer, you are tasked with enhancing a web server\'s logging system. The server logs multiple events per second, and it\'s crucial to efficiently process and analyze this data to identify patterns and unusual activities. One of the requirements is to develop a data structure that supports logging events and querying the number of events within a given time range. **Task**: Using your knowledge of data structures and algorithms, implement a class `EventLogger` with the following functionalities: 1. `log_event(self, timestamp: int) -> None`: This method should log an event that occurs at the given `timestamp`. 2. `count_events(self, start_time: int, end_time: int) -> int`: This method should return the number of events that occurred between `start_time` and `end_time` inclusive. # Requirements: - **`log_event` Method:** - **Input**: `timestamp` (integer) representing the time at which the event occurred. - **Output**: None, but the event should be stored internally. - **`count_events` Method:** - **Input**: `start_time` and `end_time` (both integers) representing the time range. - **Output**: An integer count of events within the specified time range. # Constraints: - Timestamp values range from 0 to 10^6. - The number of events logged will not exceed 10^6. Implement these methods efficiently, carefully considering the time complexity for logging events and querying the count. **Function Signatures**: ```python def log_event(self, timestamp: int) -> None: pass def count_events(self, start_time: int, end_time: int) -> int: pass ``` **Example**: ```python event_logger = EventLogger() event_logger.log_event(10) event_logger.log_event(20) event_logger.log_event(30) assert event_logger.count_events(10, 20) == 2 assert event_logger.count_events(15, 25) == 1 assert event_logger.count_events(0, 40) == 3 event_logger.log_event(20) assert event_logger.count_events(20, 20) == 2 assert event_logger.count_events(25, 35) == 1 ``` # Notes: - Ensure the event logging and counting are efficient and scalable. - Test for edge cases, such as no events logged or querying an empty time range. - The system should maintain accurate counts even as new events are continuously logged.","solution":"from collections import defaultdict import bisect class EventLogger: def __init__(self): self.events = [] def log_event(self, timestamp: int) -> None: bisect.insort(self.events, timestamp) def count_events(self, start_time: int, end_time: int) -> int: start_idx = bisect.bisect_left(self.events, start_time) end_idx = bisect.bisect_right(self.events, end_time) return end_idx - start_idx"},{"question":"As a software engineer working on a string analysis tool, you need to create a function to analyze the frequency of characters in a text and return the most frequent character. This functionality can be useful in applications like cryptography, text compression, and linguistic analysis. # Function Description You are required to implement the function `most_frequent_char(text)`. # Input - `text`: A string of arbitrary length. It can contain alphanumeric characters and special symbols. # Output - The function should return the character that appears the most frequently in the input text as a string. - If multiple characters have the same highest frequency, return the lexicographically smallest one. - If the input string is empty, return an empty string. # Constraints - Ensure the function handles both uppercase and lowercase letters correctly. - The function should differentiate between uppercase and lowercase letters. # Examples ```python most_frequent_char(\\"aabbbcccc\\") # Output: \\"c\\" most_frequent_char(\\"abbcc\\") # Output: \\"b\\" most_frequent_char(\\"AaBbCcAa\\") # Output: \\"A\\" most_frequent_char(\\"abc123123\\") # Output: \\"1\\" most_frequent_char(\\"\\") # Output: \\"\\" most_frequent_char(\\"!?!.!!\\") # Output: \\"!\\" most_frequent_char(\\"aA\\") # Output: \\"A\\" most_frequent_char(\\"123321\\") # Output: \\"1\\" ``` During the implementation, be mindful of edge cases such as empty strings and strings with multiple characters having the same frequency. The function should aim for efficiency and correctness in handling potentially large input texts.","solution":"from collections import Counter def most_frequent_char(text): Returns the most frequent character in the given text. If multiple characters have the same highest frequency, return the lexicographically smallest one. If the input string is empty, return an empty string. if not text: return \\"\\" counter = Counter(text) max_freq = max(counter.values()) most_frequent_chars = [char for char, freq in counter.items() if freq == max_freq] return min(most_frequent_chars)"},{"question":"# Problem Description You are given a list of integers representing heights. Your task is to find the maximum area of water that can be contained between two heights. Each height and the distance between them forms a vertical line, and the area of water contained is determined by the shorter of the two heights and the distance between them. # Input Format - The first line contains an integer `n`, the number of integers. - The second line contains `n` integers representing the heights. # Output Format - Print a single integer, the maximum area of water that can be contained. # Constraints - 2 ≤ n ≤ 1000 - 1 ≤ height[i] ≤ 10^4 # Performance Requirements - Your solution should have a time complexity of O(n). # Example **Input** ``` 9 1 8 6 2 5 4 8 3 7 ``` **Output** ``` 49 ``` Function Signature ```python def max_area(heights: List[int]) -> int: # your code here pass ``` # Implementation notes - Use a two-pointer technique to optimize your solution. - Consider both pointers starting from the ends of the list and moving inward to maximize the area calculation. - Evaluate areas by comparing and moving pointers based on the height values they point to. **Note**: This problem tests the ability to implement an efficient algorithm to solve an optimization problem, ensuring the solution scales well with the input size.","solution":"from typing import List def max_area(heights: List[int]) -> int: Returns the maximum area of water that can be contained between two heights. left, right = 0, len(heights) - 1 max_area = 0 while left < right: height = min(heights[left], heights[right]) width = right - left max_area = max(max_area, height * width) # Move the pointer with the smaller height value if heights[left] < heights[right]: left += 1 else: right -= 1 return max_area"},{"question":"# Coding Assessment Question Prerequisites: Understanding of linked lists, data structures, and traversal algorithms. Problem Statement: Implement a function `remove_nth_from_end(head: Optional[ListNode], n: int) -> Optional[ListNode]` that removes the n-th node from the end of a singly linked list and returns the head of the modified list. Function Signature: ```python class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = next def remove_nth_from_end(head: Optional[ListNode], n: int) -> Optional[ListNode]: pass ``` Input: - `head`: The head node of the linked list. If the list is empty, `head` is `None`. - `n` (1 ≤ n ≤ length of linked list): An integer representing the position of the node to be removed from the end of the list. Output: - The head node of the modified linked list after removing the n-th node from the end. Requirements: 1. **Efficiency**: Your implementation should traverse the list no more than twice. 2. **Edge Cases**: Handle the case where removing the node results in an empty list. Constraints: - The input linked list is non-circular and singly linked. - Assume input validity such that `1 ≤ length of linked list`. Examples: ```python # Example 1: # Input: head = [1,2,3,4,5], n = 2 # Output: [1,2,3,5] # Explanation: The second node from the end is 4, remove it. # Create linked list 1->2->3->4->5 head = ListNode(1, ListNode(2, ListNode(3, ListNode(4, ListNode(5))))) assert list_to_array(remove_nth_from_end(head, 2)) == [1, 2, 3, 5] # Example 2: # Input: head = [1], n = 1 # Output: [] # Explanation: The first node from the end is 1, remove it. # Create linked list 1 head = ListNode(1) assert list_to_array(remove_nth_from_end(head, 1)) == [] # Example 3: # Input: head = [1,2], n = 1 # Output: [1] # Explanation: The first node from the end is 2, remove it. # Create linked list 1->2 head = ListNode(1, ListNode(2)) assert list_to_array(remove_nth_from_end(head, 1)) == [1] ``` Note: - To assist in implementation and testing, you may need to write a helper function `list_to_array` to convert a linked list to a Python list for easy comparison in assertions. - Optimize for both readability and performance. - Ensure your solution handles the edge cases gracefully, such as removing the last remaining node in the list. ```python def list_to_array(head: Optional[ListNode]) -> list: array = [] while head: array.append(head.val) head = head.next return array ```","solution":"class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = next def remove_nth_from_end(head: ListNode, n: int) -> ListNode: # First, create a dummy node which will point to the head dummy = ListNode(0) dummy.next = head first = dummy second = dummy # Move first ahead by n+1 places for _ in range(n + 1): first = first.next # Move first to the end, maintaining the gap while first is not None: first = first.next second = second.next # Now second points to the (n+1)-th last node, remove the nth from last node second.next = second.next.next # Return the new head return dummy.next"},{"question":"# Question: Stock Market Analysis Background Suppose you are asked to create a Python program that analyzes historical stock prices for different companies. Your application will read stock data from a CSV file, calculate various performance metrics, and present the results. # Requirements: 1. **Function: `read_stock_data(file_path: str) -> dict[str, list[tuple[date, float]]]`** - **Input**: - `file_path` (str): Path to the CSV file containing stock data. - **Output**: A dictionary where keys are company names (str) and values are lists of tuples. Each tuple contains: - `date` (date): The date of the record. - `float` (close price): The closing price of the stock on that date. - **Task**: Read the CSV file and structure the data accordingly. 2. **Function: `calculate_metrics(stock_prices: list[tuple[date, float]]) -> dict[str, float]`** - **Input**: - `stock_prices` (list): List of tuples with stock prices for a company. - **Output**: A dictionary containing the following keys with their respective calculated values: - \\"Avg Close Price\\": Average closing price over the provided period. - \\"Max Close Price\\": Highest closing price recorded. - \\"Min Close Price\\": Lowest closing price recorded. - \\"Volatility\\": Difference between the highest and lowest closing prices. - **Task**: Calculate the required performance metrics for the stock prices given. 3. **Function: `display_stock_metrics(metrics: dict[str, dict[str, float]]) -> None`** - **Input**: A dictionary with company names as keys and calculated metrics as the value. - **Task**: Display the metrics in a formatted table, similar to the `rich` library, but you may use any library of your choice. # Constraints: - Assume the CSV file is well-formed, with columns: `Date`, `Company`, `Close`. - Ensure your program handles file-reading errors gracefully. - Handle missing or incomplete data records logically. - Make sure all calculations are precise and handle large numbers accurately. # Example: ```python >>> csv_data = Date,Company,Close 2023-01-01,Company A,100.0 2023-01-02,Company A,101.5 2023-01-01,Company B,200.0 2023-01-02,Company B,195.0 >>> with open(\\"sample_stock_data.csv\\", \\"w\\") as f: ... f.write(csv_data) ... >>> stock_data = read_stock_data(\\"sample_stock_data.csv\\") >>> stock_data { \'Company A\': [(datetime.date(2023, 1, 1), 100.0), (datetime.date(2023, 1, 2), 101.5)], \'Company B\': [(datetime.date(2023, 1, 1), 200.0), (datetime.date(2023, 1, 2), 195.0)] } >>> metrics = calculate_metrics(stock_data[\'Company A\']) >>> metrics { \'Avg Close Price\': 100.75, \'Max Close Price\': 101.5, \'Min Close Price\': 100.0, \'Volatility\': 1.5 } >>> display_stock_metrics({\'Company A\': metrics}) Company Avg Close Price Max Close Price Min Close Price Volatility Company A 100.75 101.5 100.0 1.5 ``` Develop your program fulfilling these requirements. Make sure to test it against various scenarios and edge cases.","solution":"import csv from datetime import datetime from typing import List, Tuple, Dict def read_stock_data(file_path: str) -> Dict[str, List[Tuple[datetime, float]]]: Reads stock data from a CSV file and returns a dictionary where keys are company names and values are lists of tuples with date and closing price. stock_data = {} try: with open(file_path, newline=\'\') as csvfile: reader = csv.DictReader(csvfile) for row in reader: date = datetime.strptime(row[\'Date\'], \'%Y-%m-%d\').date() company = row[\'Company\'] close_price = float(row[\'Close\']) if company not in stock_data: stock_data[company] = [] stock_data[company].append((date, close_price)) except Exception as e: print(f\\"Error reading file: {e}\\") return stock_data def calculate_metrics(stock_prices: List[Tuple[datetime, float]]) -> Dict[str, float]: Calculates performance metrics for a given list of stock prices. if not stock_prices: return {} close_prices = [close for date, close in stock_prices] avg_close_price = sum(close_prices) / len(close_prices) max_close_price = max(close_prices) min_close_price = min(close_prices) volatility = max_close_price - min_close_price return { \\"Avg Close Price\\": avg_close_price, \\"Max Close Price\\": max_close_price, \\"Min Close Price\\": min_close_price, \\"Volatility\\": volatility } def display_stock_metrics(metrics: Dict[str, Dict[str, float]]) -> None: Displays the stock metrics in a formatted table. header = f\\"{\'Company\':<15}{\'Avg Close Price\':<20}{\'Max Close Price\':<20}{\'Min Close Price\':<20}{\'Volatility\':<15}\\" print(header) print(\'-\' * len(header)) for company, metric in metrics.items(): print(f\\"{company:<15}{metric[\'Avg Close Price\']:<20.2f}{metric[\'Max Close Price\']:<20.2f}{metric[\'Min Close Price\']:<20.2f}{metric[\'Volatility\']:<15.2f}\\")"},{"question":"# CSV File Comparison You need to implement a function that compares two CSV files to determine if they contain exactly the same data. The CSV files represent sets of records with the same structure (same columns in the same order). The function should parse both files, compare their contents record by record, and return a boolean indicating if they match. Task You need to implement the `compare_csv_files` function in Python, which takes the paths of two CSV files as inputs and checks if they are identical in content. Function Signature ```python def compare_csv_files(file1: str, file2: str) -> bool: ``` Input * `file1`: A string representing the path to the first CSV file. * `file2`: A string representing the path to the second CSV file. Output * Returns `True` if the two files contain identical data, otherwise returns `False`. Constraints * Both CSV files use commas (`,`) as the delimiter. * The first row in the files represents the header and should be the same in both files. * Each subsequent row represents a record, and all rows must match exactly (including order). Examples Assume you have the following files: **file1.csv** ```csv name,age,city Alice,30,New York Bob,25,Los Angeles ``` **file2.csv** ```csv name,age,city Alice,30,New York Bob,25,Los Angeles ``` ```python assert compare_csv_files(\'file1.csv\', \'file2.csv\') == True ``` **file1.csv** ```csv name,age,city Alice,30,New York Bob,25,Los Angeles ``` **file2.csv** ```csv name,age,city Alice,30,New York Charlie,22,Boston ``` ```python assert compare_csv_files(\'file1.csv\', \'file2.csv\') == False ``` Requirements * Ensure the function handles files gracefully, even in cases of missing files or read errors. * Use a standard CSV parsing method for robustness. * Optimize the function for large files to manage memory efficiently. # Note You may use the `csv` module in Python to assist with parsing the files. The focus should be on accurately comparing each record in the files.","solution":"import csv def compare_csv_files(file1: str, file2: str) -> bool: Compare two CSV files to check if they contain the same data. Parameters: file1 (str): Path to the first CSV file. file2 (str): Path to the second CSV file. Returns: bool: True if the two files contain identical data, False otherwise. try: with open(file1, \'r\') as f1, open(file2, \'r\') as f2: reader1 = csv.reader(f1) reader2 = csv.reader(f2) for row1, row2 in zip(reader1, reader2): if row1 != row2: return False # Ensure both files have the same number of rows # If one of the readers has more rows, zip will not exhaust them # We need to explicitly read the rest and check if there is any extra row try: next(reader1) return False except StopIteration: pass try: next(reader2) return False except StopIteration: pass return True except IOError: # Handle I/O errors while reading the files raise"},{"question":"# Problem Statement Binary search is a popular searching algorithm that runs in O(log n) time for a sorted list. The algorithm works by repeatedly dividing the search interval in half. If the value of the search key is less than the item in the middle of the interval, narrow the interval to the lower half. Otherwise, narrow it to the upper half until the value is found or the interval is empty. However, implementing binary search in a way that is bug-free and works for all edge cases can be tricky. Implement a function `binary_search(sorted_list, target)` that performs binary search to find the index of the target element in the sorted list. # Function Signature ```python def binary_search(sorted_list: list, target: int) -> int: pass ``` # Input * `sorted_list` (list): A list of integers sorted in ascending order. * `target` (int): The integer value that needs to be searched within the list. # Output * Returns the index of the target value if it is present in the list; otherwise, returns -1. # Constraints * The length of `sorted_list` is between 0 and 10^6. * Each element in `sorted_list` is between -10^9 and 10^9. * `target` is between -10^9 and 10^9. # Example ```python binary_search([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 5) == 4 binary_search([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 11) == -1 binary_search([], 1) == -1 ``` # Additional Notes You can assume that `sorted_list` contains unique elements. # Performance Requirements The solution should be optimized to handle the larger input sizes efficiently, maintaining the logarithmic time complexity. # Algorithm 1. Initialize the start (`left`) and end (`right`) pointers for the list. 2. While `left` is less than or equal to `right`: - Calculate the middle index (`mid`). - If the value at `mid` matches the `target`, return `mid`. - If the `target` is less than the value at `mid`, adjust `right` to `mid - 1`. - If the `target` is greater than the value at `mid`, adjust `left` to `mid + 1`. 3. If the target value is not found, return -1. # Edge Cases * Consideration for an empty list should return -1. * Ensure algorithm handles all potential edge values for target within the given constraints.","solution":"def binary_search(sorted_list, target): This function implements the binary search algorithm. :param sorted_list: A list of integers sorted in ascending order. :param target: The integer value that needs to be searched within the list. :return: Returns the index of the target value if it is present in the list, otherwise returns -1. left, right = 0, len(sorted_list) - 1 while left <= right: mid = (left + right) // 2 if sorted_list[mid] == target: return mid elif sorted_list[mid] < target: left = mid + 1 else: right = mid - 1 return -1"},{"question":"# Maximum Consecutive Ones in Binary Array **Context**: A company is analyzing customer activity data represented as binary arrays. Each element in the array represents whether a customer was active (1) or inactive (0) on a given day. They need to determine the longest period of consecutive active days for each customer to derive insights from their activity patterns. **Objective**: Develop a function to find the maximum number of consecutive 1s (active days) in a binary array. Optimizations are encouraged for handling large arrays efficiently. **Task**: Implement a function, `max_consecutive_ones(arr: List[int]) -> int`, that calculates the maximum number of consecutive 1s in the binary array. # Input and Output Specifications: * **arr**: A list of integers where each integer is either `0` or `1`. * **Return**: An integer representing the length of the longest sequence of consecutive 1s in the provided list. * **Constraints**: * The length of the array will be between 1 and 10^6. # Function Signature: ```python from typing import List def max_consecutive_ones(arr: List[int]) -> int: pass ``` # Examples: ```python >>> max_consecutive_ones([1, 1, 0, 1, 1, 1]) 3 >>> max_consecutive_ones([1, 0, 1, 0, 1]) 1 >>> max_consecutive_ones([0, 0, 0]) 0 >>> max_consecutive_ones([1, 1, 1, 1, 1]) 5 >>> max_consecutive_ones([1, 0, 1, 1, 0, 1, 1, 1, 0, 1]) 3 ``` # Details to Note: 1. If the array contains no 1s, return 0. 2. Special non-performance constraints such as using constant space (best-effort) are appreciated. 3. Focus on achieving linear time complexity O(n) to handle large input sizes efficiently. # Performance Requirements: 1. Must run in O(n) time where n is the length of the array. 2. Avoid using extra space proportional to the input size.","solution":"from typing import List def max_consecutive_ones(arr: List[int]) -> int: Returns the maximum number of consecutive 1s in the binary array. Parameters: - arr : List[int] : Input list containing 0s and 1s. Returns: - int : The longest sequence of consecutive 1s. max_count = 0 current_count = 0 for num in arr: if num == 1: current_count += 1 if current_count > max_count: max_count = current_count else: current_count = 0 return max_count"},{"question":"# Coding Question Context A gaming company you work for is dealing with a server-side performance issue related to leaderboard ranking. To resolve this issue, they need an efficient algorithm to find the top `k` scores from a potentially large dataset of game scores. Problem Given a list of integer scores and an integer `k`, implement an efficient algorithm to find the top `k` highest scores. Requirements 1. Implement a function to return the `k` highest scores from the list, sorted in descending order. 2. Your function should handle large input sizes efficiently. 3. Ensure the solution has better time complexity than a naive O(n log n) sorting approach for large datasets. Function Signature ```python def top_k_scores(scores: list[int], k: int) -> list[int]: Finds and returns the top k highest scores in descending order. :param scores: A list of integers representing scores. :param k: An integer representing the number of top scores to return. :return: A list of the top k highest scores in descending order. Example: >>> top_k_scores([100, 90, 90, 80, 70], 3) [100, 90, 90] >>> top_k_scores([1, 2, 3, 4, 5], 2) [5, 4] >>> top_k_scores([10, 7, 1, 3], 1) [10] >>> top_k_scores([], 3) [] >>> top_k_scores([5, 10, 15], 0) [] ``` Constraints 1. You may not use Python\'s built-in functions like `sorted()`, and you should avoid O(n log n) sorting algorithms for large datasets. 2. Focus on achieving a solution that leverages a heap or another efficient method to ensure better time complexity for finding the top `k` scores. 3. The input list may include negative numbers. Input/Output Format * **Input**: A list of integers and an integer `k`. * **Output**: A new list of integers containing the top `k` scores in descending order. Examples 1. `top_k_scores([4, 2, 7, 3, 1], 3)` should return `[7, 4, 3]`. 2. `top_k_scores([10, -3, 2, 5], 2)` should return `[10, 5]`. Notes 1. Write comprehensive tests to ensure your implementation is correct and efficient. 2. Consider edge cases such as empty lists and lists where `k` is zero or larger than the list length.","solution":"import heapq def top_k_scores(scores, k): Finds and returns the top k highest scores in descending order. :param scores: A list of integers representing scores. :param k: An integer representing the number of top scores to return. :return: A list of the top k highest scores in descending order. if k <= 0: return [] if k >= len(scores): return sorted(scores, reverse=True) # Use a min-heap to keep track of the top k scores min_heap = scores[:k] heapq.heapify(min_heap) for score in scores[k:]: if score > min_heap[0]: heapq.heapreplace(min_heap, score) return sorted(min_heap, reverse=True)"},{"question":"# Coding Question: Circular Rotations of Strings In this task, you are required to implement a function that checks if two strings are circular rotations of each other. A string `B` is a circular rotation of string `A` if it can be obtained by shifting the characters in `A` in a circular manner. For instance, \\"dabc\\" is a circular rotation of \\"abcd\\". # Core Requirements: - **Function Signature**: ```python def are_circular_rotations(s1: str, s2: str) -> bool: ``` - **Input**: - `s1` (str): The first input string. - `s2` (str): The second input string. - **Output**: - A boolean value `True` if `s2` is a circular rotation of `s1`, and `False` otherwise. - **Constraints**: - Both strings will have a length within the range (1 leq text{len}(s1), text{len}(s2) leq 1000). # Instructions 1. **Equality Check**: The function should first check if the two strings have the same length. If not, return `False`. 2. **Rotation Logic**: Implement the logic to determine if one string is a circular rotation of the other. 3. **Efficiency**: Optimize the function to handle the maximum input length efficiently. # Example ```python >>> are_circular_rotations(\\"abcd\\", \\"dabc\\") True >>> are_circular_rotations(\\"abcd\\", \\"bcda\\") True >>> are_circular_rotations(\\"abcd\\", \\"abdc\\") False >>> are_circular_rotations(\\"abcde\\", \\"cdeab\\") True >>> are_circular_rotations(\\"abcde\\", \\"edcba\\") False ``` This task will test your understanding of string manipulations, pattern recognition, and efficiency in handling moderate-sized sequences.","solution":"def are_circular_rotations(s1: str, s2: str) -> bool: Checks if s2 is a circular rotation of s1. Args: s1 (str): The first input string. s2 (str): The second input string. Returns: bool: True if s2 is a circular rotation of s1, False otherwise. if len(s1) != len(s2): return False concatenated = s1 + s1 return s2 in concatenated"},{"question":"# Trie - Implementation and Word Search Background: A Trie (pronounced \\"try\\") is a special type of tree used to store associative data structures. A common application of a Trie is storing a predictive text or autocomplete dictionary. It allows for fast retrieval of words stored in it. Task: 1. **Construct the Trie**: Implement code to construct a Trie from a given list of words. 2. **Implement Word Search**: Write a function to search for a given word and prefix within the Trie. Function Signatures: 1. `def insert_word(trie: dict, word: str) -> None`: * **Input**: * `trie` - A dictionary representing the root of the Trie. Each key is a character and its value is another dictionary. * `word` - The word to be inserted into the Trie. * **Output**: * None. The function modifies the `trie` in place. 2. `def search_word(trie: dict, word: str) -> bool`: * **Input**: * `trie` - The root dictionary of the Trie. * `word` - The word to be searched in the Trie. * **Output**: * Returns `True` if the word is found in the Trie, `False` otherwise. 3. `def search_prefix(trie: dict, prefix: str) -> bool`: * **Input**: * `trie` - The root dictionary of the Trie. * `prefix` - The prefix to be searched in the Trie. * **Output**: * Returns `True` if the prefix is found in the Trie, `False` otherwise. Constraints: * The words contain only lowercase letters. * The length of each word and prefix is not more than 100. * The number of words to be inserted in the Trie, `n` (1 ≤ n ≤ 10^5). Example: ```python # Example words and prefix words = [\\"apple\\", \\"app\\", \\"application\\", \\"apt\\", \\"bat\\"] prefix = \\"ap\\" word = \\"apple\\" # Initialize an empty trie trie = {} # Insert each word into the trie for w in words: insert_word(trie, w) # Search for the word in the trie word_found = search_word(trie, word) print(word_found) # Output: True # Search for the prefix in the trie prefix_found = search_prefix(trie, prefix) print(prefix_found) # Output: True ``` Notes: * The `insert_word` function should handle inserting each character of the word into the Trie. * The `search_word` function should check if the word exists as a complete word in the Trie. * The `search_prefix` function should check if there is any word in the Trie starting with the given prefix. * Consider edge cases such as inserting and searching for very short or very long words/prefixes and empty inputs.","solution":"def insert_word(trie: dict, word: str) -> None: Inserts a word into the Trie. node = trie for char in word: if char not in node: node[char] = {} node = node[char] node[\'\'] = True # Use \'\' as a marker for the end of a word def search_word(trie: dict, word: str) -> bool: Searches for a word in the Trie. Returns True if the word is found, False otherwise. node = trie for char in word: if char not in node: return False node = node[char] return \'\' in node def search_prefix(trie: dict, prefix: str) -> bool: Searches for a prefix in the Trie. Returns True if at least one word with the given prefix exists, False otherwise. node = trie for char in prefix: if char not in node: return False node = node[char] return True"},{"question":"# Problem Statement You are tasked with writing a function that performs matrix rotation. Given a square matrix, rotate it 90 degrees clockwise in-place. This common operation is often used in image processing and computational geometry problems. # Requirements * Implement a function `rotate_matrix_90_clockwise(matrix)` that takes a square matrix (2D list) as input and rotates it 90 degrees clockwise in-place. * The matrix dimensions will always be n x n (where 1 ≤ n ≤ 100). * Optimize the algorithm to perform the rotation with minimal auxiliary space, ideally in O(1) space complexity. # Input and Output * **Input**: A 2D list `matrix` representing the square matrix. For example: - `[[1, 2], [3, 4]]` - `[[1, 2, 3], [4, 5, 6], [7, 8, 9]]` * **Output**: The input matrix rotated in-place 90 degrees clockwise. The function does not need to return anything. # Constraints 1. The input matrix will only contain integers. 2. The function should handle the rotation in-place, without using extra matrix data structures. # Example Scenarios Example 1: * **Input**: `[[1, 2], [3, 4]]` * **Output**: The input matrix itself is modified to `[[3, 1], [4, 2]]` Example 2: * **Input**: `[[1, 2, 3], [4, 5, 6], [7, 8, 9]]` * **Output**: The input matrix itself is modified to `[[7, 4, 1], [8, 5, 2], [9, 6, 3]]` Write the function `rotate_matrix_90_clockwise(matrix)` to perform the rotation as described.","solution":"def rotate_matrix_90_clockwise(matrix): Rotates the given n x n matrix 90 degrees clockwise in place. n = len(matrix) # First step: transpose the matrix for i in range(n): for j in range(i, n): matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j] # Second step: reverse each row for i in range(n): matrix[i].reverse()"},{"question":"# Problem Statement In a game application, players collect points as they move from one level to another. The points gathered by each player need to be analyzed to compute the number of players who qualify for the bonus round. A player qualifies for the bonus round if the total points collected are above a certain threshold. Implement a function `count_bonus_qualifiers` to determine the number of qualifiers. # Function Signature ```python def count_bonus_qualifiers(points_list: list[float], threshold: float) -> int: ``` # Parameters: - `points_list` (list[float]): A list of non-negative floats representing the points collected by each player. The list may be empty. - `threshold` (float): A non-negative float representing the minimum points required to qualify for the bonus round. # Returns: - The function should return an integer representing the total number of players who qualify for the bonus round. # Constraints: - The function must raise a `ValueError` if any value in `points_list` is negative. - The function must raise a `ValueError` if `threshold` is negative. # Example ```python # Example 1 print(count_bonus_qualifiers([10, 20, 30, 40, 50], 25)) # Output: 3 # Example 2 print(count_bonus_qualifiers([5, 8, 12, 19], 15)) # Output: 1 # Example 3 print(count_bonus_qualifiers([50, 60, 70], 55)) # Output: 2 # Example 4 print(count_bonus_qualifiers([1, 2, 3, 4], 5)) # Output: 0 # Example 5 print(count_bonus_qualifiers([], 10)) # Output: 0 ``` Notes: - Ensure that your function performs input validation and handles erroneous inputs gracefully by raising appropriate exceptions. - The list `points_list` can be empty, in which case the function should return 0 since no players would qualify for the bonus round.","solution":"def count_bonus_qualifiers(points_list, threshold): Returns the number of players who qualify for the bonus round. :param points_list: list of points collected by each player. :param threshold: minimum points required to qualify for the bonus round. :returns: Number of players who qualify for the bonus round. if threshold < 0: raise ValueError(\\"Threshold must be non-negative\\") if any(point < 0 for point in points_list): raise ValueError(\\"Points in the points_list must all be non-negative\\") count = 0 for points in points_list: if points > threshold: count += 1 return count"},{"question":"# Coding Question: You are tasked with implementing a function that finds the smallest positive integer `n` such that the sum of the factorial of its digits is equal to `n`. This tests your understanding of number manipulation and the properties of factorials. Function Signature: ```python def find_smallest_factorial_sum() -> int: Finds the smallest positive integer \'n\' such that the sum of the factorial of its digits equals \'n\'. Returns: - int: The smallest positive integer \'n\' satisfying the condition. Example: - Output: 145 (1! + 4! + 5! = 145) pass ``` Constraints: - The solution should find the smallest `n` without any upper limit constraint on the digit range. Implementation Details: - Write helper functions if necessary to compute factorials of digits and to check the sum condition. - Optimize your solution to handle increasingly large values efficiently. Example: The number `145` satisfies the condition as `1! + 4! + 5! = 1 + 24 + 120 = 145`. Tips: - Use an efficient method to compute factorials to avoid recalculating them each time. - Ensure your solution can potentially check large ranges of numbers effectively. Good luck!","solution":"import math def find_smallest_factorial_sum() -> int: Finds the smallest positive integer \'n\' such that the sum of the factorial of its digits equals \'n\'. Returns: - int: The smallest positive integer \'n\' satisfying the condition. def digit_factorial_sum(n): return sum(math.factorial(int(d)) for d in str(n)) num = 10 while True: if digit_factorial_sum(num) == num: return num num += 1"},{"question":"Binary Tree Level Order Traversal **Scenario**: You are a software developer working on a project that involves manipulating and analyzing tree data structures. One of the tasks requires you to traverse a binary tree level by level, which is essential for operations like breadth-first search. # Problem Statement Write a function `level_order_traversal` that performs a level order traversal on a given binary tree and returns a list of its elements in the visited order. Your task is two-fold: 1. Implement the `level_order_traversal` function to traverse a binary tree level by level. 2. Discuss the time and space complexity of your implementation. **Function Signature** ```python def level_order_traversal(root: TreeNode) -> list[int]: pass ``` **Input/Output Format** * **Input**: - A binary tree root node `root`. * **Output**: - A list of integers representing the elements of the tree in level order traversal. **Constraints** * The number of nodes in the tree can be up to 10^4. * The value of each node will be between -10^5 and 10^5. **TreeNode Class Definition** ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right ``` # Constraints/Edge Cases to Consider 1. Empty tree 2. Tree with a single node 3. Tree with multiple levels 4. Tree with varying values (including negative and positive values) # Requirements Besides implementing the `level_order_traversal` function, ensure you explain the time and space complexity of your solution, considering both average and worst-case scenarios. Discuss any potential trade-offs involved in using this approach.","solution":"from collections import deque class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def level_order_traversal(root: TreeNode) -> list[int]: Perform a level order traversal on a given binary tree and return a list of its elements in the visited order. if not root: return [] result = [] queue = deque([root]) while queue: node = queue.popleft() result.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) return result # Time Complexity: O(n) where n is the number of nodes in the tree. # Each node is enqueued and dequeued exactly once. # Space Complexity: O(n) for the queue, which in the worst case scenario (a full binary tree), # can hold all the nodes at the deepest level (approximately n/2 nodes)."},{"question":"# Coding Challenge: Word Relevance Scoring In natural language processing, calculating the relevance of a word within a document or a collection of documents is a common task. One simple method to measure word relevance is using Term Frequency (TF) and Inverse Document Frequency (IDF). Your task is to implement a function that calculates the TF-IDF score for a word in a collection of documents. **Your Task**: - Write a function `calculate_tfidf(word: str, document: str, corpus: List[str]) -> float` that computes the TF-IDF score of a word in a given document relative to a corpus of documents. - The document and corpus will be provided as strings, with each document being a string of lowercase words separated by spaces. **Input**: - `word` (str): The word for which TF-IDF score is to be calculated. - `document` (str): The document in which the word\'s frequency is to be measured. - `corpus` (List[str]): A list of strings representing the collection of documents. **Output**: - A float representing the TF-IDF score of the word in the document. **Constraints**: - Words in the documents are separated by single spaces. - The corpus contains at least one document. - The word exists in the document. ```python from typing import List import math def calculate_tfidf(word: str, document: str, corpus: List[str]) -> float: Calculate the TF-IDF score of a word in a document relative to a corpus. Parameters: - word (str): The word for which TF-IDF score is to be calculated. - document (str): The document in which the word\'s frequency is to be measured. - corpus (List[str]): A list of strings representing the collection of documents. Returns: - float: The TF-IDF score of the word in the document. # Calculate Term Frequency (TF) in the document words_in_document = document.split() term_count = words_in_document.count(word) tf = term_count / len(words_in_document) # Calculate Inverse Document Frequency (IDF) in the corpus num_documents_with_word = sum(1 for doc in corpus if word in doc.split()) idf = math.log(len(corpus) / (1 + num_documents_with_word)) # Calculate TF-IDF tfidf = tf * idf return tfidf ``` **Example Scenarios**: 1. Given the params: - `word = \\"example\\"` - `document = \\"this is an example document with example word\\"` - `corpus = [\\"this is the first document\\", \\"this is an example document with example word\\", \\"another example document\\"]` - Calling `calculate_tfidf(word, document, corpus)` should output the TF-IDF value. 2. Given the params: - `word = \\"word\\"` - `document = \\"another example document with unique word\\"` - `corpus = [\\"this is the first document\\", \\"this is an example document with example word\\", \\"another example document\\", \\"one more document\\"]` - Calling `calculate_tfidf(word, document, corpus)` should output the TF-IDF value. **Edge cases**: - The word is very frequent across many documents. - The word appears only in one document. Ensure your solution handles these appropriately.","solution":"from typing import List import math def calculate_tfidf(word: str, document: str, corpus: List[str]) -> float: Calculate the TF-IDF score of a word in a document relative to a corpus. Parameters: - word (str): The word for which TF-IDF score is to be calculated. - document (str): The document in which the word\'s frequency is to be measured. - corpus (List[str]): A list of strings representing the collection of documents. Returns: - float: The TF-IDF score of the word in the document. # Calculate Term Frequency (TF) in the document words_in_document = document.split() term_count = words_in_document.count(word) tf = term_count / len(words_in_document) # Calculate Inverse Document Frequency (IDF) in the corpus num_documents_with_word = sum(1 for doc in corpus if word in doc.split()) idf = math.log(len(corpus) / (1 + num_documents_with_word)) # Calculate TF-IDF tfidf = tf * idf return tfidf"},{"question":"Trie-Based Autocomplete System An autocomplete system suggests a list of possible completions for a given prefix, providing enhanced user experience in search engines, text editors, etc. This exercise focuses on implementing such a system using a Trie data structure, which ensures efficient storage and retrieval of strings. Task You need to implement a Trie data structure to support the insertion of words and retrieval of autocomplete suggestions based on a given prefix. Input * A list `dictionary` of words with `1 ≤ len(dictionary) ≤ 10^4` and each word having `1 ≤ len(word) ≤ 100`. * A string `prefix` of length `1 ≤ len(prefix) ≤ 100`. Output * A list of strings containing the autocomplete suggestions in lexicographical order. Function Signature ```python def autocomplete_system(dictionary: list[str], prefix: str) -> list[str]: pass ``` Examples ```python >>> autocomplete_system([\\"apple\\", \\"app\\", \\"apricot\\", \\"banana\\", \\"carrot\\"], \\"ap\\") [\\"app\\", \\"apple\\", \\"apricot\\"] >>> autocomplete_system([\\"dog\\", \\"deer\\", \\"deal\\"], \\"de\\") [\\"deal\\", \\"deer\\"] >>> autocomplete_system([\\"cat\\", \\"cap\\", \\"car\\", \\"can\\"], \\"ca\\") [\\"can\\", \\"cap\\", \\"car\\", \\"cat\\"] >>> autocomplete_system([\\"hello\\", \\"hell\\", \\"heaven\\", \\"heavy\\"], \\"he\\") [\\"heaven\\", \\"heavy\\", \\"hell\\", \\"hello\\"] ``` Trie Characteristics * Each node represents a character and has up to 26 children (for lowercase letters). * The root represents an empty string, and branches out to all possible first characters of the inserted words. * Words are inserted character by character, creating new nodes as needed. * Autocomplete involves traversing down to the node corresponding to the prefix, and performing a lexicographical traversal from there. Constraints * Ensure the Trie structure handles duplicate words gracefully. * Time Complexity: (O(sum_{i=1}^{n} len(word_i) + k log k)), where `n` is the number of words in the dictionary and `k` is the number of suggestions. * Space Complexity: (O(sum_{i=1}^{n} len(word_i))) for the Trie storage. Tips * Implement a Trie node class with functionality to insert words and retrieve prefix-based suggestions. * Use a depth-first search (DFS) or a breadth-first search (BFS) to gather all words that start with the given prefix. * Ensure the output is sorted in lexicographical order before returning.","solution":"class TrieNode: def __init__(self): self.children = {} self.is_end_of_word = False class Trie: def __init__(self): self.root = TrieNode() def insert(self, word): node = self.root for char in word: if char not in node.children: node.children[char] = TrieNode() node = node.children[char] node.is_end_of_word = True def autocomplete(self, prefix): def dfs(node, path, results): if node.is_end_of_word: results.append(\'\'.join(path)) for char in sorted(node.children.keys()): path.append(char) dfs(node.children[char], path, results) path.pop() node = self.root for char in prefix: if char not in node.children: return [] node = node.children[char] results = [] dfs(node, list(prefix), results) return results def autocomplete_system(dictionary, prefix): trie = Trie() for word in dictionary: trie.insert(word) return trie.autocomplete(prefix)"},{"question":"# Problem Statement: In a coding competition, participants earn points for each problem they solve. The leaderboard shows the top scores in descending order. Given a list of scores and a new score obtained by a participant, your task is to determine the rank of the new score if it were added to the leaderboard. The rank is defined as 1 for the highest score, 2 for the second-highest, and so on. If multiple participants have the same score, they share the same rank, and the subsequent ranks are skipped. # Function Signature: ```python def leaderboard_rank(scores: List[int], new_score: int) -> int: pass ``` # Input: - A list of integers `scores` representing the current leaderboard scores in descending order where 1 ≤ len(scores) ≤ 10^5 and all scores are ≥ 0. - An integer `new_score` representing the new score earned by the participant where 0 ≤ new_score ≤ 10^9. # Output: - Return an integer representing the rank of the new score on the leaderboard. # Constraints: - Ensure that the algorithm handles large input sizes efficiently. - The leaderboard must maintain the scores in descending order after adding the new score. # Example: ```python assert leaderboard_rank([100, 90, 90, 80], 85) == 3 assert leaderboard_rank([100, 100, 90, 90, 80], 100) == 1 assert leaderboard_rank([99, 99, 99], 99) == 1 assert leaderboard_rank([100, 90, 85, 80], 75) == 5 ``` # Detailed Steps: 1. Traverse through the `scores` list to find the correct rank position for the `new_score`. 2. Compare the `new_score` with each score in the list to determine its rank. 3. Efficiently handle cases where multiple ranks can have the same score. 4. Return the rank as 1-based, where the highest score has rank 1. 5. Ensure the algorithm has a time complexity approximately O(n) for large inputs.","solution":"from typing import List def leaderboard_rank(scores: List[int], new_score: int) -> int: Determine the rank of the new_score on the leaderboard when added to the given scores. rank = 1 for score in scores: if new_score >= score: return rank if rank == 1 or score != scores[rank - 2]: rank += 1 return rank"},{"question":"# Longest Common Substring with Constraints Given two strings `s1` and `s2`, and an integer `k`, implement the following functionalities to find the longest common substring between `s1` and `s2` such that the substring contains exactly `k` distinct characters. # Function Specifications Your task is to implement a class `SubstringFinder` which contains the following methods: - `__init__(self, s1: str, s2: str, k: int)`: Initializes the class with two strings `s1` and `s2`, and the integer `k` which specifies the number of distinct characters allowed in the common substring. - `get_longest_common_substring(self) -> str`: Returns the longest common substring of `s1` and `s2` that contains exactly `k` distinct characters. If no such substring exists, return an empty string. # Constraints * ( 1 leq |s1|, |s2| leq 500 ) * ( 1 leq k leq 26 ) * Strings `s1` and `s2` contain only lowercase English letters. # Example ```python # Creating an instance of SubstringFinder with s1, s2, and k finder = SubstringFinder(\\"banana\\", \\"anaconda\\", 2) # Finding the longest common substring with exactly 2 distinct characters assert finder.get_longest_common_substring() == \\"ana\\" # Creating another instance finder = SubstringFinder(\\"abcde\\", \\"fghij\\", 2) # Trying to find the longest common substring with exactly 2 distinct characters assert finder.get_longest_common_substring() == \\"\\" ``` # Notes Make sure to efficiently handle the constraints and edge cases, especially when the strings have different lengths or no valid substrings can be found.","solution":"class SubstringFinder: def __init__(self, s1: str, s2: str, k: int): self.s1 = s1 self.s2 = s2 self.k = k def get_longest_common_substring(self) -> str: def has_k_distinct_chars(s: str, k: int) -> bool: return len(set(s)) == k longest_substr = \\"\\" len1, len2 = len(self.s1), len(self.s2) for i in range(len1): for j in range(i + 1, len1 + 1): substr = self.s1[i:j] if has_k_distinct_chars(substr, self.k) and substr in self.s2: if len(substr) > len(longest_substr): longest_substr = substr return longest_substr"},{"question":"# Problem Description You are required to write a function `next_highest` that takes an integer `n` as input and returns the next highest integer that can be formed using the digits of `n`. If no such integer exists, return -1. # Input Format - A single integer `n` (0 <= n <= 10^6) # Output Format - An integer representing the next highest integer formed by the digits of `n`, or -1 if no such integer exists. # Constraints - `n` is a non-negative integer. - Minimize the impact of edge cases and ensure the function runs optimally for large inputs. # Performance Requirements - The solution should aim for an optimal search and swap operation potentially involving sorting. - The complexity can be up to O(n log n) if necessary due to sorting. # Example Scenarios 1. **Example 1:** - Input: n = 1234 - Output: 1243 2. **Example 2:** - Input: n = 4321 - Output: -1 3. **Example 3:** - Input: n = 534976 - Output: 536479 # Edge Cases 1. **Single Digit:** - Input: n = 5 - Output: -1 2. **Repeating Digits:** - Input: n = 111 - Output: -1 # Function Signature ```python def next_highest(n: int) -> int: pass ``` # Write the function `next_highest` to solve the problem:","solution":"def next_highest(n: int) -> int: digits = list(str(n)) length = len(digits) if length == 1: return -1 # Step 1: find the first digit that is smaller than the digit next to it for i in range(length - 2, -1, -1): if digits[i] < digits[i + 1]: break else: return -1 # Step 2: find the smallest digit on the right side of (i) which is greater than digits[i] for j in range(length - 1, i, -1): if digits[j] > digits[i]: break # Step 3: Swap the found digits digits[i], digits[j] = digits[j], digits[i] # Step 4: Sort the digits after (i) in ascending order digits = digits[:i + 1] + sorted(digits[i + 1:]) return int(\'\'.join(digits))"},{"question":"# Merge Linked Lists Challenge In this challenge, you need to implement a function that merges two sorted linked lists into one sorted linked list. # Requirements 1. Implement a function `merge_linked_lists(list1: ListNode, list2: ListNode) -> ListNode` that takes the head nodes of two sorted linked lists and returns the head node of a new sorted linked list containing all nodes from both inputs. 2. Ensure the solution preserves the sorted order of elements. # Function Signature ```python class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = next def merge_linked_lists(list1: ListNode, list2: ListNode) -> ListNode: pass ``` # Input - `list1`: The head node of the first sorted linked list. - `list2`: The head node of the second sorted linked list. # Output - Returns the head node of the new sorted linked list. # Constraints - The linked lists `list1` and `list2` contain `0 <= n <= 1000` nodes. - Each node\'s value is a non-negative integer. # Example ```python # Utility function to convert Python list to linked list def list_to_linked(lst): if not lst: return None head = ListNode(lst[0]) current_node = head for value in lst[1:]: current_node.next = ListNode(value) current_node = current_node.next return head # Utility function to convert linked list to Python list for easy comparison def linked_to_list(node): result = [] while node: result.append(node.val) node = node.next return result list1 = list_to_linked([1, 2, 4]) list2 = list_to_linked([1, 3, 4]) merged_head = merge_linked_lists(list1, list2) print(linked_to_list(merged_head)) # Sample Output # [1, 1, 2, 3, 4, 4] ``` # Explanation In the example, two linked lists `[1, 2, 4]` and `[1, 3, 4]` are merged into one sorted linked list: `[1, 1, 2, 3, 4, 4]`. The `merge_linked_lists` function ensures that the resulting linked list is sorted correctly, preserving all elements from both input lists.","solution":"class ListNode: def __init__(self, val=0, next=None): self.val = val self.next = next def merge_linked_lists(list1: ListNode, list2: ListNode) -> ListNode: dummy = ListNode() current = dummy while list1 and list2: if list1.val < list2.val: current.next = list1 list1 = list1.next else: current.next = list2 list2 = list2.next current = current.next # Attach the remaining part of the list that is not null if list1: current.next = list1 else: current.next = list2 return dummy.next"},{"question":"# List Rotation Challenge **Context**: Rotating elements in a list is a common task in data manipulation. It is often used to cycle through elements, shift data positions, or rearrange elements for specific algorithms. Efficient rotation operations can crucially impact performance in real-time applications and data processing tasks. You have three implementations of functions that rotate a list by a given number of positions: 1. `rotate_list_left(nums: List[int], k: int) -> List[int]` 2. `rotate_list_right(nums: List[int], k: int) -> List[int]` 3. `rotate_list_both_directions(nums: List[int], k: int, direction: str) -> List[int]` # Task Your task is to implement a new function that rotates a list by a given number of positions using a method different from the provided functions. Your solution will be evaluated based on correctness, efficiency, and handling edge cases effectively. # Specification * **Function Name**: `optimized_list_rotation` * **Input**: - `nums` (List[int]): a list of integers that needs to be rotated. - `k` (int): the number of positions to rotate the list. - `direction` (str): a string that can either be `\'left\'` or `\'right\'`, indicating the direction of rotation. * **Output**: - Returns `List[int]`: the list after being rotated by `k` positions in the specified direction. # Constraints - The list `nums` can have up to `10^5` elements. - The integer `k` will be in the range `[0, 10^5]`. - Your solution should handle negative values of `k` by converting them into their equivalent positive rotations. - Your implementation should not simply replicate the provided functions directly but aim to offer a different and possibly more optimized approach. # Examples ```python >>> optimized_list_rotation([1, 2, 3, 4, 5], 2, \'left\') [3, 4, 5, 1, 2] >>> optimized_list_rotation([1, 2, 3, 4, 5], 3, \'right\') [3, 4, 5, 1, 2] >>> optimized_list_rotation([1, 2, 3, 4, 5], 0, \'left\') [1, 2, 3, 4, 5] >>> optimized_list_rotation([1, 2, 3, 4, 5], 5, \'right\') [1, 2, 3, 4, 5] >>> optimized_list_rotation([1, 2, 3, 4, 5], 7, \'left\') [3, 4, 5, 1, 2] >>> optimized_list_rotation([], 2, \'right\') [] ``` # Additional Requirement Include a brief paragraph in your solution describing why your approach is distinct and any trade-offs made. # Bonuses 1. **Runtime Efficiency**: Provide a runtime analysis comparing your implementation with the given functions for lists of various lengths. 2. **Algorithm Efficiency**: Discuss any algorithmic improvements or optimizations used.","solution":"def optimized_list_rotation(nums, k, direction): Rotates the list nums by k positions in the specified direction. Parameters: nums (List[int]): The list of integers to be rotated. k (int): The number of positions to rotate the list. direction (str): The direction to rotate (\'left\' or \'right\'). Returns: List[int]: The rotated list. n = len(nums) if n == 0: return nums # Normalize k to be within the length of the list k = k % n if direction == \'left\': # Rotate to the left return nums[k:] + nums[:k] elif direction == \'right\': # Rotate to the right return nums[-k:] + nums[:-k] else: raise ValueError(\\"Direction must be either \'left\' or \'right\'.\\") # A brief paragraph describing my approach: # This approach calculates the effective number of rotations needed by using the modulo operation. This reduces unnecessary full cycles of rotations which would result in no change. It then slices the list into two parts and concatenates them in the rotated order. This method has O(n) time complexity and O(n) space complexity which is efficient for list slicing operations. # Runtime efficiency and trade-offs: # This approach ensures that even with large k values, rotations are reduced using modulo to the minimum necessary size. The slicing and concatenation maintain fast performance. The trade-off is that while slicing and concatenating lists are efficient, this method uses additional space proportional to the size of the input list, which might be a consideration in very memory-constrained environments."},{"question":"You are given a list of integers representing an unsorted set of scores, and you need to normalize these scores to a range between 0 and 1. To normalize the scores, you will use the Min-Max normalization technique. The normalized value for a score is calculated as `(score - min_score) / (max_score - min_score)`, where `min_score` is the minimum score in the list, and `max_score` is the maximum score in the list. Implement a function to perform this normalization. # Function Signature ```python def normalize_scores(scores: list[int]) -> list[float]: pass ``` # Input - `scores`: A list of integers representing scores (1 ≤ len(scores) ≤ 10^5; -10^9 ≤ scores[i] ≤ 10^9 for all integers in `scores`). # Output - Return a list of floats representing the normalized scores, each ranging between 0 and 1 (inclusive). # Constraints 1. Your implementation should handle the edge case where all scores are the same. 2. Ensure that the normalized scores are calculated efficiently, keeping the time complexity of the solution reasonable. 3. Avoid using external libraries for the normalization process. # Examples ```python assert normalize_scores([50, 20, 30, 40, 10]) == [1.0, 0.25, 0.5, 0.75, 0.0] assert normalize_scores([100, 200, 300, 400, 500]) == [0.0, 0.25, 0.5, 0.75, 1.0] assert normalize_scores([-10, 0, 10, 20, 30]) == [0.0, 0.25, 0.5, 0.75, 1.0] assert normalize_scores([5, 5, 5, 5, 5]) == [0.0, 0.0, 0.0, 0.0, 0.0] ``` # Additional Notes 1. In the example [50, 20, 30, 40, 10], the minimum score is 10 and the maximum score is 50. Using the Min-Max normalization, the normalized values are calculated as follows: - `50 -> (50 - 10) / (50 - 10) = 1.0` - `20 -> (20 - 10) / (50 - 10) = 0.25` - `30 -> (30 - 10) / (50 - 10) = 0.5` - `40 -> (40 - 10) / (50 - 10) = 0.75` - `10 -> (10 - 10) / (50 - 10) = 0.0` 2. The output list should maintain the same order as the input list after normalization. 3. Ensure that the solution accounts for potential edge cases such as an empty input list or a list with all identical elements.","solution":"def normalize_scores(scores: list[int]) -> list[float]: if not scores: return [] min_score = min(scores) max_score = max(scores) if min_score == max_score: return [0.0] * len(scores) # If all scores are the same, return a list of 0.0 return [(score - min_score) / (max_score - min_score) for score in scores]"},{"question":"# Coding Assessment Question As a software developer at a utility company, you have been tasked with creating a system to monitor electricity usage across various departments. The system needs to aggregate usage data from multiple sources and generate a summary report. Your task is to: 1. Implement a function to parse and combine usage data from multiple departments. 2. Implement another function to generate a summary report showing total usage for each department and the overall usage. Expected Input and Output **Function 1**: `def parse_and_combine_usage_data(department_data: list[dict[str, Any]]) -> dict[str, int]`: Parse and combine the electricity usage data from different departments. - **Input**: A list of dictionaries, each representing usage data from a department. Each dictionary contains: - `department` (str): The department name. - `usage` (int): The electricity usage in kilowatt-hours (kWh). - **Output**: A dictionary where the keys are department names and the values are the total electricity usage for each department. **Function 2**: `def generate_usage_summary(aggregated_data: dict[str, int]) -> dict[str, int]`: Generate a summary report of the electricity usage. - **Input**: A dictionary of aggregated usage data where keys are department names and values are total electricity usage in kWh. - **Output**: A dictionary containing: - `total_usage` (int): The total electricity usage of all departments combined. - `highest_usage_department` (str): The department with the highest electricity usage. - `lowest_usage_department` (str): The department with the lowest electricity usage. # Constraints - Ensure all input data is properly validated, such as checking for non-negative values for usage. - Handle edge cases such as departments with zero electricity usage. - Ensure efficient data combination and summary generation even for large datasets.","solution":"from typing import List, Dict, Any def parse_and_combine_usage_data(department_data: List[Dict[str, Any]]) -> Dict[str, int]: Parse and combine the electricity usage data from different departments. Args: department_data: A list of dictionaries, each containing: \'department\' (str): The department name \'usage\' (int): The electricity usage in kWh Returns: A dictionary where keys are department names and values are the total electricity usage for each department. usage_combined = {} for data in department_data: department = data[\'department\'] usage = data[\'usage\'] if usage < 0: raise ValueError(\\"Usage cannot be negative\\") if department not in usage_combined: usage_combined[department] = 0 usage_combined[department] += usage return usage_combined def generate_usage_summary(aggregated_data: Dict[str, int]) -> Dict[str, int]: Generate a summary report of the electricity usage. Args: aggregated_data: A dictionary where keys are department names and values are total electricity usage in kWh. Returns: A dictionary containing: \'total_usage\' (int): The total electricity usage of all departments combined. \'highest_usage_department\' (str): The department with the highest electricity usage. \'lowest_usage_department\' (str): The department with the lowest electricity usage. if not aggregated_data: return { \'total_usage\': 0, \'highest_usage_department\': \\"\\", \'lowest_usage_department\': \\"\\" } total_usage = sum(aggregated_data.values()) highest_usage_department = max(aggregated_data, key=aggregated_data.get) lowest_usage_department = min(aggregated_data, key=aggregated_data.get) return { \'total_usage\': total_usage, \'highest_usage_department\': highest_usage_department, \'lowest_usage_department\': lowest_usage_department }"},{"question":"# Question: Implement a Custom Merge Sort with Inversion Count You are tasked with implementing a custom merge sort function that not only sorts an array but also counts the number of inversions. An inversion is a pair of indices `(i, j)` such that `i < j` and `array[i] > array[j]`. Function Signature ```python def merge_sort_with_inversions(array: list) -> tuple: ``` Input * `array`: A list of integers representing the array to be sorted. Output * A tuple where: * The first element is the sorted array. * The second element is the inversion count. Constraints * The array will have at most 10^5 elements. * The elements are within the range of -10^6 to 10^6. Requirements 1. Implement the merge sort algorithm. 2. Efficiently count the inversions during the merging process. 3. Ensure the solution handles edge cases such as empty arrays. # Example ```python array_1 = [2, 4, 1, 3, 5] array_2 = [5, 4, 3, 2, 1] assert merge_sort_with_inversions(array_1) == ([1, 2, 3, 4, 5], 3) assert merge_sort_with_inversions(array_2) == ([1, 2, 3, 4, 5], 10) ``` Explanation * For `array_1 = [2, 4, 1, 3, 5]`, the sorted array is `[1, 2, 3, 4, 5]` and there are 3 inversions: `(2, 1)`, `(4, 1)`, and `(4, 3)`. * For `array_2 = [5, 4, 3, 2, 1]`, the sorted array is `[1, 2, 3, 4, 5]` and there are 10 inversions as every pair `(i, j)` with `i < j` is an inversion.","solution":"def merge_sort_with_inversions(array): Function that performs merge sort and counts inversions. Returns a tuple: (sorted array, inversion count) def merge_and_count(left, right): sorted_array = [] i = j = 0 inversions = 0 while i < len(left) and j < len(right): if left[i] <= right[j]: sorted_array.append(left[i]) i += 1 else: sorted_array.append(right[j]) j += 1 inversions += len(left) - i # All elements left in left array are inversions sorted_array.extend(left[i:]) sorted_array.extend(right[j:]) return sorted_array, inversions def merge_sort(arr): if len(arr) <= 1: return arr, 0 middle = len(arr) // 2 left, left_inversions = merge_sort(arr[:middle]) right, right_inversions = merge_sort(arr[middle:]) merged, split_inversions = merge_and_count(left, right) total_inversions = left_inversions + right_inversions + split_inversions return merged, total_inversions sorted_array, inversion_count = merge_sort(array) return sorted_array, inversion_count"},{"question":"# Context: Create a function that simulates a basic digital communication channel, which takes a binary string and applies Gaussian noise to it. The function will output the noisy version of the binary string. # Function Specification: Implement a function `simulate_channel(binary_string: str, snr: float) -> str` that: * Takes as input: - `binary_string`: a string consisting of \'0\'s and \'1\'s representing the transmitted data. - `snr`: a float representing the Signal-to-Noise Ratio in decibels. * Returns: - A string representing the received binary data after adding noise. Constraints: * The noise should be Gaussian (normally distributed). * Use a threshold of 0.5 to determine if a bit should be flipped due to noise. * Assume the binary data is perfectly synchronized and does not suffer from synchronization errors. Examples: ```python >>> binary_string = \\"110010101100\\" >>> snr = 10 # SNR of 10 dB >>> noisy_string = simulate_channel(binary_string, snr) >>> noisy_string \\"110010001101\\" # Example output, the actual output may vary due to randomness in noise ``` Requirements: 1. Convert each bit in the binary string to a corresponding value of 1 (for \'1\') or -1 (for \'0\'). 2. Calculate the noise power from the given SNR. 3. Add Gaussian noise with the calculated power to each value. 4. Convert the noisy values back to \'0\' or \'1\' based on a threshold of 0.5. 5. Return the noisy binary string. # Additional Information: * You may use numpy for generating Gaussian noise. * Logarithm operations and power calculations are part of implementing the SNR-to-noise conversion. # Implementation: Write your solution within the function signature provided below: ```python import numpy as np def simulate_channel(binary_string: str, snr: float) -> str: Simulate a digital communication channel with Gaussian noise. Args: binary_string: The transmitted binary data as a string of \'0\'s and \'1\'s. snr: Signal-to-Noise Ratio in decibels. Returns: A string representing the received binary data after adding noise. # Convert binary string to array of 1s and -1s signal = np.array([1 if bit == \'1\' else -1 for bit in binary_string]) # Calculate noise power signal_power = np.mean(signal ** 2) snr_linear = 10 ** (snr / 10) noise_power = signal_power / snr_linear # Generate Gaussian noise noise = np.random.normal(0, np.sqrt(noise_power), signal.shape) # Add noise to signal noisy_signal = signal + noise # Thresholding to convert back to binary noisy_binary_string = \'\'.join(\'1\' if value > 0.5 else \'0\' for value in noisy_signal) return noisy_binary_string ```","solution":"import numpy as np def simulate_channel(binary_string: str, snr: float) -> str: Simulate a digital communication channel with Gaussian noise. Args: binary_string: The transmitted binary data as a string of \'0\'s and \'1\'s. snr: Signal-to-Noise Ratio in decibels. Returns: A string representing the received binary data after adding noise. # Convert binary string to array of 1s (for \'1\') and -1s (for \'0\') signal = np.array([1 if bit == \'1\' else -1 for bit in binary_string]) # Calculate noise power signal_power = np.mean(signal ** 2) snr_linear = 10 ** (snr / 10) noise_power = signal_power / snr_linear # Generate Gaussian noise noise = np.random.normal(0, np.sqrt(noise_power), signal.shape) # Add noise to signal noisy_signal = signal + noise # Thresholding to convert back to binary noisy_binary_string = \'\'.join(\'1\' if value > 0.5 else \'0\' for value in noisy_signal) return noisy_binary_string"},{"question":"# Problem Statement You are given a list of strings where each string is a word. Implement a function that performs a word frequency analysis on the list and then sorts the results by the frequency of the words in descending order. If two words have the same frequency, they should be sorted in alphabetical order. You need to complete the function: 1. `word_frequency_sort(words: list) -> list` Function Description 1. **word_frequency_sort** * **Input:** - `words (list)`: List of words (strings). * **Output:** - Returns a list of tuples where each tuple contains a word and its frequency, sorted by frequency in descending order and then alphabetically in case of ties. Performance Requirements The solution should be efficient with a time complexity of O(n log n) where n is the number of words. Input/Output Format * **Input Example:** ```python words = [\\"apple\\", \\"banana\\", \\"apple\\", \\"orange\\", \\"banana\\", \\"banana\\"] ``` * **Output Example:** ```python word_frequency_sort(words) # Output: [(\'banana\', 3), (\'apple\', 2), (\'orange\', 1)] ``` Make sure to handle edge cases such as an empty list of words or a list where all words are unique.","solution":"def word_frequency_sort(words): Performs a word frequency analysis on the list and sorts the results by the frequency of the words in descending order. If two words have the same frequency, they are sorted in alphabetical order. Args: words (list): List of words (strings). Returns: list: List of tuples where each tuple contains a word and its frequency. from collections import Counter # Count the frequency of each word word_count = Counter(words) # Sort by frequency (descending) and then alphabetically sorted_word_count = sorted(word_count.items(), key=lambda item: (-item[1], item[0])) return sorted_word_count"},{"question":"# Context You are developing a file management system that requires the capability to track changes in file sizes over time. To achieve this, you need to implement a specialized data structure that efficiently supports this functionality. # Task Implement a class `FileSizeTracker` that allows you to add, update, and retrieve the sizes of files. Additionally, it should be capable of determining the median file size among the tracked files at any given moment. # Class Definition ```python class FileSizeTracker: def __init__(self): Initialize your data structure here. def addFile(self, filename: str, filesize: int) -> None: Add a new file with its size. If the file already exists, overwrite its size. def updateFile(self, filename: str, newsize: int) -> None: Update the size of an existing file. def getMedianSize(self) -> float: Return the median size of all tracked files. If there are an even number of files, return the average of the two middle sizes. ``` # Methods - `__init__() -> None`: Initialize the data structure. - `addFile(filename: str, filesize: int) -> None`: Add a new file with its size. If the file already exists, overwrite its size. - `updateFile(filename: str, newsize: int) -> None`: Update the size of an existing file. - `getMedianSize() -> float`: Return the median size of all tracked files. If there are an even number of files, return the average of the two middle sizes. # Examples ```python tracker = FileSizeTracker() tracker.addFile(\'file1\', 100) tracker.addFile(\'file2\', 200) tracker.updateFile(\'file1\', 150) assert tracker.getMedianSize() == 175.0 tracker.addFile(\'file3\', 300) tracker.addFile(\'file4\', 400) assert tracker.getMedianSize() == 250.0 ``` # Constraints 1. Filenames are unique and will only contain alphanumeric characters and underscores. 2. Files sizes are non-negative integers. 3. It is guaranteed that `addFile` and `updateFile` will always have valid inputs. 4. The number of files can grow large, so optimize for both time and space efficiency, especially for the `getMedianSize` method. # Edge Cases 1. When no files are being tracked, `getMedianSize` should handle this scenario appropriately, for example, by raising an exception or returning `None`. 2. Ensure the implementation can handle adding, updating, and retrieving the sizes for a large number of files efficiently.","solution":"import bisect class FileSizeTracker: def __init__(self): Initialize your data structure here. self.file_sizes = {} self.sorted_sizes = [] def addFile(self, filename: str, filesize: int) -> None: Add a new file with its size. If the file already exists, overwrite its size. if filename in self.file_sizes: # Removing old file size from sorted list old_size = self.file_sizes[filename] self.sorted_sizes.remove(old_size) # Inserting new file size into the sorted list bisect.insort(self.sorted_sizes, filesize) self.file_sizes[filename] = filesize def updateFile(self, filename: str, newsize: int) -> None: Update the size of an existing file. if filename in self.file_sizes: # Removing old file size from sorted list old_size = self.file_sizes[filename] self.sorted_sizes.remove(old_size) # Inserting new file size into the sorted list bisect.insort(self.sorted_sizes, newsize) self.file_sizes[filename] = newsize def getMedianSize(self) -> float: Return the median size of all tracked files. If there are an even number of files, return the average of the two middle sizes. if not self.sorted_sizes: return None # or raise an exception n = len(self.sorted_sizes) mid = n // 2 if n % 2 == 1: # Odd number of elements return float(self.sorted_sizes[mid]) else: # Even number of elements return (self.sorted_sizes[mid - 1] + self.sorted_sizes[mid]) / 2"},{"question":"Question: Given a positive integer `n`, your task is to write a function that generates the `n`th Fibonacci number. This test is designed to assess your understanding of recursion and dynamic programming in Python. # Requirements: 1. **Function**: `def fibonacci(n: int) -> int:` 2. **Input**: * A positive integer `n`, e.g., `5`. 3. **Output**: * The `n`th Fibonacci number. 4. **Constraints**: * 1 <= n <= 30 5. **Performance**: * You should aim for a time complexity of O(n). * O(1) additional space (not accounting for the space used by the input and function stack). # Scenario: A programming enthusiast presented you with a challenge to implement a function that can quickly compute the nth Fibonacci number. You decide to take a step further and ensure your implementation uses dynamic programming to achieve efficient computation. # Example: Input: `5` Output: `5` Explanation: The first five Fibonacci numbers are `[0, 1, 1, 2, 3, 5]`, so the 5th Fibonacci number is `5`. # Edge Cases to Consider: * Ensure the function handles the smallest input size (n=1) by returning the first Fibonacci number properly. * Consider the efficiency of your implementation for the largest possible value within constraints. # Additional Tests: Make sure your implementation passes the expected outputs for the following scenarios: 1. Input: `1` Output: `0` 2. Input: `2` Output: `1` 3. Input: `10` Output: `34` 4. Input: `15` Output: `377` # Instructions: * Implement your solution in Python. * Ensure your code is efficient and includes necessary comments for clarity. * Test your solution against multiple test cases to verify correctness.","solution":"def fibonacci(n: int) -> int: Generates the nth Fibonacci number. if n <= 0: raise ValueError(\\"Input must be a positive integer\\") if n == 1: return 0 if n == 2: return 1 fib_1, fib_2 = 0, 1 for _ in range(3, n + 1): fib_1, fib_2 = fib_2, fib_1 + fib_2 return fib_2"},{"question":"# JSON Data Validator **Context**: You are working on a data validation module for an API that handles incoming JSON payloads. Each payload must follow a specific schema format, and you need to ensure the data integrity before processing it further. **Task**: Implement the function `validate_json(payload: dict) -> bool` that validates whether a given JSON object adheres to the specified schema. The schema requirements are: - The JSON must contain the keys: `\\"name\\"`, `\\"age\\"`, and `\\"email\\"`. - The value of `\\"name\\"` must be a non-empty string. - The value of `\\"age\\"` must be an integer between 1 and 120 (inclusive). - The value of `\\"email\\"` must be a string containing an \\"@\\" symbol. **Function Signature**: ```python def validate_json(payload: dict) -> bool: ``` **Input**: - `payload` (dict): A JSON object represented as a dictionary. **Output**: - (bool): `True` if the JSON object adheres to the schema; otherwise, `False`. **Constraints**: - The input JSON will have no nested structures, making it a flat dictionary. - The input JSON may contain additional keys, which should be ignored. - All values will be basic data types (no lists or nested objects). **Examples**: ```python assert validate_json({\\"name\\": \\"Alice\\", \\"age\\": 30, \\"email\\": \\"alice@example.com\\"}) == True assert validate_json({\\"name\\": \\"\\", \\"age\\": 30, \\"email\\": \\"alice@example.com\\"}) == False assert validate_json({\\"name\\": \\"Bob\\", \\"age\\": 130, \\"email\\": \\"bob@example.com\\"}) == False assert validate_json({\\"name\\": \\"Charlie\\", \\"age\\": 25, \\"email\\": \\"charlie-at-example.com\\"}) == False assert validate_json({\\"name\\": \\"Dave\\", \\"age\\": 40, \\"email\\": \\"dave@example.com\\", \\"country\\": \\"USA\\"}) == True assert validate_json({\\"age\\": 25, \\"email\\": \\"charlie@example.com\\"}) == False ``` **Additional Notes**: 1. The validation function should be robust and handle edge cases such as missing keys or data types mismatch. 2. Be mindful of the constraints and optimize for performance where applicable. 3. Consider using regular expressions to validate the email format succinctly.","solution":"def validate_json(payload: dict) -> bool: Validates if the given JSON object adheres to the schema: - Contains the keys: \\"name\\", \\"age\\", \\"email\\". - \\"name\\" is a non-empty string. - \\"age\\" is an integer between 1 and 120 (inclusive). - \\"email\\" contains an \\"@\\" symbol. Args: payload (dict): The JSON object to validate. Returns: bool: True if the JSON object adheres to the schema, otherwise False. # Check if required keys are present required_keys = [\\"name\\", \\"age\\", \\"email\\"] if not all(key in payload for key in required_keys): return False # Validate \\"name\\" if not isinstance(payload[\\"name\\"], str) or not payload[\\"name\\"]: return False # Validate \\"age\\" if not isinstance(payload[\\"age\\"], int) or not (1 <= payload[\\"age\\"] <= 120): return False # Validate \\"email\\" if not isinstance(payload[\\"email\\"], str) or \\"@\\" not in payload[\\"email\\"]: return False return True"},{"question":"# Collecting Key-Value Items from Nested Dictionary Context: As a software engineer, you might often deal with JSON responses or nested dictionaries where you need to extract specific key-value pairs regardless of the depth. Being able to traverse such dictionaries and collect items efficiently is an essential skill. Task: Write a function `collect_items(nested_dict: dict, target_key: str) -> list` that extracts all values associated with a given key in a nested dictionary. The function should search through all levels of nesting and return a list of values that are associated with the specified key. Input: * A nested dictionary `nested_dict`. * A string `target_key` representing the key to search for. Output: * A list of all values associated with the `target_key`. Example: ```python def collect_items(nested_dict: dict, target_key: str) -> list: Example usage: >>> collect_items({\'a\': 1, \'b\': {\'a\': 2, \'c\': {\'a\': 3, \'d\': 4}}}, \'a\') [1, 2, 3] >>> collect_items({\'x\': {\'y\': {\'z\': 1}}, \'y\': 2}, \'y\') [2, {\'z\': 1}] >>> collect_items({\'key\': \'value\', \'nested\': {\'key\': \'nested_value\'}}, \'key\') [\'value\', \'nested_value\'] ``` Constraints: * The nested dictionary may have any depth of nesting. * The target key will always be a string. * The function should handle cases where the target key does not exist in the dictionary gracefully, returning an empty list. **Edge Cases to Consider**: * If the target key doesn\'t exist at any level of the dictionary, the function should return an empty list. * Dictionaries with varying depths should be processed correctly, returning all occurrences of the target key. Requirements: * Ensure your function can handle deeply nested structures. * Maintain an efficient approach to traversing and collecting key-value pairs.","solution":"def collect_items(nested_dict: dict, target_key: str) -> list: Extracts all values associated with the specified target_key in a nested dictionary. :param nested_dict: Dictionary with nested structures :param target_key: Key to search for throughout the nested dictionary :return: List of values associated with the target_key result = [] def recursive_search(d): if isinstance(d, dict): for k, v in d.items(): if k == target_key: result.append(v) recursive_search(v) elif isinstance(d, list): for item in d: recursive_search(item) recursive_search(nested_dict) return result"},{"question":"# Context Sorting algorithms are fundamental in computer science. One such algorithm that is versatile and efficient for a variety of datasets is the merge sort algorithm. # Problem Statement Implement the `merge_sort` function to sort a list of integers in ascending order. # Task Create a function `merge_sort` that implements the merge sort algorithm. The function should take a list of integers as input and return a new list that is a sorted version of the input list. # Function Signature ```python from typing import List def merge_sort(arr: List[int]) -> List[int]: pass ``` # Input * A list of integers `arr` where `1 <= len(arr) <= 1000` and each integer `0 <= arr[i] <= 10^5`. # Output * A new list `sorted_arr`, which contains all the elements of `arr` arranged in ascending order. # Example Usage ```python # Example Usage input_list = [38, 27, 43, 3, 9, 82, 10] print(merge_sort(input_list)) # Should output [3, 9, 10, 27, 38, 43, 82] input_list = [1, 4, 2, 8, 5, 7] print(merge_sort(input_list)) # Should output [1, 2, 4, 5, 7, 8] ``` # Constraints 1. The implemented function should not modify the original input list. 2. You may assume the input list contains no duplicate values. 3. Aim for a time complexity of O(n log n) and space complexity of O(n) for a list of size `n`. # Notes * The merge sort algorithm involves recursively dividing the list into halves, sorting each half, and then merging the sorted halves back together. * Be mindful of the function’s time complexity, especially how you handle splitting and merging operations.","solution":"from typing import List def merge_sort(arr: List[int]) -> List[int]: Sorts the list of integers in ascending order using the merge sort algorithm. if len(arr) <= 1: return arr def merge(left: List[int], right: List[int]) -> List[int]: sorted_list = [] left_index, right_index = 0, 0 # Merge the two halves in sorted order while left_index < len(left) and right_index < len(right): if left[left_index] < right[right_index]: sorted_list.append(left[left_index]) left_index += 1 else: sorted_list.append(right[right_index]) right_index += 1 # Collect the remaining elements from both halves sorted_list.extend(left[left_index:]) sorted_list.extend(right[right_index:]) return sorted_list mid = len(arr) // 2 left_half = merge_sort(arr[:mid]) right_half = merge_sort(arr[mid:]) return merge(left_half, right_half)"},{"question":"# Rotating a Sublist of an Array Given an array of integers and two integer indices, your task is to rotate the elements within the sublist defined by these indices to the left. Rotating a sublist to the left means moving each element within the sublist one position to the left and placing the first element of the sublist at the end of the sublist. Write a function `rotate_sublist` to achieve this. # Function Signature ```python def rotate_sublist(arr: List[int], start: int, end: int) -> List[int]: pass ``` # Input * `arr`: A list of integers. * `start`: An integer representing the starting index (inclusive) of the sublist. * `end`: An integer representing the ending index (inclusive) of the sublist. # Output * Returns a list of integers where the specified sublist has been rotated to the left. # Constraints * 0 <= start <= end < len(arr) * The list `arr` will have at most 1000 elements. # Example ```python >>> rotate_sublist([1, 2, 3, 4, 5, 6], 1, 4) [1, 3, 4, 5, 2, 6] >>> rotate_sublist([10, 20, 30, 40, 50], 0, 2) [20, 30, 10, 40, 50] >>> rotate_sublist([7, 8, 9], 1, 2) [7, 9, 8] ``` In the function `rotate_sublist`, ensure correct shuffling of elements in the specified sublist without affecting the elements outside this range.","solution":"def rotate_sublist(arr, start, end): Rotates the sublist of arr from start to end indices to the left. if start < end: sublist = arr[start:end + 1] rotated_sublist = sublist[1:] + [sublist[0]] arr[start:end + 1] = rotated_sublist return arr"},{"question":"# Problem Statement Create a function `rotate_and_find_min(matrix: List[List[int]]) -> int` that rotates an NxN matrix 90 degrees clockwise and then finds and returns the minimum value in the rotated matrix. # Function Signature ```python def rotate_and_find_min(matrix: List[List[int]]) -> int: pass ``` # Input - `matrix`: A 2D list of integers representing an NxN matrix, where `1 ≤ N ≤ 1000`. # Output - Return the minimum integer value found in the rotated matrix. # Constraints - The elements in the matrix are within the range of standard 32-bit integers. # Requirements - Rotate the matrix 90 degrees clockwise. - Find and return the minimum value in the rotated matrix. - You may not use built-in functions for matrix rotation. # Example ```python assert rotate_and_find_min([[1, 2], [3, 4]]) == 1 assert rotate_and_find_min([[5, -1], [2, 3]]) == -1 assert rotate_and_find_min([[10, 15, 30], [5, 7, 8], [2, 3, 6]]) == 2 ``` # Notes - Ensure the matrix rotation is implemented without using high-level built-in functions. - Consider handling different matrix sizes efficiently. - Take special care of the matrix bounds to ensure there are no out-of-bound errors during the rotation.","solution":"from typing import List def rotate_and_find_min(matrix: List[List[int]]) -> int: n = len(matrix) # Rotate the matrix 90 degrees clockwise rotated_matrix = [[0]*n for _ in range(n)] for i in range(n): for j in range(n): rotated_matrix[j][n-1-i] = matrix[i][j] # Find the minimum value in the rotated matrix min_value = float(\'inf\') for row in rotated_matrix: for value in row: if value < min_value: min_value = value return min_value"},{"question":"# Sparse Matrix Multiplication You are tasked with implementing an efficient multiplication routine for two sparse matrices represented in a coordinate list (COO) format. A sparse matrix is a matrix where most of the elements are zero, and the COO format only stores the non-zero elements. Task: Implement a function `sparse_matrix_multiply(A: List[Tuple[int, int, int]], B: List[Tuple[int, int, int]], A_shape: Tuple[int, int], B_shape: Tuple[int, int]) -> List[Tuple[int, int, int]]` that: 1. Multiplies the sparse matrices `A` and `B`. 2. Returns the result in COO format as a list of tuples. Function Input: - `A`: A list of tuples representing the non-zero elements of matrix A. Each tuple is of the form `(row_index, col_index, value)`. - `B`: A list of tuples representing the non-zero elements of matrix B. Each tuple is of the form `(row_index, col_index, value)`. - `A_shape`: A tuple representing the shape of matrix A (number of rows, number of columns). - `B_shape`: A tuple representing the shape of matrix B (number of rows, number of columns). Function Output: - Returns a list of tuples representing the non-zero elements of the resultant matrix C in COO format. Each tuple is of the form `(row_index, col_index, value)`. Constraints: - `1 <= len(A), len(B) <= 10^5` - The number of rows and columns in matrices A and B are positive integers not exceeding 1000. - Matrix dimensions must allow for valid multiplication (i.e., the number of columns in A must equal the number of rows in B). Example: ```python A = [ (0, 0, 1), (0, 1, 2), (1, 0, 3) ] B = [ (0, 0, 4), (1, 0, 5) ] A_shape = (2, 2) B_shape = (2, 1) result = sparse_matrix_multiply(A, B, A_shape, B_shape) print(result) # Expected output: [(0, 0, 14), (1, 0, 12)] ``` Note: - Carefully handle the multiplication when iterating through the non-zero elements. - Ensure that the output respects the sparse format by consolidating any potential duplicate entries if they appear during the multiplication process. Implementation Tip: - Use dictionaries or default dictionaries to accumulate sums for each coordinate to efficiently manage the resultant sparse matrix\'s non-zero entries.","solution":"from collections import defaultdict from typing import List, Tuple def sparse_matrix_multiply(A: List[Tuple[int, int, int]], B: List[Tuple[int, int, int]], A_shape: Tuple[int, int], B_shape: Tuple[int, int]) -> List[Tuple[int, int, int]]: # Resultant matrix dimension result_shape = (A_shape[0], B_shape[1]) # Dictionary to store non-zero values of matrix B for quick lookup B_dict = defaultdict(list) for row, col, value in B: B_dict[row].append((col, value)) # Dictionary to accumulate results result = defaultdict(int) # Iterate over all non-zero elements in A for i, j, a_value in A: if j in B_dict: for b_col, b_value in B_dict[j]: result[(i, b_col)] += a_value * b_value # Convert result to list of tuples result_coo = [(i, j, val) for (i, j), val in result.items() if val != 0] return result_coo"},{"question":"# Coding Question You are tasked with developing a utility that checks if a given string contains a valid mathematical expression of parentheses. Your solution should implement the main function `is_valid_parentheses(expression: str) -> bool` which determines the validity of the parentheses. Function Signature ```python def is_valid_parentheses(expression: str) -> bool: # implementation goes here ``` # Requirements 1. **Input**: - `expression` (str): A string containing the mathematical expression which may include parentheses `()`, `{}`, `[]`. 2. **Output**: - Returns a boolean value (`True` or `False`) indicating if the parentheses in the expression are valid. # Constraints 1. The function must ensure that every opening parenthesis has a corresponding closing parenthesis and they are in the correct order. 2. The function should only check the validity of the parentheses and ignore all other characters. 3. Consider nested and sequential parentheses properly. # Example Scenarios Example 1: ```python print(is_valid_parentheses(\\"((1 + 2) * 3)\\")) # Expected Output: True ``` Example 2: ```python print(is_valid_parentheses(\\"{[1 + 2] * (3 / 4)}\\")) # Expected Output: True ``` Example 3: ```python print(is_valid_parentheses(\\"((1 + 2) * 3\\")) # Expected Output: False ``` Example 4: ```python print(is_valid_parentheses(\\"{[1 + 2] * (3 / 4)]}\\")) # Expected Output: False ``` # Notes - The function should efficiently parse through the string to evaluate the parentheses. - Make sure the function handles various types of invalid expressions gracefully. - Consider optimizing the function to handle large inputs if necessary. Present your code in a clean, readable format with appropriate use of data structures and comments.","solution":"def is_valid_parentheses(expression: str) -> bool: Returns True if the parentheses in the expression are valid, otherwise False. A valid expression has every opening parenthesis properly closed in the correct order. stack = [] parentheses_map = {\')\': \'(\', \'}\': \'{\', \']\': \'[\'} for char in expression: if char in parentheses_map.values(): stack.append(char) elif char in parentheses_map.keys(): if stack == [] or parentheses_map[char] != stack.pop(): return False elif not stack: return True else: continue # ignore other characters return stack == []"},{"question":"# Sorted Squares Array You are given an integer array `nums` sorted in non-decreasing order. You need to implement a function that returns a new array containing the squares of each number in `nums`, also sorted in non-decreasing order. Function Signature: ```python def sorted_squares(nums: List[int]) -> List[int]: ``` Input: * `nums` (List[int]): A list of integers sorted in non-decreasing order. Output: * (List[int]): A list of the squares of each number in `nums` sorted in non-decreasing order. Constraints: * `1 <= len(nums) <= 10^4` * `-10^4 <= nums[i] <= 10^4` * `nums` is sorted in non-decreasing order. Example: ```python sorted_squares([-4,-1,0,3,10]) # Expected output: [0, 1, 9, 16, 100] sorted_squares([-7,-3,2,3,11]) # Expected output: [4, 9, 9, 49, 121] ``` Implement your function to handle edge cases, performance concerns, and large input sizes efficiently.","solution":"from typing import List def sorted_squares(nums: List[int]) -> List[int]: Returns a new array containing the squares of each number in nums, sorted in non-decreasing order. n = len(nums) result = [0] * n left, right = 0, n - 1 for i in range(n - 1, -1, -1): if abs(nums[left]) > abs(nums[right]): result[i] = nums[left] ** 2 left += 1 else: result[i] = nums[right] ** 2 right -= 1 return result"},{"question":"# Coding Challenge: Valid Sudoku **Problem Statement**: Determine if a given 9x9 Sudoku board is valid. The Sudoku board could be partially filled, where empty cells are filled with the character \'.\'. A valid board: - Contains digits 1-9 without repetition in each row. - Contains digits 1-9 without repetition in each column. - Contains digits 1-9 without repetition in each of the nine 3x3 sub-grids. **Function Specification**: Implement the function `is_valid_sudoku(board: list) -> bool` to verify the validity of the Sudoku board. # Input - A 2D list `board` representing a 9x9 grid. Each element can be a digit \'1\'-\'9\' or the character \'.\'. # Output - Return `True` if the board is valid, otherwise `False`. # Constraints - The board should be a 9x9 grid containing only \'1\'-\'9\' and \'.\' characters. - The function should run in O(1) time complexity with respect to the number of cells (since the board size is constant) and use O(1) space complexity, excluding input/output space. # Example 1. Given input: ``` [ [\\"5\\",\\"3\\",\\".\\",\\".\\",\\"7\\",\\".\\",\\".\\",\\".\\",\\".\\"], [\\"6\\",\\".\\",\\".\\",\\"1\\",\\"9\\",\\"5\\",\\".\\",\\".\\",\\".\\"], [\\".\\",\\"9\\",\\"8\\",\\".\\",\\".\\",\\".\\",\\".\\",\\"6\\",\\".\\"], [\\"8\\",\\".\\",\\".\\",\\".\\",\\"6\\",\\".\\",\\".\\",\\".\\",\\"3\\"], [\\"4\\",\\".\\",\\".\\",\\"8\\",\\".\\",\\"3\\",\\".\\",\\".\\",\\"1\\"], [\\"7\\",\\".\\",\\".\\",\\".\\",\\"2\\",\\".\\",\\".\\",\\".\\",\\"6\\"], [\\".\\",\\"6\\",\\".\\",\\".\\",\\".\\",\\".\\",\\"2\\",\\"8\\",\\".\\"], [\\".\\",\\".\\",\\".\\",\\"4\\",\\"1\\",\\"9\\",\\".\\",\\".\\",\\"5\\"], [\\".\\",\\".\\",\\".\\",\\".\\",\\"8\\",\\".\\",\\".\\",\\"7\\",\\"9\\"] ] ``` Expected output: `True` 2. Given input: ``` [ [\\"8\\",\\"3\\",\\".\\",\\".\\",\\"7\\",\\".\\",\\".\\",\\".\\",\\".\\"], [\\"6\\",\\".\\",\\".\\",\\"1\\",\\"9\\",\\"5\\",\\".\\",\\".\\",\\".\\"], [\\".\\",\\"9\\",\\"8\\",\\".\\",\\".\\",\\".\\",\\".\\",\\"6\\",\\".\\"], [\\"8\\",\\".\\",\\".\\",\\".\\",\\"6\\",\\".\\",\\".\\",\\".\\",\\"3\\"], [\\"4\\",\\".\\",\\".\\",\\"8\\",\\".\\",\\"3\\",\\".\\",\\".\\",\\"1\\"], [\\"7\\",\\".\\",\\".\\",\\".\\",\\"2\\",\\".\\",\\".\\",\\".\\",\\"6\\"], [\\".\\",\\"6\\",\\".\\",\\".\\",\\".\\",\\".\\",\\"2\\",\\"8\\",\\".\\"], [\\".\\",\\".\\",\\".\\",\\"4\\",\\"1\\",\\"9\\",\\".\\",\\".\\",\\"5\\"], [\\".\\",\\".\\",\\".\\",\\".\\",\\"8\\",\\".\\",\\".\\",\\"7\\",\\"9\\"] ] ``` Expected output: `False` (The number \'8\' is repeated in the first column) # Edge Cases 1. The board is completely empty. 2. The board is completely filled and valid. 3. The board is completely filled but invalid. **Note**: The examples provided in the problem statement are not exhaustive. Ensure to thoroughly test your code against various edge cases. ```python def is_valid_sudoku(board: list) -> bool: Determine if a given 9x9 Sudoku board is valid. Args: board (list): 2D list representing a 9x9 grid Returns: bool: True if the board is valid, False otherwise def is_valid_unit(unit): unit = [i for i in unit if i != \'.\'] return len(unit) == len(set(unit)) # Check rows and columns for i in range(9): if not is_valid_unit(board[i]) or not is_valid_unit([board[j][i] for j in range(9)]): return False # Check 3x3 sub-grids for i in (0, 3, 6): for j in (0, 3, 6): if not is_valid_unit([board[x][y] for x in range(i, i+3) for y in range(j, j+3)]): return False return True ```","solution":"def is_valid_sudoku(board: list) -> bool: Determine if a given 9x9 Sudoku board is valid. Args: board (list): 2D list representing a 9x9 grid Returns: bool: True if the board is valid, False otherwise def is_valid_unit(unit): unit = [i for i in unit if i != \'.\'] return len(unit) == len(set(unit)) # Check rows and columns for i in range(9): if not is_valid_unit(board[i]) or not is_valid_unit([board[j][i] for j in range(9)]): return False # Check 3x3 sub-grids for i in (0, 3, 6): for j in (0, 3, 6): if not is_valid_unit([board[x][y] for x in range(i, i+3) for y in range(j, j+3)]): return False return True"},{"question":"# Coding Assessment Question: Implement a Binary Search Tree Inversion You are tasked to implement functionality for inverting a Binary Search Tree (BST), transforming it into a mirror image of itself. **Context**: Inverting a BST involves swapping the left and right children of all nodes in the tree, resulting in the BST\'s mirror image. The inverted tree should still maintain the overall structure but with left-right children exchanged at each level. **Instructions**: 1. **Function**: Implement `invert_bst`. # Function Definition: * `invert_bst(root: TreeNode) -> TreeNode` * **Input**: * `root`: A TreeNode object representing the root of the BST. * **Output**: * Returns the root of the inverted BST. # Specifications: * A `TreeNode` is defined as: ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right ``` * Traverse the tree and recursively invert all nodes, swapping their left and right children. * Nodes should be swapped in place, and the root node should point to the root of the modified tree upon function completion. # Constraints: * The input BST can have up to (10^4) nodes. * Values within the nodes are unique and fit within 32-bit signed integers. # Example: ```python # Tree representation before inversion: # 4 # / # 2 7 # / / # 1 3 6 9 root = TreeNode(4) root.left = TreeNode(2, TreeNode(1), TreeNode(3)) root.right = TreeNode(7, TreeNode(6), TreeNode(9)) # Invert the BST inverted_root = invert_bst(root) # After inversion, the tree representation should be: # 4 # / # 7 2 # / / # 9 6 3 1 ``` Good luck and demonstrate your ability to handle the inversion of binary search trees efficiently and correctly!","solution":"class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def invert_bst(root: TreeNode) -> TreeNode: if not root: return None # Swap the left and right children root.left, root.right = root.right, root.left # Recur on left and right subtrees invert_bst(root.left) invert_bst(root.right) return root"},{"question":"# Problem Statement You need to implement a function that normalizes a given list of non-negative integers using Min-Max Scaling. The Min-Max scaling transforms the values such that the minimum value in the array becomes 0 and the maximum value becomes 1, with all other values scaled proportionally in between. # Function Signature ```python def min_max_scale(data: List[int]) -> List[float]: Normalize the given list of non-negative integers using Min-Max Scaling. Parameters: data (List[int]): A list of non-negative integers. Returns: List[float]: A list of normalized floating-point numbers. Examples: >>> min_max_scale([0, 5, 10, 15]) [0.0, 0.33333333, 0.66666667, 1.0] >>> min_max_scale([1, 2, 3, 4]) [0.0, 0.33333333, 0.66666667, 1.0] >>> min_max_scale([5, 5, 5, 5]) [0.0, 0.0, 0.0, 0.0] ``` # Requirements 1. **Input**: * A list of non-negative integers, `data`, of length N where N is at least 1. 2. **Output**: * A list of floating-point numbers of the same length as `data`, representing the normalized values. 3. **Constraints**: * If all elements in `data` are the same, return a list of zeros of the same length. # Example Scenarios Example 1: * **Input**: `[0, 5, 10, 15]` * **Output**: `[0.0, 0.33333333, 0.66666667, 1.0]` * **Explanation**: The minimum value (0) is scaled to 0 and the maximum value (15) is scaled to 1. Example 2: * **Input**: `[1, 2, 3, 4]` * **Output**: `[0.0, 0.33333333, 0.66666667, 1.0]` * **Explanation**: The minimum value (1) is scaled to 0 and the maximum value (4) is scaled to 1. Example 3: * **Input**: `[5, 5, 5, 5]` * **Output**: `[0.0, 0.0, 0.0, 0.0]` * **Explanation**: All values being the same results in a normalized list of zeros. # Notes 1. Ensure the function handles cases where all elements in the list are the same. 2. The function should be efficient and scalable for larger lists. 3. Consider edge cases such as a list containing only one element. # Hints 1. You may use basic list operations and arithmetic to achieve the scaling. 2. Be mindful of floating-point precision and round-off errors in Python.","solution":"from typing import List def min_max_scale(data: List[int]) -> List[float]: Normalize the given list of non-negative integers using Min-Max Scaling. Parameters: data (List[int]): A list of non-negative integers. Returns: List[float]: A list of normalized floating-point numbers. if len(data) <= 1: return [0.0] * len(data) min_value = min(data) max_value = max(data) if max_value == min_value: return [0.0] * len(data) scaled_data = [(x - min_value) / (max_value - min_value) for x in data] return scaled_data"},{"question":"**Problem Statement:** Given an integer array `nums`, find the maximum length of a subarray that has an equal number of 0\'s and 1\'s. **Objective:** Write a function `find_max_length(nums: List[int]) -> int` that computes the length of the largest subarray with an equal number of 0\'s and 1\'s. **Input:** - A list `nums` consisting of integers 0 and 1 with length `n` (1 <= n <= 100,000). **Output:** - An integer representing the maximum length of the subarray. **Examples:** ```python assert find_max_length([0, 1]) == 2 assert find_max_length([0, 1, 0]) == 2 assert find_max_length([0, 1, 0, 1, 0, 1, 1, 0]) == 8 assert find_max_length([1, 1, 1, 1, 0, 0, 0, 0]) == 8 assert find_max_length([1, 0, 1, 0, 1, 1, 0, 0, 1, 0]) == 10 ``` **Constraints:** - You must ensure your solution has a time complexity of O(n) and space complexity of O(n). - The input list will only contain the integers 0 and 1. **Explanation:** - Convert the problem of counting 0\'s and 1\'s to a problem of finding the largest subarray with sum zero. - Transform the array by converting all 0\'s to -1\'s. - Use a hash map to store the first occurrence of each cumulative sum. - Iterate through the transformed array, keeping track of the cumulative sum. - Update the maximum length whenever the same cumulative sum is encountered again. **Detailed Requirements:** 1. Write a Python function named `find_max_length`. 2. The function should take one list of integers `nums` as the input. 3. Return the length of the longest subarray with an equal number of 0\'s and 1\'s. 4. Ensure the solution handles large input values efficiently.","solution":"from typing import List def find_max_length(nums: List[int]) -> int: count_map = {0: -1} # Map to store the first occurrence of each count max_length = 0 count = 0 for i, num in enumerate(nums): # Convert 0 to -1 to make the counting easier count += 1 if num == 1 else -1 if count in count_map: # If count has been seen before, update max_length max_length = max(max_length, i - count_map[count]) else: # Store the first occurrence of this count count_map[count] = i return max_length"},{"question":"# Scenario A home automation company aims to develop an intelligent light control system where the lights can be turned on or off based on certain conditions such as time of the day, ambient light intensity, and presence of a person in the room. # Task 1. **Function Requirement: `control_lights`** - **Purpose**: Create a function to control the state of the lights based on input conditions related to time, ambient light intensity, and presence detection. - **Input**: - `current_time: str`: Current time in \\"HH:MM\\" 24-hour format. - `ambient_light: int`: Ambient light intensity (range 0-100, where 0 is complete darkness and 100 is very bright). - `presence_detected: bool`: Boolean indicating whether a person is detected in the room. - `light_state: str`: Current state of the lights, either \\"on\\" or \\"off\\". - **Output**: - Returns the new state of the lights, either \\"on\\" or \\"off\\". 2. **Function Requirement: `schedule_lights`** - **Purpose**: Create a function to define a schedule for turning the lights on and off at specific times. - **Input**: - `on_schedule: str`: Time to turn on the lights in \\"HH:MM\\" 24-hour format. - `off_schedule: str`: Time to turn off the lights in \\"HH:MM\\" 24-hour format. - `current_time: str`: Current time in \\"HH:MM\\" 24-hour format. - **Output**: - Returns the scheduled state of the lights, either \\"on\\" or \\"off\\". # Constraints: - Handle edge cases such as invalid time formats and unintended time overlaps. - Consider daylight saving transitions where applicable. - Ensure the lights only change state at the scheduled times and adjust immediately when the presence of a person is detected. - Raise custom exceptions with meaningful messages in case of critical errors. # Example ```python # Example Usage current_time = \\"21:30\\" ambient_light = 40 presence_detected = True light_state = \\"off\\" # 1. Control lights based on conditions new_light_state = control_lights(current_time, ambient_light, presence_detected, light_state) print(new_light_state) # Expected output: \\"on\\" based on given conditions on_schedule = \\"18:00\\" off_schedule = \\"06:00\\" # 2. Schedule lights based on time scheduled_state = schedule_lights(on_schedule, off_schedule, current_time) print(scheduled_state) # Expected output: \\"on\\" based on the current time and schedule ```","solution":"from datetime import datetime class TimeFormatError(Exception): pass def control_lights(current_time, ambient_light, presence_detected, light_state): Controls the state of the lights based on time of the day, ambient light intensity, and presence of a person in the room. # Check time format try: datetime.strptime(current_time, \\"%H:%M\\") except ValueError: raise TimeFormatError(\\"Invalid time format. Use \'HH:MM\' 24-hour format.\\") if not (0 <= ambient_light <= 100): raise ValueError(\\"Ambient light should be in the range 0-100.\\") if presence_detected: return \'on\' if ambient_light < 30: return \'on\' return \'off\' def schedule_lights(on_schedule, off_schedule, current_time): Defines a schedule for turning the lights on and off at specific times. try: on_time = datetime.strptime(on_schedule, \\"%H:%M\\").time() off_time = datetime.strptime(off_schedule, \\"%H:%M\\").time() current = datetime.strptime(current_time, \\"%H:%M\\").time() except ValueError: raise TimeFormatError(\\"Invalid time format. Use \'HH:MM\' 24-hour format.\\") if on_time < off_time: if on_time <= current < off_time: return \'on\' else: if current >= on_time or current < off_time: return \'on\' return \'off\'"},{"question":"# Coding Assessment Question **Context**: You are working on a financial application that helps users track their expenses. Your task is to implement a feature that calculates the monthly budget summary based on user expenses. This functionality will help users understand their spending habits and adjust their budgets accordingly. # Task Write a function `monthly_budget_summary` that takes a list of individual expenses and categorizes them into predefined categories. Then, return a summary that shows the total amount spent in each category for the given month. # Function Signature ```python def monthly_budget_summary(expenses: List[Tuple[str, float]]) -> Dict[str, float]: ``` # Input - `expenses` (List[Tuple[str, float]]): A list of tuples where each tuple contains a category (str) and an amount (float) representing the expense. # Output - Returns a dictionary where keys are the categories (as strings) and values are the total amounts spent in each category (as floats). # Constraints - Ensure to handle categories such as \'Groceries\', \'Utilities\', \'Entertainment\', \'Healthcare\', \'Miscellaneous\', etc. - Handle edge cases such as empty lists or invalid data types gracefully. - Validate that the amount in each expense is a non-negative number. # Example ```python expenses = [ (\'Groceries\', 150.0), (\'Utilities\', 100.0), (\'Entertainment\', 200.0), (\'Groceries\', 50.0), (\'Healthcare\', 75.0) ] print(monthly_budget_summary(expenses)) ``` Expected Output: ``` { \'Groceries\': 200.0, \'Utilities\': 100.0, \'Entertainment\': 200.0, \'Healthcare\': 75.0 } ``` # Additional Information 1. Ensure that the function is efficient enough to handle a large number of expense entries. 2. Consider edge cases, such as missing categories or negative values in expenses, and handle them appropriately. 3. This function can be extended to include more sophisticated financial analysis in future iterations. For now, focus on accurately categorizing and summing expenses.","solution":"from typing import List, Tuple, Dict def monthly_budget_summary(expenses: List[Tuple[str, float]]) -> Dict[str, float]: Categorizes expenses and returns a summary of the total amount spent in each category. Parameters: - expenses: List of tuples where each tuple contains a category (str) and an amount (float) Returns: - Dictionary with categories as keys and total amounts spent as values summary = {} for category, amount in expenses: if not isinstance(category, str) or not isinstance(amount, (int, float)) or amount < 0: raise ValueError(\\"Invalid category or amount in expenses\\") if category not in summary: summary[category] = 0.0 summary[category] += amount return summary"},{"question":"# Coding Assessment Question Scenario You are assigned to develop a component for an online shopping system that handles dynamic inventory management. Each product in the inventory has a unique identifier and a quantity available. The goal is to efficiently process a series of operations to maintain and query the inventory state. Task Write a function to process a sequence of operations on an initially empty inventory. Each operation can either: - Add a new product with a specified quantity. - Update the quantity of an existing product. - Remove a specified product from the inventory. - Retrieve the quantity of a specific product. Function Signature ```python def process_inventory_operations(operations: List[Tuple[str, Union[int, Tuple[int, int]]]]) -> List[int]: Processes a sequence of inventory operations and returns results of query operations. :param operations: A list of tuples where each tuple represents an operation. - \\"add\\", (product_id, quantity): Adds a product with the specified quantity. - \\"update\\", (product_id, new_quantity): Updates the quantity of the specified product. - \\"remove\\", product_id: Removes the specified product from the inventory. - \\"query\\", product_id: Retrieves the quantity of the specified product. :return: A list of quantities for each \\"query\\" operation. ``` Constraints 1. The `product_id` is guaranteed to be unique for each product. 2. The `operations` list will contain up to (10^5) operations. 3. Quantities are positive integer values. Example Given the following operations: ```python operations = [ (\\"add\\", (1, 50)), (\\"add\\", (2, 20)), (\\"update\\", (1, 30)), (\\"query\\", 1), (\\"remove\\", 2), (\\"query\\", 2), (\\"add\\", (3, 60)), (\\"query\\", 3) ] ``` The function should return: `[30, 0, 60]` because: - The quantity of product 1 is updated to 30 and then queried. - Product 2 is removed, so querying it returns 0. - Product 3 is added with a quantity of 60 and then queried. Ensure the function efficiently handles up to (10^5) operations, including add, update, remove, and query operations.","solution":"def process_inventory_operations(operations): Processes a sequence of inventory operations and returns results of query operations. :param operations: A list of tuples where each tuple represents an operation. - \\"add\\", (product_id, quantity): Adds a product with the specified quantity. - \\"update\\", (product_id, new_quantity): Updates the quantity of the specified product. - \\"remove\\", product_id: Removes the specified product from the inventory. - \\"query\\", product_id: Retrieves the quantity of the specified product. :return: A list of quantities for each \\"query\\" operation. inventory = {} results = [] for operation in operations: op_type = operation[0] if op_type == \'add\': product_id, quantity = operation[1] inventory[product_id] = quantity elif op_type == \'update\': product_id, new_quantity = operation[1] if product_id in inventory: inventory[product_id] = new_quantity elif op_type == \'remove\': product_id = operation[1] inventory.pop(product_id, None) elif op_type == \'query\': product_id = operation[1] results.append(inventory.get(product_id, 0)) return results"},{"question":"# Question: Simplify File Paths Description You are given a string representing a Unix-style file path. Write a function to simplify the path. A Unix-style file path (absolute path) always starts with \'/\' (the root directory), and each directory or file is separated by a \'/\' (forward slash). The simplified path must adhere to the following rules: - Any number of consecutive slashes (\'/\') are considered as a single slash \'/\'. - Any \'.\' represents the current directory and can be ignored. - Any \'..\' moves the directory up one level and must be handled appropriately. - The simplified path should not end with a \'/\' unless it is the root directory. Function Signature ```python def simplify_path(path: str) -> str: pass ``` Input 1. `path` (str): The Unix-style file path to be simplified (1 <= |path| <= 3000). Output - Returns a string representing the simplified path. Example ```python path = \\"/home//foo/\\" print(simplify_path(path)) # Expected output: \\"/home/foo\\" path = \\"/a/./b/../../c/\\" print(simplify_path(path)) # Expected output: \\"/c\\" path = \\"/../\\" print(simplify_path(path)) # Expected output: \\"/\\" path = \\"/home//../\\" print(simplify_path(path)) # Expected output: \\"/\\" ``` Constraints 1. The input string is a valid Unix-style file path. 2. \'.\' and \'..\' can appear in the path, as well as multiple slashes. 3. The length of the path string will not exceed 3000 characters. 4. The path will contain only ASCII characters. Performance Requirements - The solution should be efficient and operate in linear time with respect to the length of the input path. - Use appropriate data structures to handle the simplification process optimally. Note - Edge cases to consider include paths that change to the root directory multiple times, paths containing only slashes, and paths ending with slashes.","solution":"def simplify_path(path: str) -> str: Simplifies a given Unix-style file path. parts = path.split(\\"/\\") stack = [] for part in parts: if part == \'\' or part == \'.\': continue elif part == \'..\': if stack: stack.pop() else: stack.append(part) simplified_path = \\"/\\" + \\"/\\".join(stack) return simplified_path"},{"question":"# Pascal\'s Triangle Row Sum Context Pascal\'s Triangle is an infinite triangular array of numbers, where the numbers on the borders are all 1 and each inside number is the sum of the two numbers above it. The rows are enumerated from 0. The sum of the elements in the nth row of Pascal\'s Triangle is `2^n`. Task Write a function `pascal_triangle_row_sum(n: int) -> int` that computes the sum of the numbers in the nth row of Pascal\'s Triangle exclusively using the property that the sum is `2^n`. Input/Output Formats * **Input**: An integer `n`, where `n` is non-negative. * Example: `4` * **Output**: An integer representing the sum of the elements in the nth row of Pascal\'s Triangle. * Example: `16` Constraints * `0 <= n <= 10^6` Performance Requirements * The function should compute the result in O(1) time complexity with a space complexity of O(1). Example Code ```python def pascal_triangle_row_sum(n: int) -> int: return 2 ** n # Test Cases print(pascal_triangle_row_sum(0)) # Output: 1 print(pascal_triangle_row_sum(4)) # Output: 16 print(pascal_triangle_row_sum(10)) # Output: 1024 print(pascal_triangle_row_sum(20)) # Output: 1048576 ``` Note * Ensure that the function handles the edge case where `n` is 0. * The solution should work efficiently for large values of `n` within the given constraints. By following the core principles of Pascal\'s Triangle, you should be able to derive the sum accurately without explicitly generating the triangle itself.","solution":"def pascal_triangle_row_sum(n: int) -> int: Computes the sum of the numbers in the nth row of Pascal\'s Triangle. The sum of the elements in the nth row is 2^n. return 2 ** n"},{"question":"# Array Rotation by d Positions Problem Statement Implement a function to rotate an array by `d` positions. The rotation should be performed in place, meaning you should not use any extra space for another array (other than a few extra variables). The function should be able to handle both left and right rotations. Function Signature ```python def rotate_array(arr: list[int], d: int, direction: str) -> None: pass ``` Input - **arr**: A list of integers. - **d**: A non-negative integer representing the number of positions to rotate. - **direction**: A string that can either be `\\"left\\"` or `\\"right\\"`, indicating the direction of rotation. Output - This function modifies the array in place and does not return any value. Constraints - The length of the array will not exceed 1000 elements. - `d` will be between 0 and the length of the array (inclusive). - `direction` will always be either `\\"left\\"` or `\\"right\\"`. Example ```python # Example 1 input_array = [1, 2, 3, 4, 5, 6, 7] d = 2 direction = \\"left\\" # Resultant array: [3, 4, 5, 6, 7, 1, 2] # Example 2 input_array = [1, 2, 3, 4, 5, 6, 7] d = 3 direction = \\"right\\" # Resultant array: [5, 6, 7, 1, 2, 3, 4] rotate_array(input_array, d, direction) print(input_array) ``` Notes - The function should handle edge cases such as an empty array or when `d` is 0. - The rotation should be effective for cases when `d` is larger than the length of the array.","solution":"def rotate_array(arr: list[int], d: int, direction: str) -> None: Rotate an array by `d` positions in the specified direction. n = len(arr) if n == 0 or d == 0: return d = d % n # Handle cases where d is larger than the length of the array if direction == \\"left\\": reverse(arr, 0, d - 1) reverse(arr, d, n - 1) reverse(arr, 0, n - 1) elif direction == \\"right\\": reverse(arr, 0, n - d - 1) reverse(arr, n - d, n - 1) reverse(arr, 0, n - 1) def reverse(arr: list[int], start: int, end: int) -> None: Helper function to reverse elements in the array from start to end indices. while start < end: arr[start], arr[end] = arr[end], arr[start] start += 1 end -= 1"},{"question":"# Question: Merge and Sort Lists with Data Integrity Check Context: You are developing a data processing tool that frequently merges and sorts multiple lists of numeric data. Each list needs to be validated to ensure that it is properly formatted and only contains integers or floats. Task: Write a function `merge_and_sort_lists` that merges multiple lists and returns a single sorted list, while ensuring that the input lists are valid. 1. **Input**: - A list of lists, `list_of_lists`, where each sublist contains numeric values (integers or floats). - Implement input validation to ensure: * Each element in `list_of_lists` is a list. * Each sublist only contains numeric values. - Raise appropriate errors with meaningful messages for invalid inputs. 2. **Output**: - Return a single list containing all the elements from the input lists, sorted in ascending order. - If the input list contains invalid data, raise a `ValueError` with an appropriate message. 3. **Constraints**: - Each input list may contain up to 10,000 elements. - The total number of lists may be up to 100. 4. **Performance**: - Combine and sort the lists efficiently, aiming for a time complexity of O(n log n), where n is the total number of elements combined. 5. **Edge Cases**: - Empty lists within `list_of_lists`. - Lists containing zero. - Invalid input types, such as dictionaries or strings within the sublists. - Sufficient error handling for non-list and non-numeric inputs. Example Usage: ```python def merge_and_sort_lists(list_of_lists: List[List[Union[int, float]]]) -> List[Union[int, float]]: # Your implementation goes here pass # Example test cases print(merge_and_sort_lists([[1, 3, 5], [2, 4, 6]])) # Output: [1, 2, 3, 4, 5, 6] print(merge_and_sort_lists([[10, 7], [1.2, 3.6], [5, 2]])) # Output: [1.2, 2, 3.6, 5, 7, 10] print(merge_and_sort_lists([[], [2, 6], [5]])) # Output: [2, 5, 6] # Example of error handling try: merge_and_sort_lists([[1, 2, 3], \\"4, 5, 6\\"]) except ValueError as e: print(e) # Output: Each element should be a list try: merge_and_sort_lists([[1, 2, 3], [4, \\"five\\", 6]]) except ValueError as e: print(e) # Output: All sublist elements must be integers or floats ``` Note: Include test cases that demonstrate error handling to ensure robust input validation.","solution":"from typing import List, Union def merge_and_sort_lists(list_of_lists: List[List[Union[int, float]]]) -> List[Union[int, float]]: Merges multiple lists and returns a single sorted list, while ensuring that the input lists are valid. :param list_of_lists: List of lists containing numeric values (integers or floats) :return: Single sorted list containing all elements from the input lists :raises ValueError: If the input lists contain non-numeric values or invalid types if not isinstance(list_of_lists, list): raise ValueError(\\"Input should be a list of lists\\") merged_list = [] for sublist in list_of_lists: if not isinstance(sublist, list): raise ValueError(\\"Each element should be a list\\") for element in sublist: if not isinstance(element, (int, float)): raise ValueError(\\"All sublist elements must be integers or floats\\") merged_list.extend(sublist) return sorted(merged_list)"},{"question":"# Coding Question: Product of Array Except Self Given an array of integers `nums`, implement a Python function `product_except_self(nums: list[int]) -> list[int]` that returns an array `answer` such that `answer[i]` is equal to the product of all the elements of `nums` except `nums[i]`. # Requirements - You must demonstrate an understanding of both brute force and optimized approaches. - Implement the solution with an emphasis on using constant space (O(1) extra space) excluding the output array. # Input - A list of integers `nums` where `nums[i]` represents the elements in the array. - The array has `n` elements (`2 <= n <= 10^5`). - Each element in the array is an integer in the range `[-30, 30]`. # Output - A list of integers representing the product of elements except the one at each index. # Constraints - The array can contain both positive and negative numbers, as well as zeros. # Examples Example 1: ```python nums = [1, 2, 3, 4] assert product_except_self(nums) == [24, 12, 8, 6] ``` Example 2: ```python nums = [-1, 1, 0, -3, 3] assert product_except_self(nums) == [0, 0, 9, 0, 0] ``` Example 3: ```python nums = [2, 3, 4, 5] assert product_except_self(nums) == [60, 40, 30, 24] ``` # Function Signature ```python def product_except_self(nums: list[int]) -> list[int]: ``` # Additional Information - You can write helper functions if needed. - Ensure your solution is efficient and can handle arrays up to the specified size constraints.","solution":"def product_except_self(nums: list[int]) -> list[int]: Returns an array such that each element at index \'i\' of the output array is equal to the product of all the elements of \'nums\' except \'nums[i]\'. # Length of the input array length = len(nums) # The answer array to be returned answer = [0] * length # answer[i] will contain the product of all the elements to the left of nums[i] answer[0] = 1 for i in range(1, length): answer[i] = nums[i - 1] * answer[i - 1] # R will hold the running product of all the elements to the right of nums[i] R = 1 for i in reversed(range(length)): answer[i] = answer[i] * R R *= nums[i] return answer"},{"question":"# Matrix Rotation Context: In many applications, it is necessary to manipulate and transform 2D arrays or matrices. An important operation is rotating the matrix to manipulate its orientation for various processing steps. This problem tests your ability to manipulate matrix structures and understand multidimensional arrays. Task: Write a function `rotate_matrix(matrix: List[List[int]]) -> List[List[int]]` that rotates a given `n x n` matrix 90 degrees clockwise. Specifications: 1. The function should take a single parameter, `matrix`, which is a 2D list representing an `n x n` matrix. 2. The function should return the rotated matrix. Input: - A single 2D list of integers `matrix`, where `n` is the number of rows and columns in the matrix. - The matrix will have `n` rows and `n` columns where `1 ≤ n ≤ 100`. - The elements in the matrix will be integers, `1 ≤ matrix[i][j] ≤ 1000`. Output: - Return a 2D list representing the 90-degree clockwise rotated matrix. Constraints: - The input matrix is always a non-empty square matrix (number of rows equals the number of columns). Example: ```python assert rotate_matrix([ [1, 2, 3], [4, 5, 6], [7, 8, 9] ]) == [ [7, 4, 1], [8, 5, 2], [9, 6, 3] ] assert rotate_matrix([ [1, 2], [3, 4] ]) == [ [3, 1], [4, 2] ] ``` Notes: - Ensure your implementation correctly handles matrices of varying sizes. - Focus on efficiency to handle the largest possible input size within acceptable runtime limits. ```python from typing import List def rotate_matrix(matrix: List[List[int]]) -> List[List[int]]: Given an n x n 2D matrix, returns a new matrix rotated 90 degrees clockwise. n = len(matrix) # Transpose the matrix for i in range(n): for j in range(i, n): matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j] # Reverse each row for i in range(n): matrix[i].reverse() return matrix # Example usage: if __name__ == \\"__main__\\": matrix = [ [1, 2, 3], [4, 5, 6], [7, 8, 9] ] print(rotate_matrix(matrix)) # Output should be: # [ # [7, 4, 1], # [8, 5, 2], # [9, 6, 3] # ] ```","solution":"from typing import List def rotate_matrix(matrix: List[List[int]]) -> List[List[int]]: Given an n x n 2D matrix, returns a new matrix rotated 90 degrees clockwise. n = len(matrix) # Transpose the matrix for i in range(n): for j in range(i, n): matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j] # Reverse each row for i in range(n): matrix[i].reverse() return matrix"},{"question":"# Problem Statement You are tasked with implementing a function that converts a string into a \\"zigzag\\" pattern on a given number of rows and then reads the pattern row by row to form the final string. This problem commonly appears in coding assessments to test your understanding of string manipulation and patterns. Function Signature ```python def convert_to_zigzag(s: str, numRows: int) -> str: ``` # Input - `s`: A string representing the input message to be converted. - `numRows`: An integer indicating the number of rows for the zigzag pattern. # Output - Returns a string that represents the input message read row by row from the zigzag pattern. # Constraints - 1 <= len(s) <= 1000 - 1 <= numRows <= 1000 # Example ```python # Example 1: s = \\"PAYPALISHIRING\\" numRows = 3 assert convert_to_zigzag(s, numRows) == \\"PAHNAPLSIIGYIR\\" # Example 2: s = \\"PAYPALISHIRING\\" numRows = 4 assert convert_to_zigzag(s, numRows) == \\"PINALSIGYAHRPI\\" # Example 3: s = \\"A\\" numRows = 1 assert convert_to_zigzag(s, numRows) == \\"A\\" # Example 4: s = \\"HELLO\\" numRows = 2 assert convert_to_zigzag(s, numRows) == \\"HLOEL\\" ``` # Notes 1. The zigzag pattern is formed by arranging the characters of the string in rows and then reading them line by line. 2. If `numRows` is 1, the output will be the same as the input string. 3. The direction of the pattern switches between going downwards and upwards, simulating the zigzag motion. 4. Handle edge cases such as: - Strings of length 1. - Strings where `numRows` equals the length of the string or is greater than the length of the string. 5. Validate the input to ensure it meets the constraints before processing.","solution":"def convert_to_zigzag(s: str, numRows: int) -> str: # Edge case where numRows is 1, return the original string if numRows == 1 or numRows >= len(s): return s # Create an array of strings for all n rows rows = [\'\'] * numRows current_row = 0 going_down = False # Traverse the input string to populate the rows list for char in s: rows[current_row] += char if current_row == 0 or current_row == numRows - 1: going_down = not going_down current_row += 1 if going_down else -1 # Concatenate all rows to get the final zigzag string zigzag = \'\'.join(rows) return zigzag"},{"question":"# Relative Prime Count **Scenario**: In number theory, Euler\'s Totient Function (phi(n)) is an important function that counts the number of integers up to (n) that are relatively prime to (n). Two numbers are said to be relatively prime if their greatest common divisor (gcd) is 1. Computing (phi(n)) directly using a naive method can be time-consuming for large (n). Your task is to optimize the computation of Euler\'s Totient Function using an efficient algorithm that leverages prime factorization of (n). **Task**: Implement an optimized version of Euler\'s Totient Function that efficiently computes (phi(n)) for a given number (n). **Function Signature**: ```python def euler_totient(n: int) -> int: Returns the value of Euler\'s Totient Function for the given n. :param n: A positive integer greater than 1 :return: The value of Euler\'s Totient Function for n ``` **Input**: - An integer ( n ) (2 <= ( n ) <= 10^12) **Output**: - An integer representing the value of Euler\'s Totient Function (phi(n)) **Constraints**: - The solution should be efficient enough to handle the upper limit of ( n ) within reasonable time and memory. **Example**: ```python >>> euler_totient(9) 6 >>> euler_totient(12) 4 ``` **Explanation**: - For ( n = 9 ), the numbers relatively prime to 9 are 1, 2, 4, 5, 7, 8, so (phi(9) = 6). - For ( n = 12 ), the numbers relatively prime to 12 are 1, 5, 7, 11, so (phi(12) = 4). **Implementation Notes**: - Leverage the properties of prime factorization and the formula: [ phi(n) = n left(1 - frac{1}{p_1}right)left(1 - frac{1}{p_2}right)ldotsleft(1 - frac{1}{p_k}right) ] where ( p_1, p_2, ldots, p_k ) are the distinct prime factors of ( n ). - Consider caching or precomputing prime numbers if needed.","solution":"def euler_totient(n: int) -> int: if n == 1: return 1 result = n p = 2 # Check for each number if it\'s a factor of n while p * p <= n: if n % p == 0: # If p is a factor, divide n by p until it\'s no longer divisible while n % p == 0: n //= p # Apply the Euler\'s Totient function formula factor result -= result // p p += 1 # If there\'s a remaining factor greater than sqrt(n) if n > 1: result -= result // n return result"},{"question":"# Implement a Simple Database using Dictionary You are tasked with implementing a simple in-memory database that supports basic CRUD (Create, Read, Update, Delete) operations. The database will store record objects and allow the user to manipulate records identified by unique IDs. Tasks: 1. **Database Class Implementation**: - **Initialization**: Initialize with an empty dictionary to hold records. - **Create**: Add a new record with a unique ID. If the ID already exists, do nothing. - **Read**: Fetch and return the record associated with the provided ID. - **Update**: Modify an existing record identified by a unique ID. If the ID does not exist, do nothing. - **Delete**: Remove a record associated with the provided ID. 2. **Record Class Implementation**: - **Initialization**: Initialize a record with attributes, which are stored in a dictionary. Constraints: - Unique ID\'s will be strings with a maximum length of 10 characters. - Records will have a maximum of 5 attributes. - Attribute keys and values will be strings with a maximum length of 100 characters each. - Number of records in the database will not exceed 100. Expected Input and Output Format: - **Input**: Operations by calling various methods. - **Output**: Printed results of operations. Example: ```python # Define a Record record1 = Record({\'name\': \'Alice\', \'age\': \'30\', \'city\': \'New York\'}) record2 = Record({\'name\': \'Bob\', \'age\': \'25\', \'city\': \'Los Angeles\'}) # Initialize the Database db = Database() # Test Create Operation db.create(\'001\', record1) db.create(\'002\', record2) # Test Read Operation print(db.read(\'001\')) # Output: {\'name\': \'Alice\', \'age\': \'30\', \'city\': \'New York\'} print(db.read(\'003\')) # Output: None # Test Update Operation db.update(\'001\', Record({\'name\': \'Alice\', \'age\': \'31\', \'city\': \'Boston\'})) print(db.read(\'001\')) # Output: {\'name\': \'Alice\', \'age\': \'31\', \'city\': \'Boston\'} # Test Delete Operation db.delete(\'002\') print(db.read(\'002\')) # Output: None ``` Implement the classes such that they satisfy the constraints above, handling any edge cases appropriately.","solution":"class Record: def __init__(self, attributes): Initialize a record with attributes, which are stored in a dictionary. self.attributes = attributes class Database: def __init__(self): Initialize with an empty dictionary to hold records. self.records = {} def create(self, unique_id, record): Add a new record with a unique ID. If the ID already exists, do nothing. if unique_id not in self.records: self.records[unique_id] = record def read(self, unique_id): Fetch and return the record associated with the provided ID. Return None if not found. return self.records.get(unique_id, None) def update(self, unique_id, record): Modify an existing record identified by a unique ID. If the ID does not exist, do nothing. if unique_id in self.records: self.records[unique_id] = record def delete(self, unique_id): Remove a record associated with the provided ID. if unique_id in self.records: del self.records[unique_id]"},{"question":"**Context**: You are tasked with developing a software module within a project management application that helps users manage dependencies between tasks. The task dependencies are represented as a directed acyclic graph (DAG), where nodes represent tasks and directed edges represent dependencies. **Task**: Implement the `topological_sort` function, which outputs a valid topological ordering of tasks. A topological sort of a directed graph is an ordering of its vertices such that for every directed edge `uv` from vertex `u` to vertex `v`, `u` appears before `v` in the ordering. **Function Signature**: ```python def topological_sort(tasks: list, dependencies: list) -> list: Compute and return a list representing a valid topological order of tasks. :param tasks: list, a list of tasks :param dependencies: list, a list of tuples where each tuple (u, v) represents a dependency u -> v :return: list, a valid topological ordering of tasks; return an empty list if no valid ordering exists ``` # Input: - `tasks` (list): A list of tasks represented by unique strings. - `dependencies` (list): A list of tuples representing the directed edges (u, v) indicating `u` must be completed before `v`. # Output: - A list representing a valid topological ordering of tasks. If no valid ordering exists (which is theoretically impossible since the input must be a DAG), return an empty list. # Constraints: - The graph is acyclic and directed. - There can be multiple valid topological orders; any valid order is acceptable. # Example: ```python tasks = [\\"task1\\", \\"task2\\", \\"task3\\", \\"task4\\", \\"task5\\"] dependencies = [(\\"task1\\", \\"task2\\"), (\\"task2\\", \\"task3\\"), (\\"task1\\", \\"task4\\"), (\\"task4\\", \\"task5\\")] assert topological_sort(tasks, dependencies) in [ [\'task1\', \'task2\', \'task4\', \'task3\', \'task5\'], [\'task1\', \'task4\', \'task5\', \'task2\', \'task3\'], [\'task1\', \'task4\', \'task2\', \'task5\', \'task3\'], [\'task1\', \'task2\', \'task4\', \'task5\', \'task3\'] # ... and potentially other valid topological sorts. ] tasks = [\\"a\\", \\"b\\", \\"c\\"] dependencies = [(\\"a\\", \\"c\\"), (\\"b\\", \\"c\\"), (\\"a\\", \\"b\\")] assert topological_sort(tasks, dependencies) in [ [\\"a\\", \\"b\\", \\"c\\"], [\\"a\\", \\"c\\"], [\\"b\\", \\"a\\", \\"c\\"] # ... and potentially other valid topological sorts. ] ``` # Note: - Pay attention to edge cases, such as tasks with no dependencies or multiple roots. - Ensure the implementation is efficient and can handle a reasonable number of tasks and dependencies.","solution":"from collections import deque, defaultdict def topological_sort(tasks, dependencies): Compute and return a list representing a valid topological order of tasks. :param tasks: list, a list of tasks :param dependencies: list, a list of tuples where each tuple (u, v) represents a dependency u -> v :return: list, a valid topological ordering of tasks; return an empty list if no valid ordering exists # Create an adjacency list and a dict to count in-degrees graph = defaultdict(list) in_degree = {task: 0 for task in tasks} for u, v in dependencies: graph[u].append(v) in_degree[v] += 1 # Initialize the queue with nodes of in-degree 0 (no dependencies) queue = deque([task for task in tasks if in_degree[task] == 0]) # List to store the topological order topological_order = [] while queue: task = queue.popleft() topological_order.append(task) # Reduce the in-degree of the neighbouring nodes for neighbor in graph[task]: in_degree[neighbor] -= 1 if in_degree[neighbor] == 0: queue.append(neighbor) # If the topological sort includes all tasks, return it if len(topological_order) == len(tasks): return topological_order else: # Cycle detected or not all tasks are included return []"},{"question":"# Scenario: You are developing a real-time data processing pipeline that involves applying a series of mathematical transformations to incoming data. One such transformation is the Piecewise Linear Interpolation function, which maps a given set of input values to their corresponding outputs based on predefined input-output pairs. # Task: Write a function that performs piecewise linear interpolation for a given set of input-output pairs and applies this interpolation to a given array of values. Your function should handle arrays containing floating-point numbers and return the interpolated results. # Function Signature: ```python def piecewise_linear_interpolation( inputs: np.ndarray, outputs: np.ndarray, values: np.ndarray ) -> np.ndarray: pass ``` # Input: - `inputs`: A numpy ndarray of shape (m,) consisting of m sorted floating-point numbers representing the input points. - `outputs`: A numpy ndarray of shape (m,) consisting of m floating-point numbers representing the respective output points. - `values`: A numpy ndarray of shape (n,) consisting of n floating-point numbers for which the interpolation should be applied. # Output: - Returns a numpy ndarray of shape (n,) consisting of the interpolated values for the given input `values`. # Constraints: - All elements in the `inputs` array are sorted in ascending order. - The `inputs` and `outputs` arrays have the same length. - Handle arrays `inputs` and `outputs` up to length 10^5 efficiently. - Handle arrays `values` up to length 10^6 efficiently. - If an element in `values` is outside the range of `inputs`, return the nearest endpoint value from `outputs`. # Example: ```python >>> inputs = np.array([1.0, 2.0, 3.0, 4.0]) >>> outputs = np.array([2.0, 4.0, 6.0, 8.0]) >>> values = np.array([0.5, 1.5, 2.5, 3.5, 4.5]) >>> piecewise_linear_interpolation(inputs, outputs, values) array([2.0, 3.0, 5.0, 7.0, 8.0]) ``` # Notes: - Use numpy for efficient numerical computations. - Focus on both accuracy and efficiency when implementing the function. - You may assume the input parameters are always valid and lead to a well-defined output.","solution":"import numpy as np def piecewise_linear_interpolation(inputs: np.ndarray, outputs: np.ndarray, values: np.ndarray) -> np.ndarray: Performs piecewise linear interpolation for a given set of input-output pairs on given values. Args: inputs (np.ndarray): A numpy array of shape (m,) consisting of m sorted floating-point input points. outputs (np.ndarray): A numpy array of shape (m,) consisting of m floating-point output points. values (np.ndarray): A numpy array of shape (n,) consisting of n floating-point numbers to interpolate. Returns: np.ndarray: A numpy array of shape (n,) consisting of the interpolated output values. interpolated_values = np.interp(values, inputs, outputs) return interpolated_values"},{"question":"# Question: Reordering List by Index You are given two lists: one list `words` containing strings, and another list `indexes` containing integers. Your task is to write a function `reorder_list(words: List[str], indexes: List[int]) -> List[str]` that reorders the `words` list according to the positions provided in the `indexes` list. # Constraints * The input list `words` will have lengths up to 1000 elements. * The input list `indexes` will have the same length as the `words` list and will contain each index from `0` to `len(words) - 1` exactly once. * Ensure the function raises a `ValueError` if lengths of `words` and `indexes` do not match or if `indexes` contains invalid positions. * Input list `words` will only contain printable ASCII characters in the strings. # Input * `words`: List of strings * `indexes`: List of integers # Output * A list of strings reordered according to the given indexes. # Examples Example 1 ```python words = [\\"apple\\", \\"banana\\", \\"cherry\\"] indexes = [2, 0, 1] output = [\\"banana\\", \\"cherry\\", \\"apple\\"] ``` Example 2 ```python words = [\\"one\\", \\"two\\", \\"three\\", \\"four\\"] indexes = [3, 2, 0, 1] output = [\\"three\\", \\"four\\", \\"two\\", \\"one\\"] ``` Example 3 ```python words = [\\"a\\", \\"b\\", \\"c\\", \\"d\\", \\"e\\"] indexes = [4, 3, 2, 1, 0] output = [\\"e\\", \\"d\\", \\"c\\", \\"b\\", \\"a\\"] ``` # Implementation Notes * Your function should efficiently perform the reordering in O(n) time complexity. * Make sure to validate the input to handle incorrect lengths and invalid indices by raising appropriate exceptions. Implement the function `reorder_list(words, indexes)`, ensuring it performs the reordering accurately and handles all specified edge cases.","solution":"from typing import List def reorder_list(words: List[str], indexes: List[int]) -> List[str]: Reorders the words list according to the given indexes list. Args: words (List[str]): List of strings to be reordered. indexes (List[int]): List of integers representing the new positions for the elements in words list. Returns: List[str]: Reordered list of strings. Raises: ValueError: If the lengths of words and indexes do not match or if indexes contain invalid positions. if len(words) != len(indexes): raise ValueError(\\"The lengths of words and indexes lists do not match.\\") if sorted(indexes) != list(range(len(words))): raise ValueError(\\"Indexes list contains invalid positions.\\") reordered = [None] * len(words) for idx, word in zip(indexes, words): reordered[idx] = word return reordered"},{"question":"# Coding Assessment Question You are provided with a portion of the implementation and utility functions for a Depth-First Search (DFS) algorithm. This question will focus on utilizing the DFS technique to detect if there are any cycles in a directed graph. # Problem Statement Implement a function `detect_cycle_in_directed_graph(graph: GraphDirected) -> bool` that determines if the given directed graph contains any cycles. # Input Format - An instance of the `GraphDirected` class, representing a directed graph. The graph is populated using the `add_edge` function where `graph.add_edge(start, end)` adds a directed edge from `start` node to `end` node. # Output Format - Returns a boolean value: `True` if the graph contains at least one cycle, and `False` otherwise. # Constraints - The graph can have up to 1000 nodes. - Each node in the graph can have 0 or more directed edges to other nodes. # Example Input ```python graph = GraphDirected() graph.add_edge(\\"a\\", \\"b\\") graph.add_edge(\\"b\\", \\"c\\") graph.add_edge(\\"c\\", \\"a\\") graph.add_edge(\\"d\\", \\"e\\") ``` Output ``` True ``` Input ```python graph = GraphDirected() graph.add_edge(\\"a\\", \\"b\\") graph.add_edge(\\"b\\", \\"c\\") graph.add_edge(\\"c\\", \\"d\\") graph.add_edge(\\"d\\", \\"e\\") ``` Output ``` False ``` # Explanation In the first example, the graph contains a cycle formed by the edges a → b → c → a. Therefore, the function returns `True`. In the second example, the graph does not contain any cycles, so the function returns `False`. # Function Signature ```python def detect_cycle_in_directed_graph(graph: GraphDirected[str]) -> bool: # Your code here ``` # Guidelines - Use the provided `GraphDirected` class to manage graph operations. - Implement the DFS algorithm to check for back edges that indicate cycles. - Efficiently track visited nodes and recursion stack to ensure optimal performance. --- Note: Ensure `GraphDirected` and `add_edge` functions are properly defined as they are critical for constructing the graph and should support string type nodes.","solution":"class GraphDirected: def __init__(self): self.graph = {} def add_edge(self, start, end): if start not in self.graph: self.graph[start] = [] self.graph[start].append(end) def get_adjacent_nodes(self, node): return self.graph.get(node, []) def detect_cycle_in_directed_graph(graph: GraphDirected) -> bool: def dfs(node): if node in recursion_stack: return True if node in visited: return False visited.add(node) recursion_stack.add(node) for neighbor in graph.get_adjacent_nodes(node): if dfs(neighbor): return True recursion_stack.remove(node) return False visited = set() recursion_stack = set() for node in graph.graph: if dfs(node): return True return False"},{"question":"# Subsequence with Maximum Sum Given an integer array `nums`, find the maximum sum of any subsequence that consists of non-adjacent elements. Your task is to implement the function `max_sum_non_adjacent(nums)` to achieve this. Function Signature ```python def max_sum_non_adjacent(nums: List[int]) -> int: ``` Input * `nums`: A list of integers representing the array. Output * Returns an integer representing the maximum sum of a subsequence with non-adjacent elements. Constraints * `1 <= len(nums) <= 10^5` * `-10^4 <= nums[i] <= 10^4` Example ```python # Provided Example nums = [3, 2, 7, 10] print(max_sum_non_adjacent(nums)) # Expected output is 13 # Additional Example nums = [5, 5, 10, 100, 10, 5] print(max_sum_non_adjacent(nums)) # Expected output is 110 # Additional Example nums = [-1, -2, -3, -4, -5] print(max_sum_non_adjacent(nums)) # Expected output is 0 ``` Explanation of Examples In the first example, the maximum sum is obtained by selecting the elements 3 and 10, which gives a sum of 13. In the second example, the maximum sum is obtained by selecting the elements 5, 100, and 5, which gives a sum of 110. In the third example, since all numbers are negative, the maximum sum of any non-adjacent subsequence is 0 (choosing no elements). Notes - Consider edge cases such as all negative numbers or arrays with only one element. - Optimize for both time and space according to the constraints provided. - You must not select adjacent elements to form the maximum sum subsequence.","solution":"from typing import List def max_sum_non_adjacent(nums: List[int]) -> int: if not nums: return 0 if len(nums) == 1: return max(0, nums[0]) include = 0 # max sum including the current element exclude = 0 # max sum excluding the current element for num in nums: new_exclude = max(exclude, include) include = exclude + num exclude = new_exclude return max(include, exclude)"},{"question":"# Binary Search Tree (BST) Operations and Depth Calculation Context You are tasked with implementing and enhancing a Binary Search Tree (BST) data structure that supports standard insertion, search, and deletion operations, as well as calculating the depth of the tree. This will help ensure comprehension of tree traversal, BST properties, and manipulation. Task 1. **Implement BST Basic Operations**: - Implement functions to insert a node, search for a node, and delete a node in the BST. - Ensure that the BST properties are maintained after each operation. 2. **Calculate Tree Depth**: - Implement a function to calculate the depth of the BST, defined as the number of edges in the longest path from the root to a leaf. Expected Function Implementation 1. **BST Node and Operations**: ```python class TreeNode: def __init__(self, key: int): self.key = key self.left = None self.right = None class BinarySearchTree: def __init__(self): self.root = None def insert(self, key: int): # Your code here def search(self, key: int) -> bool: # Your code here def delete(self, key: int): # Your code here ``` 2. **Calculate Tree Depth**: ```python def tree_depth(node: TreeNode) -> int: # Your code here ``` 3. **Integration of Operations**: - Ensure your modifications integrate seamlessly with the BST operations and depth calculation. Input and Output **Input**: - Series of operations to perform on the BST (e.g., \'insert 10\', \'search 5\', \'delete 3\', \'depth\') as a list of strings. **Output**: - Results of search operations as a list of booleans (True if the key is found, False otherwise). - Result of the depth operation as an integer (depth of the BST). Constraints - All keys to be inserted, searched, or deleted are integers. - Assume input operations are provided in a valid sequence. - The series of operations will handle no more than 10^4 operations. Scenario Implement the respective functions for insertion, search, deletion, and depth calculation. Test your BST implementation with a series of operations to ensure correctness. Validate that the BST properties hold after each operation and that the depth function accurately reports the tree\'s depth. ```python # Example usage bst = BinarySearchTree() operations = [\'insert 5\', \'insert 3\', \'insert 7\', \'search 3\', \'depth\', \'delete 3\', \'search 3\', \'depth\'] ```","solution":"class TreeNode: def __init__(self, key: int): self.key = key self.left = None self.right = None class BinarySearchTree: def __init__(self): self.root = None def insert(self, key: int): self.root = self._insert(self.root, key) def _insert(self, node: TreeNode, key: int) -> TreeNode: if not node: return TreeNode(key) if key < node.key: node.left = self._insert(node.left, key) else: node.right = self._insert(node.right, key) return node def search(self, key: int) -> bool: return self._search(self.root, key) def _search(self, node: TreeNode, key: int) -> bool: if not node: return False if key == node.key: return True elif key < node.key: return self._search(node.left, key) else: return self._search(node.right, key) def delete(self, key: int): self.root = self._delete(self.root, key) def _delete(self, node: TreeNode, key: int) -> TreeNode: if not node: return node if key < node.key: node.left = self._delete(node.left, key) elif key > node.key: node.right = self._delete(node.right, key) else: if not node.left: return node.right elif not node.right: return node.left temp = self._min_value_node(node.right) node.key = temp.key node.right = self._delete(node.right, temp.key) return node def _min_value_node(self, node: TreeNode) -> TreeNode: current = node while current.left: current = current.left return current def tree_depth(node: TreeNode) -> int: if not node: return -1 left_depth = tree_depth(node.left) right_depth = tree_depth(node.right) return max(left_depth, right_depth) + 1 def process_operations(operations): bst = BinarySearchTree() results = [] for operation in operations: op = operation.split() if op[0] == \'insert\': bst.insert(int(op[1])) elif op[0] == \'search\': results.append(bst.search(int(op[1]))) elif op[0] == \'delete\': bst.delete(int(op[1])) elif op[0] == \'depth\': results.append(tree_depth(bst.root)) return results"},{"question":"# Coding Assessment Question In a software system that processes a stream of events, it is crucial to maintain the count of occurrences of each distinct event over time. One efficient way to achieve this is by keeping a running tally as each event is processed. Your task is to implement a function that receives events and updates the tallies accordingly. **Function Specification:** Implement the function `update_event_count` that takes a list of event strings and returns a dictionary mapping each distinct event to its count. ```python def update_event_count(events: list[str]) -> dict[str, int]: pass ``` # Input - `events` (list of strings): Each string represents an event that needs to be tallied. There can be duplicate events in the list. # Output - Returns a dictionary where the keys are event strings and the values are their respective counts in the provided events list. # Constraints - You can assume that each event in the list is a non-empty string. - The list size can be arbitrarily large, so performance should be efficient for large inputs. - Handle empty lists by returning an empty dictionary. # Requirements - Focus on time complexity of (O(n)), where (n) is the number of events in the input list. - The solution should work efficiently even with a large number of events. # Functionality Tests Ensure your function passes the following test cases: ```python >>> update_event_count([\'login\', \'logout\', \'login\', \'signup\', \'login\']) {\'login\': 3, \'logout\': 1, \'signup\': 1} >>> update_event_count([\'event1\', \'event2\', \'event3\', \'event2\', \'event3\', \'event3\']) {\'event1\': 1, \'event2\': 2, \'event3\': 3} >>> update_event_count([]) {} >>> update_event_count([\'click\', \'click\', \'click\', \'view\', \'view\']) {\'click\': 3, \'view\': 2} >>> update_event_count([\'error\']) {\'error\': 1} ``` # Scenario Imagine you are working on a dashboard for a web application where user events, such as \'login\', \'logout\', \'signup\', are logged continuously. To present the data effectively, you need a real-time tally of these events to display on the dashboard. Implement and utilize the `update_event_count` function to process the stream of events and keep the event counters up-to-date.","solution":"def update_event_count(events: list[str]) -> dict[str, int]: Given a list of event strings, returns a dictionary that maps each event to its count in the provided list. :param events: A list of event strings. :return: A dictionary with event counts. event_count = {} for event in events: if event in event_count: event_count[event] += 1 else: event_count[event] = 1 return event_count"},{"question":"# Array Rotation: Left Rotation by K Elements In this coding problem, you will implement a function to perform a left rotation on an array. Specifically, you will write a function to rotate an array `arr` by `k` positions to the left. Problem Description You are given an array `arr` of integers and an integer `k`. Your task is to rotate the array to the left by `k` positions. A left rotation operation moves each element of the array one unit to the left, and the first element is moved to the end of the array. Function to Implement 1. **`left_rotate_array`**: ```python def left_rotate_array(arr: List[int], k: int) -> List[int]: ``` - **Input Parameters**: - `arr`: A list of integers to be rotated. - `k`: An integer representing the number of positions to rotate the array to the left. - **Output**: - Returns a new list of integers that represents the rotated array. Constraints - The size of `arr` will be at least 1 and can be up to 10⁶. - `k` will be a non-negative integer such that `0 <= k <= 10⁹`. - If `k` is greater than or equal to the length of `arr`, the rotation should be performed effectively using `k % len(arr)`. Example Usage 1. Rotating an array `[1, 2, 3, 4, 5]` by `2` positions to the left: ```python rotated_array = left_rotate_array([1, 2, 3, 4, 5], 2) print(rotated_array) # Output: [3, 4, 5, 1, 2] ``` 2. Rotating an array `[1, 2, 3, 4, 5, 6]` by `4` positions to the left: ```python rotated_array = left_rotate_array([1, 2, 3, 4, 5, 6], 4) print(rotated_array) # Output: [5, 6, 1, 2, 3, 4] ``` 3. Rotating an array `[1, 2, 3]` by `5` positions to the left: ```python rotated_array = left_rotate_array([1, 2, 3], 5) print(rotated_array) # Output: [3, 1, 2] ``` You must follow the given function signature and provide a complete implementation for the problem described above.","solution":"from typing import List def left_rotate_array(arr: List[int], k: int) -> List[int]: Rotates the array to the left by k positions. Parameters: arr (List[int]): The array to be rotated. k (int): The number of positions to rotate to the left. Returns: List[int]: The rotated array. n = len(arr) k = k % n # In case k is greater than the length of the array return arr[k:] + arr[:k]"},{"question":"# Problem Statement You are tasked with developing a function for a sports analytics application that needs to compute the player\'s average performance statistics over a series of games. The application receives a nested list containing several game statistics for each player, where each inner list represents the statistics for one player over multiple games. Each player\'s statistics for a single game are represented as a list of positive integers. You need to calculate the average statistics per game for each player. Your task is to create a function `calculate_averages(statistics: List[List[int]]) -> List[float]` that computes the average statistics for each player and returns a list of the averages. Make sure to handle edge cases appropriately, such as an empty list of statistics for a player. Function Signature ```python from typing import List def calculate_averages(statistics: List[List[int]]) -> List[float]: pass ``` Input and Output - **Input**: A list of lists of integers `statistics`, where each inner list contains positive integers representing one player\'s game statistics. - **Output**: A list of floating-point numbers representing the average statistics for each player. Constraints - The inner lists will contain at least one integer. - Each integer in the inner lists will be a positive number. - There will be at least one player. Requirements - If a player\'s statistics list is empty, raise a ValueError with an appropriate message. # Examples ```python >>> calculate_averages([[10, 20, 30], [15, 25, 35]]) [20.0, 25.0] >>> calculate_averages([[5, 10, 15]]) [10.0] >>> calculate_averages([[7, 8], [10, 12, 14]]) [7.5, 12.0] >>> calculate_averages([[]]) Traceback (most recent call last): ... ValueError: A player\'s statistics cannot be empty >>> calculate_averages([[40, 50, 60], [70, 80, 90, 100]]) [50.0, 85.0] ``` Validate the function with the provided examples to ensure it adheres to the specifications outlined above.","solution":"from typing import List def calculate_averages(statistics: List[List[int]]) -> List[float]: Calculates the average statistics for each player. Args: statistics (List[List[int]]): A nested list where each inner list contains the statistics for one player over multiple games. Returns: List[float]: A list of floating-point numbers representing the average statistics for each player. Raises: ValueError: If any inner list (representing a player\'s statistics) is empty. averages = [] for player_stats in statistics: if not player_stats: raise ValueError(\\"A player\'s statistics cannot be empty\\") avg = sum(player_stats) / len(player_stats) averages.append(avg) return averages"},{"question":"# Question: Implement a Tic-Tac-Toe Game Judge Context: Tic-Tac-Toe is a classic two-player game also known as Naughts and Crosses. The game is played on a 3x3 grid, where players take turns to place their mark, either \'X\' or \'O\', in an empty cell. The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row wins the game. Task: Implement a Python function that determines the status of a completed Tic-Tac-Toe game. The function should take a 3x3 grid as input, where each cell is either \'X\', \'O\', or an empty string (\'\') representing the state of the grid. It should determine if the game has been won by either player or if it resulted in a draw. Function Signature: ```python def tic_tac_toe_judge(board: list) -> str: pass ``` Input: * **board** (list): A list of lists representing the 3x3 Tic-Tac-Toe board. Each inner list has 3 strings, each being \'X\', \'O\', or \'\'. Output: * **result** (str): A string that can be: - `\'X\'` if player X wins, - `\'O\'` if player O wins, - `\'Draw\'` if the game is a draw, - `\'Incomplete\'` if there are empty cells but no winner yet. Constraints: * Ensure the function handles all possible valid board states. * Optimize the function to determine the result with minimal processing. Example: ```python >>> board1 = [ ... [\'X\', \'O\', \'X\'], ... [\'O\', \'X\', \'\'], ... [\'O\', \'\', \'X\'] ... ] >>> tic_tac_toe_judge(board1) \'X\' >>> board2 = [ ... [\'X\', \'O\', \'X\'], ... [\'O\', \'O\', \'X\'], ... [\'O\', \'X\', \'X\'] ... ] >>> tic_tac_toe_judge(board2) \'Draw\' >>> board3 = [ ... [\'X\', \'O\', \'X\'], ... [\'O\', \'X\', \'\'], ... [\'O\', \'\', \'\'] ... ] >>> tic_tac_toe_judge(board3) \'Incomplete\' ``` Notes: * The function should return as soon as a winner is determined to avoid unnecessary processing. * Ensure that the function correctly identifies horizontal, vertical, and diagonal wins.","solution":"def tic_tac_toe_judge(board: list) -> str: # Check rows and columns for i in range(3): if board[i][0] != \'\' and board[i][0] == board[i][1] and board[i][1] == board[i][2]: return board[i][0] if board[0][i] != \'\' and board[0][i] == board[1][i] and board[1][i] == board[2][i]: return board[0][i] # Check diagonals if board[0][0] != \'\' and board[0][0] == board[1][1] and board[1][1] == board[2][2]: return board[0][0] if board[0][2] != \'\' and board[0][2] == board[1][1] and board[1][1] == board[2][0]: return board[0][2] # Check for incomplete game for row in board: if \'\' in row: return \'Incomplete\' # If no winner and no incomplete spots, it\'s a draw return \'Draw\'"},{"question":"# Problem Statement You are tasked with creating a function that reads an MxN grid of characters where each character represents either a tree (denoted as \'T\') or an open space (denoted as \'.\'). The function should determine the number of distinct clusters of trees present in the grid. A cluster is defined as a group of adjacent \'T\' characters connected vertically or horizontally (but not diagonally). # Guidelines - Implement a function `count_tree_clusters(grid: List[List[str]]) -> int` that takes a 2D list of characters representing the grid and returns the total number of distinct tree clusters. # Input and Output - **Input**: A 2D list `grid` of characters (`List[List[str]]`). - **Output**: An integer representing the number of distinct tree clusters. # Constraints - The dimensions of the grid M (rows) and N (columns) are such that 1 <= M, N <= 100. - Each cell in the grid can either be \'T\' (tree) or \'.\' (open space). # Example ```python def count_tree_clusters(grid: List[List[str]]) -> int: # Your implementation here # Example usage: grid = [ [\'T\', \'.\', \'T\', \'T\', \'.\'], [\'T\', \'T\', \'.\', \'.\', \'T\'], [\'.\', \'T\', \'.\', \'T\', \'T\'], [\'.\', \'.\', \'.\', \'T\', \'.\'], [\'T\', \'T\', \'T\', \'.\', \'T\'] ] assert count_tree_clusters(grid) == 5 ``` # Description of Example In the given example, the grid has the following tree clusters: 1. Cluster at top-left starting from (0,0). 2. Cluster at top-middle starting from (0,2) and extending through (0,3). 3. Cluster at bottom-left starting from (4,0) and extending through (1,1). 4. Cluster in the center starting from (3,3) and extending through (1,4). 5. Cluster at bottom-right starting from (4,4). The total number of distinct tree clusters in the grid is 5. # Hints - You may use Depth-First Search (DFS) or Breadth-First Search (BFS) to traverse each tree cluster. - Mark visited \'T\' cells to avoid counting the same cluster more than once. - Ensure boundary checks to prevent index out of range errors during traversal.","solution":"from typing import List def count_tree_clusters(grid: List[List[str]]) -> int: def dfs(x, y): Perform a depth-first search to visit all parts of the cluster. if x < 0 or x >= len(grid) or y < 0 or y >= len(grid[0]) or grid[x][y] != \'T\': return # Mark this cell as visited grid[x][y] = \'V\' # Visit all four adjacent cells (up, down, left, right) dfs(x + 1, y) dfs(x - 1, y) dfs(x, y + 1) dfs(x, y - 1) cluster_count = 0 for i in range(len(grid)): for j in range(len(grid[0])): if grid[i][j] == \'T\': # Start a new cluster search cluster_count += 1 dfs(i, j) return cluster_count"},{"question":"# Question: Implement a Priority Queue with Replace-Max Operation Design a priority queue data structure that supports the following operations: - `push(val: int) -> None`: Adds an element to the priority queue. - `pop() -> int`: Removes and returns the maximum element from the priority queue. - `peek() -> int`: Returns the maximum element without removing it. - `is_empty() -> bool`: Checks if the priority queue is empty. - `replace_max(val: int) -> int`: Replaces the current maximum element with `val` and returns the old maximum. - `__repr__() -> str`: Returns a string representation of the priority queue. Function Signature: ```python class MaxPriorityQueue: def __init__(self: MaxPriorityQueue) -> None: pass def push(self: MaxPriorityQueue, val: int) -> None: pass def pop(self: MaxPriorityQueue) -> int: pass def peek(self: MaxPriorityQueue) -> int: pass def is_empty(self: MaxPriorityQueue) -> bool: pass def replace_max(self: MaxPriorityQueue, val: int) -> int: pass def __repr__(self: MaxPriorityQueue) -> str: pass ``` # Constraints: - Implement the priority queue using a heap data structure. - Ensure that the `peek()` and `replace_max()` operations run in O(log n) time. # Example: ```python pq = MaxPriorityQueue() pq.push(3) pq.push(5) pq.push(7) print(pq.peek()) # Output: 7 print(pq.replace_max(4)) # Output: 7 print(pq.peek()) # Output: 5 pq.pop() print(pq.peek()) # Output: 4 ```","solution":"import heapq class MaxPriorityQueue: def __init__(self): self._heap = [] def push(self, val: int) -> None: heapq.heappush(self._heap, -val) def pop(self) -> int: return -heapq.heappop(self._heap) def peek(self) -> int: return -self._heap[0] def is_empty(self) -> bool: return len(self._heap) == 0 def replace_max(self, val: int) -> int: old_max = -heapq.heapreplace(self._heap, -val) return old_max def __repr__(self) -> str: return \\"MaxPriorityQueue(\\" + str([-x for x in self._heap]) + \\")\\""},{"question":"# Question: Find the Overlapping Interval Context Given two sets of intervals, your task is to identify the overlapping interval between these sets. An interval is represented by a pair of integers, where the first integer is the start of the interval and the second integer is the end of the interval. If there are multiple overlapping intervals, return the one that starts the earliest. If no overlap exists, return `None`. Function Definition Complete the function `find_overlapping_interval` that accepts two parameters: - `set1` (list of tuples): First set of intervals. - `set2` (list of tuples): Second set of intervals. The function should return an interval (a tuple with start and end) representing the overlapping interval. If no overlap exists, return `None`. Example: ```python def find_overlapping_interval(set1, set2): Returns the earliest overlapping interval between the two sets of intervals. >>> find_overlapping_interval([(1, 5), (10, 15)], [(3, 6), (8, 10)]) (3, 5) >>> find_overlapping_interval([(1, 4), (6, 9)], [(2, 3), (10, 15)]) (2, 3) >>> find_overlapping_interval([(1, 2), (3, 5)], [(6, 8)]) None # Your implementation here # Example usage find_overlapping_interval([(1, 5), (10, 15)], [(3, 6), (8, 10)]) ``` Constraints: - Interval values are inclusive. - Each interval in the sets is represented as `(start, end)` and satisfies `start <= end`. - The intervals within each set are non-overlapping. - Interval points are integers within reasonable bounds for algorithmic processing.","solution":"def find_overlapping_interval(set1, set2): Returns the earliest overlapping interval between the two sets of intervals. overlap = None def get_overlap(interval1, interval2): Helper function to find overlap between two intervals. Returns None if there\'s no overlap, otherwise the overlapping interval. start1, end1 = interval1 start2, end2 = interval2 if end1 < start2 or end2 < start1: return None else: return (max(start1, start2), min(end1, end2)) earliest_start = float(\'inf\') for int1 in set1: for int2 in set2: current_overlap = get_overlap(int1, int2) if current_overlap: start, end = current_overlap if start < earliest_start: earliest_start = start overlap = current_overlap return overlap # Example usage print(find_overlapping_interval([(1, 5), (10, 15)], [(3, 6), (8, 10)])) # Output should be (3, 5)"},{"question":"# Rotate Matrix 90 Degrees Problem Statement Write a function `rotate_matrix(matrix)` that takes a 2D list (matrix) and rotates it 90 degrees clockwise. The function should return the rotated matrix. If the input is not a valid matrix (i.e., differing row lengths or not a list of lists), the function should raise a `ValueError`. Constraints 1. The input `matrix` will be a non-empty list of lists where each sub-list represents a row. 2. Each element in the matrix is an integer. 3. Suppose the matrix is (m times n). Ensure that the function handles the variable dimensions of (m) and (n). 4. The function should handle large matrices efficiently. Input * A 2D list `matrix`. Example: [[1,2,3],[4,5,6],[7,8,9]] or [[1,2],[3,4],[5,6]]. Output * A 2D list representing the matrix rotated 90 degrees clockwise. * Raises a `ValueError` if the input is not a valid matrix. Example ```python rotate_matrix([[1,2,3], [4,5,6], [7,8,9]]) # Returns: [[7,4,1], [8,5,2], [9,6,3]] rotate_matrix([[1,2], [3,4], [5,6]]) # Returns: [[5, 3, 1], [6, 4, 2]] rotate_matrix([[1]]) # Returns: [[1]] rotate_matrix([[1,2,3], [4,5,6], [7,8]]) # Raises: ValueError ``` Note * Ensure the function verifies if the input is a well-formed 2D list before processing. * Consider both square and rectangular matrices. * Pay attention to edge cases such as matrices with a single row, a single column, or a single element. --- The above question integrates seamlessly with the initial set while maintaining similar complexity, scope, and style.","solution":"def rotate_matrix(matrix): Rotates the given 2D matrix 90 degrees clockwise. :param matrix: List[List[int]] - A 2D list representing the matrix to rotate :return: List[List[int]] - The rotated matrix :raises ValueError: If the input matrix is not a valid 2D list with uniform row lengths # Validate the matrix input if not isinstance(matrix, list) or not all(isinstance(row, list) for row in matrix): raise ValueError(\\"Input must be a list of lists (2D list).\\") num_cols = len(matrix[0]) for row in matrix: if len(row) != num_cols: raise ValueError(\\"All rows must have the same number of columns.\\") # Rotate the matrix 90 degrees clockwise num_rows = len(matrix) rotated_matrix = [[None] * num_rows for _ in range(num_cols)] for i in range(num_rows): for j in range(num_cols): rotated_matrix[j][num_rows - 1 - i] = matrix[i][j] return rotated_matrix"},{"question":"# Matrix Transpose and Sum **Problem Statement**: You are required to implement two functions: one to transpose a given matrix and another to compute the sum of elements in the transposed matrix. Your task is to create functions `transpose_matrix` and `sum_transposed_matrix` to achieve this. **Function Signatures**: ```python from typing import List def transpose_matrix(matrix: List[List[int]]) -> List[List[int]]: Approach: - The function takes a 2D list (matrix) and returns its transpose. Params: - matrix (List[List[int]]): A 2D list representing the matrix. Returns: - List[List[int]]: A 2D list representing the transposed matrix. pass def sum_transposed_matrix(matrix: List[List[int]]) -> int: Approach: - The function takes a 2D list (matrix), calculates its transpose using the \'transpose_matrix\' function. - Computes the sum of all elements in the transposed matrix. Params: - matrix (List[List[int]]): A 2D list representing the matrix. Returns: - int: The sum of all elements in the transposed matrix. pass ``` **Input**: * `matrix` - A List of Lists of integers representing the matrix. **Output**: * The `transpose_matrix` function returns a List of Lists of integers representing the transposed matrix. * The `sum_transposed_matrix` function returns an integer representing the sum of all elements in the transposed matrix. **Constraints**: * The matrix is non-empty and rectangular. * The number of rows and columns can be varied but should fit within typical memory constraints for 2D lists in Python. **Examples**: ```python # Example use-case matrix_1 = [ [1, 2, 3], [4, 5, 6] ] # Transposed matrix: # [ # [1, 4], # [2, 5], # [3, 6] # ] # Sum of the transposed matrix: # 1 + 4 + 2 + 5 + 3 + 6 = 21 print(transpose_matrix(matrix_1)) # Output: [[1, 4], [2, 5], [3, 6]] print(sum_transposed_matrix(matrix_1)) # Output: 21 matrix_2 = [ [7] ] # Transposed matrix: # [ # [7] # ] # Sum of the transposed matrix: # 7 print(transpose_matrix(matrix_2)) # Output: [[7]] print(sum_transposed_matrix(matrix_2)) # Output: 7 ``` **Note**: - Make sure to test the functions with various matrix sizes including edge cases like single row, single column, and different rectangular shapes to ensure correctness and robustness. - The transposition should handle negative numbers and mixed values in the matrix as well.","solution":"from typing import List def transpose_matrix(matrix: List[List[int]]) -> List[List[int]]: Transposes the given 2D matrix. Params: - matrix (List[List[int]]): A 2D list representing the matrix. Returns: - List[List[int]]: A 2D list representing the transposed matrix. return [list(row) for row in zip(*matrix)] def sum_transposed_matrix(matrix: List[List[int]]) -> int: Computes the sum of all elements in the transposed matrix. Params: - matrix (List[List[int]]): A 2D list representing the matrix. Returns: - int: The sum of all elements in the transposed matrix. transposed = transpose_matrix(matrix) return sum(sum(row) for row in transposed)"},{"question":"# Dynamic Array Manipulation You are tasked with implementing a dynamic array that supports common operations and resizes itself as needed. Specifically, the dynamic array should support the following operations: `append`, `remove`, and `resize`. For the `resize` operation, the array should double its capacity when it exceeds the current capacity and halve its capacity when the fill percentage drops below 30%. # Function Specifications 1. **Class Name**: `DynamicArray` 2. **Methods**: - `__init__(self)`: Initializes an empty array with an initial capacity of 4. - `append(self, value)`: Adds `value` to the end of the array, resizing if necessary. - `remove(self, value)`: Removes the first occurrence of `value` from the array, resizing if necessary. - `resize(self, new_capacity)`: Resizes the underlying array to `new_capacity`. 3. **Additional Requirements**: - Ensure the `append` method resizes the array before adding a new element if the array is at full capacity. - Ensure the `remove` method resizes the array after removing an element if the remaining number of elements drops below 30% of the capacity. 4. **Performance Requirements**: - All operations (append, remove) should operate in amortized constant time, although resizing will take linear time. # Examples ```python # Example Usage da = DynamicArray() da.append(1) da.append(2) da.append(3) da.append(4) # Triggers resize to capacity 8 da.append(5) da.remove(3) # Removes the value 3 da.remove(2) da.remove(1) da.remove(4) # Triggers resize to capacity 4 print(da.array) # Output should demonstrate the internal state of the array ``` # Implementation Details Include the necessary class definition and implement all methods. Ensure you handle the edge cases such as removing from an empty array or appending when the array is full. The initial size of the internal storage should be 4. ```python class DynamicArray: def __init__(self): self.array = [None] * 4 self.capacity = 4 self.size = 0 def append(self, value): if self.size == self.capacity: self.resize(self.capacity * 2) self.array[self.size] = value self.size += 1 def remove(self, value): for i in range(self.size): if self.array[i] == value: for j in range(i, self.size - 1): self.array[j] = self.array[j + 1] self.array[self.size - 1] = None self.size -= 1 if self.size > 0 and self.size < self.capacity // 3: self.resize(self.capacity // 2) return raise ValueError(\\"Value not found in the array.\\") def resize(self, new_capacity): new_array = [None] * new_capacity for i in range(self.size): new_array[i] = self.array[i] self.array = new_array self.capacity = new_capacity # Example Usage da = DynamicArray() da.append(1) da.append(2) da.append(3) da.append(4) # Triggers resize to capacity 8 da.append(5) da.remove(3) # Removes the value 3 da.remove(2) da.remove(1) da.remove(4) # Triggers resize to capacity 4 print(da.array) # Output should demonstrate the internal state of the array ``` Ensure the class handles appends and removals with plenty of internal capacity changes and maintains the integrity of the data held within the dynamic array.","solution":"class DynamicArray: def __init__(self): self.array = [None] * 4 self.capacity = 4 self.size = 0 def append(self, value): if self.size == self.capacity: self.resize(self.capacity * 2) self.array[self.size] = value self.size += 1 def remove(self, value): for i in range(self.size): if self.array[i] == value: for j in range(i, self.size - 1): self.array[j] = self.array[j + 1] self.array[self.size - 1] = None self.size -= 1 # Check if resizing is needed after removal if self.size > 0 and self.size < self.capacity // 3: self.resize(max(4, self.capacity // 2)) return raise ValueError(\\"Value not found in the array.\\") def resize(self, new_capacity): new_array = [None] * new_capacity for i in range(self.size): new_array[i] = self.array[i] self.array = new_array self.capacity = new_capacity"},{"question":"# Coding Assessment Question **Scenario**: You are part of a team developing a web application that requires efficient handling of user-related data. To that end, you need to develop a function to process and validate user objects before they are stored in the system. **Problem Description**: Write a function `validate_and_process_users` that takes a list of user dictionaries and processes them according to specific criteria. Each user is represented as a dictionary with keys `username`, `email`, `age`, and `signup_date`. The function should return a list of valid user dictionaries after applying the following validations and processing logic: 1. Ensure `username` is a non-empty string consisting of alphanumeric characters and underscores only. 2. Verify that `email` is a valid email address format. 3. Check that `age` is a positive integer. 4. Convert `signup_date` from a string format `YYYY-MM-DD` to a Python `datetime.date` object. 5. Exclude any user dictionary that does not meet all the criteria. # Function Signature ```python import datetime import re def validate_and_process_users(users: list) -> list: pass ``` # Input - **users** (list): A list of dictionaries, each representing a user with the following structure: ```json { \\"username\\": \\"johndoe_123\\", \\"email\\": \\"john.doe@example.com\\", \\"age\\": 30, \\"signup_date\\": \\"2023-01-01\\" } ``` # Output - **list**: A list of validated and processed user dictionaries. # Constraints and Validations - The `username` must be a non-empty string containing only alphanumeric characters and underscores. - The `email` must follow a valid email address format. - The `age` must be a positive integer. - The `signup_date` must be a string in the format `YYYY-MM-DD` and should be converted to a `datetime.date` object. - If any dictionary does not meet these criteria, it should be excluded from the output list. # Example ```python users = [ {\\"username\\": \\"johndoe_123\\", \\"email\\": \\"john.doe@example.com\\", \\"age\\": 30, \\"signup_date\\": \\"2023-01-01\\"}, {\\"username\\": \\"invalid email\\", \\"email\\": \\"invalid@\\", \\"age\\": 25, \\"signup_date\\": \\"2023-02-15\\"}, {\\"username\\": \\"janedoe_456\\", \\"email\\": \\"jane.doe@example.com\\", \\"age\\": 28, \\"signup_date\\": \\"2023-03-10\\"} ] output = validate_and_process_users(users) print(output) ``` Expected Output: ```python [ {\\"username\\": \\"johndoe_123\\", \\"email\\": \\"john.doe@example.com\\", \\"age\\": 30, \\"signup_date\\": datetime.date(2023,1,1)}, {\\"username\\": \\"janedoe_456\\", \\"email\\": \\"jane.doe@example.com\\", \\"age\\": 28, \\"signup_date\\": datetime.date(2023,3,10)} ] ```","solution":"import datetime import re def validate_and_process_users(users: list) -> list: processed_users = [] def is_valid_username(username): return isinstance(username, str) and bool(re.match(r\'^w+\', username)) def is_valid_email(email): return isinstance(email, str) and bool(re.match(r\'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+\', email)) def is_valid_age(age): return isinstance(age, int) and age > 0 def is_valid_signup_date(signup_date): try: return datetime.datetime.strptime(signup_date, \'%Y-%m-%d\').date() except ValueError: return None for user in users: username = user.get(\'username\') email = user.get(\'email\') age = user.get(\'age\') signup_date = user.get(\'signup_date\') if is_valid_username(username) and is_valid_email(email) and is_valid_age(age): processed_date = is_valid_signup_date(signup_date) if processed_date: user[\'signup_date\'] = processed_date processed_users.append(user) return processed_users"},{"question":"# Question: Maximum Subarray Sum with Indices Objective Implement an efficient algorithm to find the contiguous subarray within a one-dimensional array of numbers which has the largest sum and return that sum along with the starting and ending indices of the subarray. Task 1. **Implement a function, `max_subarray_sum(arr: list[int]) -> tuple[int, int, int]`,** that returns the maximum subarray sum along with the starting and ending indices of the subarray. Function Signature ```python def max_subarray_sum(arr: list[int]) -> tuple[int, int, int]: # Implement the function to find the maximum subarray sum and its indices pass ``` Expected Input and Output - **Input**: A list `arr` of integers where the length of the list is between 1 and 10,000. - **Output**: A tuple containing the maximum subarray sum, the starting index of the subarray, and the ending index of the subarray. Constraints - -10^4 ≤ arr[i] ≤ 10^4 - 1 ≤ len(arr) ≤ 10,000 Example ```python >>> max_subarray_sum([1, -2, 3, 4, -1, 2, 1, -5, 4]) (9, 2, 6) >>> max_subarray_sum([-2, 1, -3, 4, -1, 2, 1, -5, 4]) (6, 3, 6) >>> max_subarray_sum([5, 4, -1, 7, 8]) (23, 0, 4) ``` Explanation - For the first example, the subarray with the maximum sum is `[3, 4, -1, 2, 1]` with sum `9`, starting at index `2` and ending at index `6`. - For the second example, the subarray with the maximum sum is `[4, -1, 2, 1]` with sum `6`, starting at index `3` and ending at index `6`. - For the third example, the subarray with the maximum sum is `[5, 4, -1, 7, 8]` with sum `23`, starting at index `0` and ending at index `4`.","solution":"def max_subarray_sum(arr): Finds the maximum subarray sum along with the starting and ending indices of the subarray. max_sum = arr[0] current_sum = arr[0] start = 0 end = 0 current_start = 0 for i in range(1, len(arr)): if current_sum < 0: current_sum = arr[i] current_start = i else: current_sum += arr[i] if current_sum > max_sum: max_sum = current_sum start = current_start end = i return (max_sum, start, end)"},{"question":"# Cyclic Rotation of an Array Cyclic rotation of an array means moving each element of the array right by a certain number of steps, where the last element moves back to the start. Your task is to write a function `cyclic_rotation(arr: List[int], rotations: int) -> List[int]` that performs the cyclic rotation on a given list of integers by a specified number of steps. Input - `arr`: A list of integers. - `rotations`: An integer representing the number of steps to rotate the array. It can be any integer, positive or negative. Positive values indicate rotation to the right, and negative values indicate rotation to the left. Output - A list of integers representing the rotated array. Constraints - The input list `arr` can be empty, and the function should handle this case correctly. - `arr` can contain up to (10^5) elements. - The elements of `arr` are integers within the range ([-10^5, 10^5]). - The absolute value of `rotations` can be larger than the length of `arr`. # Examples ```python >>> cyclic_rotation([1, 2, 3, 4, 5], 2) [4, 5, 1, 2, 3] >>> cyclic_rotation([1, 2, 3, 4, 5], -2) [3, 4, 5, 1, 2] >>> cyclic_rotation([1, 2, 3], 0) [1, 2, 3] >>> cyclic_rotation([], 3) [] ``` Notes - If the `rotations` parameter is positive, the function should move elements to the right. - If `rotations` is negative, the function should move elements to the left. - For large values of `rotations`, equivalent minimal rotations should be used (e.g., rotating by the length of the array results in no change).","solution":"from typing import List def cyclic_rotation(arr: List[int], rotations: int) -> List[int]: Rotates a given list of integers by a specified number of steps. Parameters: arr (List[int]): The list of integers to rotate. rotations (int): The number of steps to rotate the array. Positive for right rotation, negative for left rotation. Returns: List[int]: The rotated list of integers. if not arr: return arr n = len(arr) rotations = rotations % n if rotations == 0: return arr return arr[-rotations:] + arr[:-rotations]"},{"question":"Sorting Strings by Character Frequency Problem Statement You are given a function `sort_by_frequency` that sorts an array of strings based on the frequency of a specified character within each string. Your task is to implement this function. Function Signature ```python def sort_by_frequency(strings: list, char: str) -> list: pass ``` Detailed Description * `strings` (list): A list of string values to be sorted. * `char` (str): A character whose frequency within each string determines the sorting order. Input Constraints - Each item in the `strings` list is a non-empty string. - The `char` is guaranteed to be a single character (not an empty string). - The sorting should be in descending order based on the frequency of `char`. If two strings have the same frequency, they should appear in their original order relative to each other (stable sort). Output - Return a list of strings sorted based on the frequency of `char`. Example Usage Implement the function with the following behavior: ```python >>> sort_by_frequency([\\"apple\\", \\"banana\\", \\"cherry\\", \\"date\\"], \'a\') [\'banana\', \'apple\', \'date\', \'cherry\'] >>> sort_by_frequency([\\"ant\\", \\"bat\\", \\"cat\\", \\"rat\\"], \'t\') [\'bat\', \'cat\', \'rat\', \'ant\'] >>> sort_by_frequency([\\"zz\\", \\"z\\", \\"zzz\\", \\"zzzz\\"], \'z\') [\'zzzz\', \'zzz\', \'zz\', \'z\'] >>> sort_by_frequency([\\"apple\\", \\"banana\\", \\"cherry\\", \\"date\\"], \'x\') [\'apple\', \'banana\', \'cherry\', \'date\'] ``` Hints - Use the `sorted` function with a custom `key` argument to count occurrences of `char` in each string. - Consider edge cases where `char` is not present in any of the strings. Ensure that your implementation passes these test cases and handles additional edge cases appropriately.","solution":"def sort_by_frequency(strings, char): Sorts strings by the frequency of the specified character in descending order. return sorted(strings, key=lambda s: s.count(char), reverse=True)"},{"question":"# Sorting 0s, 1s, and 2s Problem Statement: You are given an array containing only three distinct integers: 0, 1, and 2. Write a function to sort this array in ascending order. This problem is commonly known as the \\"Dutch National Flag problem\\" and must be solved in O(n) time complexity with a single traversal of the array. Function Signature: ```python def sort_colors(nums: List[int]) -> None: Given an array containing only integers 0, 1, and 2, sort the array in-place. :param nums: List of integers where each element is either 0, 1, or 2. :return: None. The function modifies the list in-place. ``` Input: - A list `nums` of length `n` (0 ≤ n ≤ 10^5), where each element is either 0, 1, or 2. Output: - The list sorted in ascending order. Constraints: - You must solve this problem in O(n) time complexity. - The function should modify the list in-place without using extra space for another list. Example: ```python nums = [2, 0, 2, 1, 1, 0] sort_colors(nums) assert nums == [0, 0, 1, 1, 2, 2] nums = [2, 1, 0] sort_colors(nums) assert nums == [0, 1, 2] nums = [0, 1, 2] sort_colors(nums) assert nums == [0, 1, 2] ``` Explanation: - For the input `[2, 0, 2, 1, 1, 0]`, the function modifies it in-place to `[0, 0, 1, 1, 2, 2]` after sorting. - For the input `[2, 1, 0]`, the function modifies it in-place to `[0, 1, 2]`. - For already sorted input like `[0, 1, 2]`, the list remains `[0, 1, 2]`. This function should properly handle sorting an array containing only the values 0, 1, and 2 by traversing the array only once and making in-place modifications to achieve the sorted order.","solution":"from typing import List def sort_colors(nums: List[int]) -> None: Given an array containing only integers 0, 1, and 2, sort the array in-place. :param nums: List of integers where each element is either 0, 1, or 2. :return: None. The function modifies the list in-place. low, mid, high = 0, 0, len(nums) - 1 while mid <= high: if nums[mid] == 0: nums[low], nums[mid] = nums[mid], nums[low] low += 1 mid += 1 elif nums[mid] == 1: mid += 1 else: nums[high], nums[mid] = nums[mid], nums[high] high -= 1"},{"question":"Prime Factorization and GCD # Context: Finding the greatest common divisor (GCD) of two numbers is essential in various areas of computer science and mathematics. A common method to determine the GCD is by using Euclid\'s algorithm, but another interesting way can be derived from the prime factorization of the numbers. # Task: Implement a function `prime_factorization_gcd(a: int, b: int) -> int`. This function should compute the GCD of (a) and (b) by first determining their prime factorizations. # Function Signature: ```python def prime_factorization_gcd(a: int, b: int) -> int: ``` # Input: * **a (int)**: First input number, (1 le a le 10^{12}) * **b (int)**: Second input number, (1 le b le 10^{12}) # Output: * **int**: The GCD of (a) and (b) # Constraints: * (1 le a, b le 10^{12}) # Example: ```python assert prime_factorization_gcd(48, 180) == 12 assert prime_factorization_gcd(100, 75) == 25 ``` # Notes: To factorize numbers effectively, consider using a sieve-based approach up to the square root of the larger number, and then find common factors from their factorizations. Remember to handle edge cases where one input could be 1 or both inputs are prime numbers. Here\'s a helper function for prime factorization: ```python def prime_factors(n: int) -> dict: i = 2 factors = {} # Check for number of 2s while n % i == 0: factors[i] = factors.get(i, 0) + 1 n //= i # Check for other primes for i in range(3, int(n**0.5) + 1, 2): while n % i == 0: factors[i] = factors.get(i, 0) + 1 n //= i if n > 2: factors[n] = 1 return factors ``` By using this helper function, you can combine the factors to compute the GCD from their prime factorizations. Good luck! Ensure your solution handles large inputs efficiently and correctly computes the GCD using the prime factorization method.","solution":"def prime_factors(n: int) -> dict: i = 2 factors = {} # Check for number of 2s while n % i == 0: factors[i] = factors.get(i, 0) + 1 n //= i # Check for other primes for i in range(3, int(n**0.5) + 1, 2): while n % i == 0: factors[i] = factors.get(i, 0) + 1 n //= i # If n is a prime number greater than 2 if n > 2: factors[n] = 1 return factors def prime_factorization_gcd(a: int, b: int) -> int: Computes the GCD of a and b using their prime factorizations. factors_a = prime_factors(a) factors_b = prime_factors(b) common_factors = {} for p in factors_a: if p in factors_b: common_factors[p] = min(factors_a[p], factors_b[p]) gcd = 1 for p in common_factors: gcd *= p ** common_factors[p] return gcd"},{"question":"# Matrix Rotation Checker You are given two matrices, `matrix1` and `matrix2`, each represented as a 2D list of integers. Your task is to determine if `matrix2` can be obtained by rotating `matrix1` by 90, 180, or 270 degrees. # Input Format - `matrix1`: A 2D list of integers `[aij]` with dimensions `m x n`. - `matrix2`: A 2D list of integers `[bij]` with dimensions `n x m`. # Output Format - Return a boolean value: - `True` if `matrix2` can be obtained by rotating `matrix1` by 90, 180, or 270 degrees. - `False` otherwise. # Constraints - The dimensions of `matrix1` and `matrix2` will be such that the rotation conditions can be checked. - Elements of the matrices are integers and can be negative or positive. - 1 ≤ `m`, `n` ≤ 100 # Example ```python matrix1 = [[1, 2, 3], [4, 5, 6]] matrix2 = [[4, 1], [5, 2], [6, 3]] result = can_rotate(matrix1, matrix2) # Expected output: True ``` # Function Signature ```python def can_rotate(matrix1, matrix2): # Your code here ``` Implementation Details - You need to check all possible rotations of `matrix1` (90, 180, 270 degrees) and see if any of them matches `matrix2`. - A 90 degrees rotation of `matrix1` results in each element `(i, j)` moving to `(j, n-1-i)`. - A 180 degrees rotation of `matrix1` results in each element `(i, j)` moving to `(m-1-i, n-1-j)`. - A 270 degrees rotation of `matrix1` results in each element `(i, j)` moving to `(m-1-j, i)`. - Compare the resulting matrices after each rotation with `matrix2` to determine if they match.","solution":"def can_rotate(matrix1, matrix2): def rotate_90(matrix): rows, cols = len(matrix), len(matrix[0]) return [[matrix[rows - 1 - j][i] for j in range(rows)] for i in range(cols)] def rotate_180(matrix): rows, cols = len(matrix), len(matrix[0]) return [[matrix[rows - 1 - i][cols - 1 - j] for j in range(cols)] for i in range(rows)] def rotate_270(matrix): rows, cols = len(matrix), len(matrix[0]) return [[matrix[j][cols - 1 - i] for j in range(rows)] for i in range(cols)] # Check all rotations if matrix2 == rotate_90(matrix1): return True if matrix2 == rotate_180(matrix1): return True if matrix2 == rotate_270(matrix1): return True return False"},{"question":"# Question You are provided with a binary tree and given a specific value. Your task is to write a function that determines the depth of the given value in the binary tree. The depth of the root node is 0. If the value is not found in the tree, return -1. # Function Signature ```python def find_depth(root: TreeNode, value: int) -> int: ``` # Input - `root`: the root node of the binary tree (the input will be given as a TreeNode object). - `value`: an integer representing the value whose depth is to be found. # Output - An integer representing the depth of the given value in the binary tree. - If the value is not found, return -1. # Constraints - Each value in the binary tree is unique. - The number of nodes in the tree is between 1 and 10^4. - Node values will be integers within the range of -10^9 to 10^9. # Example ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right >>> root = TreeNode(3) >>> root.left = TreeNode(9) >>> root.right = TreeNode(20) >>> root.right.left = TreeNode(15) >>> root.right.right = TreeNode(7) >>> find_depth(root, 15) 2 >>> find_depth(root, 9) 1 >>> find_depth(root, 10) -1 ``` # Explanation - In the first example, the value `15` is found at depth 2. - In the second example, the value `9` is found at depth 1. - In the third example, the value `10` is not found in the tree, so the function returns -1. Implement your function in Python: ```python class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def find_depth(root: TreeNode, value: int) -> int: # Your code here # ```","solution":"class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def find_depth(root: TreeNode, value: int) -> int: def dfs(node, depth): if node is None: return -1 if node.val == value: return depth left_depth = dfs(node.left, depth + 1) if left_depth != -1: return left_depth return dfs(node.right, depth + 1) return dfs(root, 0)"},{"question":"# Friend Circles Using Disjoint Set You are tasked with writing a program that identifies friend circles in a social network using the Disjoint Set data structure. A friend circle is defined as a group of friends who are directly or indirectly friends with each other. Input and Output: - **Input**: * A 2D list `friends` where friends[i][j] = 1 indicates that person `i` is friends with person `j`, and friends[i][j] = 0 indicates they are not. - **Output**: * An integer `num_circles` representing the number of distinct friend circles. Constraints: - The list `friends` is an n x n matrix where 1 <= n <= 200. - The diagonal elements `friends[i][i]` will always be 1 (each person is friends with themselves). - There are no duplicate relations (i.e., friends[i][j] == friends[j][i]). Performance: - Your implementation should efficiently handle the matrix size up to 200 x 200. Example: ```python friends = [ [1, 1, 0], [1, 1, 0], [0, 0, 1] ] # Expected Output: 2 (Friend circles are {0, 1} and {2}) print(find_friend_circles(friends)) ``` Function Signature: ```python def find_friend_circles(friends: List[List[int]]) -> int: pass ``` Provide the implementation for the `find_friend_circles` function using the Disjoint Set data structure, ensuring it handles all constraints and edge cases listed above.","solution":"from typing import List class DisjointSet: def __init__(self, size: int): self.parent = list(range(size)) self.rank = [1] * size def find(self, node: int) -> int: if self.parent[node] != node: self.parent[node] = self.find(self.parent[node]) # path compression return self.parent[node] def union(self, node1: int, node2: int) -> None: root1 = self.find(node1) root2 = self.find(node2) if root1 != root2: # union by rank if self.rank[root1] > self.rank[root2]: self.parent[root2] = root1 elif self.rank[root1] < self.rank[root2]: self.parent[root1] = root2 else: self.parent[root2] = root1 self.rank[root1] += 1 def find_friend_circles(friends: List[List[int]]) -> int: n = len(friends) ds = DisjointSet(n) for i in range(n): for j in range(i + 1, n): if friends[i][j] == 1: ds.union(i, j) # Count the number of unique roots, which corresponds to distinct friend circles unique_roots = set() for i in range(n): unique_roots.add(ds.find(i)) return len(unique_roots)"},{"question":"# Coding Challenge # Problem Statement You are given a list of unique integers. Your task is to find the length of the longest consecutive elements sequence. # Input - A string representation of the list of integers, separated by commas. - Guarantee: The list will contain between 1 and 10^5 integers. # Output - An integer representing the length of the longest consecutive elements sequence. # Example Input ``` 100,4,200,1,3,2 ``` Output ``` 4 ``` # Explanation For the given example, the longest consecutive elements sequence is [1, 2, 3, 4] which has a length of 4. # Function Signature ```python def longest_consecutive_sequence(nums_str: str) -> int: pass ``` # Constraints - 1 ≤ length of list ≤ 10^5 - All list values are integers between -10^9 and 10^9. - All integers in the list are unique. # Scenario You are developing an optimized solution for a system that needs to continuously track runs of consecutive numbers in a dynamic dataset. This problem combines efficient algorithms with careful attention to input constraints, ensuring high performance even with large datasets. Your approach should ideally operate with linear complexity.","solution":"def longest_consecutive_sequence(nums_str: str) -> int: nums = list(map(int, nums_str.split(\',\'))) num_set = set(nums) longest_length = 0 for num in nums: # Only check for the start of a sequence if num - 1 not in num_set: current_num = num current_length = 1 while current_num + 1 in num_set: current_num += 1 current_length += 1 longest_length = max(longest_length, current_length) return longest_length"},{"question":"# Scenario In a streaming data analysis workshop, you are asked to create a function to compute the moving average of a sequence of numbers. You have observed that understanding moving averages is crucial for data smoothing and trend identification. # Task Write a function `moving_average(sequence: list[float], window_size: int) -> list[float]` that calculates the moving average of the sequence with a specified window size. # Function Signature ```python def moving_average(sequence: list[float], window_size: int) -> list[float] ``` # Input * A list of floating-point numbers `sequence` of length n (1 <= n <= 1000) * An integer `window_size` (1 <= window_size <= n) # Output * A list of floating-point numbers representing the moving average of the sequence, where each element is the average of the current and the previous (window_size - 1) elements. # Constraints * The input list will have at most 1000 elements. * The window size will always be a positive integer and no greater than the length of the sequence. * The result should include as many averages as possible, with enough elements in the sequence to form the specified window size. # Example 1. For an input `sequence = [1, 2, 3, 4, 5]` and `window_size = 3` - The function should return `[2.0, 3.0, 4.0]` 2. For an input `sequence = [5, 8, 6, 7, 10]` and `window_size = 2` - The function should return `[6.5, 7.0, 6.5, 8.5]` 3. For an input `sequence = [10, 20, 30, 40]` and `window_size = 4` - The function should return `[25.0]` # Additional Requirements * The function should handle edge cases like when the `window_size` is 1, returning the sequence itself. * Ensure that the averages are calculated as floating-point numbers and maintain precision.","solution":"def moving_average(sequence: list[float], window_size: int) -> list[float]: Computes the moving average of the input sequence with the specified window size. n = len(sequence) if window_size > n: return [] averages = [] for i in range(n - window_size + 1): window = sequence[i:i + window_size] window_avg = sum(window) / window_size averages.append(window_avg) return averages"},{"question":"# Task: Your task is to implement a function that receives a string and returns the character that appears the most frequently. If there are multiple characters with the same highest frequency, return the one that appears first in the string. # Function Signature: ```python def most_frequent_char(text: str) -> str: pass ``` # Input: - `text` (str): A string of text from which to find the most frequent character. # Output: - A single character (str): The character that appears most frequently in the string. If there is a tie, return the first one encountered. # Sample Usage: ```python print(most_frequent_char(\\"test\\")) # Prints: \\"t\\" print(most_frequent_char(\\"character\\")) # Prints: \\"c\\" print(most_frequent_char(\\"aabbcc\\")) # Prints: \\"a\\" ``` # Constraints: - The text contains only ASCII characters and spaces. - Text length can be up to 10,000 characters. - The function should be case-sensitive (\'a\' and \'A\' are considered different characters). # Implementation Tips: - Use the `Counter` class from `collections` to count occurrences of each character. - Iterate through the string to determine the first character with the highest frequency in the case of ties. - Handle edge cases, like empty text or text with a single character, appropriately.","solution":"from collections import Counter def most_frequent_char(text: str) -> str: if not text: return \\"\\" count = Counter(text) max_freq = max(count.values()) for char in text: if count[char] == max_freq: return char"},{"question":"# Coding Question: Implement a Custom HashMap with Collision Handling **Objective**: Write a class `CustomHashMap` that implements a hash map with basic functionality while efficiently handling collisions using separate chaining with linked lists. # Context A hash map (or hash table) is a data structure that implements an associative array, a structure that can map keys to values. The goal is to achieve `O(1)` time complexity for average-case operations like insertions, deletions, and lookups. # Input and Output Format - **Methods**: - `put(key: int, value: int) -> None`: Inserts a key-value pair into the hash map. If the key already exists, update the value. - `get(key: int) -> int`: Returns the value associated with the key if it exists, otherwise returns `-1`. - `remove(key: int) -> None`: Removes the key and its associated value from the hash map if the key exists. # Constraints - The keys and values will be integer numbers. - The hash map should handle collisions using separate chaining with linked lists. - The maximum number of keys that will be stored does not exceed 10,000. # Performance Requirements - Optimize for efficient collision handling and minimize the possibility of clustering. - Ensure the hash map supports efficient resizing as needed. # Examples ```python class CustomHashMap: def __init__(self): pass def put(self, key: int, value: int) -> None: pass def get(self, key: int) -> int: pass def remove(self, key: int) -> None: pass # Example Usage: # hashMap = CustomHashMap() # hashMap.put(1, 1) # The map is now [[1, 1]] # hashMap.put(2, 2) # The map is now [[1, 1], [2, 2]] # assert hashMap.get(1) == 1 # returns 1 # assert hashMap.get(3) == -1 # returns -1 (not found) # hashMap.put(2, 1) # The map is now [[1, 1], [2, 1]] (update existing value) # assert hashMap.get(2) == 1 # returns 1 # hashMap.remove(2) # The map becomes [[1, 1]] # assert hashMap.get(2) == -1 # returns -1 (not found) ``` # Additional Notes 1. Choose an initial size for the hash table and resize it dynamically to maintain a low load factor. 2. Consider edge cases like inserting, retrieving, and deleting keys in quick succession. 3. Implement necessary helper functions to manage linked list operations within the hash map, such as insertion, deletion, and searching within a bucket.","solution":"class ListNode: def __init__(self, key=None, value=None): self.key = key self.value = value self.next = None class CustomHashMap: def __init__(self): self.size = 1000 self.buckets = [None] * self.size def put(self, key: int, value: int) -> None: index = self._hash(key) if self.buckets[index] is None: self.buckets[index] = ListNode(key, value) else: current = self.buckets[index] while True: if current.key == key: current.value = value return if current.next is None: break current = current.next current.next = ListNode(key, value) def get(self, key: int) -> int: index = self._hash(key) current = self.buckets[index] while current is not None: if current.key == key: return current.value current = current.next return -1 def remove(self, key: int) -> None: index = self._hash(key) current = self.buckets[index] if current is None: return if current.key == key: self.buckets[index] = current.next return prev = None while current is not None: if current.key == key: prev.next = current.next return prev = current current = current.next def _hash(self, key: int) -> int: return key % self.size"},{"question":"# Coding Assessment Question **Context**: You need to implement a function that checks if two binary trees are identical. Two binary trees are considered identical if their structure is the same and the nodes have the same values. **Objective**: Implement a function that determines whether two binary trees represented as adjacency lists are identical or not. **Function Signature**: ```python def are_identical_trees(tree1: dict, tree2: dict, root: int = 1) -> bool: ``` **Input**: * `tree1` (dict): A dictionary where each key is a node value, and its value is a list containing two elements - the left and right children. If a child is missing, it should be represented as `None`. * `tree2` (dict): A dictionary representing another binary tree using the same format as `tree1`. * `root` (int): An integer specifying the root of the binary trees. Default is 1. **Output**: * `bool`: `True` if the binary trees are identical, otherwise `False`. **Constraints**: * Trees can have zero or more nodes. * Nodes are indexed with unique integers. * The function should return `False` if either or both of the trees are empty. **Requirements**: 1. If either `tree1` or `tree2` is empty, your function should return `False`. **Examples**: ```python are_identical_trees({1: [2, 3], 2: [4, 5], 3: [6, 7]}, {1: [2, 3], 2: [4, 5], 3: [6, 7]}, 1) # Output: True are_identical_trees({1: [2, 3], 2: [4, 5]}, {1: [2, None], 2: [4, 5]}, 1) # Output: False are_identical_trees({1: [2, None]}, {1: [2, None]}, 1) # Output: True are_identical_trees({}, {1: [2, None]}, 1) # Output: False are_identical_trees({}, {}, 1) # Output: False ```","solution":"def are_identical_trees(tree1: dict, tree2: dict, root: int = 1) -> bool: # Both trees must not be empty if not tree1 or not tree2: return False def check_identical(n1, n2): if n1 is None and n2 is None: return True if n1 is None or n2 is None: return False if n1 != n2: return False l1, r1 = tree1.get(n1, [None, None]) l2, r2 = tree2.get(n2, [None, None]) return check_identical(l1, l2) and check_identical(r1, r2) return check_identical(root, root)"},{"question":"# Question: Implement a Priority Queue Using a Min-Heap You are required to implement a priority queue using a min-heap. A priority queue is a data structure that allows elements to be inserted in arbitrary order but always removes the element with the highest priority (i.e., the smallest element) first. Implement the following class: ```python class MinHeapPriorityQueue: def __init__(self): Initializes an empty priority queue. self.heap = [] def insert(self, val: int) -> None: Insert an integer \'val\' into the priority queue. pass def extract_min(self) -> int: Removes and returns the smallest element in the priority queue. If the queue is empty, raise an IndexError. pass def peek_min(self) -> int: Returns the smallest element in the priority queue without removing it. If the queue is empty, raise an IndexError. pass ``` # Requirements: 1. Implement `insert(self, val: int) -> None` method to add a value to the heap. 2. Implement `extract_min(self) -> int` method to remove and return the smallest value. Raise `IndexError` if the heap is empty. 3. Implement `peek_min(self) -> int` method to return the smallest value without removing it. Raise `IndexError` if the heap is empty. 4. Ensure the heap property is maintained in all operations. # Constraints: * All elements in the heap are integers. * The heap will contain at most 10^4 elements. # Example Usage: ```python >>> queue = MinHeapPriorityQueue() >>> queue.insert(5) >>> queue.insert(3) >>> queue.insert(10) >>> queue.peek_min() 3 >>> queue.extract_min() 3 >>> queue.extract_min() 5 >>> queue.extract_min() 10 >>> queue.extract_min() Traceback (most recent call last): ... IndexError: extract_min from an empty Priority Queue ``` # Additional Guideline: - You may use the `heapq` library from Python\'s standard library in your implementation if you choose, or implement the heap operations manually. - Make sure to handle edge cases appropriately.","solution":"import heapq class MinHeapPriorityQueue: def __init__(self): Initializes an empty priority queue. self.heap = [] def insert(self, val: int) -> None: Insert an integer \'val\' into the priority queue. heapq.heappush(self.heap, val) def extract_min(self) -> int: Removes and returns the smallest element in the priority queue. If the queue is empty, raise an IndexError. if self.heap: return heapq.heappop(self.heap) else: raise IndexError(\\"extract_min from an empty Priority Queue\\") def peek_min(self) -> int: Returns the smallest element in the priority queue without removing it. If the queue is empty, raise an IndexError. if self.heap: return self.heap[0] else: raise IndexError(\\"peek_min from an empty Priority Queue\\")"},{"question":"# LRU Cache Implementation and Analysis Background An LRU (Least Recently Used) cache is a type of data structure that stores a limited number of items. When the cache reaches its maximum capacity, it evicts the least recently accessed item before inserting a new one. This ensures that recently accessed items remain available in the cache. Problem Statement You are required to implement an LRU Cache. Your implementation should: 1. Allow specification of the cache capacity during initialization. 2. Support retrieval and insertion of items while ensuring the most recently accessed items are retained. 3. Implement an efficient mechanism to manage item eviction and access. Requirements 1. **Function Signatures and Definitions**: - `class LRUCache(capacity)`: Constructor to initialize the LRU cache with specified capacity. - `def get(key)`: Retrieve the value associated with the key if it exists; return -1 otherwise. - `def put(key, value)`: Insert or update the value with the associated key. If the cache exceeds the capacity, evict the least recently accessed item. - `@property def cache_contents()`: Return the current state of the cache as a dictionary. 2. **Input/Output**: - Initialize the LRU Cache with a specified `capacity`. - Insert and retrieve items and check cache contents. 3. **Constraints**: - Capacity must be at least 1. - Keys and values are assumed to be integers. - Ensure all operations (get and put) have an average time complexity of O(1). Objectives - Understand the use of a doubly linked list and a hash table in implementing the LRU Cache. - Optimize for fast access and eviction. - Ensure the cache maintains the specified capacity and correctly evicts items in LRU order. Implement the LRU Cache with the specified functionality and constraints.","solution":"class Node: def __init__(self, key=None, value=None): self.key = key self.value = value self.prev = None self.next = None class LRUCache: def __init__(self, capacity): self.capacity = capacity self.cache = {} self.head = Node() self.tail = Node() self.head.next = self.tail self.tail.prev = self.head def _remove(self, node): prev = node.prev nxt = node.next prev.next = nxt nxt.prev = prev def _add(self, node): prev = self.tail.prev prev.next = node self.tail.prev = node node.prev = prev node.next = self.tail def get(self, key): if key in self.cache: node = self.cache[key] self._remove(node) self._add(node) return node.value return -1 def put(self, key, value): if key in self.cache: node = self.cache[key] self._remove(node) elif len(self.cache) == self.capacity: node = self.head.next self._remove(node) del self.cache[node.key] node = Node(key, value) self.cache[key] = node self._add(node) @property def cache_contents(self): contents = {} current = self.head.next while current != self.tail: contents[current.key] = current.value current = current.next return contents"},{"question":"Maximum Bipartite Matching - Graph Algorithm The Bipartite Matching problem involves finding the maximum matching in a bipartite graph. A Matching is a set of edges without common vertices. In a bipartite graph, the vertices can be divided into two disjoint sets such that every edge connects a vertex in the first set to a vertex in the second set. # Task Implement the function `max_bipartite_matching(graph: dict, set1: set, set2: set) -> int` that finds and returns the maximum number of matching edges in the bipartite graph. # Constraints * The graph is represented as an adjacency list. * Vertices are labeled as non-negative integers. * `set1` and `set2` represent the two disjoint sets of vertices. * The graph can have up to 1000 vertices and 5000 edges but will always be bipartite. # Expected Input and Output * **Input**: A dictionary where each key is a vertex and the corresponding value is a list of vertices connected by an edge, and two sets representing the bipartite division. ```python { 0: [3, 4], 1: [3], 2: [4, 5], 3: [0, 1], 4: [0, 2], 5: [2] }, {0, 1, 2}, # Set1 {3, 4, 5} # Set2 ``` * **Output**: An integer representing the maximum number of matching edges. ```python 3 ``` # Performance Requirements Your solution should be efficient to handle large graphs. Consider using depth-first search (DFS) or breadth-first search (BFS) for finding augmenting paths. # Edge Cases * Handle graphs with no edges. * Handle graphs where some vertices have no connections. * Ensure correctness for complete and incomplete bipartite graphs. # Example ```python def max_bipartite_matching(graph: dict, set1: set, set2: set) -> int: # Your implementation here # Example usage: graph = {0: [3, 4], 1: [3], 2: [4, 5], 3: [0, 1], 4: [0, 2], 5: [2]} set1 = {0, 1, 2} set2 = {3, 4, 5} print(max_bipartite_matching(graph, set1, set2)) # Expected output: 3 ```","solution":"def bpm(graph, u, matchR, seen): A DFS based recursive function that returns True if a matching for vertex u is possible. for v in graph[u]: # If vertex v is not seen and u-v is an edge in the graph if not seen[v]: # Mark v as seen seen[v] = True # If v is not matched or previously matched vertex for v has an alternative match if matchR[v] == -1 or bpm(graph, matchR[v], matchR, seen): matchR[v] = u return True return False def max_bipartite_matching(graph, set1, set2): Returns the maximum number of matching edges in the bipartite graph. # An array to keep track of the matchings for vertices in set2. -1 indicates no match. matchR = [-1] * (len(set1) + len(set2)) result = 0 # Count of matches made # Iterate over each vertex in set1 for u in set1: seen = [False] * (len(set1) + len(set2)) # Mark all vertices as not seen for next u # Find an augmenting path and if found increase the number of matches if bpm(graph, u, matchR, seen): result += 1 return result"},{"question":"# Question: Design and Implement a Prefix Trie with Support for Wildcard Queries You are tasked with designing and implementing a prefix trie (also known as a prefix tree) that supports the following functionalities: 1. **Insert**: Add a word to the trie. 2. **Search**: Check if a word exists in the trie. 3. **Wildcard Query**: Search for words in the trie that match a given pattern, where a question mark `?` serves as a wildcard for any single character. Function Specifications: 1. **Insert**: * Function Name: `insert` * Input: A string `word` * Output: None 2. **Search**: * Function Name: `search` * Input: A string `word` * Output: Boolean value indicating whether the word exists in the trie. 3. **Wildcard Query**: * Function Name: `wildcard_search` * Input: A string `pattern` containing alphabet characters and the wildcard character `?`. * Output: A list of strings from the trie that match the given pattern. Constraints: - All strings consist of lowercase English letters only. - Ensure that insert and search operations maintain a time complexity of O(n), where n is the length of the word. - The wildcard `?` can replace any single character in the pattern but does not match zero characters. Example Usage: ```python trie = Trie() # Insert words into the trie trie.insert(\\"apple\\") trie.insert(\\"apply\\") trie.insert(\\"apt\\") trie.insert(\\"bat\\") trie.insert(\\"ball\\") # Search for words print(trie.search(\\"apple\\")) # Expected Output: True print(trie.search(\\"app\\")) # Expected Output: False # Wildcard search print(trie.wildcard_search(\\"a?ple\\")) # Expected Output: [\'apple\'] print(trie.wildcard_search(\\"b??l\\")) # Expected Output: [\'ball\'] ``` Write a class `Trie` that implements the given functionalities. Ensure all methods are thoroughly tested, and handle edge cases (e.g., searching for words or patterns that don\'t exist in the trie).","solution":"class TrieNode: def __init__(self): self.children = {} self.is_end_of_word = False class Trie: def __init__(self): self.root = TrieNode() def insert(self, word): Inserts a word into the trie. node = self.root for char in word: if char not in node.children: node.children[char] = TrieNode() node = node.children[char] node.is_end_of_word = True def search(self, word): Returns if the word is in the trie. node = self.root for char in word: if char not in node.children: return False node = node.children[char] return node.is_end_of_word def wildcard_search(self, pattern): Returns words in the trie that match the given pattern. def dfs(node, pattern, index, path, result): if index == len(pattern): if node.is_end_of_word: result.append(path) return char = pattern[index] if char == \'?\': for child_char, child_node in node.children.items(): dfs(child_node, pattern, index + 1, path + child_char, result) elif char in node.children: dfs(node.children[char], pattern, index + 1, path + char, result) result = [] dfs(self.root, pattern, 0, \\"\\", result) return result"},{"question":"# Coding Assessment Question: Optimize an Inventory Tracking System Context You are given a basic inventory system that tracks items in a store. Each item has a name, category, price, and quantity. The current implementation allows adding new items, updating existing items, and querying the inventory. However, it lacks certain features that would enhance its usability and efficiency. Task 1. **Extend Item Class**: Modify the `Item` class to include methods for: - Applying a discount to the price. - Displaying item details in a formatted string. 2. **Inventory Report Generation**: Implement a method `generate_report` in the `Inventory` class that: - Returns a summary of all items in the inventory, grouped by their category. 3. **Total Inventory Value Calculation**: Implement a method `total_inventory_value` in the `Inventory` class that: - Calculates and returns the total value of all items in the inventory. 4. **Searching Items by Name**: Implement a method `search_items` in the `Inventory` class that: - Returns a list of items that match a given name or part of a name (case-insensitive). Implementation ```python class Item: def __init__(self, name, category, price, quantity): self.name = name self.category = category self.price = price self.quantity = quantity def apply_discount(self, discount_percentage): self.price -= self.price * (discount_percentage / 100) def display_details(self): return f\\"Item: {self.name}, Category: {self.category}, Price: {self.price:.2f}, Quantity: {self.quantity}\\" class Inventory: def __init__(self): self.items = [] def add_item(self, item): self.items.append(item) def update_item(self, item_name, price=None, quantity=None): for item in self.items: if item.name == item_name: if price is not None: item.price = price if quantity is not None: item.quantity = quantity break def generate_report(self): report = {} for item in self.items: if item.category not in report: report[item.category] = [] report[item.category].append(item.display_details()) return report def total_inventory_value(self): total_value = sum(item.price * item.quantity for item in self.items) return total_value def search_items(self, name): return [item for item in self.items if name.lower() in item.name.lower()] ``` Input Format - The `Item` class constructor takes four parameters: `name`, `category`, `price`, and `quantity`. - Method `add_item` adds an `Item` object to the inventory. - Method `update_item` takes the item\'s name and optional parameters `price` and `quantity`. - Method `apply_discount` takes a `discount_percentage`. - Method `search_items` takes a string `name`. Output Format - Method `generate_report` returns a dictionary with categories as keys and lists of item detail strings as values. - Method `total_inventory_value` returns a float representing the total value of the inventory. - Methods to update and add items, and apply discounts do not return values. Constraints - Prices and quantities of items are non-negative numbers. - Discounts applied should be between 0 and 100 percent. You should implement your solution within the given `Item` and `Inventory` class templates.","solution":"class Item: def __init__(self, name, category, price, quantity): self.name = name self.category = category self.price = price self.quantity = quantity def apply_discount(self, discount_percentage): if 0 <= discount_percentage <= 100: self.price -= self.price * (discount_percentage / 100) else: raise ValueError(\\"Discount percentage must be between 0 and 100.\\") def display_details(self): return f\\"Item: {self.name}, Category: {self.category}, Price: {self.price:.2f}, Quantity: {self.quantity}\\" class Inventory: def __init__(self): self.items = [] def add_item(self, item): self.items.append(item) def update_item(self, item_name, price=None, quantity=None): for item in self.items: if item.name == item_name: if price is not None: item.price = price if quantity is not None: item.quantity = quantity break def generate_report(self): report = {} for item in self.items: if item.category not in report: report[item.category] = [] report[item.category].append(item.display_details()) return report def total_inventory_value(self): total_value = sum(item.price * item.quantity for item in self.items) return total_value def search_items(self, name): return [item for item in self.items if name.lower() in item.name.lower()]"},{"question":"# Problem: Implement a Mini-Library and Book Management System You are tasked with developing a simple book management system for a mini-library. The system should support adding, removing, and searching for books, while also managing the borrowing and returning of books. # Requirements 1. **Input**: - Commands to manage the books in the library. Each command comes with necessary parameters. 2. **Output**: - Perform the specified operations, and output the result of `search` commands. # Command Specifications Implement functions to handle the following commands: 1. `add_book(isbn, title, author)`: - Adds a book to the library. - Parameters: - `isbn` (string): The unique International Standard Book Number. - `title` (string): The title of the book. - `author` (string): The author of the book. 2. `remove_book(isbn)`: - Removes a book from the library by its ISBN. 3. `search_title(title)`: - Searches for books by their title. - Parameter: - `title` (string): The title or a keyword in the title of the book. - Output: - List of books (ISBN, title, author) that match the search keyword. - If no books match, return an empty list. 4. `borrow_book(isbn)`: - Marks a book as borrowed if it is available. 5. `return_book(isbn)`: - Marks a book as returned. # Constraints - Each `isbn` is unique and follows a specific pattern. - The library can contain up to 1000 books. - A book cannot be borrowed if it is already borrowed. # Example ```python # Expected use of the functions add_book(\\"978-3-16-148410-0\\", \\"The Great Gatsby\\", \\"F. Scott Fitzgerald\\") add_book(\\"978-0-14-143960-0\\", \\"Pride and Prejudice\\", \\"Jane Austen\\") print(search_title(\\"Gatsby\\")) # [(\'978-3-16-148410-0\', \'The Great Gatsby\', \'F. Scott Fitzgerald\')] print(search_title(\\"Prejudice\\")) # [(\'978-0-14-143960-0\', \'Pride and Prejudice\', \'Jane Austen\')] borrow_book(\\"978-3-16-148410-0\\") print(search_title(\\"Gatsby\\")) # [] since the book is borrowed return_book(\\"978-3-16-148410-0\\") print(search_title(\\"Gatsby\\")) # [(\'978-3-16-148410-0\', \'The Great Gatsby\', \'F. Scott Fitzgerald\')] ``` # Notes 1. **Edge Cases**: Handle cases like searching for a keyword that matches multiple books, attempting to borrow a book that’s already borrowed, and removing a book that doesn\'t exist. 2. **Data Management**: Use appropriate data structures to efficiently store and retrieve the books. --- Feel free to expand the system as needed to handle more complex library operations, but ensure that the core functionality works efficiently within the given constraints.","solution":"class Library: def __init__(self): self.books = {} self.borrowed_books = set() def add_book(self, isbn, title, author): self.books[isbn] = {\\"title\\": title, \\"author\\": author} def remove_book(self, isbn): if isbn in self.books: del self.books[isbn] def search_title(self, title): result = [] for isbn, info in self.books.items(): if title.lower() in info[\\"title\\"].lower(): if isbn not in self.borrowed_books: result.append((isbn, info[\\"title\\"], info[\\"author\\"])) return result def borrow_book(self, isbn): if isbn in self.books and isbn not in self.borrowed_books: self.borrowed_books.add(isbn) def return_book(self, isbn): if isbn in self.borrowed_books: self.borrowed_books.remove(isbn)"},{"question":"# Matrix Region Sum Query Problem Statement You are provided with a two-dimensional matrix of integers `matrix` and a series of queries represented by a list of tuples. Each query consists of four integers `(row1, col1, row2, col2)` indicating the top-left and bottom-right corners of a submatrix. Your task is to return the sum of all elements in that submatrix for each query. Requirements Implement the following function: ```python def matrix_region_sum(matrix: List[List[int]], queries: List[Tuple[int, int, int, int]]) -> List[int]: Calculate the sum of elements in submatrix for each query. Args: - matrix (List[List[int]]): 2D list of integers representing the matrix. - queries (List[Tuple[int, int, int, int]]): List of tuples where each tuple represents a query with (row1, col1, row2, col2) indicating the top-left and bottom-right corners of the submatrix. Returns: - List[int]: List of sums of elements for each submatrix defined by the queries. Example: >>> matrix = [ ... [1, 2, 3], ... [4, 5, 6], ... [7, 8, 9] ... ] >>> queries = [(0, 0, 1, 1), (1, 1, 2, 2), (0, 0, 2, 2)] >>> matrix_region_sum(matrix, queries) [12, 28, 45] ``` Your implementation must: - Use efficient prefix sum techniques to handle multiple queries efficiently. Input and Output - **Input**: - `matrix`: A 2D list of integers representing the matrix. - `queries`: A list of tuples, each containing four integers `(row1, col1, row2, col2)`. - **Output**: - A list of integers where each integer is the sum of elements for the corresponding submatrix for each query. Constraints - The dimensions of the matrix can be up to `1000 x 1000`. - You may have up to `10^4` queries. - All elements in the matrix and queries are within the provided integer range constraints. Performance Requirements - Ensure the sum query operations are optimized to handle large dimensions of the matrix and numerous queries efficiently. Example ```python >>> matrix = [ ... [1, 2, 3], ... [4, 5, 6], ... [7, 8, 9] ... ] >>> queries = [(0, 0, 1, 1), (1, 1, 2, 2), (0, 0, 2, 2)] >>> print(matrix_region_sum(matrix, queries)) # Output: [12, 28, 45] >>> matrix = [ ... [1, 1], ... [1, 1] ... ] >>> queries = [(0, 0, 1, 1), (0, 0, 0, 0), (1, 1, 1, 1)] >>> print(matrix_region_sum(matrix, queries)) # Output: [4, 1, 1] ``` # Note - Utilize an auxiliary matrix for prefix sums to enable querying sum of submatrix in constant time. - Be mindful of off-by-one errors when handling matrix indices in the prefix sum logic.","solution":"from typing import List, Tuple def matrix_region_sum(matrix: List[List[int]], queries: List[Tuple[int, int, int, int]]) -> List[int]: if not matrix or not matrix[0]: return [] rows = len(matrix) cols = len(matrix[0]) # Step 1: Construct the prefix sum matrix prefix_sum = [[0] * (cols + 1) for _ in range(rows + 1)] for r in range(1, rows + 1): for c in range(1, cols + 1): prefix_sum[r][c] = matrix[r-1][c-1] + prefix_sum[r-1][c] + prefix_sum[r][c-1] - prefix_sum[r-1][c-1] # Step 2: Resolve each query using the prefix sum matrix result = [] for row1, col1, row2, col2 in queries: total = (prefix_sum[row2 + 1][col2 + 1] - prefix_sum[row2 + 1][col1] - prefix_sum[row1][col2 + 1] + prefix_sum[row1][col1]) result.append(total) return result"},{"question":"# Problem Description You are tasked to implement a function that checks if a given 2D matrix contains a specific submatrix. This system will be used to perform pattern recognition on a grid. # Function Requirements 1. **Function Name**: `is_submatrix_present` - **Input**: - `matrix` (List[List[int]]): A 2D matrix of integers where the submatrix search will be performed. - `submatrix` (List[List[int]]): The submatrix to be searched within the 2D matrix. - **Output**: - `bool`: Returns `True` if the submatrix is present in the main matrix, otherwise `False`. # Constraints - The matrix and the submatrix consist of integers. - Both the matrix and the submatrix dimensions are positive and non-zero. - The size of the submatrix should be less than or equal to the size of the main matrix. # Performance Requirements - The function should have a time complexity of O(m * n * p * q), where m and n are the dimensions of the main matrix and p and q are the dimensions of the submatrix. # Example ```python matrix = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16] ] submatrix = [ [6, 7], [10, 11] ] print(is_submatrix_present(matrix, submatrix)) # Output: True submatrix = [ [7, 8], [11, 12] ] print(is_submatrix_present(matrix, submatrix)) # Output: True submatrix = [ [7, 8], [12, 13] ] print(is_submatrix_present(matrix, submatrix)) # Output: False ``` # Task Write the `is_submatrix_present` function to achieve the above requirements. Use any helper functions if necessary.","solution":"def is_submatrix_present(matrix, submatrix): Checks if submatrix is contained within the matrix. :param matrix: List[List[int]] - The main matrix. :param submatrix: List[List[int]] - The submatrix to find. :return: bool - True if the submatrix is present in the main matrix, False otherwise. m, n = len(matrix), len(matrix[0]) p, q = len(submatrix), len(submatrix[0]) for i in range(m - p + 1): for j in range(n - q + 1): if all(matrix[i + pi][j + qj] == submatrix[pi][qj] for pi in range(p) for qj in range(q)): return True return False"},{"question":"# Problem Statement You are tasked with implementing a system that processes a series of bank transactions, performs balance calculations, and detects invalid transactions. A transaction consists of a `type` (either \\"credit\\" or \\"debit\\"), an `amount`, and an optional `description`. Your function should iterate through the list of transactions, update the balance accordingly, and return a summary containing the final balance and any invalid transactions. # Enhanced Requirements 1. Implement a function that processes a list of transactions and calculates the account balance. 2. A transaction is considered invalid if it is a debit and the amount exceeds the available balance. 3. Keep track of each invalid transaction\'s index in the list and return them. 4. Define appropriate error handling for invalid data input, such as missing or incorrect transaction fields. # Function Signature ```python def process_transactions(starting_balance: float, transactions: list) -> dict: pass ``` # Expected Input and Output * **Input**: * A float `starting_balance` representing the initial balance of the account. * A list of dictionaries `transactions`, where each dictionary contains: * A string `type`: \\"credit\\" or \\"debit\\". * A float `amount`: the value of the transaction. * An optional string `description`. * **Output**: * A dictionary with two keys: * `final_balance`: A float representing the final account balance after processing all valid transactions. * `invalid_transactions`: A list of integers representing the indices of invalid transactions in the input list. * **Constraints**: * Amounts are always non-negative floats. * Transactions are processed in the order they appear in the input list. * The solution should handle cases with large numbers of transactions efficiently. # Performance Requirements * The solution should have a linear time complexity O(n), where n is the number of transactions, and handle large input sizes within acceptable time limits. # Example Usage ```python transactions = [ {\\"type\\": \\"debit\\", \\"amount\\": 50.0, \\"description\\": \\"Groceries\\"}, {\\"type\\": \\"credit\\", \\"amount\\": 100.0, \\"description\\": \\"Salary\\"}, {\\"type\\": \\"debit\\", \\"amount\\": 200.0, \\"description\\": \\"Rent\\"}, {\\"type\\": \\"debit\\", \\"amount\\": 30.0}, {\\"type\\": \\"credit\\", \\"amount\\": 20.0} ] assert process_transactions(100.0, transactions) == { \\"final_balance\\": 90.0, \\"invalid_transactions\\": [2] } ``` # Hints 1. Loop through the transactions and update the balance based on the transaction type. 2. Check for invalid transactions before performing debits. 3. Maintain a list of indices for transactions that cannot be processed due to insufficient balance. 4. Ensure proper handling of optional transaction fields and invalid input data.","solution":"def process_transactions(starting_balance: float, transactions: list) -> dict: Process a list of bank transactions and update the balance accordingly. Detect and return invalid transactions. Parameters: - starting_balance (float): The initial account balance. - transactions (list): A list of transactions where each transaction is a dictionary containing \'type\', \'amount\', and optional \'description\'. Returns: - dict: A dictionary containing the final account balance and a list of invalid transaction indices. final_balance = starting_balance invalid_transactions = [] for index, transaction in enumerate(transactions): # Validate transaction data if \'type\' not in transaction or \'amount\' not in transaction: invalid_transactions.append(index) continue tr_type = transaction.get(\'type\') tr_amount = transaction.get(\'amount\') if tr_type not in [\'credit\', \'debit\'] or not isinstance(tr_amount, (int, float)): invalid_transactions.append(index) continue if tr_type == \'credit\': final_balance += tr_amount elif tr_type == \'debit\': if tr_amount > final_balance: invalid_transactions.append(index) else: final_balance -= tr_amount return { \\"final_balance\\": final_balance, \\"invalid_transactions\\": invalid_transactions }"},{"question":"# Task: Determine if a Matrix is Monotonic You are tasked with writing a function to determine if a given matrix is monotonic. A matrix is defined as monotonic if every row and every column is either entirely non-increasing or non-decreasing. Function Signature ```python def is_monotonic(matrix: list) -> bool: ``` # Input * `matrix`: A non-empty 2D list of integers where each sublist represents a row in the matrix. # Output * A boolean value `True` if the matrix is monotonic, else `False`. # Constraints * The matrix will have dimensions between 1x1 and 1000x1000. * Each element in the matrix will be an integer between -10^5 and 10^5. # Example ```python >>> is_monotonic([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) True >>> is_monotonic([[9, 8, 7], [6, 5, 4], [3, 2, 1]]) True >>> is_monotonic([[1, 3, 2], [4, 1, 6], [7, 7, 9]]) False >>> is_monotonic([[1]]) True ``` # Notes * A matrix with a single row or a single column is considered monotonic. * You may assume that the input will always be a non-empty matrix. * Consider edge cases such as matrices with all identical elements or matrices with alternating patterns.","solution":"def is_monotonic(matrix): # Helper function to check if a list is monotonic def is_list_monotonic(lst): increasing = all(lst[i] <= lst[i + 1] for i in range(len(lst) - 1)) decreasing = all(lst[i] >= lst[i + 1] for i in range(len(lst) - 1)) return increasing or decreasing # Check all rows for row in matrix: if not is_list_monotonic(row): return False # Check all columns for col in range(len(matrix[0])): column = [matrix[row][col] for row in range(len(matrix))] if not is_list_monotonic(column): return False return True"},{"question":"You are given the task of determining whether a given number is an Armstrong number. An Armstrong number (also known as a narcissistic number) is a number that is equal to the sum of the cubes of its own digits. For example, 153 is an Armstrong number because (1^3 + 5^3 + 3^3 = 153). # Task Write a function `is_armstrong_number(num: int) -> bool` that determines if the provided number is an Armstrong number. # Functional Requirements * The function should accept an integer `num` and return `True` if it is an Armstrong number, otherwise `False`. * The function should handle both positive and negative integers by considering only the magnitude of the number (i.e., treat -153 as 153). # Examples ```python >>> is_armstrong_number(153) True >>> is_armstrong_number(123) False >>> is_armstrong_number(-153) True >>> is_armstrong_number(0) True >>> is_armstrong_number(9474) True ``` # Constraints 1. -10^6 <= num <= 10^6 # Notes * Consider the magnitude of the number when determining if it is an Armstrong number. * Ensure that the function is efficient and correctly handles edge cases such as zero and negative numbers.","solution":"def is_armstrong_number(num: int) -> bool: Determines whether a given number is an Armstrong number. Args: num (int): The number to be checked. Returns: bool: True if num is an Armstrong number, False otherwise. # Convert the number to its absolute value num = abs(num) # Convert the number to a string to easily access each digit num_str = str(num) num_len = len(num_str) # Calculate the sum of the cubes of its digits sum_of_cubes = sum(int(digit) ** num_len for digit in num_str) # Check if the sum of the cubes of its digits is equal to the number itself return sum_of_cubes == num"},{"question":"# Employee Shift Scheduling Context: You are tasked with creating a function to help manage employee shifts. The shifts are stored in a nested dictionary where the keys are the employee names, and the values are dictionaries containing day-shift pairs. Each day has a boolean value indicating whether the employee is working that day (True) or not (False). Your function should be able to: 1. Add new shifts for employees. 2. Remove shifts for employees. 3. List all employees scheduled for a specific day. Requirements: 1. Your function should: * Add new shifts for an employee or update existing ones if the employee already has shifts. * Remove a single shift for an employee for a given day. * List all employees working on a specified day. 2. Ensure that the input is validated and the function handles errors gracefully. 3. Optimize the function to maintain efficiency even with a large number of employees and shifts. # Function Signature: ```python def manage_shifts(action: str, employee_name: str = \\"\\", day: str = \\"\\", is_working: bool = True, shifts: dict = None) -> dict or list: pass ``` # Input/Output Specifications: * **Input**: * `action` (str): The action to be performed. Can be \'add\', \'remove\', or \'list\'. * \'add\' action requires `employee_name`, `day`, `is_working`, and `shifts`. * \'remove\' action requires `employee_name`, `day`, and `shifts`. * \'list\' action requires `day` and `shifts`. * `employee_name` (str): The name of the employee. Only required for \'add\' and \'remove\' actions. * `day` (str): The day of the shift in \'YYYY-MM-DD\' format. * `is_working` (bool): True if the employee is working that day, False otherwise. Only required for \'add\' action. * `shifts` (dict): The nested dictionary containing all shifts. * **Output**: * A modified dictionary of shifts if the action is \'add\' or \'remove\'. * A list of employees working on the specified day if the action is \'list\'. # Constraints: * `employee_name` must be a non-empty string. * `day` must be in \'YYYY-MM-DD\' format. * `shifts` must be a valid nested dictionary. # Examples: ```python shifts = { \\"Alice\\": {\\"2023-10-01\\": True, \\"2023-10-02\\": False}, \\"Bob\\": {\\"2023-10-01\\": False, \\"2023-10-02\\": True} } # Adding a new shift shifts = manage_shifts(\'add\', \'Alice\', \'2023-10-03\', True, shifts) # Output: {\'Alice\': {\'2023-10-01\': True, \'2023-10-02\': False, \'2023-10-03\': True}, \'Bob\': {\'2023-10-01\': False, \'2023-10-02\': True}} # Removing a shift shifts = manage_shifts(\'remove\', \'Alice\', \'2023-10-02\', shifts=shifts) # Output: {\'Alice\': {\'2023-10-01\': True, \'2023-10-03\': True}, \'Bob\': {\'2023-10-01\': False, \'2023-10-02\': True}} # Listing employees working on a specific day employees = manage_shifts(\'list\', day=\'2023-10-02\', shifts=shifts) # Output: [\'Bob\'] ``` # Notes: - Ensure your function handles non-existent employees and days gracefully. - The dictionary format should remain consistent throughout the operations.","solution":"def manage_shifts(action: str, employee_name: str = \\"\\", day: str = \\"\\", is_working: bool = True, shifts: dict = None): Manage employee shifts based on the specified action. Parameters: - action (str): The action to be performed (\'add\', \'remove\', \'list\'). - employee_name (str): The name of the employee (required for \'add\' and \'remove\' actions). - day (str): The day of the shift in \'YYYY-MM-DD\' format. - is_working (bool): True if the employee is working that day, False otherwise (only required for \'add\' action). - shifts (dict): The nested dictionary containing all shifts. Returns: - dict: Updated dictionary of shifts (for \'add\' and \'remove\' actions). - list: List of employees working on the specified day (for \'list\' action). if shifts is None: raise ValueError(\\"Shifts dictionary cannot be None\\") if action not in [\'add\', \'remove\', \'list\']: raise ValueError(\\"Invalid action. Must be \'add\', \'remove\', or \'list\'\\") if action in [\'add\', \'remove\'] and (not employee_name or not day): raise ValueError(\\"Employee name and day must be provided for \'add\' and \'remove\' actions\\") if action == \'list\' and not day: raise ValueError(\\"Day must be provided for \'list\' action\\") if action == \'add\': if employee_name not in shifts: shifts[employee_name] = {} shifts[employee_name][day] = is_working return shifts elif action == \'remove\': if employee_name in shifts and day in shifts[employee_name]: del shifts[employee_name][day] if not shifts[employee_name]: # Remove employee if no more shifts del shifts[employee_name] return shifts elif action == \'list\': working_employees = [employee for employee, days in shifts.items() if days.get(day, False)] return working_employees"},{"question":"# Question Design and implement a `StackWithMin` class that supports typical stack operations (`push`, `pop`, `peek`) but also provides a `get_min` method that returns the minimum element in the stack in O(1) time. Specific Requirements: 1. **Class Name**: StackWithMin 2. **Methods to Implement**: * `__init__(self)`: Initialize the stack. * `push(self, item: int) -> None`: Push an integer item onto the stack. * `pop(self) -> int`: Remove the item at the top of the stack and return it. * `peek(self) -> int`: Return the item at the top of the stack without removing it. * `get_min(self) -> int`: Return the minimum element in the stack in O(1) time. Raise `IndexError` if the stack is empty. * `is_empty(self) -> bool`: Return True if the stack is empty, False otherwise. Constraints: * Do not use built-in functions like `min()` or external libraries. * Your `get_min` method must be O(1). * Raise `IndexError` for attempts to peek or pop from an empty stack. Example Usage: ```python stack = StackWithMin() stack.push(3) stack.push(5) print(stack.get_min()) # 3 stack.push(2) stack.push(1) print(stack.get_min()) # 1 stack.pop() print(stack.get_min()) # 2 stack.pop() print(stack.peek()) # 5 print(stack.get_min()) # 3 stack.pop() stack.pop() print(stack.is_empty()) # True ``` Your implementation should pass the above cases and be optimized as described.","solution":"class StackWithMin: def __init__(self): self.stack = [] self.min_stack = [] def push(self, item: int) -> None: self.stack.append(item) if not self.min_stack or item <= self.min_stack[-1]: self.min_stack.append(item) def pop(self) -> int: if not self.stack: raise IndexError(\\"pop from empty stack\\") item = self.stack.pop() if item == self.min_stack[-1]: self.min_stack.pop() return item def peek(self) -> int: if not self.stack: raise IndexError(\\"peek from empty stack\\") return self.stack[-1] def get_min(self) -> int: if not self.min_stack: raise IndexError(\\"get_min from empty stack\\") return self.min_stack[-1] def is_empty(self) -> bool: return len(self.stack) == 0"},{"question":"# Scenario You are developing a file management system that needs to keep track of several files and directories. As part of this system, you want to check if the current directory has a specific path, and if that path exists, retrieve its complete relative path from the root directory. # Task You need to write two functions, `path_exists` and `get_full_path`, that will help in the path verification and construction. # Details 1. **path_exists(path: str, current_directory: dict) -> bool**: * Takes a string representing the target path and a dictionary representing the current directory\'s structure. * Returns `True` if the path exists in the current directory; otherwise, returns `False`. 2. **get_full_path(path: str, current_directory: dict) -> str**: * Takes a string representing the target path and a dictionary representing the current directory\'s structure. * Returns the full relative path from the root of the directory structure if the path exists; otherwise, returns an empty string. # Input and Output * **Input Format**: * The input consists of a string `path` and a dictionary `current_directory`. * `path` is a \\"/\\"-separated string representing the target path. * `current_directory` is a nested dictionary where each key represents a directory name and its value is another dictionary representing its subdirectories. * **Output Format**: * The `path_exists` function should return a boolean value indicating whether the path exists. * The `get_full_path` function should return the full relative path as a string. # Constraints * Paths will always start from the current directory (\\"/\\" represents the root directory). * Assume all directory names are unique within their respective levels. * The directory structure will not contain cycles or self-referencing entries. # Examples * Example 1: Given the current directory structure: ```python current_directory = { \\"home\\": { \\"user\\": { \\"documents\\": {}, \\"photos\\": { \\"2021\\": {}, \\"2022\\": {} } }, \\"guest\\": {} }, \\"var\\": { \\"log\\": {}, \\"tmp\\": {} } } ``` ```python path_exists(\\"home/user/photos/2021\\", current_directory) # True ``` ```python get_full_path(\\"home/user/photos/2021\\", current_directory) # \\"/home/user/photos/2021\\" ``` * Example 2: Given the same directory structure: ```python path_exists(\\"home/guest/photos\\", current_directory) # False ``` ```python get_full_path(\\"home/guest/photos\\", current_directory) # \\"\\" ``` # Additional Considerations 1. Ensure your solution handles edge cases correctly, such as deeply nested paths, non-existent paths, and empty current directory structures. 2. Implement the functions efficiently to accommodate large directory structures without significant performance degradation.","solution":"def path_exists(path, current_directory): Checks if the given path exists in the current directory structure. parts = path.strip(\\"/\\").split(\\"/\\") current = current_directory for part in parts: if part not in current: return False current = current[part] return True def get_full_path(path, current_directory): Returns the full relative path from the root if the path exists in the current directory structure. if path_exists(path, current_directory): return \\"/\\" + \\"/\\".join(path.strip(\\"/\\").split(\\"/\\")) return \\"\\""},{"question":"# Scenario You are a software engineer for a company that manages electronic health records (EHRs). Your team is tasked with developing a feature that identifies the most common medical diagnoses for a given set of patients over a specified time period. Your company has an API that provides diagnosis data, but the data comes in batches and needs to be aggregated. # Task Write a function that returns the most frequent diagnosis for a group of patients over a given date range by utilizing the `fetch_diagnoses(patient_id, start, end)` function. # Function Signature ```python def most_frequent_diagnosis(patient_ids: List[int], start: date, end: date) -> str: pass ``` # Input and Output * **Input**: * `patient_ids`: A list of integers representing unique patient IDs. * `start`: A `date` object representing the start of the date range. * `end`: A `date` object representing the end of the date range. * **Output**: * Returns a string representing the most frequent diagnosis for the patients over the specified date range. # Constraints * Utilize the provided `fetch_diagnoses(patient_id, start, end)` function to retrieve diagnosis data. * Assume that the function provides accurate and timely data. * The `start` date should be before or equal to the `end` date. * Handle edge cases such as empty data sets or no diagnoses within the given date range. # Example ```python from datetime import date patient_ids = [101, 102, 103] start_date = date(2021, 1, 1) end_date = date(2021, 12, 31) result = most_frequent_diagnosis(patient_ids, start_date, end_date) print(result) # Expected to print the most frequent diagnosis for the list of patients within the given date range ``` # Performance Requirements Ensure that the function runs efficiently within the given date range constraints and handles cases where there may be a large volume of diagnosis data. Optimize the function to aggregate and analyze the data promptly.","solution":"from typing import List from datetime import date from collections import Counter def fetch_diagnoses(patient_id: int, start: date, end: date) -> List[str]: Mock function to represent the fetching of diagnoses data. In a real scenario, this function would query a database or an API. # This is a mock implementation and should be replaced with the actual API call. mock_data = { 101: [\\"Flu\\", \\"Cold\\", \\"Covid\\"], 102: [\\"Cold\\", \\"Covid\\", \\"Cold\\"], 103: [\\"Cancer\\", \\"Cold\\", \\"Covid\\"], } return mock_data.get(patient_id, []) def most_frequent_diagnosis(patient_ids: List[int], start: date, end: date) -> str: diagnoses_counter = Counter() for patient_id in patient_ids: diagnoses = fetch_diagnoses(patient_id, start, end) diagnoses_counter.update(diagnoses) if not diagnoses_counter: return \\"\\" # Return empty string if no diagnoses found most_common_diagnosis, _ = diagnoses_counter.most_common(1)[0] return most_common_diagnosis"},{"question":"# Optimizing Matrix Multiplication Background Matrix multiplication is a fundamental operation in linear algebra with applications in numerous fields, including computer graphics, machine learning, and scientific computing. The naive approach of multiplying two matrices, each of size ( n times n ), has a time complexity of ( O(n^3) ). For large matrices, this can be very inefficient. Instead, optimized algorithms such as Strassen\'s algorithm can be used to reduce the complexity. Strassen\'s algorithm reduces the time complexity to approximately ( O(n^{2.81}) ) by decomposing each matrix into sub-matrices, performing multiplication on these sub-matrices, and recombining the results. Task Implement the Strassen\'s matrix multiplication algorithm. Your function should multiply two ( n times n ) matrices efficiently using this method. Assume that ( n ) is a power of 2 to simplify the recursive decomposition. Your function should have the following signature: ```python def strassen_matrix_mult(A: list[list[int]], B: list[list[int]]) -> list[list[int]]: ``` Constraints * Both matrices ( A ) and ( B ) are ( n times n ) matrices where ( n ) is a power of 2 (e.g., 2, 4, 8, ...). * Entries in the matrices ( A ) and ( B ) are integers. * Use recursion to apply the Strassen\'s algorithm. * Ensure the implementation handles the base case where matrices are ( 1 times 1 ). Example Usage ```python A = [ [1, 2], [3, 4] ] B = [ [5, 6], [7, 8] ] # Test case product = strassen_matrix_mult(A, B) expected_product = [ [19, 22], [43, 50] ] assert product == expected_product, \\"Test Case 1 Failed\\" print(\\"Product of A and B is:\\", product) ``` Notes * Write appropriate unit tests to verify your Strassen\'s matrix multiplication implementation. * Handle edge cases, such as when the input matrices contain negative or zero values.","solution":"def add_matrices(A, B): return [[A[i][j] + B[i][j] for j in range(len(A))] for i in range(len(A))] def subtract_matrices(A, B): return [[A[i][j] - B[i][j] for j in range(len(A))] for i in range(len(A))] def split_matrix(matrix): n = len(matrix) mid = n // 2 A11 = [[matrix[i][j] for j in range(mid)] for i in range(mid)] A12 = [[matrix[i][j] for j in range(mid, n)] for i in range(mid)] A21 = [[matrix[i][j] for j in range(mid)] for i in range(mid, n)] A22 = [[matrix[i][j] for j in range(mid, n)] for i in range(mid, n)] return A11, A12, A21, A22 def combine_matrices(C11, C12, C21, C22): n = len(C11) * 2 C = [[0] * n for _ in range(n)] for i in range(len(C11)): for j in range(len(C11)): C[i][j] = C11[i][j] C[i][j + len(C11)] = C12[i][j] C[i + len(C11)][j] = C21[i][j] C[i + len(C11)][j + len(C11)] = C22[i][j] return C def strassen_matrix_mult(A, B): n = len(A) if n == 1: return [[A[0][0] * B[0][0]]] A11, A12, A21, A22 = split_matrix(A) B11, B12, B21, B22 = split_matrix(B) M1 = strassen_matrix_mult(add_matrices(A11, A22), add_matrices(B11, B22)) M2 = strassen_matrix_mult(add_matrices(A21, A22), B11) M3 = strassen_matrix_mult(A11, subtract_matrices(B12, B22)) M4 = strassen_matrix_mult(A22, subtract_matrices(B21, B11)) M5 = strassen_matrix_mult(add_matrices(A11, A12), B22) M6 = strassen_matrix_mult(subtract_matrices(A21, A11), add_matrices(B11, B12)) M7 = strassen_matrix_mult(subtract_matrices(A12, A22), add_matrices(B21, B22)) C11 = add_matrices(subtract_matrices(add_matrices(M1, M4), M5), M7) C12 = add_matrices(M3, M5) C21 = add_matrices(M2, M4) C22 = add_matrices(subtract_matrices(add_matrices(M1, M3), M2), M6) return combine_matrices(C11, C12, C21, C22)"},{"question":"# Scenario You are working on a file management system where different users can have different permissions to access various files. The permissions include \'read\', \'write\', and \'execute\'. To manage these permissions efficiently, you need to create a system that supports operations to grant permissions, check permissions, and revoke permissions. # Task Implement a class called `PermissionManager` that utilizes a combination of data structures to manage user permissions for files. Each user can have multiple permissions for multiple files. Function Implementations 1. **grant_permission(user: str, file: str, permissions: List[str]) -> None** - Grants the specified `permissions` (a list of \'read\', \'write\', \'execute\') for the `file` to the `user`. 2. **check_permission(user: str, file: str, permission: str) -> bool** - Checks if the `user` has the specific `permission` (\'read\', \'write\', \'execute\') for the `file`. Returns `True` if the permission is granted, and `False` otherwise. 3. **revoke_permission(user: str, file: str, permission: str) -> None** - Revokes the specific `permission` (\'read\', \'write\', \'execute\') for the `file` from the `user`. Constraints - Usernames and filenames are non-empty strings. - Permissions are one of \'read\', \'write\', or \'execute\'. - The system can handle up to `10^6` users, each having permissions for up to `10^4` files. Performance Requirements - The `grant_permission` and `revoke_permission` operations should be optimized for speed and should operate in constant or near-constant time. - The `check_permission` operation should efficiently verify permissions with minimal latency. Example ```python pm = PermissionManager() # Granting permissions pm.grant_permission(\\"Alice\\", \\"file1.txt\\", [\\"read\\", \\"write\\"]) pm.grant_permission(\\"Bob\\", \\"file2.txt\\", [\\"read\\"]) pm.grant_permission(\\"Alice\\", \\"file2.txt\\", [\\"execute\\"]) # Checking permissions print(pm.check_permission(\\"Alice\\", \\"file1.txt\\", \\"read\\")) # Output: True print(pm.check_permission(\\"Alice\\", \\"file2.txt\\", \\"write\\")) # Output: False print(pm.check_permission(\\"Bob\\", \\"file2.txt\\", \\"read\\")) # Output: True # Revoking permissions pm.revoke_permission(\\"Alice\\", \\"file1.txt\\", \\"write\\") print(pm.check_permission(\\"Alice\\", \\"file1.txt\\", \\"write\\")) # Output: False ``` Implement the `PermissionManager` class with the required methods ensuring optimal performance and considering possible edge cases.","solution":"class PermissionManager: def __init__(self): # Dictionary to store user\'s file permissions self.permissions = {} def grant_permission(self, user: str, file: str, permissions: list): if user not in self.permissions: self.permissions[user] = {} if file not in self.permissions[user]: self.permissions[user][file] = set() self.permissions[user][file].update(permissions) def check_permission(self, user: str, file: str, permission: str) -> bool: return (user in self.permissions and file in self.permissions[user] and permission in self.permissions[user][file]) def revoke_permission(self, user: str, file: str, permission: str): if self.check_permission(user, file, permission): self.permissions[user][file].remove(permission) if not self.permissions[user][file]: del self.permissions[user][file] if not self.permissions[user]: del self.permissions[user]"},{"question":"# Question: Implement a Hashtable with Open Addressing Context: You have been tasked with creating a simple hashtable data structure that uses open addressing for collision resolution. # Task: Implement a class `Hashtable` with the following functionalities: 1. **Insertion**: Method `insert(key, value)` which inserts the key-value pair into the hashtable. 2. **Deletion**: Method `delete(key)` which deletes the key and its associated value from the hashtable. 3. **Search**: Method `search(key)` which returns the value associated with the key if it exists in the hashtable, otherwise returns `None`. 4. **Resizing**: Automatically resize the hashtable when the load factor exceeds 0.75, doubling the size of the table. # Requirements: 1. **Input/Output**: - The `insert` method should handle collision using open addressing (linear probing). - When `delete` is called, the key-value pair should be removed and the method should handle rehashing if necessary. - The `search` method should return the correct value or `None` without modifying the hashtable. - The string representation of the hashtable\'s state should be implemented using the `__repr__` method. 2. **Constraints**: - Handle edge cases such as inserting into a full hashtable and dealing with deleted slots. - Ensure efficient time complexity for each method. 3. **Performance**: - Insertions, deletions, and searches should have an average case time complexity of O(1). # Example: ```python # Creating an instance of Hashtable hashtable = Hashtable() # Inserting key-value pairs hashtable.insert(\\"apple\\", 10) hashtable.insert(\\"banana\\", 20) hashtable.insert(\\"cherry\\", 30) print(hashtable) # Example output: { \\"apple\\": 10, \\"banana\\": 20, \\"cherry\\": 30 } # Searching for a key value = hashtable.search(\\"banana\\") print(value) # Expected output: 20 # Searching for a non-existent key value = hashtable.search(\\"orange\\") print(value) # Expected output: None # Deleting a key-value pair hashtable.delete(\\"banana\\") print(hashtable) # Example output: { \\"apple\\": 10, \\"cherry\\": 30 } # Insert more elements to trigger resizing hashtable.insert(\\"dad\\", 40) hashtable.insert(\\"eel\\", 50) hashtable.insert(\\"fig\\", 60) print(hashtable) # Example output after resizing: { \\"apple\\": 10, \\"cherry\\": 30, \\"dad\\": 40, \\"eel\\": 50, \\"fig\\": 60 } ``` This new question aligns with the style, complexity, and scope of the initial question provided. It covers core programming concepts like data structures, collision handling, dynamic resizing, and ensures a comparable length and difficulty level.","solution":"class Hashtable: def __init__(self, capacity=8): self.capacity = capacity self.size = 0 self.table = [None] * self.capacity def _hash(self, key, i): return (hash(key) + i) % self.capacity def _resize(self): old_table = self.table self.capacity *= 2 self.table = [None] * self.capacity self.size = 0 for item in old_table: if item is not None and item != \'DELETED\': self.insert(item[0], item[1]) def insert(self, key, value): if self.size / self.capacity >= 0.75: self._resize() i = 0 while i < self.capacity: idx = self._hash(key, i) if self.table[idx] is None or self.table[idx] == \'DELETED\': self.table[idx] = (key, value) self.size += 1 return elif self.table[idx][0] == key: self.table[idx] = (key, value) # Update existing key return i += 1 raise Exception(\\"Hashtable is full\\") def search(self, key): i = 0 while i < self.capacity: idx = self._hash(key, i) if self.table[idx] is None: return None elif self.table[idx] != \'DELETED\' and self.table[idx][0] == key: return self.table[idx][1] i += 1 return None def delete(self, key): i = 0 while i < self.capacity: idx = self._hash(key, i) if self.table[idx] is None: return elif self.table[idx] != \'DELETED\' and self.table[idx][0] == key: self.table[idx] = \'DELETED\' self.size -= 1 return i += 1 def __repr__(self): items = [] for item in self.table: if item is not None and item != \'DELETED\': items.append(f\'\\"{item[0]}\\": {item[1]}\') return \'{ \' + \', \'.join(items) + \' }\'"},{"question":"Coding Assessment Question Context A company needs an optimized solution for tracking their inventory. They have a variety of items and each item is identified by a unique product ID. They often need to query the system to find out the k most frequent items within a specific range of product IDs. Problem Implement a function that, given a list of product IDs and a target range, returns the k most frequent product IDs within that range. If two products have the same frequency, the one with the lower product ID should be given preference. Specifications * **Function Signature**: `def frequent_items_within_range(ids: list[int], left: int, right: int, k: int) -> list[int]:` * **Input**: * A list of integers `ids` representing product IDs. * Two integers, `left` and `right`, representing the inclusive range of product IDs to consider. * An integer `k` representing the number of most frequent product IDs to return. * **Output**: * A list of `k` integers representing the most frequent product IDs within the specified range. The output should be sorted by frequency (descending) and by product ID (ascending) in case of ties. * **Constraints**: * The input list `ids` can contain up to (10^5) integers. * The value of `k` will be less than or equal to the number of unique product IDs in the given range. * The product IDs in `ids` can range from 0 to (10^6). Example ```python ids = [101, 202, 101, 303, 101, 202, 303, 404, 505] left = 100 right = 300 k = 2 print(frequent_items_within_range(ids, left, right, k)) # Output: [101, 202] ids = [10, 20, 10, 30, 10, 20, 30, 40, 50] left = 10 right = 40 k = 3 print(frequent_items_within_range(ids, left, right, k)) # Output: [10, 20, 30] ``` Notes * You need to build an efficient algorithm that can handle large input sizes up to (10^5) while ensuring accurate frequency counting and sorting operations. * Make sure to handle edge cases such as when no product IDs in `ids` fall within the specified range.","solution":"from collections import Counter def frequent_items_within_range(ids: list[int], left: int, right: int, k: int) -> list[int]: Returns the k most frequent product IDs found within the specified range [left, right]. # Count the frequency of each product ID within the specified range counter = Counter(id for id in ids if left <= id <= right) # Sort the items first by frequency (descending) and then by product ID (ascending) sorted_items = sorted(counter.items(), key=lambda x: (-x[1], x[0])) # Extract the top k product IDs result = [id for id, count in sorted_items[:k]] return result"},{"question":"# Coding Assessment Question Context: You are working as a software engineer at an e-commerce company. One of your tasks is to analyze customer purchase data to identify spending habits. Among various metrics, you have been asked to implement a function that calculates the maximum profit that can be made by buying and selling a product given an array representing daily prices of the product. Task: Write a Python function named `max_profit` that takes a list of integers representing the prices of a product on different days and returns the maximum profit that can be achieved by buying on one day and selling on another subsequent day. Specifications: - **Function Name**: `max_profit` - **Parameters**: - `prices` (list[int]): A list of integers where each element represents the price of the product on a specific day. - **Returns**: An integer representing the maximum profit possible. # Constraints: 1. If no profit can be made, return 0. 2. The list `prices` has at least one integer. 3. Implement the function to run in linear time complexity, i.e., O(n). # Example: ```python assert max_profit([7, 1, 5, 3, 6, 4]) == 5 # Buy on day 2 (price=1) and sell on day 5 (price=6) assert max_profit([7, 6, 4, 3, 1]) == 0 # No profit can be made assert max_profit([2, 4, 1, 7, 5, 3]) == 6 # Buy on day 3 (price=1) and sell on day 4 (price=7) assert max_profit([5, 3, 6, 8, 6, 1, 4]) == 5 # Buy on day 2 (price=3) and sell on day 4 (price=8) ```","solution":"def max_profit(prices): Calculates the maximum profit that can be achieved by buying and selling a product given an array of daily prices. :param prices: list of integers representing the price of the product on different days. :return: integer representing the maximum profit possible. if not prices: return 0 min_price = float(\'inf\') max_profit = 0 for price in prices: if price < min_price: min_price = price profit = price - min_price if profit > max_profit: max_profit = profit return max_profit"},{"question":"# Coding Assessment Question You are given a list of integers representing house values in a neighborhood where a robber plans to rob houses. However, due to security systems, the robber cannot rob two adjacent houses. Given this constraint, determine the maximum amount of money the robber can rob. Write a function to find the maximum sum of non-adjacent numbers from the list, following the rule that two consecutive elements cannot be included in the sum. # Function Signature ```python def rob_houses(house_values: List[int]) -> int: pass ``` # Input * `house_values` (List[int]): A list of integers representing the value of each house. # Output * Returns an integer representing the maximum value the robber can rob without alerting security systems. # Constraints * 0 ≤ len(house_values) ≤ 100 * 0 ≤ house_values[i] ≤ 400 # Examples ```python # Example 1: # If house values are [2, 3, 2], the robber can rob first and last house for a maximum value of 4. assert rob_houses([2, 3, 2]) == 4 # Example 2: # If house values are [1, 2, 3, 1], the robber can rob the second and fourth house for a maximum value of 4. assert rob_houses([1, 2, 3, 1]) == 4 # Example 3: # If house values are [2, 7, 9, 3, 1], the robber can rob the first, third, and fifth house for a maximum value of 12. assert rob_houses([2, 7, 9, 3, 1]) == 12 ``` # Explanation The function should: 1. Iterate through the list of house values. 2. Track the maximum value that can be robbed at each house while ensuring no two adjacent houses are robbed. 3. Use dynamic programming to store intermediate results and optimize the solution. # Notes - Consider edge cases where there are no houses or the list is empty. - Ensure proper handling of arrays of different lengths to provide the correct maximum value. - Optimize the algorithm for the given constraints to handle the upper limit efficiently.","solution":"from typing import List def rob_houses(house_values: List[int]) -> int: Determines the maximum amount of money the robber can rob without robbing two adjacent houses. if not house_values: return 0 n = len(house_values) if n == 1: return house_values[0] dp = [0] * n dp[0] = house_values[0] dp[1] = max(house_values[0], house_values[1]) for i in range(2, n): dp[i] = max(dp[i-1], dp[i-2] + house_values[i]) return dp[-1]"},{"question":"# Binary Search Tree (BST) Implementation and Validation You are required to implement a Binary Search Tree (BST) data structure in Python, including methods for inserting elements, deleting elements, finding elements, and validating the tree\'s structure. You must also provide functionality to check if the tree satisfies the BST properties. # Specifications: * **Class Name**: `BinarySearchTree` * **Attributes**: - `root`: The root node of the BST. * **Node Class**: An inner `Node` class representing each node in the tree. - Attributes: - `key`: The key stored in the node. - `left`: Pointer to the left child node. - `right`: Pointer to the right child node. * **Methods**: - `insert(key)`: Inserts a new node with the given key into the BST. - `delete(key)`: Deletes the node with the given key from the BST. - `find(key)`: Returns `True` if a node with the given key exists in the tree, `False` otherwise. - `validate()`: Checks if the tree satisfies BST properties, i.e., for every node, all keys in the left subtree are smaller, and all keys in the right subtree are larger. - `in_order_traversal()`: Returns a list of nodes\' keys in in-order traversal. # Constraints: * Keys will be unique integers. * Methods should raise appropriate Python exceptions for invalid operations: - `TypeError` if keys are not integers. - `ValueError` if attempting to delete non-existent keys. # Example Usage: ```python bst = BinarySearchTree() # Insertions bst.insert(10) bst.insert(5) bst.insert(15) # Find print(bst.find(15)) # Output: True print(bst.find(20)) # Output: False # Deletion bst.delete(10) # Validate BST properties print(bst.validate()) # Output: True # In-Order Traversal print(bst.in_order_traversal()) # Output: [5, 15] ``` # Performance Requirements: * Operations should be efficient with time complexity approximately O(log n) on average for insertion, deletion, and search operations. # Implementation: Implement the `BinarySearchTree` class with the specified methods. Ensure that the tree maintains its structure according to BST properties after each insertion and deletion. Use recursion for methods where applicable and handle edge cases such as attempting to delete a node not present in the tree or performing operations with invalid key types.","solution":"class BinarySearchTree: class Node: def __init__(self, key): self.key = key self.left = None self.right = None def __init__(self): self.root = None def insert(self, key): if not isinstance(key, int): raise TypeError(\\"Key must be an integer\\") if self.root is None: self.root = self.Node(key) else: self._insert(self.root, key) def _insert(self, node, key): if key < node.key: if node.left is None: node.left = self.Node(key) else: self._insert(node.left, key) elif key > node.key: if node.right is None: node.right = self.Node(key) else: self._insert(node.right, key) def delete(self, key): if not isinstance(key, int): raise TypeError(\\"Key must be an integer\\") self.root = self._delete(self.root, key) def _delete(self, node, key): if node is None: raise ValueError(\\"Key not found in the tree\\") if key < node.key: node.left = self._delete(node.left, key) elif key > node.key: node.right = self._delete(node.right, key) else: if node.left is None: return node.right elif node.right is None: return node.left temp = self._min_value_node(node.right) node.key = temp.key node.right = self._delete(node.right, temp.key) return node def _min_value_node(self, node): current = node while current.left is not None: current = current.left return current def find(self, key): if not isinstance(key, int): raise TypeError(\\"Key must be an integer\\") return self._find(self.root, key) def _find(self, node, key): if node is None: return False if key < node.key: return self._find(node.left, key) elif key > node.key: return self._find(node.right, key) else: return True def validate(self): return self._validate(self.root, float(\'-inf\'), float(\'inf\')) def _validate(self, node, min_key, max_key): if node is None: return True if not (min_key < node.key < max_key): return False return (self._validate(node.left, min_key, node.key) and self._validate(node.right, node.key, max_key)) def in_order_traversal(self): result = [] self._in_order_traversal(self.root, result) return result def _in_order_traversal(self, node, result): if node is not None: self._in_order_traversal(node.left, result) result.append(node.key) self._in_order_traversal(node.right, result)"},{"question":"# Problem: Repeated Substring Pattern **Description:** Given a string `s`, your task is to determine whether it can be constructed by taking a substring of it and appending multiple copies of the substring together. Implement a function `repeated_substring_pattern` to solve this problem. **Function Signature:** ```python def repeated_substring_pattern(s: str) -> bool: pass ``` **Input:** - A string `s` where (1 leq text{len}(s) leq 10^4). **Output:** - Returns `True` if the string can be constructed by repeating a substring of itself. Otherwise, return `False`. **Constraints:** - All characters in `s` are lowercase English letters. # Example: ```python print(repeated_substring_pattern(\\"abab\\")) # Outputs: True (substring \\"ab\\" repeated twice) print(repeated_substring_pattern(\\"aba\\")) # Outputs: False print(repeated_substring_pattern(\\"abcabcabcabc\\")) # Outputs: True (substring \\"abc\\" repeated four times) ``` **Performance Requirement:** - Ensure your function executes efficiently within the given constraints. # Note: Think about efficient methods to determine if a string can be formed by repeating its substring pattern. You might want to explore properties of string concatenation or utilize repeated pattern checks.","solution":"def repeated_substring_pattern(s: str) -> bool: Determine if the string can be constructed by repeating a substring pattern. if not s: return False # concatenate the string with itself ss = s + s # remove first and last characters ss = ss[1:-1] # check if the original string is present in this new string return s in ss"},{"question":"# Coding Assessment Question Context You are developing a password strength checker for an application. The system should ensure that the password meets various security criteria, including having a mix of characters and a minimum length. Task Write a function `is_strong_password(password: str) -> bool` that returns `True` if the input string `password` meets the following criteria: - At least 8 characters long. - Contains at least one uppercase letter. - Contains at least one lowercase letter. - Contains at least one digit. - Contains at least one special character (such as !, @, #, etc.). Return `False` if the password does not satisfy any one of these conditions. Input * A single string `password`, where `0 <= len(password) <= 10^3`. Output * A boolean value: `True` if `password` is strong according to the above criteria, otherwise `False`. Constraints * Consider ASCII characters only. * Your implementation should be efficient and simple. Examples ```python assert is_strong_password(\\"Aa1!abcd\\") == True assert is_strong_password(\\"abcdefg\\") == False assert is_strong_password(\\"Ab1!\\") == False # Length less than 8 assert is_strong_password(\\"!@#%^^&*\\") == False # No digit and no lowercase assert is_strong_password(\\"ABCdef123\\") == False # No special character assert is_strong_password(\\"Aa1!Aa1!\\") == True ``` **Note**: Optimize your function to check the criteria with minimal passes through the string.","solution":"import re def is_strong_password(password: str) -> bool: Checks if the given password is strong based on defined criteria. Args: password (str): The password to check. Returns: bool: True if password is strong, False otherwise. if len(password) < 8: return False if not re.search(r\'[A-Z]\', password): return False if not re.search(r\'[a-z]\', password): return False if not re.search(r\'[0-9]\', password): return False if not re.search(r\'[W_]\', password): return False return True"},{"question":"# **Matrix Block Summation** You are tasked with creating a function to calculate the block sum of a given matrix. The block sum of a matrix is defined such that for each element in the original matrix, its block sum is the sum of all elements within a specified distance `K` from it. The distance `K` determines how far you look in all directions (up, down, left, right) to find elements to include in the sum. **Function Signature**: ```python def matrixBlockSum(mat: List[List[int]], K: int) -> List[List[int]]: pass ``` **Input**: * `mat`: A 2D list representing the input matrix of integers. * `K`: An integer representing the block distance. **Output**: * A 2D list where each element represents the block sum of the corresponding element in the input matrix. **Constraints**: * `1 <= len(mat), len(mat[0]) <= 100` * `0 <= mat[i][j] <= 100` * `0 <= K <= 100` **Example**: ```python mat = [ [1, 2, 3], [4, 5, 6], [7, 8, 9] ] K = 1 result = matrixBlockSum(mat, K) assert result == [ [12, 21, 16], [27, 45, 33], [24, 39, 28] ] ``` In the example above: - For `K=1`, the block sum for element `mat[0][0]` is calculated by summing all the elements within `K=1` distance from `(0,0)`, which includes elements at positions `(0,0)`, `(0,1)`, `(1,0)`, and `(1,1)`. Summing these elements yields `1 + 2 + 4 + 5 = 12`. **Note**: - Ensure your implementation efficiently handles the block sum calculation for each matrix element within the given constraints. - Consider edge cases where small matrices and extreme values of `K` may lead to different behavior in the block summation process. - Optimize for time complexity to handle the maximum size constraints effectively.","solution":"from typing import List def matrixBlockSum(mat: List[List[int]], K: int) -> List[List[int]]: # Get the size of the matrix m, n = len(mat), len(mat[0]) # Create the integral image integral_image = [[0] * (n + 1) for _ in range(m + 1)] for i in range(m): for j in range(n): integral_image[i + 1][j + 1] = (mat[i][j] + integral_image[i][j + 1] + integral_image[i + 1][j] - integral_image[i][j]) # Calculate the block sum using the integral image result = [[0] * n for _ in range(m)] for i in range(m): for j in range(n): r1, c1 = max(0, i - K), max(0, j - K) r2, c2 = min(m, i + K + 1), min(n, j + K + 1) result[i][j] = (integral_image[r2][c2] - integral_image[r1][c2] - integral_image[r2][c1] + integral_image[r1][c1]) return result"},{"question":"# Ticket Priority Management System You are tasked with enhancing an existing ticket priority management system that tracks the priority of tickets in a service desk. Task Implement the following enhancements to the ticket priority management functionality: 1. **Priority Assignment**: - Modify the `add_ticket` function to automatically assign a default priority of \'Medium\' if none is specified. 2. **Priority Escalation**: - Implement a function `escalate_priority` that increases the priority of a given ticket to the next level. Priorities are: \'Low\', \'Medium\', \'High\', \'Urgent\'. 3. **Priority Level Validation**: - Ensure that the functions handle invalid priority levels gracefully, logging a warning if an invalid priority is encountered during any operation. 4. **Display Sorted Tickets**: - Add a method `get_sorted_tickets` that returns a list of tickets sorted by priority in descending order: \'Urgent\', \'High\', \'Medium\', \'Low\'. Function Specifications **Add Ticket Function**: ```python def add_ticket(ticket_id: int, description: str, priority: str = None) -> None: Adds a new ticket with the given ID, description, and optional priority. Parameters: - ticket_id: int : The ID of the ticket to be added. - description: str : A brief description of the issue. - priority: str (Optional) : The priority level (\'Low\', \'Medium\', \'High\', \'Urgent\'). Notes: - Automatically assign a \'Medium\' priority if no priority is specified. - Log a warning if an invalid priority is provided. Example: >>> add_ticket(1, \\"Network issue\\", \\"High\\") >>> add_ticket(2, \\"Software crash\\") >>> add_ticket(3, \\"Password reset\\", \\"InvalidPriority\\") # logs warning and defaults to \'Medium\' pass ``` **Escalate Priority Function**: ```python def escalate_priority(ticket_id: int) -> None: Escalates the priority of the given ticket to the next level. Parameters: - ticket_id: int : The ID of the ticket to be escalated. Notes: - Priorities escalate in the order: \'Low\' -> \'Medium\' -> \'High\' -> \'Urgent\'. - Log a warning if the ticket is already at \'Urgent\' priority or if the ticket ID does not exist. Example: >>> escalate_priority(1) # If the current priority is \'High\', it becomes \'Urgent\' pass ``` **Get Sorted Tickets Function**: ```python def get_sorted_tickets() -> list: Returns a list of all tickets sorted by priority in descending order. Returns: - list: A list of tickets sorted by priority (\'Urgent\', \'High\', \'Medium\', \'Low\'). Example: >>> get_sorted_tickets() [ {\'ticket_id\': 1, \'description\': \'Network issue\', \'priority\': \'High\'}, {\'ticket_id\': 2, \'description\': \'Software crash\', \'priority\': \'Medium\'} ] pass ``` **Additional Requirements**: - Write unit tests for the functions to ensure they handle typical scenarios as well as edge cases, such as invalid priorities and escalation cases. - Use appropriate logging for warnings related to invalid priorities and other edge cases. Input and Output Formats - Input: - `add_ticket`: `int` (ticket ID), `str` (description), `str` (optional priority) - `escalate_priority`: `int` (ticket ID) - `get_sorted_tickets`: No input - Output: - `add_ticket`: None - `escalate_priority`: None - `get_sorted_tickets`: list of dictionaries (each containing ticket details) --- This question complements the set by focusing on another key area in software applications, managing service desk tickets by adding priorities and handling various priority-related operations. It requires candidates to handle default values, escalate priorities, manage invalid inputs, and create sorted outputs, matching the complexity and scope of the provided examples.","solution":"import logging # Set up logging logging.basicConfig(level=logging.WARNING) logger = logging.getLogger(__name__) # List of tickets and valid priority levels tickets = [] valid_priorities = [\'Low\', \'Medium\', \'High\', \'Urgent\'] def add_ticket(ticket_id: int, description: str, priority: str = None) -> None: Adds a new ticket with the given ID, description, and optional priority. if priority not in valid_priorities: if priority is not None: logger.warning(f\\"Invalid priority \'{priority}\' provided. Defaulting to \'Medium\'.\\") priority = \'Medium\' tickets.append({\'ticket_id\': ticket_id, \'description\': description, \'priority\': priority}) def escalate_priority(ticket_id: int) -> None: Escalates the priority of the given ticket to the next level. priority_order = [\'Low\', \'Medium\', \'High\', \'Urgent\'] for ticket in tickets: if ticket[\'ticket_id\'] == ticket_id: current_priority = ticket[\'priority\'] if current_priority == \'Urgent\': logger.warning(\\"Ticket is already at \'Urgent\' priority and cannot be escalated.\\") return next_priority = priority_order[priority_order.index(current_priority) + 1] ticket[\'priority\'] = next_priority return logger.warning(f\\"Ticket ID {ticket_id} does not exist.\\") def get_sorted_tickets() -> list: Returns a list of all tickets sorted by priority in descending order. priority_order = {\'Urgent\': 1, \'High\': 2, \'Medium\': 3, \'Low\': 4} return sorted(tickets, key=lambda x: priority_order[x[\'priority\']])"},{"question":"# Context You are provided with a simple logging system that needlessly stores all messages in a list, leading to degradation in both time and space complexity for common operations like adding and retrieving logs, especially given frequent insertions and query operations. # Task Refactor the provided `Logger` class to use a more efficient data structure, such as a dictionary, to handle frequency of log retrieval based on severity levels and timestamps. # Requirements 1. Implement the methods – `log(severity, message)`, `retrieve(severity)`, `retrieve(time_start, time_end)`, and `retrieve(severity, time_start, time_end)`. 2. The `log(severity, message)` method should run in O(1) time complexity. 3. The `retrieve(severity)` method should retrieve all messages of a given severity level efficiently. 4. The `retrieve(time_start, time_end)` method should retrieve all messages within a time range efficiently. 5. The `retrieve(severity, time_start, time_end)` method should retrieve all messages of a given severity level within a time range efficiently. # Input/Output - The `log(severity, message)` method takes a severity level (e.g., \\"INFO\\", \\"ERROR\\") and a message, and records the current timestamp and message. - The `retrieve(severity)` method returns a list of messages with the specified severity level. - The `retrieve(time_start, time_end)` method returns a list of messages recorded within the specified time range. - The `retrieve(severity, time_start, time_end)` method returns a list of messages with the specified severity level within the specified time range. # Example ```python logger = Logger() logger.log(\\"INFO\\", \\"This is an info message.\\") logger.log(\\"ERROR\\", \\"This is an error message.\\") logger.log(\\"INFO\\", \\"Another info message.\\") print(logger.retrieve(\\"INFO\\")) # Output: [\\"This is an info message.\\", \\"Another info message.\\"] start_time = datetime.datetime.now() - datetime.timedelta(hours=1) end_time = datetime.datetime.now() print(logger.retrieve(start_time, end_time)) # Output: [\\"This is an info message.\\", \\"This is an error message.\\", \\"Another info message.\\"] print(logger.retrieve(\\"ERROR\\", start_time, end_time)) # Output: [\\"This is an error message.\\"] ``` # Notes * Utilize a dictionary where each severity level maps to a list of messages. * Use timestamps for logging, ensuring to add the current timestamp to each log entry. * Ensure log retrieval operations are efficient by leveraging appropriate data structures.","solution":"import datetime from collections import defaultdict class Logger: def __init__(self): self.logs = defaultdict(list) def log(self, severity, message): Logs a message with the given severity and the current timestamp. timestamp = datetime.datetime.now() self.logs[severity].append((timestamp, message)) def retrieve(self, severity=None, time_start=None, time_end=None): Retrieves messages based on severity, time range or both. if severity and time_start and time_end: return [message for timestamp, message in self.logs[severity] if time_start <= timestamp <= time_end] elif severity: return [message for _, message in self.logs[severity]] elif time_start and time_end: result = [] for logs in self.logs.values(): result.extend([message for timestamp, message in logs if time_start <= timestamp <= time_end]) return result else: return []"},{"question":"# Question: Implement Custom String Formatter **Scenario**: You are tasked with writing a custom string formatter that converts a given template string into its formatted version based on provided values. The template string uses placeholders in the format `{name}` where `name` corresponds to a key in a dictionary of values. Your goal is to write a function `custom_formatter` that formats the string correctly based on the given dictionary. # Requirements: * **Function Name**: `custom_formatter` * **Input**: * A template string containing placeholders in the format `{name}`. * A dictionary where keys are placeholder names and values are their corresponding values. * **Output**: A formatted string where all placeholders have been replaced by their corresponding dictionary values. * **Constraints**: * All placeholders in the template string must have corresponding entries in the dictionary. * Values in the dictionary may be of any type that can be converted to a string using `str()`. * **Performance Requirements**: The function should handle the replacement of placeholders efficiently. # Function Signature: ```python def custom_formatter(template: str, values: dict[str, any]) -> str: pass ``` # Example: ```python >>> custom_formatter(\\"Hello, {name}! Welcome to {city}.\\", {\\"name\\": \\"Alice\\", \\"city\\": \\"Wonderland\\"}) \'Hello, Alice! Welcome to Wonderland.\' >>> custom_formatter(\\"The price of {item} is {price} USD.\\", {\\"item\\": \\"apple\\", \\"price\\": 1.2}) \'The price of apple is 1.2 USD.\' >>> custom_formatter(\\"{greeting}, {name}!\\", {\\"greeting\\": \\"Hi\\", \\"name\\": \\"Bob\\"}) \'Hi, Bob!\' ``` # Constraints: 1. If the template contains a placeholder not found in the dictionary, raise a `KeyError`. 2. If the dictionary contains keys not in the template, they should be ignored. You are encouraged to write clear and concise code, making use of appropriate string manipulation techniques to ease processing.","solution":"def custom_formatter(template: str, values: dict[str, any]) -> str: Formats the template string using the provided dictionary values. Args: template (str): A template string containing placeholders in the format {name}. values (dict): A dictionary where keys are placeholder names and values are their corresponding values. Returns: str: The formatted string with all placeholders replaced by their corresponding dictionary values. try: formatted_string = template.format(**values) except KeyError as e: raise KeyError(f\\"Missing value for key: {e}\\") return formatted_string"},{"question":"# Sorting and Searching In this programming task, you will work on implementing an efficient search algorithm in a sorted, rotated array. Your goal is to implement and test a specific method to achieve this. Problem Statement You are given a class named `RotatedArray`. Implement the following feature that performs a search operation on the rotated sorted array: # Method: `search(target: int) -> int` Implement a function to search for a given `target` value in a sorted array that has been rotated at some pivot unknown to you beforehand. If the target value is found, return its index; otherwise, return -1. # Expected Input and Output Formats * **Input**: The method will accept an integer `target` which you need to find in the array. * **Output**: An integer representing the index of the `target` if found, else -1. # Constraints and Limitations: 1. The array contains no duplicate values. 2. The array is non-empty and is rotated between 1 and `n-1` times where `n` is the length of the array. 3. Aim for an `O(log n)` efficient solution. Example Scenario ```python >>> arr = RotatedArray([4, 5, 6, 7, 0, 1, 2]) >>> arr.search(0) 4 >>> arr.search(3) -1 ``` Implement the following method within the `RotatedArray` class: ```python def search(self, target: int) -> int: # Your code here ``` Additional Notes - The function should handle edge cases such as the smallest and largest elements being the target. - Make sure to handle arrays of different lengths, including arrays with minimal length. Evaluation Criteria * **Correctness**: The method should correctly identify the index of the target element or return -1 if not found. * **Efficiency**: The solution should operate in `O(log n)` time complexity. * **Readability**: Ensure the code is clean, well-structured, and sufficiently documented.","solution":"class RotatedArray: def __init__(self, nums): self.nums = nums def search(self, target: int) -> int: Search for the target in the rotated sorted array and return its index. If the target is not found, return -1. left, right = 0, len(self.nums) - 1 while left <= right: mid = (left + right) // 2 if self.nums[mid] == target: return mid # Check if the left half is sorted if self.nums[left] <= self.nums[mid]: if self.nums[left] <= target < self.nums[mid]: right = mid - 1 else: left = mid + 1 # Otherwise, the right half must be sorted else: if self.nums[mid] < target <= self.nums[right]: left = mid + 1 else: right = mid - 1 return -1"},{"question":"# Morse Code Encoder and Decoder Context Morse code is a method of encoding text characters into sequences of dots and dashes. It was commonly used in telegraphy and early forms of digital communication. Each character in the English alphabet, as well as numerical digits, is translated to a unique series of dots (.) and dashes (-). Objective Write a Python class to implement a Morse code encoder and decoder. Your implementation should include methods to translate text strings to Morse code and vice versa. Additionally, provide functionality to handle common punctuation and spacing between words. Core Implementation Requirements 1. Implement a class `MorseCode` with the following methods: - `__init__(self)`: Initializes the MorseCode class and sets up the necessary Morse code dictionary mappings. - `encode(self, text)`: Encodes a given text string into Morse code, using a single space to separate Morse code of each character and three spaces to separate words. - `decode(self, morse_code)`: Decodes a given Morse code string back into plain text. - `set_mappings(self, new_mappings)`: Updates the Morse code dictionary with user-defined mappings (key-value pairs for characters and their Morse code). Constraints - Input text for encoding will be in uppercase and will only contain alphabetical characters, numeric digits, spaces, and common punctuation (.,?,!). - Ensure proper handling of spaces between words when encoding and decoding. - If a character or Morse code sequence cannot be mapped, handle it gracefully (e.g., include a placeholder or skip). Example Here\'s an example to illustrate the usage: ```python if __name__ == \\"__main__\\": mc = MorseCode() text = \\"HELLO WORLD\\" morse = \\"... --- ...\\" # Encode text to Morse code encoded_text = mc.encode(text) print(encoded_text) # .... . .-.. .-.. --- .-- --- .-. .-.. -.. # Decode Morse code to text decoded_text = mc.decode(encoded_text) print(decoded_text) # HELLO WORLD # Decode custom Morse code custom_decoded_text = mc.decode(morse) print(custom_decoded_text) # SOS # Set custom mappings and encode custom_mappings = {\'A\': \'.-\', \'B\': \'-...\'} mc.set_mappings(custom_mappings) encoded_custom = mc.encode(\\"AB\\") print(encoded_custom) # .- -... # Decode custom Morse code with updated mappings decoded_custom = mc.decode(encoded_custom) print(decoded_custom) # AB ``` Your task is to complete the `MorseCode` class meeting the specified requirements. # Hints - Use a dictionary to store Morse code mappings. - Carefully manage spacing when encoding and decoding to distinguish between characters and words. - Consider edge cases such as empty strings or unsupported characters. The constructed class should be able to handle efficient and precise Morse code translations, potentially facilitating learning and decoding Morse code in practical scenarios.","solution":"class MorseCode: def __init__(self): self.morse_dict = { \'A\': \\".-\\", \'B\': \\"-...\\", \'C\': \\"-.-.\\", \'D\': \\"-..\\", \'E\': \\".\\", \'F\': \\"..-.\\", \'G\': \\"--.\\", \'H\': \\"....\\", \'I\': \\"..\\", \'J\': \\".---\\", \'K\': \\"-.-\\", \'L\': \\".-..\\", \'M\': \\"--\\", \'N\': \\"-.\\", \'O\': \\"---\\", \'P\': \\".--.\\", \'Q\': \\"--.-\\", \'R\': \\".-.\\", \'S\': \\"...\\", \'T\': \\"-\\", \'U\': \\"..-\\", \'V\': \\"...-\\", \'W\': \\".--\\", \'X\': \\"-..-\\", \'Y\': \\"-.--\\", \'Z\': \\"--..\\", \'1\': \\".----\\", \'2\': \\"..---\\", \'3\': \\"...--\\", \'4\': \\"....-\\", \'5\': \\".....\\", \'6\': \\"-....\\", \'7\': \\"--...\\", \'8\': \\"---..\\", \'9\': \\"----.\\", \'0\': \\"-----\\", \',\': \\"--..--\\", \'.\': \\".-.-.-\\", \'?\': \\"..--..\\", \'!\': \\"-.-.--\\", \' \': \'/\' } self.rev_morse_dict = {v: k for k, v in self.morse_dict.items()} def encode(self, text): encoded_message = \' \'.join([self.morse_dict.get(char, \'\') for char in text.upper()]) return encoded_message def decode(self, morse_code): words = morse_code.split(\' \') decoded_message = \' \'.join([\'\'.join([self.rev_morse_dict.get(sym, \'\') for sym in word.split()]) for word in words]) return decoded_message.replace(\'/\', \' \') def set_mappings(self, new_mappings): self.morse_dict.update(new_mappings) self.rev_morse_dict = {v: k for k, v in self.morse_dict.items()}"},{"question":"# Context: You have been given an implementation of a binary search tree (BST) with typical insert, search, and delete functionalities. Your task is to augment this BST with additional methods to ensure it remains balanced, thereby improving its operational efficiency. Specifically, implement the Self-Balancing Binary Search Tree behavior using the Adelson-Velsky and Landis (AVL) tree approach. # Problem: 1. Write a method `recalculate_height(self, node)` that updates the height of a given node. 2. Write a method `balance_factor(self, node)` that calculates and returns the balance factor of a given node. 3. Write a method `rebalance(self, node)` that performs the necessary rotations (left, right, left-right, or right-left) to keep the AVL tree balanced. # Implementation Details: - Class definition: `class AVLTree(BST):` - Methods to implement: * `def recalculate_height(self, node):` * `def balance_factor(self, node):` * `def rebalance(self, node):` # Input: - `recalculate_height(self, node)` takes a single parameter: * `node` (TreeNode): The node whose height needs to be updated. - `balance_factor(self, node)` takes a single parameter: * `node` (TreeNode): The node whose balance factor needs to be calculated. - `rebalance(self, node)` takes a single parameter: * `node` (TreeNode): The node around which the tree needs to be rebalanced. # Output: - `recalculate_height(self, node)` will update the height of the specified node and return `None`. - `balance_factor(self, node)` will return an integer indicating the balance factor of the specified node. - `rebalance(self, node)` will adjust the tree to restore AVL balance and return `None`. # Constraints: - The `node` parameter in each method can be assumed to be a valid reference to a node within the tree. - The tree contains nodes with integer values. - The AVL tree properties must be maintained after each insert and delete operation. # Performance Requirements: - `recalculate_height(self, node)` should have a time complexity of O(1). - `balance_factor(self, node)` should have a time complexity of O(1). - `rebalance(self, node)` should have a time complexity of O(log n), where n is the number of nodes in the tree. # Example Usage: ```python avl_tree = AVLTree() # Inserting elements into the AVL tree avl_tree.insert(10) avl_tree.insert(20) avl_tree.insert(30) # Checking the balance factor and height node = avl_tree.root.right print(avl_tree.balance_factor(node)) # Output depends on insertion order # Rebalancing the node if needed avl_tree.rebalance(node) ``` # Note: - Ensure that the AVL tree remains balanced after every insertion and deletion by integrating these methods appropriately within the tree modification methods. - Test your implementation rigorously to handle edge cases such as single child nodes, empty subtrees, etc.","solution":"class TreeNode: def __init__(self, key): self.left = None self.right = None self.val = key self.height = 1 class AVLTree: def insert(self, root, key): if not root: return TreeNode(key) elif key < root.val: root.left = self.insert(root.left, key) else: root.right = self.insert(root.right, key) self.recalculate_height(root) return self.rebalance(root) def recalculate_height(self, node): if not node: return 0 node.height = 1 + max(self.get_height(node.left), self.get_height(node.right)) def get_height(self, node): if not node: return 0 return node.height def balance_factor(self, node): if not node: return 0 return self.get_height(node.left) - self.get_height(node.right) def rebalance(self, node): balance = self.balance_factor(node) if balance > 1: if self.balance_factor(node.left) < 0: node.left = self.rotate_left(node.left) return self.rotate_right(node) if balance < -1: if self.balance_factor(node.right) > 0: node.right = self.rotate_right(node.right) return self.rotate_left(node) return node def rotate_left(self, z): y = z.right T2 = y.left y.left = z z.right = T2 self.recalculate_height(z) self.recalculate_height(y) return y def rotate_right(self, z): y = z.left T2 = y.right y.right = z z.left = T2 self.recalculate_height(z) self.recalculate_height(y) return y # Usage example: avl_tree = AVLTree() root = None # Inserting elements into the AVL tree root = avl_tree.insert(root, 10) root = avl_tree.insert(root, 20) root = avl_tree.insert(root, 30) # Checking the balance factor and height print(f\\"Balance factor of root: {avl_tree.balance_factor(root)}\\") print(f\\"Root value after balancing: {root.val}\\")"},{"question":"# Problem Statement You are given an array of integers where each element represents the height of a building. Your task is to find the maximum area of a rectangle formed by any number of consecutive buildings. Write a function `max_rectangle_area(heights: List[int]) -> int` that takes a list of integers representing the heights of buildings and returns the maximum rectangular area that can be formed by any number of contiguous buildings. Input * A list `heights` of `n` integers, where `heights[i]` is the height of the `i-th` building. (1 ≤ n ≤ 10^5, 1 ≤ heights[i] ≤ 10^5) Output * An integer representing the maximum rectangular area that can be formed by any number of consecutive buildings. Example ``` Input: heights = [2, 1, 5, 6, 2, 3] Output: 10 ``` In this example: - Consider the buildings with heights [2, 1, 5, 6, 2, 3]. - The maximum rectangular area can be formed between the third and fourth buildings with heights [5, 6], which gives the area 5*2 = 10. Constraints * You must achieve an `O(n)` time complexity. * Use of additional space is allowed but focus on optimal usage. Implement the function `max_rectangle_area(heights: List[int]) -> int` that adheres to these requirements.","solution":"from typing import List def max_rectangle_area(heights: List[int]) -> int: n = len(heights) stack = [] max_area = 0 for i in range(n): while stack and heights[stack[-1]] > heights[i]: h = heights[stack.pop()] w = i if not stack else i - stack[-1] - 1 max_area = max(max_area, h * w) stack.append(i) while stack: h = heights[stack.pop()] w = n if not stack else n - stack[-1] - 1 max_area = max(max_area, h * w) return max_area"},{"question":"# Data Analysis and Transformation Scenario You are helping a company analyze their sales data to identify trends and make business decisions. The sales data is provided as a list of dictionaries, where each dictionary contains information about a single sales transaction. Each dictionary contains the following keys: - `\\"date\\"`: The date of the transaction in the format `\\"YYYY-MM-DD\\"` - `\\"customer_id\\"`: An integer representing the unique ID of the customer. - `\\"amount\\"`: The total amount of the transaction in USD. The company is interested in finding out the following: 1. The total sales amount for each month. 2. The total sales amount for each customer. Task Implement a function `analyze_sales_data` that takes a list of transactions and returns two dictionaries: 1. A dictionary where the keys are the months in the format `\\"YYYY-MM\\"` and the values are the total sales amount for that month. 2. A dictionary where the keys are customer IDs and the values are the total sales amount for each customer. Function Signature ```python from typing import List, Dict def analyze_sales_data(transactions: List[Dict[str, object]]) -> (Dict[str, float], Dict[int, float]): pass ``` Parameters - `transactions (List[Dict[str, object]])`: A list of dictionaries, where each dictionary contains: - `date (str)`: The date of the transaction in the format `\\"YYYY-MM-DD\\"`. - `customer_id (int)`: The unique ID of the customer. - `amount (float)`: The total amount of the transaction in USD. Returns - A tuple containing two dictionaries: 1. A dictionary with the total sales for each month. 2. A dictionary with the total sales for each customer. Constraints - All dates in the transactions are valid dates in the format `\\"YYYY-MM-DD\\"`. - The amount is a positive float. Examples - `analyze_sales_data([{\'date\': \'2023-01-15\', \'customer_id\': 1, \'amount\': 100.0}, {\'date\': \'2023-01-20\', \'customer_id\': 2, \'amount\': 200.0}, {\'date\': \'2023-02-10\', \'customer_id\': 1, \'amount\': 300.0}])` should return `({\'2023-01\': 300.0, \'2023-02\': 300.0}, {1: 400.0, 2: 200.0})`. - `analyze_sales_data([{\'date\': \'2022-11-05\', \'customer_id\': 3, \'amount\': 150.0}, {\'date\': \'2022-11-20\', \'customer_id\': 4, \'amount\': 250.0}, {\'date\': \'2022-12-01\', \'customer_id\': 3, \'amount\': 100.0}])` should return `({\'2022-11\': 400.0, \'2022-12\': 100.0}, {3: 250.0, 4: 250.0})`.","solution":"from typing import List, Dict def analyze_sales_data(transactions: List[Dict[str, object]]) -> (Dict[str, float], Dict[int, float]): monthly_sales = {} customer_sales = {} for transaction in transactions: date = transaction[\'date\'] amount = transaction[\'amount\'] customer_id = transaction[\'customer_id\'] # Extract the month in \'YYYY-MM\' format month = date[:7] # Update monthly sales if month in monthly_sales: monthly_sales[month] += amount else: monthly_sales[month] = amount # Update customer sales if customer_id in customer_sales: customer_sales[customer_id] += amount else: customer_sales[customer_id] = amount return monthly_sales, customer_sales"},{"question":"# Coding Assessment Question Context Consider an e-commerce platform that tracks the prices of products over time. To offer better deals and attract more customers, the platform wants to analyze price trends. They maintain a history of prices for each product and need to identify the longest period during which the prices have been non-increasing. Problem Statement Implement a function to find the longest contiguous subarray of non-increasing prices for a given list of prices. Input - **prices** (List of Integers): A list of integers representing the price history of a product. Output - An integer representing the length of the longest contiguous subarray where the prices are non-increasing. Constraints - `1 <= len(prices) <= 1000` - `0 <= prices[i] <= 10^6` Function Signature ```python def longest_non_increasing_subarray(prices: List[int]) -> int: pass ``` Example ```python input: prices = [5, 3, 3, 2, 4, 4, 1] output: 4 Explanation: The longest contiguous subarray with non-increasing prices is [5, 3, 3, 2] which has a length of 4. ``` Notes * Make sure your function efficiently handles the input list up to the maximum constraint. * Consider edge cases such as lists where prices are strictly increasing or the list contains only one element.","solution":"from typing import List def longest_non_increasing_subarray(prices: List[int]) -> int: if not prices: return 0 max_length = 1 current_length = 1 for i in range(1, len(prices)): if prices[i] <= prices[i - 1]: current_length += 1 else: current_length = 1 if current_length > max_length: max_length = current_length return max_length"},{"question":"# Question: Implement a Min Heap and its Operations Context: You are required to build a Min Heap data structure from scratch. A Min Heap is a complete binary tree where the value at the root is less than or equal to the values of its children, and this property applies recursively to all nodes in the tree. # Task: Implement a `MinHeap` class supporting the following operations: 1. **Insert**: Method `insert(data)` to add an element to the heap. 2. **Extract Minimum**: Method `extract_min()` to remove and return the smallest element in the heap. 3. **Get Minimum**: Method `get_min()` to return the smallest element in the heap without removing it. 4. **Heapify**: Method `heapify()` to transform an arbitrary list into a heap. # Requirements: 1. **Input/Output**: - Each method should operate on instances of `MinHeap` and modify the heap in place. - The constructor should optionally accept a list to heapify at initialization. 2. **Constraints**: - Implement the heap with an array (or list) for simplicity. - Account for edge cases such as empty heaps. - Maintain the efficiency of heap operations, ensuring each has a time complexity of O(log n) or better where applicable. 3. **Performance**: - The `insert`, `extract_min`, and `heapify` methods should achieve optimal time complexities for heap operations. # Example: ```python # Creating MinHeap with initial list data initial_data = [5, 13, 2, 25, 7, 17, 20, 8, 4] min_heap = MinHeap(initial_data) print(min_heap.get_min()) # Expected: 2 # Inserting into the MinHeap min_heap.insert(1) print(min_heap.get_min()) # Expected: 1 # Extracting Minimum print(min_heap.extract_min()) # Expected: 1 print(min_heap.extract_min()) # Expected: 2 # Getting Minimum after extractions print(min_heap.get_min()) # Expected: 4 # Heapify a new list min_heap.heapify([10, 3, 15, 30, 2, 7]) print(min_heap.get_min()) # Expected: 2 ``` ```python class MinHeap: def __init__(self, data=None): self.heap = [] if data: self.heap = data[:] self.heapify() def insert(self, data): self.heap.append(data) self._sift_up(len(self.heap) - 1) def extract_min(self): if not self.heap: return None if len(self.heap) == 1: return self.heap.pop() root = self.heap[0] self.heap[0] = self.heap.pop() self._sift_down(0) return root def get_min(self): if not self.heap: return None return self.heap[0] def heapify(self): for i in range(len(self.heap) // 2, -1, -1): self._sift_down(i) def _sift_up(self, index): parent = (index - 1) // 2 if index > 0 and self.heap[index] < self.heap[parent]: self.heap[index], self.heap[parent] = self.heap[parent], self.heap[index] self._sift_up(parent) def _sift_down(self, index): smallest = index left = 2 * index + 1 right = 2 * index + 2 if left < len(self.heap) and self.heap[left] < self.heap[smallest]: smallest = left if right < len(self.heap) and self.heap[right] < self.heap[smallest]: smallest = right if smallest != index: self.heap[index], self.heap[smallest] = self.heap[smallest], self.heap[index] self._sift_down(smallest) ```","solution":"class MinHeap: def __init__(self, data=None): self.heap = [] if data: self.heap = data[:] self.heapify() def insert(self, data): self.heap.append(data) self._sift_up(len(self.heap) - 1) def extract_min(self): if not self.heap: return None if len(self.heap) == 1: return self.heap.pop() root = self.heap[0] self.heap[0] = self.heap.pop() self._sift_down(0) return root def get_min(self): if not self.heap: return None return self.heap[0] def heapify(self): for i in range(len(self.heap) // 2, -1, -1): self._sift_down(i) def _sift_up(self, index): parent = (index - 1) // 2 if index > 0 and self.heap[index] < self.heap[parent]: self.heap[index], self.heap[parent] = self.heap[parent], self.heap[index] self._sift_up(parent) def _sift_down(self, index): smallest = index left = 2 * index + 1 right = 2 * index + 2 if left < len(self.heap) and self.heap[left] < self.heap[smallest]: smallest = left if right < len(self.heap) and self.heap[right] < self.heap[smallest]: smallest = right if smallest != index: self.heap[index], self.heap[smallest] = self.heap[smallest], self.heap[index] self._sift_down(smallest)"},{"question":"# Problem Statement You are given a non-empty array of unique integers. Your task is to return the length of the longest contiguous subarray where all elements are consecutive (the order of elements in the array doesn\'t matter). # Function Signature ```python def longest_consecutive_subarray(arr: List[int]) -> int: pass ``` # Input - `arr` (1 <= len(arr) <= 1000): A list of unique integers. # Output - An integer, the length of the longest contiguous subarray of consecutive integers. # Example ```python assert longest_consecutive_subarray([1, 2, 3, 4, 5]) == 5 assert longest_consecutive_subarray([10, 12, 11, 14]) == 3 assert longest_consecutive_subarray([1, 3, 5, 2, 4]) == 5 assert longest_consecutive_subarray([1, 9, 3, 10, 4, 20, 2]) == 4 assert longest_consecutive_subarray([8, 6, 7, 5, 4]) == 5 ``` # Constraints - The input array `arr` contains unique integers. - The input size is within the range (1 <= len(arr) <= 1000). - The elements are not necessarily sorted. - The array will have at least one element. # Scenarios 1. For `arr = [1, 2, 3, 4, 5]`, the function returns `5` because the entire array consists of consecutive numbers. 2. For `arr = [10, 12, 11, 14]`, the function returns `3` because the subsequence `[10, 11, 12]` is the longest consecutive subarray. 3. For `arr = [1, 3, 5, 2, 4]`, the function returns `5` because the whole array can be rearranged to form the consecutive subarray `[1, 2, 3, 4, 5]`. 4. For `arr = [1, 9, 3, 10, 4, 20, 2]`, the function returns `4` because the subsequence `[1, 2, 3, 4]` is consecutive. 5. For `arr = [8, 6, 7, 5, 4]`, the function returns `5` because the whole array forms the consecutive subarray `[4, 5, 6, 7, 8]`. # Hints - Consider using a set to quickly check the existence of potential consecutive elements. - Iterate through the array and for each element, expand to find the maximum consecutive subarray length containing that element.","solution":"def longest_consecutive_subarray(arr): arr_set = set(arr) max_length = 0 for num in arr: if num - 1 not in arr_set: current_num = num current_length = 1 while current_num + 1 in arr_set: current_num += 1 current_length += 1 max_length = max(max_length, current_length) return max_length"},{"question":"# Coding Challenge **Scenario**: You are given a list of pairs representing courses and their respective prerequisites. Each course may have multiple prerequisites. Your task is to determine if it\'s possible to finish all the courses. There are no duplicate numbers or pairs. **Function Signature**: ```python def can_finish_courses(num_courses: int, prerequisites: list[tuple[int, int]]) -> bool: pass ``` # Input * `num_courses` (int): The total number of courses you need to take. * `prerequisites` (list[tuple[int, int]]): A list of tuples where each tuple `(a, b)` indicates that course `a` has `b` as a prerequisite. # Output * (bool): Return `True` if it\'s possible to finish all courses, otherwise return `False`. # Constraints * (1 leq text{num_courses} leq 10^4) * (0 leq text{len(prerequisites)} leq 5 times 10^4) * There are no duplicate pairs. # Examples **Example 1** * Input: ```python num_courses = 2 prerequisites = [(1, 0)] ``` * Output: `True` **Example 2** * Input: ```python num_courses = 2 prerequisites = [(1, 0), (0, 1)] ``` * Output: `False` # Guidelines: * Model the problem as a Directed Acyclic Graph (DAG) and use topological sorting to detect cycles. * You can use Depth-First Search (DFS) or Kahn\'s Algorithm (BFS) to identify if there\'s a cycle in the graph. * Be cautious of edge cases such as no prerequisites or all courses forming a single chain. * Your solution should efficiently handle the upper constraints in both time and space complexity.","solution":"def can_finish_courses(num_courses: int, prerequisites: list[tuple[int, int]]) -> bool: from collections import defaultdict, deque # Create a graph from the prerequisites list graph = defaultdict(list) indegree = [0] * num_courses for course, prereq in prerequisites: graph[prereq].append(course) indegree[course] += 1 # Use Kahn\'s Algorithm (BFS) to perform topological sort queue = deque([i for i in range(num_courses) if indegree[i] == 0]) visited_courses = 0 while queue: current_course = queue.popleft() visited_courses += 1 for neighbor in graph[current_course]: indegree[neighbor] -= 1 if indegree[neighbor] == 0: queue.append(neighbor) # If we\'ve visited all the courses, then it\'s possible to finish all courses return visited_courses == num_courses"},{"question":"# Problem Statement You are given an integer array and a window size k. Implement the sliding window maximum algorithm to find the maximum value in each sliding window of size k that moves from the start of the array to the end. # Input Format * **arr**: A list of integers (1 ≤ len(arr) ≤ 10^5, -10^4 ≤ arr[i] ≤ 10^4) * **k**: An integer representing the window size (1 ≤ k ≤ len(arr)) # Output Format * Return a list of integers where each integer represents the maximum value of the corresponding sliding window. # Example ```python >>> sliding_window_max([1, 3, -1, -3, 5, 3, 6, 7], 3) [3, 3, 5, 5, 6, 7] >>> sliding_window_max([4, 2, 12, 11, -5], 2) [4, 12, 12, 11] >>> sliding_window_max([9, 11], 2) [11] >>> sliding_window_max([1, 3, 1, 2, 0, 5], 3) [3, 3, 2, 5] >>> sliding_window_max([7, 2, 4], 1) [7, 2, 4] ``` # Constraints * The given array can contain both negative and positive integers. * The sliding window moves only one index at a time. * The solution should have an expected time complexity of O(n). # Performance Requirements Your implementation should be efficient enough to handle large arrays up to length 10^5. # Hints 1. Utilize a deque data structure to keep track of the indices of maximum elements for the current window. 2. Ensure the deque maintains the window size constraint and always contains potential max elements. 3. Remove elements not within the current window and ensure the maximum element is always at the front of the deque.","solution":"from collections import deque def sliding_window_max(arr, k): Finds the maximum value in each sliding window of size k that moves from the start of the array to the end. Args: arr: List of integers. k: Integer representing the window size. Returns: List of integers representing the maximum value of each sliding window. if k == 1: return arr n = len(arr) deq = deque() # Stores indices of potential max elements in the current window result = [] for i in range(n): # Remove elements not within the current window if deq and deq[0] < i - k + 1: deq.popleft() # Remove elements that are smaller than the currently being added element while deq and arr[deq[-1]] < arr[i]: deq.pop() # Add the current element\'s index to the deque deq.append(i) # Add the maximum element (front of the deque) to the result list once the first window is reached if i >= k - 1: result.append(arr[deq[0]]) return result"},{"question":"# Context Optimizing data storage and retrieval is a fundamental challenge in computer science, particularly when dealing with large datasets. Be familiar with algorithms for efficient data manipulation like sorting, searching, and updating collections. # Problem Statement Given a list of integers, write a function `solution` that returns the `k`th smallest number from the list. Your implementation should be efficient enough to handle large lists and multiple queries. # Function Signature ```python def solution(arr: list, k: int) -> int: Returns the k-th smallest number in the list. :param arr: A list of integers from which to find the k-th smallest element. :param k: An integer representing the 1-based position of the desired smallest element. :return: The k-th smallest integer in the list. ``` # Input * `arr` (list): A list of integers where the length of the list can be in the order of (10^5). * `k` (int): A positive integer representing the 1-based position in the sorted order of the desired smallest element. # Output * An integer which is the `k`th smallest element in the list. # Constraints * The `arr` list will have at least one element and at most (10^5) elements. * Each integer in `arr` will be in the range [-(10^9), (10^9)]. * The function should raise a `ValueError` if `k` is not a valid index (i.e., not between 1 and the length of the list, inclusive). # Examples ```python >>> solution([7, 10, 4, 3, 20, 15], 3) 7 >>> solution([7, 10, 4, 3, 20, 15], 4) 10 >>> solution([7, 10, 4, 3, 20, 15], 0) Traceback (most recent call last): ... ValueError: Invalid k value. >>> solution([1, 2, 3, 4, 5], 5.5) Traceback (most recent call last): ... ValueError: Invalid k value. >>> solution([1, 2, 3, 4, 5], 6) Traceback (most recent call last): ... ValueError: Invalid k value. ``` # Note * Consider leveraging efficient selection algorithms like Quickselect for an optimized solution. * Ensure that the function handles invalid input for `k` values gracefully.","solution":"def solution(arr: list, k: int) -> int: Returns the k-th smallest number in the list. :param arr: A list of integers from which to find the k-th smallest element. :param k: An integer representing the 1-based position of the desired smallest element. :return: The k-th smallest integer in the list. if not (1 <= k <= len(arr)): raise ValueError(\\"Invalid k value.\\") return quickselect(arr, 0, len(arr) - 1, k - 1) def quickselect(arr, low, high, k): if low == high: return arr[low] pivot_index = partition(arr, low, high) if k == pivot_index: return arr[k] elif k < pivot_index: return quickselect(arr, low, pivot_index - 1, k) else: return quickselect(arr, pivot_index + 1, high, k) def partition(arr, low, high): pivot = arr[high] pivot_index = low for j in range(low, high): if arr[j] <= pivot: arr[pivot_index], arr[j] = arr[j], arr[pivot_index] pivot_index += 1 arr[pivot_index], arr[high] = arr[high], arr[pivot_index] return pivot_index"},{"question":"# Question: Validate BST and Count Nodes Background: You are provided with a binary tree that could potentially be a Binary Search Tree (BST). A BST is a binary tree in which for each node, the left subtree of that node contains only nodes with values less than the node’s key, and the right subtree contains only nodes with values more significant than the node’s key. Your task is to validate if the tree is a BST and count the number of nodes within the tree. Problem Statement: Write a function `validate_bst_and_count_nodes(root: Optional[TreeNode]) -> Tuple[bool, int]` that performs the following: 1. **Validation**: Check if the given binary tree is a valid BST. 2. **Counting**: Count and return the total number of nodes in the tree. Input: * `root`: The root node of a binary tree. Output: * Return a tuple `(is_bst, node_count)`, where: - `is_bst` is a boolean that indicates whether the tree is a BST. - `node_count` is an integer representing the number of nodes in the tree. Example: ```python Input: root = TreeNode(2, TreeNode(1), TreeNode(3)) Output: (True, 3) ``` ```python Input: root = TreeNode(5, TreeNode(1), TreeNode(4, TreeNode(3), TreeNode(6))) Output: (False, 5) ``` Explanation: 1. For the first input, the tree is: ```plaintext 2 / 1 3 ``` This tree is a valid BST and has 3 nodes. 2. For the second input, the tree is: ```plaintext 5 / 1 4 / 3 6 ``` This tree is not a valid BST because node 4 is on the right side of node 5 but contains 3, which is less than 5. The tree has 5 nodes in total. Constraints: - The function should handle edge cases such as an empty tree (root is None). - Consider the constraints of typical binary trees, keeping the depth reasonably small to avoid stack overflow in recursion. --- Implement the function `validate_bst_and_count_nodes(root: Optional[TreeNode]) -> Tuple[bool, int]` in Python, ensuring that it correctly validates the BST property and accurately counts the number of nodes. Provide an analysis of its time and space complexity.","solution":"from typing import Optional, Tuple class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = right def validate_bst_and_count_nodes(root: Optional[TreeNode]) -> Tuple[bool, int]: def is_valid_bst(node, low=float(\'-inf\'), high=float(\'inf\')): if not node: return True if not (low < node.val < high): return False return (is_valid_bst(node.left, low, node.val) and is_valid_bst(node.right, node.val, high)) def count_nodes(node): if not node: return 0 return 1 + count_nodes(node.left) + count_nodes(node.right) if not root: return (True, 0) is_bst = is_valid_bst(root) node_count = count_nodes(root) return (is_bst, node_count)"},{"question":"# Problem Statement: You are required to implement a `minStack` data structure that supports the following operations in constant time: * `push(x)`: Push the element x onto the stack. * `pop()`: Removes the element on top of the stack. * `top()`: Get the top element. * `getMin()`: Retrieve the minimum element in the stack. # Requirements: 1. Implement the `MinStack` class with the following methods: ```python class MinStack: def __init__(self): # Initialize the MinStack with required properties. def push(self, x: int) -> None: # Push the element x onto the stack. def pop(self) -> None: # Remove the element on top of the stack. def top(self) -> int: # Get the top element. def getMin(self) -> int: # Retrieve the minimum element in the stack. ``` 2. The `MinStack` class should be able to perform the operations mentioned in constant time. # Example: ```python # Initialize the MinStack. minStack = MinStack() minStack.push(-2) # Stack: [-2] minStack.push(0) # Stack: [-2, 0] minStack.push(-3) # Stack: [-2, 0, -3] print(minStack.getMin()) # returns -3 (minimum element is -3) minStack.pop() # removes -3 (Stack: [-2, 0]) print(minStack.top()) # returns 0 (top element is 0) print(minStack.getMin()) # returns -2 (minimum element is -2) ``` # Constraints: * Methods `pop()`, `top()`, and `getMin()` should not raise any exceptions if called on an appropriate state of the stack. * The elements pushed onto the stack are within the range of a 32-bit signed integer.","solution":"class MinStack: def __init__(self): self.stack = [] self.min_stack = [] def push(self, x: int) -> None: self.stack.append(x) if not self.min_stack or x <= self.min_stack[-1]: self.min_stack.append(x) def pop(self) -> None: if self.stack: top_element = self.stack.pop() if top_element == self.min_stack[-1]: self.min_stack.pop() def top(self) -> int: if self.stack: return self.stack[-1] return None def getMin(self) -> int: if self.min_stack: return self.min_stack[-1] return None"},{"question":"# Coding Assessment Question You are tasked with writing a function to simulate a parking lot ticketing system. The parking lot has a finite number of parking spots, and each spot can be either occupied or available. Your function should manage the entry and exit of vehicles based on the following requirements: 1. **Input**: * An integer `total_spots` representing the total number of parking spots. * A list of tuples where each tuple contains two elements: * An action (`str`) which can be either `\\"enter\\"` or `\\"exit\\"`. * A vehicle license number (`str`) uniquely identifying the vehicle. 2. **Behavior**: * If the action is `\\"enter\\"`: * Check if there are available spots. * If a spot is available, assign it to the vehicle and return a success message. * If no spots are available, return a failure message indicating the lot is full. * If the action is `\\"exit\\"`: * If the vehicle is currently in the lot, vacate its spot and return a success message. * If the vehicle is not found in the lot, return a failure message indicating the vehicle was not parked. 3. **Output**: * Return a list of results, corresponding to the list of actions, with success or failure messages. 4. **Constraints**: * The `total_spots` is a positive integer (1 ≤ total_spots ≤ 1000). * The list of actions may contain up to 10^4 elements. * All license numbers are unique and consist of alphanumeric characters. Here is an example function signature to get you started: ```python def manage_parking_lot(total_spots: int, actions: list[tuple[str, str]]) -> list[str]: pass ``` **Example Input**: ```python total_spots = 2 actions = [(\\"enter\\", \\"ABC123\\"), (\\"enter\\", \\"XYZ987\\"), (\\"enter\\", \\"DEF456\\"), (\\"exit\\", \\"ABC123\\"), (\\"enter\\", \\"DEF456\\")] ``` **Example Output**: ```python [\\"Success: Vehicle ABC123 parked.\\", \\"Success: Vehicle XYZ987 parked.\\", \\"Failure: Parking lot is full.\\", \\"Success: Vehicle ABC123 exited.\\", \\"Success: Vehicle DEF456 parked.\\"] ``` **Performance Requirements**: - The function should have a time complexity of O(m) where m is the number of actions. - The space complexity should be O(n) where n is the total number of spots available for additional space used. Write the `manage_parking_lot` function according to the stated requirements.","solution":"def manage_parking_lot(total_spots: int, actions: list[tuple[str, str]]) -> list[str]: parking_lot = set() results = [] for action, vehicle in actions: if action == \\"enter\\": if len(parking_lot) < total_spots: parking_lot.add(vehicle) results.append(f\\"Success: Vehicle {vehicle} parked.\\") else: results.append(f\\"Failure: Parking lot is full.\\") elif action == \\"exit\\": if vehicle in parking_lot: parking_lot.remove(vehicle) results.append(f\\"Success: Vehicle {vehicle} exited.\\") else: results.append(f\\"Failure: Vehicle {vehicle} not found.\\") else: results.append(f\\"Failure: Invalid action {action}.\\") return results"},{"question":"# Objective Your task is to write a function that checks whether a given string contains all the alphabets at least once (case insensitive). # Problem Description Write a function `check_pangram(s: str) -> bool` that: 1. Accepts a single string `s`. 2. Returns `True` if the string is a pangram (contains every letter of the alphabet at least once), and `False` otherwise. # Constraints * The string `s` can have a length between 1 and 1000 inclusive. # Function Signature ```python def check_pangram(s: str) -> bool: pass ``` # Example ```python # Example 1 s = \\"The quick brown fox jumps over the lazy dog\\" # The string is a pangram because it contains every letter of the English alphabet. assert check_pangram(s) == True # Example 2 s = \\"Hello World\\" # The string is not a pangram because it does not contain every letter of the English alphabet. assert check_pangram(s) == False ``` # Scenario Context Imagine you are developing a text analysis tool that needs to validate if provided strings have complete sets of alphabet letters for language processing tasks. You need to write a function that efficiently verifies this property, aiding in the detection of comprehensive texts or documents.","solution":"def check_pangram(s: str) -> bool: Checks if a given string is a pangram. A pangram is a sentence that contains all the letters of the English alphabet at least once. Parameters: s (str): Input string to check Returns: bool: True if the string is a pangram, False otherwise alphabet_set = set(\\"abcdefghijklmnopqrstuvwxyz\\") return alphabet_set.issubset(set(s.lower()))"},{"question":"# Question: Convert a List to a Zigzag Matrix Context You are given a list of integers called `nums`. Your task is to convert this list into a zigzag matrix with `n` rows, where `n` is a positive integer no greater than the length of `nums`. The zigzag pattern is formed by filling the matrix in the following manner: - the first row is filled left to right, - the second row is filled right to left, - the third row is filled left to right, and so on. If there are not enough elements to fill the matrix, you should fill the remaining places with -1. Function Signature ```python def list_to_zigzag_matrix(nums: List[int], n: int) -> List[List[int]]: ``` Input * A list `nums` (1 ≤ len(nums) ≤ 10^5) containing integers. * An integer `n` (1 ≤ n ≤ len(nums)) representing the number of rows. Output * A list of lists representing the zigzag matrix. Constraints * The length of `nums` list will always be non-zero. * The integer `n` will always be positive and not be greater than the length of `nums`. Example ```python >>> list_to_zigzag_matrix([1, 2, 3, 4, 5, 6, 7, 8, 9], 3) [[1, 2, 3], [6, 5, 4], [7, 8, 9]] >>> list_to_zigzag_matrix([1, 2, 3, 4], 2) [[1, 2], [4, 3]] >>> list_to_zigzag_matrix([1, 2, 3, 4, 5], 3) [[1, 2], [4, 3], [5, -1]] >>> list_to_zigzag_matrix([1, 2], 1) [[1, 2]] ``` Analysis Write a function to accomplish the task as specified. Your implementation will be evaluated for correctness and efficiency.","solution":"from typing import List def list_to_zigzag_matrix(nums: List[int], n: int) -> List[List[int]]: # Determine the number of columns needed num_cols = (len(nums) + n - 1) // n # Initialize the result matrix with -1 matrix = [[-1] * num_cols for _ in range(n)] # Populate the matrix in zigzag manner row, col = 0, 0 forward = True # Indicates whether to fill left to right or right to left for num in nums: if forward: # Fill left to right matrix[row][col] = num col += 1 else: # Fill right to left matrix[row][num_cols - 1 - col] = num col += 1 # Move to the next row if we reach the end of a row if col == num_cols: row += 1 col = 0 forward = not forward # Flip the direction return matrix"},{"question":"# Matrix Transpose You are provided with a class, `Matrix`, that represents a 2D matrix and supports various operations on it. Your task is to implement one additional method for this class: `transpose`. This method will generate the transpose of the matrix (i.e., flip the matrix over its diagonal). Function Signature ```python def transpose(self) -> \'Matrix\': ``` Input - No explicit input; this method will use the matrix instance it belongs to. Output - Returns a new `Matrix` object which is the transpose of the original matrix. Constraints - You can assume that the matrix contains integers. - The number of rows and columns of the matrix are both non-negative integers. - The matrix can be non-square. Example ```python m = Matrix([[1, 2, 3], [4, 5, 6]]) # m represents the matrix: # 1 2 3 # 4 5 6 transposed_m = m.transpose() # transposed_m represents the matrix: # 1 4 # 2 5 # 3 6 assert transposed_m.data == [[1, 4], [2, 5], [3, 6]] ``` Your implementation should handle edge cases like empty matrices appropriately.","solution":"class Matrix: def __init__(self, data): self.data = data def transpose(self) -> \'Matrix\': transposed_data = list(map(list, zip(*self.data))) return Matrix(transposed_data)"},{"question":"# Coding Assessment Question **Context**: You\'re part of a team developing a recommendation system for an online bookstore, `BookZone.com`. The system should suggest books to users based on their past purchases. Your task is to create a function that analyzes purchase data and returns recommendations of books that other users, who bought similar books, also purchased. # Task Write a function `recommend_books` that recommends a list of books based on a given user\'s purchase history. The function should analyze a provided dataset of user purchases and suggest books that other users, with overlapping purchase histories, have bought but the given user has not. # Function Signature ```python def recommend_books(user_id: int, purchases: List[Tuple[int, int]]) -> List[int]: ``` # Input - `user_id` (int): An integer representing the ID of the user for whom recommendations are to be made. - `purchases` (List[Tuple[int, int]]): A list of tuples where each tuple contains two integers `(user_id, book_id)` representing a purchase. # Output - Returns a list of integers, each representing the ID of a recommended book. # Constraints - `user_id` will be a positive integer representing an existing user in the purchase dataset. - `purchases` will have at least one purchase and will be a list of tuples, each containing two integers `(user_id, book_id)`. # Performance Requirements - The function should efficiently process and analyze large datasets. - Ensure the function scales well with an increasing number of users and books. # Example ```python user_purchases = [ (1, 101), (1, 102), (1, 103), (2, 101), (2, 104), (3, 102), (3, 103), (4, 105) ] print(recommend_books(1, user_purchases)) ``` Expected Output: ``` [104] ``` **Explanation**: User 1 has bought books 101, 102, and 103. Users 2 and 3 have similar purchase histories and have also bought books that user 1 hasn\'t: user 2 bought book 104, and user 3 bought book 104 as well. Book 104 is recommended because it was bought by users with similar tastes, but not yet by user 1. # Additional Information 1. Ensure that the recommendations do not include books that the user has already purchased. 2. The recommendation list should be unique and not contain duplicate book IDs. If there are multiple books to recommend, order them by the frequency of purchase by similar users, with the most frequently purchased books appearing first.","solution":"from typing import List, Tuple from collections import defaultdict, Counter def recommend_books(user_id: int, purchases: List[Tuple[int, int]]) -> List[int]: user_books = defaultdict(set) # Step 1: Build user-book purchase history for u_id, b_id in purchases: user_books[u_id].add(b_id) # Step 2: Extract the target user\'s purchased books target_books = user_books[user_id] # Step 3: Find books purchased by other users who have similar books with the target user recommended_books = Counter() for u_id, books in user_books.items(): if u_id != user_id: common_books = target_books.intersection(books) if common_books: for book in books - target_books: recommended_books[book] += 1 # Step 4: Sort the recommended books by their frequency in descending order recommended_books = [book for book, count in recommended_books.most_common()] return recommended_books"},{"question":"# Coding Assessment Question **Title**: Implement Dynamic Fibonacci Sequence with Memoization **Context**: You are responsible for optimizing a program that computes Fibonacci numbers. The Fibonacci sequence is defined as follows: - F(0) = 0 - F(1) = 1 - F(n) = F(n-1) + F(n-2) for n > 1 Implement an efficient approach to compute the nth Fibonacci number using dynamic programming with memoization to avoid redundant computations. **Task**: Write a function `fibonacci_memo` that computes the nth Fibonacci number. Use a dictionary to store the already computed Fibonacci numbers. **Input**: - `n`: an integer representing the position in the Fibonacci sequence (0 ≤ n ≤ 1000). **Output**: - An integer representing the nth Fibonacci number. **Constraints**: - 0 ≤ n ≤ 1000 **Example**: ```python print(fibonacci_memo(0)) # Expected output: 0 print(fibonacci_memo(1)) # Expected output: 1 print(fibonacci_memo(10)) # Expected output: 55 print(fibonacci_memo(50)) # Expected output: 12586269025 ``` **Notes**: - Utilize a dictionary to store previously computed Fibonacci values to achieve efficient computation. - Avoid recursion depth issues by implementing an iterative approach if necessary, or handle large recursive depth properly.","solution":"def fibonacci_memo(n, memo={}): Compute the nth Fibonacci number using memoization. if n in memo: return memo[n] if n == 0: memo[n] = 0 elif n == 1: memo[n] = 1 else: memo[n] = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo) return memo[n]"},{"question":"# Problem Description: You are tasked with designing an algorithm to merge two sorted linked lists into a single sorted linked list. The linked lists may have overlapping integer values. Your goal is to implement a function that efficiently merges these two lists while maintaining their sorted order. # Input: * Two linked lists `l1` and `l2`, where each node contains an integer value and a reference to the next node, or `None` if it is the end of the list. # Output: * A single linked list containing all elements from both `l1` and `l2`, sorted in ascending order. # Function Signature: ```python class ListNode: def __init__(self, x): self.val = x self.next = None def merge_two_lists(l1: ListNode, l2: ListNode) -> ListNode: pass ``` # Constraints: * Both `l1` and `l2` are sorted in non-decreasing order. * The number of nodes in both linked lists is in the range `[0, 50]`. * `-100 <= Node.val <= 100` # Performance Requirements: Your solution should merge the two lists in linear time, taking advantage of the sorted order of the input lists. # Edge Cases: * One or both input lists are empty, returning the non-empty list or an empty list if both are empty. * Input lists contain duplicate values. # Example: ```python # Example 1: # Input: l1 = [1,2,4], l2 = [1,3,4] # Output: [1,1,2,3,4,4] # Example 2: # Input: l1 = [], l2 = [] # Output: [] # Example 3: # Input: l1 = [], l2 = [0] # Output: [0] ``` **Notes**: 1. The input linked lists are already sorted, so your algorithm should take advantage of this property to efficiently combine them. 2. Handle edge cases where either or both of the input linked lists are empty by directly returning the non-empty list or a null list if both are empty. 3. You may assume that the ListNode class and its constructor are provided, which initializes a node with a value `x` and sets the `next` to `None`. Keep your implementation clean and efficient, ensuring that it adheres to the constraints and performance requirements specified.","solution":"class ListNode: def __init__(self, x): self.val = x self.next = None def merge_two_lists(l1: ListNode, l2: ListNode) -> ListNode: # Dummy node to provide a uniform starting point dummy = ListNode(0) current = dummy # Traverse both lists and link nodes in sorted order while l1 and l2: if l1.val <= l2.val: current.next = l1 l1 = l1.next else: current.next = l2 l2 = l2.next current = current.next # Attach the non-null list if there are still elements left if l1: current.next = l1 else: current.next = l2 return dummy.next"},{"question":"# Problem Scenario As a developer working on a gaming application, you have been tasked with implementing the undo functionality for the movements of a character. The movements include four directions: up, down, left, and right. The system should allow tracking of the character\'s movements and the ability to undo the last movement made by the character. # Task: Implement a class `CharacterMovement` that supports recording movements, undoing the last movement, and retrieving the current position of the character. # Key Requirements: 1. Record movements in four directions: up, down, left, and right. 2. Undo the last recorded movement. 3. Retrieve the current position of the character. # Specifications: 1. **Class**: `CharacterMovement` 2. **Methods**: * `__init__(self)`: Initializes the character\'s position at the origin `(0, 0)`. * `move(self, direction: str) -> None`: Records a move in the specified direction. * `undo(self) -> None`: Undoes the last recorded movement. * `get_position(self) -> tuple[int, int]`: Returns the current position of the character as a tuple `(x, y)`. 3. **Input/Output**: * The `move` method takes a string `direction` which can be one of `\'up\'`, `\'down\'`, `\'left\'`, or `\'right\'`. Each move changes the character\'s position by one unit in the specified direction. * The `undo` method reverses the last movement. If there are no movements to undo, it does nothing. * The `get_position` method returns the tuple `(x, y)` representing the current position of the character. # Constraints: * The `direction` input to the `move` method will always be one of the valid directions. * Assume the character can move infinitely in any direction. # Example: ```python # Example Usage character = CharacterMovement() character.move(\'up\') character.move(\'up\') character.move(\'left\') print(character.get_position()) # Output: (-1, 2) character.undo() print(character.get_position()) # Output: (0, 2) character.undo() character.undo() character.undo() # No more moves to undo print(character.get_position()) # Output: (0, 0) ``` # Notes: * Remember to handle the edge case where multiple undo operations may be called consecutively. * Ensure that the internal state is correctly updated to reflect the character\'s movements and their reversals effectively.","solution":"class CharacterMovement: def __init__(self): self.position = [0, 0] # Starting at origin (0,0) self.history = [] # List to track movements def move(self, direction: str) -> None: if direction == \'up\': self.position[1] += 1 self.history.append((\'up\', -1)) elif direction == \'down\': self.position[1] -= 1 self.history.append((\'down\', 1)) elif direction == \'left\': self.position[0] -= 1 self.history.append((\'left\', 1)) elif direction == \'right\': self.position[0] += 1 self.history.append((\'right\', -1)) def undo(self) -> None: if self.history: last_move, undo_amount = self.history.pop() if last_move == \'up\' or last_move == \'down\': self.position[1] += undo_amount else: self.position[0] += undo_amount def get_position(self) -> tuple[int, int]: return tuple(self.position)"},{"question":"# Minimum Spanning Tree with Unique Paths You are given an undirected graph represented as an adjacency list where each edge has a positive integer weight. Implement the following functionalities: 1. Add edges to the graph. 2. Compute the Minimum Spanning Tree (MST) and return the unique paths for each node from a given start node. # Function Specifications Your task is to implement a class `GraphMST` which contains the following methods: - `__init__(self, n: int)`: Initializes the graph with `n` vertices (0 to n-1). - `add_edge(self, from_vertex: int, to_vertex: int, weight: int)`: Adds an undirected edge between `from_vertex` and `to_vertex` with the given weight. - `get_mst_paths(self, start_vertex: int) -> List[Tuple[int, List[int]]]`: Computes the MST of the graph and returns a list of tuples where each tuple contains a vertex and the unique path from `start_vertex` to that vertex in the MST. If there is no path to a vertex, return an empty list for that vertex. # Constraints * The weight of each edge will always be a positive integer. * The indices of the vertices will be within the range [0, n-1] where n is the number of vertices. * The graph will have at least 2 vertices and less than 10000 vertices. * There will not be any duplicate edges. * An edge between `u` and `v` implies an edge between `v` and `u`. # Example ```python # Creating a graph with 6 vertices g = GraphMST(6) # Adding edges g.add_edge(0, 1, 4) g.add_edge(0, 2, 3) g.add_edge(1, 2, 1) g.add_edge(1, 3, 2) g.add_edge(2, 3, 4) g.add_edge(3, 4, 2) g.add_edge(4, 5, 6) # Computing MST paths from vertex 0 assert g.get_mst_paths(0) == [ (0, [0]), (1, [0, 2, 1]), (2, [0, 2]), (3, [0, 2, 1, 3]), (4, [0, 2, 1, 3, 4]), (5, [0, 2, 1, 3, 4, 5]) ] # Computing MST paths from vertex 1 assert g.get_mst_paths(1) == [ (0, [1, 2, 0]), (1, [1]), (2, [1, 2]), (3, [1, 3]), (4, [1, 3, 4]), (5, [1, 3, 4, 5]) ] ``` # Notes Make sure the implementation follows the expected complexities and handles edge cases effectively. You can assume that the graph is connected, so an MST will always exist.","solution":"import heapq from typing import List, Tuple class GraphMST: def __init__(self, n: int): self.n = n self.graph = [[] for _ in range(n)] def add_edge(self, from_vertex: int, to_vertex: int, weight: int): self.graph[from_vertex].append((weight, to_vertex)) self.graph[to_vertex].append((weight, from_vertex)) def get_mst_paths(self, start_vertex: int) -> List[Tuple[int, List[int]]]: parent = [-1] * self.n key = [float(\'inf\')] * self.n in_mst = [False] * self.n key[start_vertex] = 0 pq = [(0, start_vertex)] while pq: weight, u = heapq.heappop(pq) if in_mst[u]: continue in_mst[u] = True for w, v in self.graph[u]: if not in_mst[v] and key[v] > w: key[v] = w parent[v] = u heapq.heappush(pq, (w, v)) # Reconstruct paths from the parent array def build_path(vertex): path = [] while vertex != -1: path.append(vertex) vertex = parent[vertex] return path[::-1] return [(i, build_path(i)) for i in range(self.n)]"},{"question":"# Binary Search Tree (BST) Balancing Context You are working with a Binary Search Tree (BST) data structure that supports basic operations such as insertion, search, and deletion. Currently, the tree can become unbalanced after a series of operations, leading to degraded performance. Your task is to implement a function to rebalance the BST to ensure its height is minimized and operations remain efficient. Objective Enhance the existing `BinarySearchTree` class by implementing a `rebalance` method that restructures the tree to be balanced: 1. Implement a method to collect all elements of the BST into a sorted list. 2. Implement a method to convert a sorted list to a balanced BST. 3. Modify the existing `BinarySearchTree` class to include the `rebalance` method, which combines the previous methods to transform the tree into a balanced BST. Requirements - **Input/Output Specifications**: * The `BinarySearchTree` class should expose an `insert`, `find`, `delete`, and `rebalance` method. * The `insert` method adds an element to the BST. * The `find` method searches for an element in the BST and returns a boolean indicating its presence. * The `delete` method removes an element from the BST. * The `rebalance` method restructures the BST to be balanced. - **Constraints**: * Ensure the BST properties are maintained after rebalancing. * The `rebalance` method should run in O(n) time complexity. * Properly handle cases where the BST is empty or contains a single node. * Emphasize memory efficiency and correctness. Implementation Reimplement the `BinarySearchTree` class as outlined and make sure the `rebalance` method is correctly integrated. Here is a function definition for reference: ```python class TreeNode: def __init__(self, value: int) -> None: ... class BinarySearchTree: def __init__(self) -> None: ... def insert(self, value: int) -> None: ... def find(self, value: int) -> bool: ... def delete(self, value: int) -> None: ... def rebalance(self) -> None: ... def _in_order_traversal(self, node: Optional[TreeNode], result: List[int]) -> None: ... def _sorted_list_to_bst(self, sorted_list: List[int]) -> Optional[TreeNode]: ... ``` Example Usage: ```python bst = BinarySearchTree() bst.insert(10) bst.insert(20) bst.insert(5) print(bst.find(20)) # True bst.delete(20) print(bst.find(20)) # False bst.insert(15) bst.insert(25) bst.insert(1) bst.rebalance() # The tree is now rebalanced ``` Ensure to run comprehensive tests to validate your implementation.","solution":"class TreeNode: def __init__(self, value: int) -> None: self.value = value self.left = None self.right = None class BinarySearchTree: def __init__(self) -> None: self.root = None def insert(self, value: int) -> None: if not self.root: self.root = TreeNode(value) return self._insert_recursive(self.root, value) def _insert_recursive(self, node: TreeNode, value: int) -> None: if value < node.value: if node.left: self._insert_recursive(node.left, value) else: node.left = TreeNode(value) else: if node.right: self._insert_recursive(node.right, value) else: node.right = TreeNode(value) def find(self, value: int) -> bool: return self._find_recursive(self.root, value) def _find_recursive(self, node: TreeNode, value: int) -> bool: if not node: return False if node.value == value: return True elif value < node.value: return self._find_recursive(node.left, value) else: return self._find_recursive(node.right, value) def delete(self, value: int) -> None: self.root = self._delete_recursive(self.root, value) def _delete_recursive(self, node: TreeNode, value: int) -> None: if not node: return None if value < node.value: node.left = self._delete_recursive(node.left, value) elif value > node.value: node.right = self._delete_recursive(node.right, value) else: if not node.left and not node.right: return None if not node.left: return node.right if not node.right: return node.left temp = self._min_value_node(node.right) node.value = temp.value node.right = self._delete_recursive(node.right, temp.value) return node def _min_value_node(self, node: TreeNode) -> TreeNode: current = node while current.left: current = current.left return current def rebalance(self) -> None: elements = [] self._in_order_traversal(self.root, elements) self.root = self._sorted_list_to_bst(elements) def _in_order_traversal(self, node: TreeNode, result: list) -> None: if node: self._in_order_traversal(node.left, result) result.append(node.value) self._in_order_traversal(node.right, result) def _sorted_list_to_bst(self, sorted_list: list) -> TreeNode: if not sorted_list: return None mid = len(sorted_list) // 2 node = TreeNode(sorted_list[mid]) node.left = self._sorted_list_to_bst(sorted_list[:mid]) node.right = self._sorted_list_to_bst(sorted_list[mid + 1:]) return node"},{"question":"# Problem Statement Consider that you have been hired to optimize warehouse logistics. Your task is to simulate a sequence of moves required to shift a stack of different-sized packages, ensuring the largest ones end up on top, but with some constraints based on available loaders (robots) each having limited capacity. You need to programmatically visualize and examine these moves in a structured sequence. You will implement the function `simulate_package_moves(packages: List[int], robot_capacity: int) -> List[str]`. This function will simulate moving a stack of packages from one location to another using robots with a given weight capacity. Each move will be recorded in a sequence list. # Function Signature ```python def simulate_package_moves(packages: List[int], robot_capacity: int) -> List[str]: ``` # Input * `packages` (List[int]): A list of integers representing the weights of the packages in the initial stack (bottom to top). * `robot_capacity` (int): The maximum weight a robot can carry. # Output * Return a list of strings each describing a move in the format `f\\"moving package of weight {package} with robot capacity {capacity}\\"`. # Constraints * `1 <= len(packages) <= 10` * `1 <= packages[i] <= 100` * `10 <= robot_capacity <= 100` # Examples ```python simulate_package_moves([40, 30, 20, 10], 50) # Output: [\'moving package of weight 10 with robot capacity 50\', # \'moving package of weight 20 with robot capacity 50\', # \'moving package of weight 30 with robot capacity 50\', # \'moving package of weight 40 with robot capacity 50\'] simulate_package_moves([15, 25, 5, 35], 30) # Output: [\'moving package of weight 5 with robot capacity 30\', # \'moving package of weight 15 with robot capacity 30\', # \'moving package of weight 25 with robot capacity 30\', # \'moving package of weight 35 with robot capacity 30\'] ``` # Guidelines 1. The function must be able to handle the permutation of packages within the constraints. 2. No print statements should be used in your function. 3. You can define additional helper functions if necessary. This question is designed to test your ability to simulate complex processes algorithmically and handle constraints on computational capacity effectively.","solution":"def simulate_package_moves(packages, robot_capacity): Simulates moving a stack of packages using robots with a defined capacity. Parameters: packages (List[int]): List of package weights. robot_capacity (int): Maximum weight a robot can carry. Returns: List[str]: List of moves in the format \'moving package of weight {package} with robot capacity {capacity}\'. moves = [] for weight in sorted(packages): if weight <= robot_capacity: moves.append(f\\"moving package of weight {weight} with robot capacity {robot_capacity}\\") return moves"},{"question":"# Context: You are implementing a part of a system that deals with large datasets, and one of the functionalities involves searching for the nearest higher value in a given list. You need to create a function that, for each element in a list, finds the nearest higher value to the right. # Problem Statement: Write a function `nearest_higher_values(arr: List[int]) -> List[int]` that takes a list of integers as input and returns a new list where each element corresponds to the nearest higher value to the right of the respective element in the input list. If there is no higher value to the right, the output should contain `-1` for that position. Input and Output Formats: * **Input**: A single argument `arr` which is a list of integers. * **Output**: A list of integers representing the nearest higher value to the right for each element in the input list. If there is no higher value to the right, the element in the output list should be `-1`. Constraints and Limitations: * The input list can be empty or contain up to 100,000 elements. * The integer values in the list can be positive or negative. Example: ```python >>> nearest_higher_values([2, 1, 2, 3, 4]) [3, 2, 3, 4, -1] >>> nearest_higher_values([4, 3, 2, 1]) [-1, -1, -1, -1] >>> nearest_higher_values([1, 3, 2, 4]) [3, 4, 4, -1] >>> nearest_higher_values([5, 5, 5]) [-1, -1, -1] >>> nearest_higher_values([]) [] ``` # Performance Requirements: * The solution should ideally run in O(n) time complexity where n is the number of elements in the input list.","solution":"from typing import List def nearest_higher_values(arr: List[int]) -> List[int]: For each element in the list, finds the nearest higher value to the right. If there is no higher value to the right, returns -1 for that position. result = [-1] * len(arr) stack = [] for i in range(len(arr)): while stack and arr[stack[-1]] < arr[i]: index = stack.pop() result[index] = arr[i] stack.append(i) return result"},{"question":"# Scenario: You are developing an application for a logistics company to optimize the distribution of packages. One of the key features required is to evaluate the efficiency of delivery routes. Your task is to implement an algorithm that estimates the shortest delivery route between multiple delivery points in a city. # Question: Implement a function `calculate_shortest_route` that uses the Dijkstra\'s algorithm to find the shortest route between a list of delivery points in a city\'s road network. ```python from typing import Dict, List, Tuple def calculate_shortest_route(connections: Dict[str, List[Tuple[str, int]]], start: str, end: str) -> List[str]: Implement a shortest route calculator for delivery points in a city. Parameters: - connections: Dictionary where the key is a point (str) and the value is a list of tuples representing connected points and the distance (point, distance). - start: Starting delivery point (str). - end: Ending delivery point (str). Returns: - List of points (str) representing the shortest route from start to end. pass ``` # Requirements: - The function should implement Dijkstra\'s algorithm to find the shortest route. - Ensure to efficiently manage nodes and distances with appropriate data structures. - Return a list of points indicating the path from the start point to the end point. - Ensure high precision and efficiency when updating distances and paths. # Input and Output: - **Input**: - `connections`: A dictionary where keys are delivery points, and values are lists of tuples each consisting of a connected point and the distance to it, as a list of tuples [(point, distance)]. - `start`: A string representing the starting delivery point. - `end`: A string representing the ending delivery point. - **Output**: - A list of strings representing the shortest route from the starting point to the ending point. # Constraints: - Delivery points and distances are represented as strings and integers respectively. - The network can consist of numerous delivery points and connections (e.g., n ≤ 10000). - Guarantee that there are no negative distance cycles in the road network. You need to write helper functions to support Dijkstra\'s algorithm for distance updating and path management. Ensure that the solution handles large inputs efficiently by using appropriate data structures and algorithms.","solution":"import heapq from typing import Dict, List, Tuple def calculate_shortest_route(connections: Dict[str, List[Tuple[str, int]]], start: str, end: str) -> List[str]: Implement a shortest route calculator for delivery points in a city. Parameters: - connections: Dictionary where the key is a point (str) and the value is a list of tuples representing connected points and the distance (point, distance). - start: Starting delivery point (str). - end: Ending delivery point (str). Returns: - List of points (str) representing the shortest route from start to end. # Priority queue to manage the frontier nodes priority_queue = [(0, start)] # Dictionary to store the shortest distance from start to each node distances = {node: float(\'infinity\') for node in connections} distances[start] = 0 # Dictionary to store the shortest path tree previous_nodes = {node: None for node in connections} while priority_queue: current_distance, current_node = heapq.heappop(priority_queue) if current_node == end: break if current_distance > distances[current_node]: continue for neighbor, weight in connections.get(current_node, []): distance = current_distance + weight if distance < distances[neighbor]: distances[neighbor] = distance previous_nodes[neighbor] = current_node heapq.heappush(priority_queue, (distance, neighbor)) # Reconstruct the shortest path from end to start path = [] current_node = end while current_node is not None: path.append(current_node) current_node = previous_nodes[current_node] path.reverse() if path[0] == start: return path else: return []"},{"question":"# Coding Assessment Question: Context: Symmetric numbers, also known as palindromic numbers, are numbers that remain the same when their digits are reversed. This concept is interesting in various mathematical and practical applications, including computer science. Your task is to implement a function that identifies and lists all symmetric numbers within a given range. Problem Statement: Write a Python function that, given an integer `n`, returns a list of all symmetric numbers less than `n`. ```python def find_symmetric_numbers(n: int) -> list: Find all symmetric numbers less than \'n\'. Args: n (int): An upper bound for the search (non-inclusive). Returns: list: A list of integers that are symmetric numbers less than \'n\'. Examples: >>> find_symmetric_numbers(100) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 33, 44, 55, 66, 77, 88, 99] >>> find_symmetric_numbers(50) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 33, 44] >>> find_symmetric_numbers(10) [1, 2, 3, 4, 5, 6, 7, 8, 9] # Implement your code here... ``` Constraints: - `n` is a positive integer. Expected output: - The solution must return a list of integers that are symmetric numbers less than `n`. Example: For `n = 50`, the symmetric numbers less than 50 are `[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 33, 44]`. Evaluation Criteria: Your solution will be evaluated based on: 1. Correctness: The function should return an accurate list of symmetric numbers. 2. Efficiency: The function should handle large values of `n` efficiently. 3. Coding Style: Use clear and descriptive variable names and ensure the code is readable and well-documented.","solution":"def find_symmetric_numbers(n: int) -> list: Find all symmetric numbers less than \'n\'. Args: n (int): An upper bound for the search (non-inclusive). Returns: list: A list of integers that are symmetric numbers less than \'n\'. Examples: >>> find_symmetric_numbers(100) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 33, 44, 55, 66, 77, 88, 99] >>> find_symmetric_numbers(50) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 33, 44] >>> find_symmetric_numbers(10) [1, 2, 3, 4, 5, 6, 7, 8, 9] symmetric_numbers = [] for num in range(1, n): if str(num) == str(num)[::-1]: symmetric_numbers.append(num) return symmetric_numbers"},{"question":"# Question: String Combination Finder You are tasked with implementing a function that finds all unique combinations of characters from a string. The combinations should be generated in lexicographical order and should not have any duplicate entries even if the original string contains duplicate characters. Specifications: * The input string will consist of lowercase alphabets only. * The function should return a list of strings, where each string is a valid combination. * Ensure that the combination strings are sorted in lexicographic order. Input: * A `str` input representing the original string. Output: * A list of strings representing all unique combinations sorted in lexicographical order. Examples: ```python def find_combinations(s: str) -> List[str]: pass # Example Usage: print(find_combinations(\\"abc\\")) # Should output [\'\', \'a\', \'ab\', \'abc\', \'ac\', \'b\', \'bc\', \'c\'] print(find_combinations(\\"aab\\")) # Should output [\'\', \'a\', \'aa\', \'aab\', \'ab\', \'b\'] ``` # Additional Details: - The function should generate combinations of all lengths, starting from an empty string to the length of the input string. - Duplicates in the input string should not lead to duplicate combinations. This example question perfectly complements the existing set by challenging fundamental programming skills including string manipulation, backtracking or recursive combination generation, and sorting.","solution":"from typing import List from itertools import combinations def find_combinations(s: str) -> List[str]: Returns all unique combinations of characters from the string s in lexicographical order. # Sort input string to ensure combinations are generated in lexicographical order sorted_s = sorted(s) unique_combinations = set() # Generate all combinations of all lengths for i in range(len(s) + 1): for combo in combinations(sorted_s, i): unique_combinations.add(\'\'.join(combo)) # Convert set to list and sort to return lexicographical order combinations return sorted(unique_combinations)"},{"question":"# Coding Assessment Question **Scenario**: You are a software developer at a logistics company. Your company uses an automated system to manage a fleet of delivery vehicles. Your task is to write programs to optimize routes and calculate metrics such as total distance, average speed, and estimated time of arrival (ETA). To help with this effort, you need to implement three functions: `total_distance`, `average_speed`, and `eta`. # Task Implement the following functions: 1. **total_distance**: * **Input**: - `distances` (list of floats): The list of distances covered by the vehicle during the day. * **Output**: - Total distance (float). * **Constraints**: - If `distances` is empty, return 0.0. 2. **average_speed**: * **Input**: - `total_distance` (float): The total distance covered. - `total_time` (float): Total time taken in hours. * **Output**: - Average speed (float). * **Constraints**: - If `total_time` is zero or negative, return -1. 3. **eta**: * **Input**: - `total_distance` (float): The remaining distance to the destination. - `average_speed` (float): The average speed of the vehicle. * **Output**: - Estimated time of arrival in hours (float). * **Constraints**: - If `average_speed` is zero or negative, return -1. # Implementation Write your solution in Python. The overall time complexity for each function should remain O(n) for `total_distance` and O(1) for `average_speed` and `eta`. # Example Usage ```python print(total_distance([10.5, 14.2, 7.8, 5.6])) # Output: 38.1 print(average_speed(150, 3)) # Output: 50.0 print(eta(200, 50)) # Output: 4.0 ``` # Function Definitions ```python def total_distance(distances): if not distances: return 0.0 return sum(distances) def average_speed(total_distance, total_time): if total_time <= 0: return -1 return total_distance / total_time def eta(total_distance, average_speed): if average_speed <= 0: return -1 return total_distance / average_speed ``` # Notes to Developers 1. Ensure to consider edge cases, such as empty `distances` lists or non-positive `total_time`/`average_speed`. 2. Maintain code efficiency and readability, following best practices.","solution":"def total_distance(distances): Calculates the total distance covered by summing the list of distances. Parameters: distances (list of float): List of distances covered. Returns: float: Total distance covered. Returns 0.0 if the list is empty. if not distances: return 0.0 return sum(distances) def average_speed(total_distance, total_time): Calculates the average speed given the total distance and the total time. Parameters: total_distance (float): The total distance covered. total_time (float): The total time taken in hours. Returns: float: The average speed. Returns -1 if total_time is zero or negative. if total_time <= 0: return -1 return total_distance / total_time def eta(total_distance, average_speed): Calculates the estimated time of arrival given the remaining distance and the average speed. Parameters: total_distance (float): The remaining distance to the destination. average_speed (float): The average speed of the vehicle. Returns: float: Estimated time of arrival in hours. Returns -1 if average_speed is zero or negative. if average_speed <= 0: return -1 return total_distance / average_speed"},{"question":"# Problem Statement You are given a data processing scenario that involves managing a stream of data as it arrives. This is often required in applications such as real-time analytics, financial data analysis, and network monitoring. Your task is to implement an efficient, robust algorithm that calculates a moving average over the stream of data. # Task 1. **Implement a Sliding Window Moving Average**: Implement a class `MovingAverage` that maintains a moving average of a specified window size. The class should efficiently handle the addition of new data points in the stream and provide the current moving average. 2. **Handle Edge Cases**: Ensure the implementation correctly handles edge cases such as when the window has fewer elements than its size and when new data is added continuously. # Class Definition Define a class `MovingAverage` with the following methods: - **`__init__(self, size: int)`**: Initialize the object with the size of the window. - **`next(self, val: float) -> float`**: Add a new value to the stream and return the current moving average. # Input and Output * **Input**: The class is initialized with a parameter `size`, which is an integer representing the size of the moving window. The `next` method takes a floating-point number `val` as input. * **Output**: The `next` method returns the current floating-point value of the moving average after adding the new data point. # Example ```python moving_average = MovingAverage(3) print(moving_average.next(1)) # Returns 1.0 (1 / 1) print(moving_average.next(10)) # Returns 5.5 (1 + 10) / 2 print(moving_average.next(3)) # Returns 4.67 (1 + 10 + 3) / 3 print(moving_average.next(5)) # Returns 6.0 (10 + 3 + 5) / 3 ``` # Constraints * The `size` of the moving window will be a positive integer. * The elements added will be floating-point numbers. * The implementation should have a time complexity of O(1) for adding a new element and calculating the moving average. # Implementation Implement the `MovingAverage` class with the appropriate methods: ```python from collections import deque class MovingAverage: def __init__(self, size: int): self.size = size self.queue = deque() self.sum = 0.0 def next(self, val: float) -> float: if len(self.queue) == self.size: self.sum -= self.queue.popleft() self.queue.append(val) self.sum += val return self.sum / len(self.queue) ``` # Explanation In this implementation, the `MovingAverage` class uses a deque to efficiently handle the sliding window of the specified size. The `next` method updates the deque and the sum as new data points arrive, ensuring that the moving average is calculated in constant time.","solution":"from collections import deque class MovingAverage: def __init__(self, size: int): self.size = size self.queue = deque() self.sum = 0.0 def next(self, val: float) -> float: if len(self.queue) == self.size: self.sum -= self.queue.popleft() self.queue.append(val) self.sum += val return self.sum / len(self.queue)"},{"question":"# Problem Statement You are given a list of movies, and each movie has an associated genre. Your task is to implement a recommendation system that suggests movies based on a user\'s preferred genre. The recommendation system should also provide the average rating for the recommended movies. # Objectives 1. **Data Structure Design**: Implement the `MovieRecommender` class to manage the movies and their genres. 2. **Movie Addition**: Add a method to include a new movie to the system, specifying its title, genre, and rating. 3. **Recommendation**: Add a method to recommend movies of a specified genre. 4. **Average Rating Calculation**: Calculate the average rating of the recommended movies. # Function Signatures - `__init__(self)` - `add_movie(self, title: str, genre: str, rating: float) -> None` - `recommend(self, genre: str) -> list[str]` - `average_rating(self, genre: str) -> float` # Example ```python R = MovieRecommender() R.add_movie(\\"Inception\\", \\"Sci-Fi\\", 8.8) R.add_movie(\\"The Matrix\\", \\"Sci-Fi\\", 8.7) R.add_movie(\\"Interstellar\\", \\"Sci-Fi\\", 8.6) R.add_movie(\\"The Godfather\\", \\"Crime\\", 9.2) R.add_movie(\\"Pulp Fiction\\", \\"Crime\\", 8.9) recommendations = R.recommend(\\"Sci-Fi\\") print(recommendations) # Output: [\\"Inception\\", \\"The Matrix\\", \\"Interstellar\\"] average_rating = R.average_rating(\\"Crime\\") print(average_rating) # Output: 9.05 ``` # Constraints - Movie titles and genres are non-empty strings. - Ratings are floating-point numbers between 0 and 10, inclusive. - Each genre can contain up to 1000 movies. - There can be up to 100 different genres. - There can be a maximum of 10,000 movies in the system. # Hints 1. Use a dictionary to map genres to lists of movies. 2. To calculate the average rating, sum the ratings of the movies in the specified genre and divide by the number of movies in that genre. # Performance Requirements - Your solution should efficiently handle the addition of movies and the retrieval of recommendations within acceptable time limits.","solution":"class MovieRecommender: def __init__(self): self.movies_by_genre = {} def add_movie(self, title, genre, rating): Adds a movie with the specified title, genre, and rating. if genre not in self.movies_by_genre: self.movies_by_genre[genre] = [] self.movies_by_genre[genre].append((title, rating)) def recommend(self, genre): Recommends movies of the specified genre. if genre in self.movies_by_genre: return [title for (title, rating) in self.movies_by_genre[genre]] return [] def average_rating(self, genre): Calculates the average rating for the movies of the specified genre. if genre in self.movies_by_genre: ratings = [rating for (title, rating) in self.movies_by_genre[genre]] if ratings: return sum(ratings) / len(ratings) return 0.0"},{"question":"# Coding Assessment Question Write a function that reads and processes a CSV file containing movie ratings data. The function should load the data, split it into training and testing sets, create a user-item interaction matrix, and implement a utility function that returns the top-N recommendations for a given user based on the most popular movies. Function Signature ```python def process_ratings_data(csv_file_path: str, test_size: float = 0.2, top_n: int = 5) -> dict: ``` Input Specifications: - **csv_file_path** (*str*): Path to the CSV file containing the ratings data. Assume the CSV file has columns: `user_id`, `movie_id`, `rating`. - **test_size** (*float*): Proportion of the dataset to include in the test split. - **top_n** (*int*): Number of top recommendations to generate for each user. Output Specifications: - **output** (*dict*): A dictionary with keys `train`, `test`, and `recommend`. - **train** (*pd.DataFrame*): Training set DataFrame. - **test** (*pd.DataFrame*): Testing set DataFrame. - **recommend** (*function*): A function that takes a `user_id` and returns the top-N movie recommendations for that user. Example Usage: ```python data = process_ratings_data(csv_file_path=\\"movie_ratings.csv\\", test_size=0.2, top_n=5) # Getting top 5 recommendations for user with ID 1 user_recommendations = data[\'recommend\'](1) ``` Constraints: - Use `pandas` to handle CSV data. - You may assume that the user IDs and movie IDs are integers. - Ensure `train` and `test` DataFrames maintain the original columns. - Recommendations should be based on the most frequently rated movies in the training set. - Implement a robust error-checking mechanism to handle potential issues such as missing or malformed data.","solution":"import pandas as pd from sklearn.model_selection import train_test_split def process_ratings_data(csv_file_path: str, test_size: float = 0.2, top_n: int = 5) -> dict: Reads a CSV file containing movie ratings data, splits it into training and testing sets, creates a user-item interaction matrix, and returns a recommendation function. # Read the CSV file try: ratings_df = pd.read_csv(csv_file_path) if not {\'user_id\', \'movie_id\', \'rating\'}.issubset(ratings_df.columns): raise ValueError(\\"CSV file must contain \'user_id\', \'movie_id\', and \'rating\' columns\\") except Exception as e: raise e # Split the data into training and testing sets train_df, test_df = train_test_split(ratings_df, test_size=test_size, random_state=42) # Create a user-item interaction matrix for the training set user_item_matrix = train_df.pivot(index=\'user_id\', columns=\'movie_id\', values=\'rating\') # Get the list of most popular movies popular_movies = train_df[\'movie_id\'].value_counts().index.tolist() def recommend(user_id): Returns the top-N recommendations for a given user_id based on most popular movies. if user_id not in user_item_matrix.index: raise ValueError(f\\"User ID {user_id} not found in the training data\\") unseen_movies = [movie for movie in popular_movies if movie not in user_item_matrix.loc[user_id].dropna().index] return unseen_movies[:top_n] return { \'train\': train_df, \'test\': test_df, \'recommend\': recommend }"},{"question":"# Coding Assessment Question Context: A company desires a secure way to store and check passwords using hashing, which involves creating a hash of the password and storing it. When a user logs in, the system hashes the entered password and compares it to the stored hash. For security, we will use the SHA-256 hashing algorithm. Task: Create a password hashing system with SHA-256. Your task is to implement two functions: 1. `hash_password(password)` to generate a hash for a given password. 2. `check_password(stored_hash, entered_password)` to verify if an entered password matches the stored hash. Requirements: - Implement a function `hash_password(password)`: - **Input**: - `password` (str): The password to be hashed. - **Output**: A string representing the SHA-256 hash of the password. - Implement a function `check_password(stored_hash, entered_password)`: - **Inputs**: - `stored_hash` (str): The previously stored hash of the original password. - `entered_password` (str): The password entered by the user. - **Output**: A boolean indicating whether the entered password matches the stored hash. Constraints: - Input strings (passwords) contain ASCII characters only. - The length of the passwords is between 1 and 100 characters inclusive. - The stored hash will always be a valid SHA-256 hash string. Examples: ```python >>> hash_password(\\"securepassword\\") \\"5e884898da28047151d0e56f8dc6292773603d0d6aabbddf522f7a9e1dd11d13\\" >>> check_password(\\"5e884898da28047151d0e56f8dc6292773603d0d6aabbddf522f7a9e1dd11d13\\", \\"securepassword\\") True >>> check_password(\\"5e884898da28047151d0e56f8dc6292773603d0d6aabbddf522f7a9e1dd11d13\\", \\"wrongpassword\\") False ``` Note: - Use Python\'s `hashlib` library for hashing. - Raise an exception if the input is outside the given constraints.","solution":"import hashlib def hash_password(password): Generate a SHA-256 hash for the given password. Parameters: password (str): The password to be hashed. Returns: str: The SHA-256 hash of the password. if not (1 <= len(password) <= 100): raise ValueError(\\"Password length must be between 1 and 100 characters inclusive.\\") return hashlib.sha256(password.encode()).hexdigest() def check_password(stored_hash, entered_password): Verify if an entered password matches the stored hash. Parameters: stored_hash (str): The previously stored hash of the original password. entered_password (str): The password entered by the user. Returns: bool: True if the entered password matches the stored hash, False otherwise. if not (1 <= len(entered_password) <= 100): raise ValueError(\\"Password length must be between 1 and 100 characters inclusive.\\") return stored_hash == hash_password(entered_password)"},{"question":"A company wants to distribute cookies to its employees, but each employee has a unique appetite level, meaning they need a minimum number of cookies to be satisfied. The company also has a list of cookie sizes available. Each cookie can only be given to one employee, and an employee can receive at most one cookie. Your task is to maximize the number of satisfied employees. Write a function called `max_satisfied_employees(employee_appetites: List[int], cookie_sizes: List[int]) -> int` which takes two lists of integers: 1. `employee_appetites` where each element represents the minimum number of cookies an employee needs to be satisfied. 2. `cookie_sizes` where each element represents the size of a cookie. The function should return the maximum number of satisfied employees. # Input Format - A list `employee_appetites` of integers. - A list `cookie_sizes` of integers. # Output Format - Return an integer representing the maximum number of employees that can be satisfied. # Example ```python def test_max_satisfied_employees(): assert max_satisfied_employees([1, 2, 3], [1, 1]) == 1 assert max_satisfied_employees([1, 2], [1, 2, 3]) == 2 assert max_satisfied_employees([1, 1, 1], [2, 3]) == 2 test_max_satisfied_employees() ``` # Constraints - The lengths of the lists `employee_appetites` and `cookie_sizes` can be up to 10,000. - Each value in the lists can be between 1 and 10,000. # Performance Requirements * The function should complete within a reasonable time limit for large lists.","solution":"from typing import List def max_satisfied_employees(employee_appetites: List[int], cookie_sizes: List[int]) -> int: employee_appetites.sort() cookie_sizes.sort() satisfied_count = 0 cookie_index = 0 for appetite in employee_appetites: while cookie_index < len(cookie_sizes) and cookie_sizes[cookie_index] < appetite: cookie_index += 1 if cookie_index < len(cookie_sizes): satisfied_count += 1 cookie_index += 1 return satisfied_count"},{"question":"# Minimum Operations to Convert Given two strings `source` and `target`, you need to determine the minimum number of operations required to convert the `source` string into the `target` string. You are allowed to use the following three operations on the `source` string: 1. **Insert a character** 2. **Delete a character** 3. **Replace a character** **Implement the function `min_operations(source: str, target: str) -> int`:** Input: * `source` (str): The string that you need to transform. * `target` (str): The string that you need to obtain after transformations. Output: * An integer representing the minimum number of operations required to convert `source` to `target`. Constraints: * `1 <= len(source), len(target) <= 1000` * Both `source` and `target` consist of lowercase English letters. Performance Requirements: * Ensure the solution uses dynamic programming to efficiently solve the problem within time and space complexity limits. **Example Usage:** ```python source = \\"horse\\" target = \\"ros\\" assert min_operations(source, target) == 3 # (replace \'h\' with \'r\', remove \'e\', remove \'s\') source = \\"intention\\" target = \\"execution\\" assert min_operations(source, target) == 5 # (replace \'i\' with \'e\', replace \'n\' with \'x\', replace \'t\' with \'c\', replace \'i\' with \'u\', replace \'n\' with \'t\') ``` Note: Ensure your solution carefully handles all edge cases and adheres to the specified constraints for optimal performance.","solution":"def min_operations(source: str, target: str) -> int: Returns the minimum number of operations required to convert source string to target string. Allowed operations are insert a character, delete a character, and replace a character. m, n = len(source), len(target) dp = [[0] * (n + 1) for _ in range(m + 1)] # Initialize the table with base cases for i in range(m + 1): dp[i][0] = i # Minimum operations to convert source[0..i] to empty string (all deletions) for j in range(n + 1): dp[0][j] = j # Minimum operations to convert empty string to target[0..j] (all insertions) # Fill dp table for i in range(1, m + 1): for j in range(1, n + 1): if source[i - 1] == target[j - 1]: dp[i][j] = dp[i - 1][j - 1] else: dp[i][j] = 1 + min(dp[i - 1][j], # Delete dp[i][j - 1], # Insert dp[i - 1][j - 1]) # Replace return dp[m][n]"},{"question":"# Coding Assignment: Implement a Memory-Efficient Trie for Autocomplete Scenario You are hired as a software engineer for a large tech company. One of your tasks is to enhance the search functionality in an application which involves predicting user input. To achieve this, autocomplete suggestions must be provided in real-time as the user types. Given the potential size of the dataset (e.g., a large dictionary of words), a memory-efficient solution is essential. Problem Statement Implement a trie (prefix tree) data structure optimized for memory usage. This trie will be used to store a dictionary of words and must support efficient insertion and search operations. Additionally, the trie should be able to return all words with a given prefix, providing the foundation for the autocomplete feature. Requirements 1. **Class Definition** - Define a class `AutocompleteTrie` with the following methods: - `insert(word: str) -> None`: Insert a word into the trie. - `search(word: str) -> bool`: Return `True` if the word is in the trie, else `False`. - `starts_with(prefix: str) -> List[str]`: Return all words in the trie that start with the given prefix. 2. **Input Format**: - `word`: A lowercase string (length 1 to 100) representing a word to insert or search. - `prefix`: A lowercase string (length 1 to 100) representing the prefix to search for. 3. **Output Format**: - `insert`: No return value. - `search`: Boolean value indicating whether the word is in the trie. - `starts_with`: List of strings representing words starting with the given prefix. 4. **Constraints**: - The trie must handle at least 100,000 different words efficiently. - Optimize for memory usage (consider using compact data representations, such as arrays or linked structures). - Ensure operations are efficient in terms of time complexity. 5. **Performance Requirements**: - Insertion, search, and prefix match should execute within a reasonable timeframe, even for large dictionaries. Example ```python trie = AutocompleteTrie() trie.insert(\\"apple\\") trie.insert(\\"app\\") trie.insert(\\"application\\") assert trie.search(\\"app\\") == True assert trie.search(\\"appl\\") == False assert trie.search(\\"banana\\") == False assert set(trie.starts_with(\\"app\\")) == {\\"app\\", \\"apple\\", \\"application\\"} assert trie.starts_with(\\"ban\\") == [] ``` Notes 1. Implement the `AutocompleteTrie` class with the specified methods. 2. Focus on optimizing both memory usage and search efficiency. 3. Ensure your code can handle typical edge cases such as inserting duplicate words and searching for prefixes not present in the trie.","solution":"from typing import List class TrieNode: def __init__(self): self.children = {} self.is_end_of_word = False class AutocompleteTrie: def __init__(self): self.root = TrieNode() def insert(self, word: str) -> None: node = self.root for char in word: if char not in node.children: node.children[char] = TrieNode() node = node.children[char] node.is_end_of_word = True def search(self, word: str) -> bool: node = self.root for char in word: if char not in node.children: return False node = node.children[char] return node.is_end_of_word def starts_with(self, prefix: str) -> List[str]: def dfs(node, path, results): if node.is_end_of_word: results.append(path) for char, next_node in node.children.items(): dfs(next_node, path + char, results) node = self.root for char in prefix: if char not in node.children: return [] node = node.children[char] results = [] dfs(node, prefix, results) return results"},{"question":"# Similarity Indices Calculation You are tasked with writing a function that calculates the similarity index between two DNA sequences. The similarity index is defined as the percentage of identical characters in the same positions in both sequences. The function should handle cases where the sequences are of different lengths by only comparing up to the length of the shorter sequence. Implement the function `similarity_index(seq1: str, seq2: str) -> float` that: - Takes two DNA sequences as inputs. - Returns a float representing the percentage of characters that are identical in the same positions. Function Signature ```python def similarity_index(seq1: str, seq2: str) -> float: pass ``` # Input - `seq1`: A string representing the first DNA sequence, consisting of characters \'A\', \'C\', \'G\', \'T\'. - `seq2`: A string representing the second DNA sequence, consisting of characters \'A\', \'C\', \'G\', \'T\'. # Output - Returns a float representing the percentage of identical characters in the same positions, rounded to two decimal places. # Examples Here are some sample test cases for your implementation: ```python assert similarity_index(\\"ACGT\\", \\"ACGT\\") == 100.00 assert similarity_index(\\"ACGT\\", \\"TGCA\\") == 0.00 assert similarity_index(\\"ACGTG\\", \\"ACGTA\\") == 80.00 assert similarity_index(\\"ACGTG\\", \\"ACGT\\") == 100.00 assert similarity_index(\\"AC\\", \\"ACGTG\\") == 100.00 ```","solution":"def similarity_index(seq1: str, seq2: str) -> float: Calculate the similarity index between two DNA sequences. The similarity index is the percentage of identical characters in the same positions in both sequences, considering only up to the length of the shorter sequence. min_length = min(len(seq1), len(seq2)) if min_length == 0: return 0.0 match_count = sum(1 for i in range(min_length) if seq1[i] == seq2[i]) similarity_percentage = (match_count / min_length) * 100 return round(similarity_percentage, 2)"},{"question":"# Problem Statement Write a function `replace_integer_elements` that replaces every element in a given list of integers with the product of other elements in the list without using division. Detailed Requirements: 1. Implement the function `replace_integer_elements` that performs this replacement. 2. For each element in the list, replace it with the product of all other elements. 3. Do not use division to compute the result. Input - A list of integers `nums` with length (n), where (2 leq n leq 10^5). ```plaintext nums: List[int] ``` Output - A list of integers where each element is replaced by the product of all other elements in the initial list. ```plaintext List[int] ``` Constraints - The input list length (n) is at most (10^5). - The integers in the list can be both positive and negative, but there will be no zeros. Performance Expectations - Time Complexity: O(n) - Space Complexity: O(n) Example ```python def replace_integer_elements(nums: List[int]) -> List[int]: Replace each element in the list with the product of all other elements. Args: nums: List[int] - list of integers Returns: List[int] - new list after replacement n = len(nums) if n == 2: return [nums[1], nums[0]] left_products = [1] * n right_products = [1] * n for i in range(1, n): left_products[i] = left_products[i - 1] * nums[i - 1] for i in range(n - 2, -1, -1): right_products[i] = right_products[i + 1] * nums[i + 1] result = [] for i in range(n): result.append(left_products[i] * right_products[i]) return result # Example Usage nums = [1, 2, 3, 4] print(replace_integer_elements(nums)) # Output: [24, 12, 8, 6] ``` In this example, the function `replace_integer_elements` takes a list of integers and replaces each element with the product of all other elements. The result should be a list with the replaced values computed without using division.","solution":"from typing import List def replace_integer_elements(nums: List[int]) -> List[int]: Replace each element in the list with the product of all other elements. Args: nums: List[int] - list of integers Returns: List[int] - new list after replacement n = len(nums) if n == 2: return [nums[1], nums[0]] left_products = [1] * n right_products = [1] * n for i in range(1, n): left_products[i] = left_products[i - 1] * nums[i - 1] for i in range(n - 2, -1, -1): right_products[i] = right_products[i + 1] * nums[i + 1] result = [] for i in range(n): result.append(left_products[i] * right_products[i]) return result"},{"question":"# Coding Challenge: LRU Cache Implementation **Context**: A Least Recently Used (LRU) cache is a data structure that stores a set of key-value pairs and has a fixed capacity. When the number of elements exceeds the capacity, it removes the least recently used element before inserting a new one. # Task Implement a class `LRUCache` using an ordered dictionary. Your class should support the following operations: 1. **Put**: Insert a key-value pair into the cache. If the cache is full, remove the least recently used item before inserting the new item. 2. **Get**: Retrieve the value associated with a specific key from the cache. 3. **Remove**: Remove a specific key-value pair from the cache. 4. **Print Cache**: Print the items in the cache in the order from the most recently used to the least recently used. # Input and Output - **Put Operation**: - Method: `put(key: int, value: int) -> None` - Input: Integer key and value. - Output: None. - **Get Operation**: - Method: `get(key: int) -> int | None` - Output: Integer value associated with the key, or None if the key is not found. - **Remove Operation**: - Method: `remove(key: int) -> None` - Output: None. - **Print Cache**: - Method: `print_cache() -> None` - Output: Print items starting from the most recently used to the least recently used in the form of key-value pairs. # Constraints 1. The cache will have a maximum fixed capacity `n` specified when the cache is created. 2. Ensure that the cache updates the usage order upon `get` and `put` operations. 3. Implement all required methods described above. # Scenario Create an `LRUCache` instance with a capacity of 3. Perform various put, get and remove operations while ensuring the correct implementation of the cache\'s functionality. ```python from collections import OrderedDict class LRUCache: def __init__(self, capacity: int): self.capacity = capacity self.cache = OrderedDict() def put(self, key: int, value: int) -> None: pass # Implement the put operation def get(self, key: int) -> int | None: pass # Implement the get operation def remove(self, key: int) -> None: pass # Implement the remove operation def print_cache(self) -> None: pass # Implement the print cache function if __name__ == \\"__main__\\": cache_capacity = 3 cache = LRUCache(cache_capacity) cache.put(1, 10) cache.put(2, 20) cache.put(3, 30) cache.print_cache() # Expected Output: [(1, 10), (2, 20), (3, 30)] cache.get(1) cache.put(4, 40) cache.print_cache() # Expected Output: [(2, 20), (3, 30), (1, 10)], since 1 was accessed before put operation cache.put(5, 50) cache.print_cache() # Expected Output: [(3, 30), (1, 10), (5, 50)], since 2 is the least recently used cache.remove(1) cache.print_cache() # Expected Output: [(3, 30), (5, 50)] } ``` Ensure to include edge cases such as cache overflow, key not found for get and remove operations, and correct update of usage order.","solution":"from collections import OrderedDict class LRUCache: def __init__(self, capacity: int): self.capacity = capacity self.cache = OrderedDict() def put(self, key: int, value: int) -> None: if key in self.cache: self.cache.pop(key) elif len(self.cache) >= self.capacity: self.cache.popitem(last=False) # Pop the least recently used item self.cache[key] = value def get(self, key: int) -> int | None: if key in self.cache: value = self.cache.pop(key) self.cache[key] = value # Re-insert to mark as most recently used return value else: return None def remove(self, key: int) -> None: if key in self.cache: self.cache.pop(key) def print_cache(self) -> None: cache_list = list(self.cache.items()) print(cache_list)"},{"question":"# Problem Statement You are tasked with implementing a Word Frequency Counter that reads a stream of text (as a list of sentences) and returns the top k most frequent words in descending order of their frequency. If two words have the same frequency, they should be sorted in lexicographical order. # Input/Output Formats - **Input**: - A list of sentences (strings), and an integer k representing the number of top frequent words to return. Example: `sentences = [\\"this is a test\\", \\"this test is fun\\", \\"test the system\\"]`, `k = 2` - **Output**: - A list of the k most frequent words in descending order of frequency. Example: `[\\"test\\", \\"is\\"]` # Constraints - The sentences only contain lowercase alphabetic characters and spaces. - Words are separated by spaces. - The value of k is a non-negative integer and does not exceed the total number of unique words in the sentences. # Example ```python sentences = [\\"this is a test\\", \\"this test is fun\\", \\"test the system\\"] k = 2 print(top_k_frequent_words(sentences, k)) # Expected Output: [\\"test\\", \\"is\\"] ``` # Task Implement the `top_k_frequent_words` function to process the list of sentences and return the k most frequent words as described. ```python from collections import Counter from typing import List def top_k_frequent_words(sentences: List[str], k: int) -> List[str]: # Step 1: Split sentences into words and count the frequency of each word word_count = Counter() for sentence in sentences: words = sentence.split() word_count.update(words) # Step 2: Sort words by frequency and then lexicographical order sorted_words = sorted(word_count.items(), key=lambda x: (-x[1], x[0])) # Step 3: Extract the top k frequent words return [word for word, _ in sorted_words[:k]] # Example usage sentences = [\\"this is a test\\", \\"this test is fun\\", \\"test the system\\"] k = 2 print(top_k_frequent_words(sentences, k)) # Expected Output: [\\"test\\", \\"is\\"] ``` In this task, your function should be able to handle splitting sentences into words, counting word frequencies, and correctly sorting and selecting the top k frequent words as specified.","solution":"from collections import Counter from typing import List def top_k_frequent_words(sentences: List[str], k: int) -> List[str]: Returns the top k most frequent words from a list of sentences. Words with the same frequency are sorted in lexicographical order. # Step 1: Split sentences into words and count the frequency of each word word_count = Counter() for sentence in sentences: words = sentence.split() word_count.update(words) # Step 2: Sort words by frequency and then lexicographical order sorted_words = sorted(word_count.items(), key=lambda x: (-x[1], x[0])) # Step 3: Extract the top k frequent words return [word for word, _ in sorted_words[:k]] # Example usage sentences = [\\"this is a test\\", \\"this test is fun\\", \\"test the system\\"] k = 2 print(top_k_frequent_words(sentences, k)) # Expected Output: [\\"test\\", \\"is\\"]"},{"question":"# Dynamic Mitigation Using Congestion Control You are tasked with developing a simplified simulation tool to estimate the average latency for data packets transmitted over a network using a congestion control mechanism. The goal is to predict how congestion affects overall transmission delay. The average latency (L) can be approximated using the formula: [ L = frac{RTT}{1 - frac{T_{in}}{T_{out}}} ] Where: - ( RTT ) (Round Trip Time) is the time it takes for a data packet to go from the sender to the receiver and back (in milliseconds). - ( T_{in} ) is the incoming data transfer rate (in Mbps - Megabits per second). - ( T_{out} ) is the outgoing data transfer rate (in Mbps - Megabits per second). Your function should calculate the average latency, ensuring it handles the following constraints: - Both ( RTT ), ( T_{in} ), and ( T_{out} ) should be greater than 0. - The incoming rate ( T_{in} ) should not exceed the outgoing rate ( T_{out} ) to avoid division by zero. # Function Signature ```python def average_latency(RTT: float, T_in: float, T_out: float) -> float: ``` # Input - `RTT` (float): Round Trip Time in milliseconds (must be > 0). - `T_in` (float): Incoming data transfer rate in Mbps (must be > 0). - `T_out` (float): Outgoing data transfer rate in Mbps (must be > 0). # Output - `float`: The average latency in milliseconds. # Constraints - Raise a `ValueError` with an appropriate message for the following conditions: - If the RTT is ≤ 0: \\"Invalid RTT value\\". - If ( T_{in} ) is ≤ 0: \\"Invalid incoming data rate\\". - If ( T_{out} ) is ≤ 0: \\"Invalid outgoing data rate\\". - If ( T_{in} ge T_{out} ): \\"Incoming rate must be less than outgoing rate\\". # Examples 1. `average_latency(RTT=100, T_in=50, T_out=100)` should return `200.0`. 2. `average_latency(RTT=150, T_in=30, T_out=60)` should return `300.0`. 3. `average_latency(RTT=200, T_in=70, T_out=140)` should return `400.0`. 4. `average_latency(RTT=200, T_in=150, T_out=140)` should raise `ValueError: Incoming rate must be less than outgoing rate`. 5. `average_latency(RTT=0, T_in=50, T_out=100)` should raise `ValueError: Invalid RTT value`. 6. `average_latency(RTT=150, T_in=0, T_out=60)` should raise `ValueError: Invalid incoming data rate`. 7. `average_latency(RTT=150, T_in=30, T_out=0)` should raise `ValueError: Invalid outgoing data rate`. Implement the function in Python, considering the points discussed above.","solution":"def average_latency(RTT: float, T_in: float, T_out: float) -> float: Calculate the average latency for data packets transmitted over a network using the given formula. Parameters: RTT (float): Round Trip Time in milliseconds (must be > 0). T_in (float): Incoming data transfer rate in Mbps (must be > 0). T_out (float): Outgoing data transfer rate in Mbps (must be > 0). Returns: float: The average latency in milliseconds. Raises: ValueError: If any input is zero or negative, or if T_in >= T_out. if RTT <= 0: raise ValueError(\\"Invalid RTT value\\") if T_in <= 0: raise ValueError(\\"Invalid incoming data rate\\") if T_out <= 0: raise ValueError(\\"Invalid outgoing data rate\\") if T_in >= T_out: raise ValueError(\\"Incoming rate must be less than outgoing rate\\") average_latency = RTT / (1 - T_in / T_out) return average_latency"},{"question":"# Array Segment Summation Problem Statement You are given an array of integers and a series of queries. Each query specifies a range within the array\'s indices, and your task is to return the sum of the elements within that range. Design a function to handle the queries efficiently, especially for large arrays and multiple queries. Functional Specification 1. **Function Name**: `array_segment_sum` 2. **Input**: - An array of integers `arr` of size `n`. - A list of tuples `queries` where each tuple `(start, end)` represents the range `[start, end]` (inclusive). 3. **Output**: A list of integers, where each integer is the sum of the elements in `arr` for the corresponding range specified in `queries`. 4. **Constraints**: - (1 leq n leq 10^5) - (1 leq text{number of queries} leq 10^5) - (0 leq text{start} leq text{end} < n) Examples ```python >>> array_segment_sum([1, 2, 3, 4, 5], [(1, 3), (0, 4), (2, 2)]) [9, 15, 3] >>> array_segment_sum([10, 20, 30, 40, 50], [(0, 1), (2, 4), (1, 3)]) [30, 120, 90] >>> array_segment_sum([-5, 8, 7, -3, 6], [(1, 4), (0, 2), (2, 2)]) [18, 10, 7] ``` Implementation Implement your solution efficiently, utilizing preprocessing techniques like prefix sums to handle the queries in optimal time. ```python def array_segment_sum(arr, queries): Returns a list of sums for each range specified in the queries. Args: arr: A list of integers. queries: A list of tuples where each tuple specifies a range. Returns: A list of integers representing the sum of elements within the query ranges. n = len(arr) if not n: return [] # Compute prefix sums prefix_sums = [0] * (n + 1) for i in range(n): prefix_sums[i + 1] = prefix_sums[i] + arr[i] result = [] for start, end in queries: result.append(prefix_sums[end + 1] - prefix_sums[start]) return result if __name__ == \\"__main__\\": import doctest doctest.testmod() ``` # Explanation: 1. **Prefix Sum Array**: The function first builds a prefix sum array, which holds cumulative sums of the array elements. This allows any segment sum to be computed in constant time by subtracting the prefix sums. 2. **Query Processing**: For each query, the function uses the prefix sums to quickly compute the sum of the specified range. 3. **Efficiency**: Building the prefix sum array takes O(n) time, and each query is processed in O(1) time, making the approach efficient for handling large input sizes as specified in the constraints.","solution":"def array_segment_sum(arr, queries): Returns a list of sums for each range specified in the queries. Args: arr: A list of integers. queries: A list of tuples where each tuple specifies a range. Returns: A list of integers representing the sum of elements within the query ranges. n = len(arr) if not n: return [] # Compute prefix sums prefix_sums = [0] * (n + 1) for i in range(n): prefix_sums[i + 1] = prefix_sums[i] + arr[i] result = [] for start, end in queries: result.append(prefix_sums[end + 1] - prefix_sums[start]) return result"},{"question":"**Problem Statement:** You are given a string `paragraph` and a list of `banned_words`. Implement a function that returns the most frequent word in the paragraph that is not in the banned words. The word returned should be in lowercase. # Function Signature ```python def most_frequent_word(paragraph: str, banned_words: list[str]) -> str: pass ``` # Input & Output Formats * **Input**: * `paragraph`: A string containing one or more sentences. May contain punctuation. * `banned_words`: A list of strings where each string is a banned word. These words should not be considered when determining the most frequent word. * **Output**: * Return the most frequent non-banned word in lowercase. # Constraints * The length of the `paragraph` will not exceed 1000 characters. * The list `banned_words` will contain at most 1000 strings, each with length not greater than 10 characters. * The answer is guaranteed to be unique, so there will be exactly one word that is the most frequent without being banned. # Performance Requirements * Aim to optimize for both time and space complexity considering the upper constraint limits. # Examples ```python assert most_frequent_word(\\"This is a test. This test is only a test.\\", [\\"is\\", \\"a\\"]) == \\"test\\" assert most_frequent_word(\\"Bob hit a ball, the hit BALL flew far after it was hit.\\", [\\"hit\\"]) == \\"ball\\" assert most_frequent_word(\\"It is sunny out there. It\'s really sunny and warm.\\", [\\"is\\", \\"it\\", \\"and\\", \\"sunny\\"]) == \\"out\\" assert most_frequent_word(\\"The quick brown fox jumps over the lazy dog. The quick brown fox is quick.\\", [\\"the\\", \\"fox\\", \\"is\\"]) == \\"quick\\" ``` **Notes**: * Words should be compared in a case-insensitive manner, but the result should be in lowercase. * Handle punctuation appropriately (e.g., periods, commas, apostrophes) by treating them as delimiters but not part of the words themselves. * Include handling for various whitespace characters in the paragraph.","solution":"import re from collections import Counter def most_frequent_word(paragraph: str, banned_words: list[str]) -> str: # Normalize the paragraph: replace punctuations by spaces and convert to lowercase normalized_paragraph = re.sub(r\'[^ws]\', \' \', paragraph).lower() # Split the paragraph into words words = normalized_paragraph.split() # Create a set of banned words for fast lookup banned_set = set(banned_words) # Filter out the banned words and count the frequency of the remaining words word_counts = Counter(word for word in words if word not in banned_set) # Find the word with the highest frequency most_common_word = word_counts.most_common(1)[0][0] return most_common_word"},{"question":"Problem Statement # Context You are part of a team developing features for a blog platform. One of the requirements is to format blog text by organizing words into justified lines. Text justification ensures that each line has exactly the same length, with spaces between the words adjusted accordingly. # Task Write a function `justify_text` that takes a list of words and a maximum line width and returns a list of justified lines. Each line should have exactly `max_width` characters, and the last line should be left-justified with no extra spaces between words. # Requirements 1. The function should be named `justify_text`. 2. The function should take two parameters: - `words` (list[str]): A list of words to be justified. - `max_width` (int): The maximum number of characters in each line. 3. The function should return a list of strings, each string being a justified line of text with exactly `max_width` characters except the last line which should be left-justified. 4. Words in each line should be separated by at least one space. 5. Extra spaces should be distributed as evenly as possible between the words. If the number of spaces left cannot be evenly distributed, the extra spaces should be added from left to right. 6. The last line should be left-justified with spaces added only at the end to ensure it has exactly `max_width` characters. # Function Signature ```python def justify_text(words: list[str], max_width: int) -> list[str]: pass ``` # Constraints * The length of each word will be between 1 and 20 characters. * The number of words will be between 1 and 10^4. * The `max_width` will be between 1 and 100 characters. # Example ```python assert justify_text([\\"This\\", \\"is\\", \\"an\\", \\"example\\", \\"of\\", \\"text\\", \\"justification.\\"], 16) == [ \\"This is an\\", \\"example of text\\", \\"justification. \\" ] assert justify_text([\\"What\\",\\"must\\",\\"be\\",\\"acknowledgment\\",\\"shall\\",\\"be\\"], 16) == [ \\"What must be\\", \\"acknowledgment \\", \\"shall be \\" ] assert justify_text([\\"Science\\",\\"is\\",\\"what\\",\\"we\\",\\"understand\\",\\"well\\",\\"enough\\",\\"to\\",\\"explain\\",\\"to\\",\\"a\\",\\"computer.\\",\\"Art\\",\\"is\\",\\"everything\\",\\"else\\",\\"we\\",\\"do\\"], 20) == [ \\"Science is what we\\", \\"understand well\\", \\"enough to explain to\\", \\"a computer. Art is\\", \\"everything else we\\", \\"do \\" ] ``` # Notes Your implementation should be efficient to handle the given constraints and properly distribute spaces where applicable.","solution":"def justify_text(words, max_width): def format_line(line_words, max_width, is_last_line): # If it\'s the last line or a line with one word, left-justify it if is_last_line or len(line_words) == 1: return \' \'.join(line_words).ljust(max_width) total_chars = sum(len(word) for word in line_words) spaces = max_width - total_chars min_space, extra_space = divmod(spaces, len(line_words) - 1) justified_line = \\"\\" for i in range(len(line_words) - 1): justified_line += line_words[i] + \' \' * (min_space + (1 if i < extra_space else 0)) justified_line += line_words[-1] return justified_line lines = [] current_line = [] current_length = 0 for word in words: if current_length + len(word) + len(current_line) > max_width: lines.append(format_line(current_line, max_width, False)) current_line = [] current_length = 0 current_line.append(word) current_length += len(word) # Handle the last line if current_line: lines.append(format_line(current_line, max_width, True)) return lines"},{"question":"You are tasked with implementing the Merge Sort algorithm, a classic divide-and-conquer sorting method. Please follow the requirements below: # Scenario You are given an unsorted list of integers. You need to write a Python function that sorts this list using the Merge Sort algorithm. # Function Signature ```python def merge_sort(arr: list) -> list: Sorts an array of integers using the Merge Sort algorithm. Parameters: - arr: A list of integers to be sorted. Returns: - A new list of integers sorted in ascending order. ``` # Constraints 1. You may assume that the input list will contain at least one integer and will fit in memory. 2. The function should divide the list into halves recursively and then merge the sorted halves. 3. Use a helper function to merge two sorted lists into a single sorted list. # Examples ```python # Example usage unsorted_list = [38, 27, 43, 3, 9, 82, 10] sorted_list = merge_sort(unsorted_list) print(f\\"Sorted list: {sorted_list}\\") # Expected Output: # Sorted list: [3, 9, 10, 27, 38, 43, 82] ``` # Performance Requirements - The function should efficiently handle lists of varying lengths. - Ensure the implementation is both time and space optimized while maintaining clarity and correctness. # Implementation Notes 1. The merge_sort function should call itself recursively to split the array into smaller subarrays. 2. Implement a helper function named `merge` to merge two sorted arrays into one sorted array. # Helper Function Signature ```python def merge(left: list, right: list) -> list: Merges two sorted lists into a single sorted list. Parameters: - left: A sorted list of integers. - right: A sorted list of integers. Returns: - A new list of integers sorted in ascending order. ``` Example usage of the helper function: ```python # Example usage left_part = [3, 27, 38] right_part = [9, 43, 82] merged = merge(left_part, right_part) print(f\\"Merged list: {merged}\\") # Expected Output: # Merged list: [3, 9, 27, 38, 43, 82] ```","solution":"def merge(left, right): Merges two sorted lists into a single sorted list. merged = [] i = j = 0 # Traverse both lists and append smaller element from either list while i < len(left) and j < len(right): if left[i] < right[j]: merged.append(left[i]) i += 1 else: merged.append(right[j]) j += 1 # If there are remaining elements in left list while i < len(left): merged.append(left[i]) i += 1 # If there are remaining elements in right list while j < len(right): merged.append(right[j]) j += 1 return merged def merge_sort(arr): Sorts an array of integers using the Merge Sort algorithm. if len(arr) <= 1: return arr # Find the middle point to divide the array into two halves mid = len(arr) // 2 # Call merge_sort recursively for each half left_half = merge_sort(arr[:mid]) right_half = merge_sort(arr[mid:]) # Merge the two sorted halves return merge(left_half, right_half)"},{"question":"# String Combination Checker You are tasked with developing a function that checks if one string can be formed by combining two other given strings without rearranging the characters in each string. The character order in the two source strings must be preserved in the resulting target string, but the characters from the two source strings can be interleaved in any order. Function Signature ```python def can_form_string(s1: str, s2: str, target: str) -> bool: ``` Input * `s1` (str): The first source string. Must be a non-empty string. * `s2` (str): The second source string. Must be a non-empty string. * `target` (str): The string to check if it can be formed by interleaving `s1` and `s2`. Must be a non-empty string. Output * Return `True` if `target` can be formed by interleaving `s1` and `s2` without rearranging the characters in `s1` or `s2`. * Return `False` otherwise. Errors The function should raise a `ValueError` if: * Any of the input strings (`s1`, `s2`, `target`) is empty. Example Usage ```python >>> can_form_string(\\"abc\\", \\"def\\", \\"adbcef\\") True >>> can_form_string(\\"abc\\", \\"def\\", \\"abdecf\\") True >>> can_form_string(\\"abc\\", \\"def\\", \\"abcdef\\") True >>> can_form_string(\\"abc\\", \\"def\\", \\"abcfed\\") False >>> can_form_string(\\"abc\\", \\"def\\", \\"abcdfe\\") False ``` # Explanation - The function should return `True` for the first three examples as the `target` string can be formed by interleaving `s1` and `s2` while maintaining their respective character orders. - The function should return `False` for the last two examples as the `target` string does not preserve the character orders of `s1` and `s2`.","solution":"def can_form_string(s1: str, s2: str, target: str) -> bool: Check if the target string can be formed by interleaving s1 and s2 while retaining the order of characters. if not s1 or not s2 or not target: raise ValueError(\\"Input strings must be non-empty.\\") if len(target) != len(s1) + len(s2): return False # Create a 2D DP table to store solutions of subproblems dp = [[False] * (len(s2) + 1) for _ in range(len(s1) + 1)] # Initialize the DP table dp[0][0] = True for i in range(1, len(s1) + 1): dp[i][0] = dp[i - 1][0] and s1[i - 1] == target[i - 1] for j in range(1, len(s2) + 1): dp[0][j] = dp[0][j - 1] and s2[j - 1] == target[j - 1] # Build the DP table for i in range(1, len(s1) + 1): for j in range(1, len(s2) + 1): dp[i][j] = (dp[i - 1][j] and s1[i - 1] == target[i + j - 1]) or (dp[i][j - 1] and s2[j - 1] == target[i + j - 1]) return dp[len(s1)][len(s2)]"},{"question":"# Coding Challenge **Context**: You are developing a utility function for a file synchronization software. This software ensures that files in a source directory match those in a target directory. **Objective**: Write a function `sync_files(source_files, target_files)` that takes two lists of file names, `source_files` and `target_files`. The function should return a list of file names that are present in the source directory but missing in the target directory, indicating which files need to be copied over to synchronize both directories. Function Signature ```python def sync_files(source_files: List[str], target_files: List[str]) -> List[str]: ... ``` # Input * `source_files` (List[str]): A list of strings representing file names in the source directory. * `target_files` (List[str]): A list of strings representing file names in the target directory. # Output * A list of strings representing the file names that need to be copied from the source to the target directory. # Constraints * Both `source_files` and `target_files` will contain strings with lengths between 1 and 100. * The number of files in `source_files` and `target_files` will be between 0 and 1000. * The file names will contain only alphanumeric characters and underscores. # Examples ```python assert sync_files([\\"file1.txt\\", \\"file2.txt\\", \\"file3.txt\\"], [\\"file1.txt\\", \\"file3.txt\\"]) == [\\"file2.txt\\"] assert sync_files([\\"image1.png\\", \\"image2.png\\"], [\\"image3.png\\", \\"image4.png\\"]) == [\\"image1.png\\", \\"image2.png\\"] assert sync_files([\\"doc1.docx\\", \\"doc2.docx\\"], [\\"doc1.docx\\", \\"doc2.docx\\", \\"doc3.docx\\"]) == [] assert sync_files([], [\\"file1.txt\\", \\"file2.txt\\"]) == [] ``` # Guidelines 1. Ensure input validation. 2. Aim for clear and efficient implementation. 3. Your solution should handle the case where there are no files in either the source or target directory appropriately. Create the function to solve this problem by reviewing the example cases and constraints.","solution":"from typing import List def sync_files(source_files: List[str], target_files: List[str]) -> List[str]: Returns a list of file names that are present in the source directory but missing in the target directory. target_set = set(target_files) return [file for file in source_files if file not in target_set]"},{"question":"# Dynamic Array Operations Context You are tasked with handling dynamic array operations where the array starts empty, and you must perform a series of queries to either append an element to the array, remove the last element, or print the current size of the array. This scenario is useful in scenarios where adaptive and flexible data structures are crucial. Objectives 1. Write a function to handle the array operations based on given queries. 2. Ensure the function processes each query efficiently. Function **Process Array Operations** ```python def process_operations(operations): Process a list of operations and return the results of \'size\' queries. :param operations: List of operations as strings (\\"append X\\", \\"pop\\", \\"size\\") :return: List of integers representing the results of \'size\' operations ``` Input - **Operations**: A list of strings representing the operations to perform. (\\"append X\\" will append X to the array; \\"pop\\" will remove the last element if the array is non-empty; \\"size\\" will output the current size of the array). Output - A list of integers that correspond to the results of \\"size\\" operations as they appear in the input list. Constraints - The number of operations will not exceed 100,000. - Values of X for \\"append X\\" operations are integers within the range [1, 10^6]. - Assume valid inputs for operations. Example ```python operations = [\\"append 1\\", \\"append 2\\", \\"size\\", \\"pop\\", \\"size\\"] result = process_operations(operations) print(result) ``` Expected output: ``` [2, 1] ```","solution":"def process_operations(operations): Process a list of operations and return the results of \'size\' queries. :param operations: List of operations as strings (\\"append X\\", \\"pop\\", \\"size\\") :return: List of integers representing the results of \'size\' operations array = [] size_results = [] for operation in operations: if operation.startswith(\'append\'): _, value = operation.split() array.append(int(value)) elif operation == \'pop\': if array: array.pop() elif operation == \'size\': size_results.append(len(array)) return size_results"},{"question":"# Problem Statement You have been assigned the task of refactoring a component in an order management system. Specifically, the task involves implementing an efficient algorithm to manage and merge users\' purchase orders. Users can place multiple orders, and each order contains distinct items with varying quantities. The goal is to merge these orders into a consolidated list of ordered items and their respective quantities. Your task is to write a function `merge_orders` that takes a list of purchase orders and consolidates them into a single merged order. Each purchase order is represented as a dictionary with item names as keys and quantities as values. # Function Signature ```python def merge_orders(orders: list[dict[str, int]]) -> dict[str, int]: ``` # Input - `orders` (List[Dict[str, int]]): A list of dictionaries, where each dictionary represents a purchase order with item names as keys and quantities as values. # Output - Returns a consolidated dictionary representing the merged order with item names and total quantities. # Constraints - The input list may contain up to 10^5 orders. - Each order may contain up to 10^3 items. - Item names are non-empty strings composed of uppercase and lowercase letters. - Quantities are positive integers within the range 1 to 10^6. # Examples ```python >>> orders = [{\\"apple\\": 5, \\"banana\\": 3}, {\\"banana\\": 2, \\"orange\\": 1}, {\\"apple\\": 2, \\"orange\\": 4, \\"banana\\": 3}] >>> merge_orders(orders) {\'apple\': 7, \'banana\': 8, \'orange\': 5} >>> orders = [{\\"pen\\": 3}, {\\"notebook\\": 1}, {\\"pen\\": 4, \\"notebook\\": 2}] >>> merge_orders(orders) {\'pen\': 7, \'notebook\': 3} >>> orders = [{}] >>> merge_orders(orders) {} >>> orders = [{\\"pen\\": 1}] >>> merge_orders(orders) {\'pen\': 1} ``` # Requirements - Implement the function `merge_orders` with an efficient approach. - Ensure the solution handles large inputs within reasonable time limits. - Handle edge cases effectively, including empty lists and orders containing a single item. # Hints - Use a dictionary to keep track of the consolidated quantities of each item. - Iterate through each order and update the total quantities in the consolidated dictionary. - Consider using the `collections.defaultdict` for easier handling of missing keys.","solution":"from collections import defaultdict def merge_orders(orders: list[dict[str, int]]) -> dict[str, int]: Consolidates a list of purchase orders into a single merged order. Args: orders (list of dict): A list of dictionaries where each dictionary represents a purchase order with item names as keys and quantities as values. Returns: dict: A consolidated dictionary representing the merged order with item names and total quantities. merged_order = defaultdict(int) for order in orders: for item, quantity in order.items(): merged_order[item] += quantity return dict(merged_order)"},{"question":"# Scenario You are developing a utility for managing a company\'s employees\' data. One critical feature involves tracking and updating their hierarchical reporting structure. As the company\'s hierarchy changes, you need a function that can adjust the employee reports accordingly. # Task Write a function `update_reports_structure` that updates the reports-to structure for a given employee when their direct supervisor changes. This involves updating the reporting structure for the entire subtree of employees who report (directly or indirectly) to the given employee. # Expected Function Signature ```python def update_reports_structure(employees: dict, emp_id: int, new_supervisor_id: int) -> dict: pass ``` # Input - `employees`: A dictionary where keys are employee IDs (integers) and values are dictionaries with two keys: - `name`: A string representing the employee\'s name. - `reports_to`: An integer representing the employee ID of their direct supervisor or `None` if they have no supervisor. - `emp_id`: An integer representing the ID of the employee whose reporting structure needs to be updated. - `new_supervisor_id`: An integer representing the ID of the new supervisor for the given employee or `None` if the employee now reports directly to the top-level management. # Output - Returns an updated dictionary with the new reporting structure. # Constraints - Given IDs for `emp_id` and `new_supervisor_id` must exist in the `employees` dictionary. - Do not create any cyclic dependencies (an employee cannot be their own supervisor directly or indirectly). - Ensure the entire subtree of employees reporting to `emp_id` is updated correctly. # Performance Requirements - The function should handle up to 1,000 employees efficiently. - Aim for a linear-time complexity based on the number of employees. # Example ```python # Input structure employees = { 1: {\\"name\\": \\"Alice\\", \\"reports_to\\": None}, 2: {\\"name\\": \\"Bob\\", \\"reports_to\\": 1}, 3: {\\"name\\": \\"Charlie\\", \\"reports_to\\": 1}, 4: {\\"name\\": \\"David\\", \\"reports_to\\": 2}, 5: {\\"name\\": \\"Eva\\", \\"reports_to\\": 2}, } # Update reporting structure by moving Bob under Charlie updated_employees = update_reports_structure(employees, 2, 3) # Expected output: # { # 1: {\\"name\\": \\"Alice\\", \\"reports_to\\": None}, # 2: {\\"name\\": \\"Bob\\", \\"reports_to\\": 3}, # 3: {\\"name\\": \\"Charlie\\", \\"reports_to\\": 1}, # 4: {\\"name\\": \\"David\\", \\"reports_to\\": 2}, # 5: {\\"name\\": \\"Eva\\", \\"reports_to\\": 2}, # } ``` # Notes 1. Validate that `emp_id` and `new_supervisor_id` exist in the dictionary. 2. Return an appropriate error if placing `emp_id` under `new_supervisor_id` would create a cyclic dependency. 3. Consider edge cases such as moving an employee to top-level management when `new_supervisor_id` is `None`.","solution":"def update_reports_structure(employees, emp_id, new_supervisor_id): Updates the reports-to structure for a given employee and their subtree. :param employees: Dictionary of employees with their reporting structure. :param emp_id: ID of the employee whose reporting structure needs to be updated. :param new_supervisor_id: ID of the new supervisor (or None for top-level) :returns: Updated dictionary with new reporting structure. def get_subtree(emp_id): Helper function to get all employees in the subtree of the given employee subtree = [] queue = [emp_id] while queue: current_id = queue.pop(0) subtree.append(current_id) # Find all employees reporting directly to current_id for e_id, details in employees.items(): if details[\'reports_to\'] == current_id: queue.append(e_id) return subtree # Detect if emp_id or new_supervisor_id does not exist if emp_id not in employees or (new_supervisor_id is not None and new_supervisor_id not in employees): raise ValueError(\\"Employee ID or New Supervisor ID does not exist.\\") # Detect cyclic dependency subtree_ids = get_subtree(emp_id) if new_supervisor_id in subtree_ids: raise ValueError(\\"Cyclic dependency detected.\\") # Update the reports_to for emp_id employees[emp_id][\'reports_to\'] = new_supervisor_id return employees"},{"question":"# Question: Unicode String Manipulator Implement a function named `unicode_string_manipulator` that performs multiple operations on Unicode strings: 1. **Input Handling**: - Accept an input string. - Accept a list of operations to perform on the string. Each operation consists of: - An operation code (`op_code`). - Additional parameters needed for the operation. 2. **Operation Types**: - `decode_utf8`: Decodes a UTF-8 encoded string. - Parameters: (string) - `encode_utf8`: Encodes the string to UTF-8. - Parameters: None - `get_length`: Returns the length of the Unicode string in code points. - Parameters: None - `to_upper`: Converts the string to uppercase. - Parameters: None - `replace`: Replaces a substring with another. - Parameters: (old_substr, new_substr, max_replace_count) - `substring`: Extracts a substring. - Parameters: (start, end) 3. **Function Signature**: ```python def unicode_string_manipulator(input_str: str, operations: list) -> list: pass ``` 4. **Constraints**: - Assume the input string is already decoded for operations other than `decode_utf8`. - The operations must be executed in the provided order. - Valid operation codes are guaranteed. 5. **Output**: - The function should return a list of results after performing each operation. If an operation modifies the string, update the string accordingly. # Example ```python operations = [ {\\"op_code\\": \\"decode_utf8\\", \\"params\\": [\\"xe2x9dxa4\\"]}, {\\"op_code\\": \\"to_upper\\", \\"params\\": []}, {\\"op_code\\": \\"substring\\", \\"params\\": [0, 1]}, {\\"op_code\\": \\"encode_utf8\\", \\"params\\": []} ] ``` - Decode hex-encoded UTF-8: `\\"❤\\"` - Convert to uppercase (no visible change for the emoji): `\\"❤\\"` - Extract the first character: `\\"❤\\"` - Encode to UTF-8: `b\'xe2x9dxa4\'` Result: ```python [b\'xe2x9dxa4\', \\"❤\\", \\"❤\\", b\'xe2x9dxa4\'] ``` # Function Template ```python def unicode_string_manipulator(input_str: str, operations: list) -> list: results = [] for op in operations: op_code = op[\\"op_code\\"] params = op[\\"params\\"] if op_code == \\"decode_utf8\\": # Decode the input string assuming it\'s a UTF-8 encoded byte string decoded_str = bytes(params[0], \'utf-8\').decode(\'utf-8\') results.append(decoded_str) input_str = decoded_str # Update input_str with the decoded string elif op_code == \\"encode_utf8\\": # Encode the input string to UTF-8 encoded_str = input_str.encode(\'utf-8\') results.append(encoded_str) elif op_code == \\"get_length\\": # Get the length of the input string in code points length = len(input_str) results.append(length) elif op_code == \\"to_upper\\": # Convert the input string to uppercase upper_str = input_str.upper() results.append(upper_str) input_str = upper_str # Update input_str with the uppercase string elif op_code == \\"replace\\": # Replace a substring with another old_substr, new_substr, max_replace_count = params replaced_str = input_str.replace(old_substr, new_substr, max_replace_count) results.append(replaced_str) input_str = replaced_str # Update input_str with the replaced string elif op_code == \\"substring\\": # Extract a substring based on start and end indices start, end = params substring = input_str[start:end] results.append(substring) return results ``` Ensure that your function covers the operations correctly and handles the strings as per the specifications.","solution":"def unicode_string_manipulator(input_str: str, operations: list) -> list: results = [] for op in operations: op_code = op[\\"op_code\\"] params = op[\\"params\\"] if op_code == \\"decode_utf8\\": # Decode the input string assuming it\'s a UTF-8 encoded byte string decoded_str = bytes(params[0], \'latin1\').decode(\'utf-8\') results.append(decoded_str) input_str = decoded_str # Update input_str with the decoded string elif op_code == \\"encode_utf8\\": # Encode the input string to UTF-8 encoded_str = input_str.encode(\'utf-8\') results.append(encoded_str) elif op_code == \\"get_length\\": # Get the length of the input string in code points length = len(input_str) results.append(length) elif op_code == \\"to_upper\\": # Convert the input string to uppercase upper_str = input_str.upper() results.append(upper_str) input_str = upper_str # Update input_str with the uppercase string elif op_code == \\"replace\\": # Replace a substring with another old_substr, new_substr, max_replace_count = params replaced_str = input_str.replace(old_substr, new_substr, max_replace_count) results.append(replaced_str) input_str = replaced_str # Update input_str with the replaced string elif op_code == \\"substring\\": # Extract a substring based on start and end indices start, end = params substring = input_str[start:end] results.append(substring) return results"},{"question":"# Complex Number Operations in Python You are required to implement a function that performs a series of arithmetic operations on complex numbers using the numerical functions provided in the `python310` package. The operations to be performed are as follows: 1. Add two complex numbers. 2. Subtract the second complex number from the first. 3. Multiply the two complex numbers. 4. Divide the first complex number by the second and return the floor division result. 5. Return the remainder of the division of the first complex number by the second. Your task is to implement the function `complex_operations(complex1, complex2)` that takes two complex numbers as inputs and returns a dictionary containing the results of the above operations. Function Signature: ```python def complex_operations(complex1, complex2): # Your code here ``` Input: - `complex1`, `complex2`: Two complex numbers. Output: - A dictionary with keys: `\'sum\'`, `\'difference\'`, `\'product\'`, `\'floor_div\'`, `\'remainder\'` and their corresponding values from the calculations. Constraints: - Use the provided `python310` package functions to perform the operations. - Handle any possible errors gracefully (e.g., division by zero). Example: ```python result = complex_operations(3+4j, 1+2j) print(result) # Expected Output: # { # \'sum\': (4+6j), # \'difference\': (2+2j), # \'product\': (-5+10j), # \'floor_div\': exception (or similar handling for complex number), # \'remainder\': exception (or similar handling for complex number) # } ``` Note: - For the purpose of this exercise, focus on demonstrating the use of `python310` package functions in handling complex numbers. - Consider edge cases and provide appropriate error handling, especially for operations that may not be straightforward with complex numbers.","solution":"import cmath import math def complex_operations(complex1, complex2): Performs arithmetic operations on two complex numbers. Parameters: - complex1: The first complex number. - complex2: The second complex number. Returns: A dictionary with the results of the operations. result = {} # Sum of two complex numbers result[\'sum\'] = complex1 + complex2 # Difference of two complex numbers result[\'difference\'] = complex1 - complex2 # Product of two complex numbers result[\'product\'] = complex1 * complex2 # Handle division operations separately to catch any exceptions try: # Complex number division (not flooring as it is not concrete in math for complex numbers) result[\'floor_div\'] = complex1 / complex2 except ZeroDivisionError: result[\'floor_div\'] = \'division by zero\' try: # Remainder computation isn\'t well-defined for complex numbers, so handle gracefully result[\'remainder\'] = \'operation not supported for complex numbers\' except Exception as e: result[\'remainder\'] = str(e) return result"},{"question":"Objective: The goal of this task is to demonstrate your understanding of Python\'s exception handling and the use of the `cgitb` module to provide detailed tracebacks. You will be required to simulate an environment where errors might occur and utilize `cgitb` to manage and report these errors effectively. Task: Create a Python function `process_data(data)` that processes a list of integers. Your task is to: 1. Raise an exception if an element of the list is not an integer. 2. Use `cgitb` to capture and display detailed exception tracebacks in plain text format. 3. Log these tracebacks to a file. Function Specification: - **Function Name:** `process_data` - **Parameters:** - `data` (list): A list of integers. - **Return:** None Implementation Details: 1. **Input Validation:** Iterate through the `data` list and raise a `TypeError` if any element is not an integer. 2. **Exception Handling:** Use the `cgitb` library to: - Display a detailed traceback in plain text format. - Save the traceback information to a file named `error_log.txt`. 3. **Output:** The function itself should not return any value, but should ensure that any error encountered is both displayed and logged. Example Usage: ```python import cgitb cgitb.enable(display=0, logdir=\'.\', context=3, format=\'text\') def process_data(data): try: for item in data: if not isinstance(item, int): raise TypeError(\\"All elements must be integers!\\") print(\\"Data processed successfully.\\") except Exception as e: cgitb.handler() ``` Constraints: - Do not use any external libraries except for `cgitb` and standard Python libraries. - Ensure that the traceback and error information is both displayed and logged correctly. Notes: - The generated log file should be human-readable and contain comprehensive traceback information to help debug the problem. - Test your implementation with both valid and invalid data lists to confirm that the error handling works as expected. Tips: - Use the `cgitb` module documentation provided to understand the available functions and their usage. - Consider edge cases such as empty lists or lists with mixed data types. Good luck, and happy coding!","solution":"import cgitb import sys # Enable cgitb to capture and log detailed traceback information cgitb.enable(format=\'text\', logdir=\'.\') def process_data(data): try: for item in data: if not isinstance(item, int): raise TypeError(\\"All elements must be integers!\\") print(\\"Data processed successfully.\\") except Exception as e: cgitb.handler()"},{"question":"You are provided with a dataset of automobile features, and you are required to create a comprehensive heatmap visualization using seaborn. Follow the steps below to complete the task. Dataset You can use seaborn\'s built-in \\"mpg\\" dataset for this task. Task Requirements: 1. **Data Loading and Preprocessing**: - Load the \\"mpg\\" dataset using `sns.load_dataset(\\"mpg\\")`. - Remove any rows with missing values. - Pivot the dataset to create a format suitable for heatmapping, where the rows should represent different car origins, columns should represent different cylinders, and the heatmap values should be the average horsepower. 2. **Heatmap Creation**: - Create a heatmap from the pivoted dataset. - Annotate the heatmap cells with the average horsepower values, formatted to one decimal place. 3. **Customization**: - Add lines between cells for clarity. - Use the \'coolwarm\' colormap. - Set the minimum and maximum data values for the colormap to be the 10th and 90th percentiles of the horsepower values. 4. **Aesthetic Tweaks**: - Set the x-axis labels to be shown at the top of the heatmap. - Remove x-axis and y-axis labels. Implementation Details: - **Function Name**: `create_custom_heatmap` - **Input**: None (The function directly uses seaborn\'s \\"mpg\\" dataset). - **Output**: None (The function should display the heatmap directly). Constraints: - Ensure proper handling of missing data. ```python import seaborn as sns import pandas as pd import matplotlib.pyplot as plt def create_custom_heatmap(): # Load dataset df = sns.load_dataset(\\"mpg\\") # Data preprocessing df = df.dropna(subset=[\\"horsepower\\", \\"cylinders\\", \\"origin\\"]) # Pivot dataset pivot_table = df.pivot_table(values=\\"horsepower\\", index=\\"origin\\", columns=\\"cylinders\\", aggfunc=\\"mean\\") # Calculate percentiles hp_values = df[\\"horsepower\\"].dropna() vmin = hp_values.quantile(0.10) vmax = hp_values.quantile(0.90) # Create heatmap ax = sns.heatmap(pivot_table, annot=True, fmt=\\".1f\\", linewidths=.5, cmap=\\"coolwarm\\", vmin=vmin, vmax=vmax) # Customize aesthetics ax.set(xlabel=\\"\\", ylabel=\\"\\") ax.xaxis.tick_top() # Display the plot plt.show() # Call the function to generate the heatmap create_custom_heatmap() ```","solution":"import seaborn as sns import pandas as pd import matplotlib.pyplot as plt def create_custom_heatmap(): # Load dataset df = sns.load_dataset(\\"mpg\\") # Data preprocessing df = df.dropna(subset=[\\"horsepower\\", \\"cylinders\\", \\"origin\\"]) # Pivot dataset pivot_table = df.pivot_table(values=\\"horsepower\\", index=\\"origin\\", columns=\\"cylinders\\", aggfunc=\\"mean\\") # Calculate percentiles hp_values = df[\\"horsepower\\"].dropna() vmin = hp_values.quantile(0.10) vmax = hp_values.quantile(0.90) # Create heatmap ax = sns.heatmap(pivot_table, annot=True, fmt=\\".1f\\", linewidths=.5, cmap=\\"coolwarm\\", vmin=vmin, vmax=vmax) # Customize aesthetics ax.set(xlabel=\\"\\", ylabel=\\"\\") ax.xaxis.tick_top() # Display the plot plt.show() # Call the function to generate the heatmap create_custom_heatmap()"},{"question":"# Question: Working with Toy and Real-World Datasets in Scikit-Learn **Objective:** Write a Python function that loads a specified dataset (either toy or real-world) and performs simple exploratory data analysis (EDA) on it. The function should: 1. Accept the name of a dataset (either \'iris\', \'digits\', \'wine\', \'breast_cancer\', or \'fetch_california_housing\') as input. 2. Load the dataset using the appropriate method from `sklearn.datasets`. - For \'iris\', \'digits\', \'wine\', and \'breast_cancer\' use the dataset loader. - For \'fetch_california_housing\' use the dataset fetcher. 3. Perform type checking to ensure valid dataset names are provided. 4. Display the following information about the dataset: - Number of samples (`n_samples`) and features (`n_features`). - Feature names. - Target names (if available). - First 5 samples of the dataset. **Function Signature:** ```python def load_and_analyze_dataset(dataset_name: str) -> None: pass ``` **Example Usage:** ```python load_and_analyze_dataset(\'iris\') ``` **Expected Output (for \'iris\'):** ``` Dataset: iris Number of samples: 150 Number of features: 4 Feature names: [\'sepal length (cm)\', \'sepal width (cm)\', \'petal length (cm)\', \'petal width (cm)\'] Target names: [\'setosa\' \'versicolor\' \'virginica\'] First 5 samples: [[5.1 3.5 1.4 0.2] [4.9 3. 1.4 0.2] [4.7 3.2 1.3 0.2] [4.6 3.1 1.5 0.2] [5. 3.6 1.4 0.2]] ``` **Constraints:** - Ensure the function handles invalid dataset names gracefully by displaying an appropriate error message. - The function should be efficient in terms of performance. **Tip:** Use the `sklearn.datasets.load_*` and `sklearn.datasets.fetch_*` functions to load the datasets. Utilize the Bunch object\'s attributes to access `data`, `target`, `feature_names`, and `target_names`.","solution":"from sklearn import datasets import numpy as np def load_and_analyze_dataset(dataset_name: str) -> None: Load a specified dataset and print some basic information about it. :param dataset_name: Name of the dataset to load. valid_datasets = [\'iris\', \'digits\', \'wine\', \'breast_cancer\', \'fetch_california_housing\'] if dataset_name not in valid_datasets: print(f\\"Error: \'{dataset_name}\' is not a valid dataset name.\\") print(f\\"Choose from: {valid_datasets}\\") return # Load the appropriate dataset if dataset_name == \'iris\': data = datasets.load_iris() elif dataset_name == \'digits\': data = datasets.load_digits() elif dataset_name == \'wine\': data = datasets.load_wine() elif dataset_name == \'breast_cancer\': data = datasets.load_breast_cancer() elif dataset_name == \'fetch_california_housing\': data = datasets.fetch_california_housing() # Print dataset information print(f\\"Dataset: {dataset_name}\\") n_samples, n_features = data.data.shape print(f\\"Number of samples: {n_samples}\\") print(f\\"Number of features: {n_features}\\") if hasattr(data, \'feature_names\'): print(f\\"Feature names: {list(data.feature_names)}\\") if hasattr(data, \'target_names\'): print(f\\"Target names: {list(data.target_names)}\\") print(\\"First 5 samples:\\") print(data.data[:5])"},{"question":"**Question: Implementing Conditional Tensor Operations with `torch.cond`** In this exercise, you are required to implement a PyTorch class that utilizes the `torch.cond` function to dynamically change the computation based on specific properties of the input tensor. You will implement a class `ConditionalComputation` that changes its computation strategy based on the sum and shape of the input tensor. # Requirements: 1. **Class Definition:** - Define a class `ConditionalComputation` that inherits from `torch.nn.Module`. 2. **`__init__` Method:** - Initialize the parent class with `super().__init__()`. 3. **`forward` Method:** - Implement a `forward` method that takes a single tensor `x` as input. - Use `torch.cond` to perform the following: - If the sum of `x` is greater than a specified threshold, apply a combination of cosine and sine functions. - If the shape of `x` has more than 2 elements, apply the sine function: - Otherwise, apply the product of the tensor with itself. # Constraints: - You can assume `x` is a 1-dimensional tensor of arbitrary length. - The threshold value is 5.0. - Avoid mutating the input tensor within the conditional branches. # Input: - A 1-dimensional tensor `x`. # Output: - A tensor with the same shape as `x`. # Example: ```python import torch # Example usage model = ConditionalComputation() # Case 1 (sum exceeds threshold) x1 = torch.tensor([1.0, 2.0, 3.0]) result1 = model(x1) # Expected to apply cosine and sine combination # Case 2 (shape exceeds threshold but sum does not) x2 = torch.tensor([1.0, 2.0]) result2 = model(x2) # Expected to apply sine function only # Case 3 (sum and shape do not meet conditions) x3 = torch.tensor([1.0]) result3 = model(x3) # Expected to apply the product of the tensor with itself ``` # Implementation: ```python import torch class ConditionalComputation(torch.nn.Module): def __init__(self): super().__init__() def forward(self, x: torch.Tensor) -> torch.Tensor: def true_fn_sum(t: torch.Tensor) -> torch.Tensor: return t.cos() + t.sin() def false_fn_sum(t: torch.Tensor) -> torch.Tensor: return torch.cond(t.shape[0] > 2, true_fn_shape, false_fn_shape, (t,)) def true_fn_shape(t: torch.Tensor) -> torch.Tensor: return t.sin() def false_fn_shape(t: torch.Tensor) -> torch.Tensor: return t * t return torch.cond(x.sum() > 5.0, true_fn_sum, false_fn_sum, (x,)) ``` Make sure to test the class with the given examples and additional test cases to validate your implementation.","solution":"import torch class ConditionalComputation(torch.nn.Module): def __init__(self): super().__init__() def forward(self, x: torch.Tensor) -> torch.Tensor: if x.sum() > 5.0: return x.cos() + x.sin() elif x.shape[0] > 2: return x.sin() else: return x * x"},{"question":"# Question: Implementing a DataFrame Operation with Copy-on-Write Rules You are provided with a DataFrame representing sales data of a company. Your task is to implement a function `process_sales_data` that modifies this DataFrame according to certain criteria. This task will test your understanding of the Copy-on-Write mechanism in pandas and how to handle operations without causing unintended side-effects. Function Signature ```python def process_sales_data(df: pd.DataFrame) -> pd.DataFrame: ``` Description 1. **Input**: - A `pandas.DataFrame` named `df` with columns: `[\'Product\', \'Region\', \'Sales\']`. 2. **Output**: - A `pandas.DataFrame` that meets the following criteria: - All rows where the \'Sales\' value is below 500 should have their \'Sales\' value increased by 50. - Any resultant DataFrame should not inadvertently modify the original DataFrame passed as input. 3. **Constraints**: - Ensure that the function uses the Copy-on-Write rules to avoid accidental changes to the input DataFrame. - Avoid using chained assignments as they are disallowed. 4. **Notes**: - Use appropriate pandas methods to ensure compliance with Copy-on-Write rules. - Your solution should handle both the in-place and out-of-place modification appropriately, ensuring no unintended side effects to the original DataFrame. Example: ```python import pandas as pd data = { \\"Product\\": [\\"A\\", \\"B\\", \\"C\\", \\"D\\"], \\"Region\\": [\\"North\\", \\"South\\", \\"East\\", \\"West\\"], \\"Sales\\": [450, 600, 480, 700] } df = pd.DataFrame(data) new_df = process_sales_data(df) print(new_df) # Expected output: The Sales column should be increased by 50 wherever the value is below 500. print(df) # The original df should remain unchanged. ``` Implement the `process_sales_data` function to satisfy the above criteria.","solution":"import pandas as pd def process_sales_data(df: pd.DataFrame) -> pd.DataFrame: Process the sales data by increasing the \'Sales\' value by 50 for all rows where \'Sales\' is below 500. Ensure that the original DataFrame is not modified. Parameters: df (pandas.DataFrame): Input DataFrame containing \'Product\', \'Region\', and \'Sales\' columns. Returns: pandas.DataFrame: A new DataFrame with applied modifications. # Create a copy of the original DataFrame to avoid modifying it modified_df = df.copy() # Apply the transformation modified_df.loc[modified_df[\'Sales\'] < 500, \'Sales\'] += 50 return modified_df"},{"question":"**Deep Learning Model Implementation Using TorchScript** # Objective: You are required to implement a deep learning model using PyTorch and convert it to TorchScript. Your task will assess your understanding of defining models, performing tensor operations, and utilizing TorchScript for optimization. # Task: 1. Implement a fully-connected (dense) neural network model in PyTorch. 2. Convert the model to TorchScript. 3. Perform a forward pass with a sample input tensor using the TorchScript model. # Specifications: 1. **Model Specification:** - The model should consist of 3 linear layers with the following configurations: - Input layer: 10 neurons - Hidden layer: 40 neurons - Output layer: 5 neurons 2. **Activation Functions:** - Use ReLU activation function after the input layer and hidden layer. - Do not use any activation function after the output layer. 3. **Conversion to TorchScript:** - Use the appropriate TorchScript method to convert the PyTorch model. 4. **Function Implementation:** - Implement a function `convert_to_torchscript` that takes a PyTorch model and returns the TorchScript version of the model. # Input: - An instance of the PyTorch model. # Output: - The TorchScript model. # Constraints: - The PyTorch model must be defined and implemented within the function. - Do not use any other deep learning frameworks. # Example: ```python import torch import torch.nn as nn import torch.jit as jit class SimpleModel(nn.Module): def __init__(self): super(SimpleModel, self).__init__() self.fc1 = nn.Linear(10, 40) self.fc2 = nn.Linear(40, 5) self.relu = nn.ReLU() def forward(self, x): x = self.relu(self.fc1(x)) x = self.fc2(x) return x def convert_to_torchscript(model): # 1. Convert the PyTorch model to TorchScript scripted_model = torch.jit.script(model) return scripted_model # Example usage # Define and initialize the model model = SimpleModel() # Convert the model to TorchScript scripted_model = convert_to_torchscript(model) # Create a sample input tensor input_tensor = torch.rand(1, 10) # Perform a forward pass using the TorchScript model output_tensor = scripted_model(input_tensor) # Print the output tensor print(output_tensor) ``` # Notes: - Ensure all necessary imports are included in your code. - You should define the model within the function for evaluation purposes. - Include appropriate comments to explain your implementation.","solution":"import torch import torch.nn as nn import torch.jit as jit # Define the fully-connected neural network model class FCModel(nn.Module): def __init__(self): super(FCModel, self).__init__() self.fc1 = nn.Linear(10, 40) self.fc2 = nn.Linear(40, 40) self.fc3 = nn.Linear(40, 5) self.relu = nn.ReLU() def forward(self, x): x = self.relu(self.fc1(x)) x = self.relu(self.fc2(x)) x = self.fc3(x) return x # Convert the model to TorchScript def convert_to_torchscript(model): Convert a PyTorch model to TorchScript. Args: model (nn.Module): A PyTorch model instance. Returns: torch.jit.ScriptModule: The TorchScript model. scripted_model = torch.jit.script(model) return scripted_model # Example usage if __name__ == \\"__main__\\": # Define and initialize the model model = FCModel() # Convert the model to TorchScript scripted_model = convert_to_torchscript(model) # Create a sample input tensor input_tensor = torch.rand(1, 10) # Perform a forward pass using the TorchScript model output_tensor = scripted_model(input_tensor) # Print the output tensor print(output_tensor)"},{"question":"**CSV Data Aggregator** You are required to implement a Python function that reads data from multiple CSV files, processes this data, and writes the aggregated result to a new CSV file. The function should handle different CSV dialects using the `csv` module. # Function Signature ```python def aggregate_csv_data(input_files: list, output_file: str, aggregate_column: str, data_column: str, aggregate_func): pass ``` # Parameters - `input_files` (list): A list of filenames (strings) from which to read data. Each CSV file may use a different dialect. - `output_file` (str): The filename (string) of the CSV file to which the aggregated data will be written. - `aggregate_column` (str): The name (string) of the column used for grouping the data. - `data_column` (str): The name (string) of the column whose values will be aggregated. - `aggregate_func`: A function that takes a list of values from the `data_column` and returns a single aggregated result (e.g., sum, mean, max, etc.). # Task 1. Implement the function to read data from the `input_files` using the `csv.DictReader` class. 2. Use the `aggregate_column` to group data from each file. 3. Apply the `aggregate_func` on the grouped values from the `data_column`. 4. Write the aggregated results to the `output_file` using the `csv.DictWriter` class. # Output Format The output CSV file should contain two columns: - The `aggregate_column` with unique values from the input files. - A new column `Aggregated_<data_column>` containing the result of the aggregation. # Example Suppose we have two input CSV files: - `file1.csv`: ``` Name,Score Alice,10 Bob,20 Alice,30 ``` - `file2.csv`: ``` Name,Score Alice,15 Bob,35 ``` And we want to aggregate the scores by summing them for each name, the function call would be: ```python def sum_scores(scores): return sum(scores) aggregate_csv_data([\'file1.csv\', \'file2.csv\'], \'output.csv\', \'Name\', \'Score\', sum_scores) ``` The output CSV `output.csv` should be: ``` Name,Aggregated_Score Alice,55 Bob,55 ``` # Constraints - The input CSV files are assumed to be small enough to fit into memory. - It is also assumed that the `aggregate_column` exists in all input files and has consistent spelling. - You can assume `aggregate_func` provided is a valid function for the data. # Notes - Pay careful attention to different CSV dialects. - Make sure to handle and report any errors in processing. - Document any assumptions you make in your implementation.","solution":"import csv from collections import defaultdict def aggregate_csv_data(input_files, output_file, aggregate_column, data_column, aggregate_func): data = defaultdict(list) # Read from all input files for file in input_files: with open(file, newline=\'\') as f: dialect = csv.Sniffer().sniff(f.read(1024)) f.seek(0) reader = csv.DictReader(f, dialect=dialect) for row in reader: data[row[aggregate_column]].append(float(row[data_column])) # Apply the aggregation function aggregated_data = {key: aggregate_func(values) for key, values in data.items()} # Write the aggregated data to output file with open(output_file, mode=\'w\', newline=\'\') as f: fieldnames = [aggregate_column, f\'Aggregated_{data_column}\'] writer = csv.DictWriter(f, fieldnames=fieldnames) writer.writeheader() for key, value in aggregated_data.items(): writer.writerow({aggregate_column: key, f\'Aggregated_{data_column}\': value})"},{"question":"# CSV File Processing with Python `csv` Module Objective: Write a Python script to read, process, and write CSV data using different dialects by leveraging the Python `csv` module. Problem Statement: You are given a CSV file `employees.csv` that contains a list of employees with the following columns: `first_name`, `last_name`, `department`, `salary`. Your task is to perform the following operations: 1. Read the data from `employees.csv` using the `DictReader` class. 2. Add a new column `annual_salary` which is computed as `salary * 12`. 3. Write the modified data to `processed_employees.csv` using the `DictWriter` class. 4. The new CSV file should follow a custom CSV dialect named `custom_dialect`, which you need to define according to the format below: - Delimiter: `;` - Quote character: `\\"` - Quoting: Only when necessary (use `csv.QUOTE_MINIMAL`) 5. Ensure proper error handling in the entire process. Input: The input file `employees.csv` has the following format: ``` first_name,last_name,department,salary John,Doe,Engineering,5000 Jane,Smith,Marketing,4500 Emily,Jones,Sales,4000 ... ``` Output: The output file `processed_employees.csv` should have an additional column `annual_salary` and should follow the `custom_dialect` format. Here’s an example of the expected output: ``` first_name;last_name;department;salary;annual_salary \\"John\\";\\"Doe\\";\\"Engineering\\";\\"5000\\";\\"60000\\" \\"Jane\\";\\"Smith\\";\\"Marketing\\";\\"4500\\";\\"54000\\" \\"Emily\\";\\"Jones\\";\\"Sales\\";\\"4000\\";\\"48000\\" ... ``` Constraints: - `employees.csv` will have at least one record. - `salary` is always a positive integer. Performance Requirements: - Efficiently handle files with thousands of records. - Ensure that the defined dialect is properly registered and applied. Implementation Notes: - You need to make sure that file reading and writing are correctly managed using context managers (`with` statement). - Proper error handling should be implemented to catch and report errors related to file operations and CSV processing. Example: For the given `employees.csv`: ``` first_name,last_name,department,salary John,Doe,Engineering,5000 Jane,Smith,Marketing,4500 Emily,Jones,Sales,4000 ``` Your script should output `processed_employees.csv`: ``` first_name;last_name;department;salary;annual_salary \\"John\\";\\"Doe\\";\\"Engineering\\";\\"5000\\";\\"60000\\" \\"Jane\\";\\"Smith\\";\\"Marketing\\";\\"4500\\";\\"54000\\" \\"Emily\\";\\"Jones\\";\\"Sales\\";\\"4000\\";\\"48000\\" ``` Evaluation Criteria: - Correct usage of `DictReader` and `DictWriter`. - Proper registration and usage of custom dialect. - Correct computation and inclusion of the `annual_salary` column. - Robust error handling and clean file operations. Submission: Submit your script file named `process_employees.py`.","solution":"import csv def process_employees(input_file, output_file): try: # Define custom dialect csv.register_dialect(\'custom_dialect\', delimiter=\';\', quotechar=\'\\"\', quoting=csv.QUOTE_MINIMAL) # Read input CSV file with open(input_file, mode=\'r\', newline=\'\') as infile: reader = csv.DictReader(infile) employees = list(reader) # Add \'annual_salary\' column for employee in employees: employee[\'annual_salary\'] = int(employee[\'salary\']) * 12 # Write to output CSV file with custom dialect with open(output_file, mode=\'w\', newline=\'\') as outfile: fieldnames = [\'first_name\', \'last_name\', \'department\', \'salary\', \'annual_salary\'] writer = csv.DictWriter(outfile, fieldnames=fieldnames, dialect=\'custom_dialect\') writer.writeheader() writer.writerows(employees) except Exception as e: print(f\\"An error occurred: {e}\\") # Example usage # process_employees(\'employees.csv\', \'processed_employees.csv\')"},{"question":"**Objective**: To demonstrate proficiency in using Python\'s standard library for file handling, JSON manipulation, and working with ZIP archives. **Problem Statement**: You are tasked with developing a Python script that processes a collection of JSON files. These JSON files contain information about various products. The script should perform the following tasks: 1. **Read JSON files**: The JSON files are located within a given directory (but it might also contain other types of files). 2. **Extract and Aggregate Data**: Extract the `price` of each product and calculate the average price for all products. 3. **Output a Summary**: Write this summary into a new JSON file named `summary.json` in the same directory. 4. **Compress the Files**: Finally, compress all JSON files (including the generated summary) into a ZIP archive named `json_files.zip`. **Input Format**: - A directory path that contains multiple JSON files. Each JSON file has the structure: ```json { \\"product_id\\": \\"string\\", \\"name\\": \\"string\\", \\"price\\": float } ``` **Output Format**: - A JSON file named `summary.json` with the structure: ```json { \\"average_price\\": float } ``` - A ZIP archive named `json_files.zip` containing all original JSON files along with the `summary.json` file. **Constraints**: - The directory may contain files that are not JSON. Ignore these files. - Ensure the script handles errors gracefully, such as malformed JSON or missing fields in JSON. - Use of the `os`, `json`, and `zipfile` modules is mandatory. - The solution should be efficient and make minimal assumptions about the external environment. **Performance Requirements**: - The script should be able to process directories containing at least 10,000 JSON files within a reasonable time frame. **Function Signature**: ```python def process_directory(directory_path: str) -> None: Processes the JSON files in the given directory. Args: directory_path (str): The path to the directory containing JSON files. Returns: None ``` **Example**: Suppose the directory `/path/to/dir` contains the following JSON files: - `product_1.json` - `product_2.json` - `example.txt` (this should be ignored) - etc. The function call: ```python process_directory(\'/path/to/dir\') ``` should produce: - A file `/path/to/dir/summary.json` with the average price of products. - A ZIP archive `/path/to/dir/json_files.zip` containing `product_1.json`, `product_2.json`, and `summary.json`. **Guidelines**: - Ensure that the code is well-documented. - Write clean, readable, and Pythonic code. - Handle exceptions and edge cases appropriately. **Good Luck!**","solution":"import os import json import zipfile def process_directory(directory_path: str) -> None: Processes the JSON files in the given directory. Reads all JSON files, calculates the average price of products, writes a summary JSON file, and compresses all JSON files into a ZIP archive. Args: directory_path (str): The path to the directory containing JSON files. Returns: None json_files = [] prices = [] # Traverse all files in the directory for filename in os.listdir(directory_path): if filename.endswith(\\".json\\"): file_path = os.path.join(directory_path, filename) try: with open(file_path, \'r\') as f: data = json.load(f) if \'price\' in data: prices.append(data[\'price\']) json_files.append(file_path) except (json.JSONDecodeError, KeyError): # Skip files with malformed JSON or missing \'price\' continue if prices: average_price = sum(prices) / len(prices) else: average_price = 0.0 summary_data = { \\"average_price\\": average_price } summary_file_path = os.path.join(directory_path, \'summary.json\') with open(summary_file_path, \'w\') as summary_file: json.dump(summary_data, summary_file, indent=4) # Include the summary file in the ZIP archive json_files.append(summary_file_path) # Compress all JSON files into a ZIP archive zip_file_path = os.path.join(directory_path, \'json_files.zip\') with zipfile.ZipFile(zip_file_path, \'w\') as zipf: for file in json_files: zipf.write(file, os.path.basename(file))"},{"question":"# Question: Implement a Custom Module Loader Using `importlib` This question requires you to implement a function that mimics the behavior of the deprecated `imp` module functions using the `importlib` module. Specifically, you need to create a function that can find and load a given module by its name. Function Signature ```python def custom_import(module_name: str): pass ``` Input - `module_name`: A string representing the name of the module to be imported. The module can be a standard library module or any installed third-party module. Output - Returns the imported module object if the module is found and loaded successfully. - Raises an `ImportError` with an appropriate message if the module cannot be found or loaded. Constraints - Your solution should only utilize the `importlib` module and standard library functionalities. - Do not use the deprecated `imp` module functions. - Ensure that any file objects or resources opened during the loading process are properly closed to prevent resource leaks. Example Usage ```python # Example usage of custom_import try: os_module = custom_import(\'os\') print(os_module.name) # Should print \'os\' except ImportError as e: print(e) ``` Notes - You may refer to the `importlib` module documentation for the recommended ways to find and load modules dynamically. - Consider handling modules that might already be imported to avoid unnecessary re-importing. - If working with submodules (modules with dots in their names like `os.path`), ensure to handle them appropriately.","solution":"import importlib def custom_import(module_name: str): Mimics the behavior of `imp` module functions using the `importlib` module to find and load a given module by its name. Args: - module_name: A string representing the name of the module to be imported. Returns: - The imported module object if the module is found and loaded successfully. Raises: - ImportError if the module cannot be found or loaded. try: module = importlib.import_module(module_name) return module except ModuleNotFoundError: raise ImportError(f\\"Module \'{module_name}\' not found\\")"},{"question":"<|Analysis Begin|> The provided documentation is quite limited, focusing on setting axis limits in seaborn plots using the new `seaborn.objects` interface. The core examples provided show how to: 1. Create a basic line plot with markers. 2. Set custom axis limits using the `limit` method. 3. Invert an axis by reversing the min and max values. 4. Use `None` to maintain the default value for one side of the limit. From this, we can infer that the `seaborn.objects` module provides a flexible but still somewhat experimental API for creating plots and setting their properties. There is a substantial emphasis on plotting, specifying axis limits, and modifying axis orientations. Overall, it indicates that the students need to understand how to manipulate plot axes using the given `seaborn.objects` methods. Given this context, a suitable coding assessment question would involve creating a plot using `seaborn.objects`, then adjusting and controlling plot axes. <|Analysis End|> <|Question Begin|> # Coding Assessment Question Objective: You are tasked with visualizing a dataset and customizing the plot axes using the `seaborn.objects` module in Python. Problem Statement: Given a dataset of points represented by two lists of coordinates `x_coords` and `y_coords`, you need to: 1. Create a scatter plot of the points. 2. Set custom axis limits for both x and y axes. 3. Invert one of the axes to visualize the plot from a different angle. 4. Ensure that throughout this process, if any limit is not specified, it should remain the default limit set by seaborn. Input: - `x_coords`: A list of x coordinates (e.g., `[1, 2, 3, 4]`) - `y_coords`: A list of y coordinates (e.g., `[4, 3, 2, 1]`) - `x_limits`: A tuple of two values representing the minimum and maximum limits for the x-axis (e.g., `(0, 5)`). If either value is `None`, the default value should be used. - `y_limits`: A tuple of two values representing the minimum and maximum limits for the y-axis (e.g., `(0, 5)`). If either value is `None`, the default value should be used. - `invert_axis`: A string that can be either `\\"x\\"` or `\\"y\\"` indicating which axis to invert. If it is not either of these, no axis should be inverted. Output: - Return the seaborn plot object after applying the specified axis customizations. Constraints: - You can assume that `x_coords` and `y_coords` will always have the same length. - The values in `x_limits` and `y_limits` can be either numeric or `None`. - The `invert_axis` string will always be either `\\"x\\"`, `\\"y\\"`, or an empty string. Function Signature: ```python def customize_plot(x_coords, y_coords, x_limits, y_limits, invert_axis): # Implementation here pass ``` # Example ```python # Example input x_coords = [1, 2, 3, 4] y_coords = [4, 3, 2, 1] x_limits = (0, 5) y_limits = (None, 4) invert_axis = \\"y\\" # Function call plot = customize_plot(x_coords, y_coords, x_limits, y_limits, invert_axis) # You may not see plot output in a typical script/run scenario; however, # in an interactive notebook, you can use `plot.show()` to display the plot. ``` # Note: Your solution should return the seaborn plot object with the expected customizations applied. Use the examples given in the documentation to guide you on seaborn object usage.","solution":"import seaborn.objects as so import matplotlib.pyplot as plt def customize_plot(x_coords, y_coords, x_limits, y_limits, invert_axis): Creates a seaborn scatter plot with the given coordinates and customizes the plot axes based on the provided limits and inversion requirement. Args: x_coords: List of x coordinates. y_coords: List of y coordinates. x_limits: Tuple of two values (min, max) for x-axis limits. y_limits: Tuple of two values (min, max) for y-axis limits. invert_axis: String specifying which axis to invert (\'x\', \'y\', or \'\'). Returns: Seaborn plot object after applying the customizations. # Create scatter plot plot = so.Plot(x=x_coords, y=y_coords).add(so.Dot()) # Set x-axis limits if x_limits[0] is not None and x_limits[1] is not None: plot = plot.limit(x=x_limits) elif x_limits[0] is not None: plot = plot.limit(x=(x_limits[0], None)) elif x_limits[1] is not None: plot = plot.limit(x=(None, x_limits[1])) # Set y-axis limits if y_limits[0] is not None and y_limits[1] is not None: plot = plot.limit(y=y_limits) elif y_limits[0] is not None: plot = plot.limit(y=(y_limits[0], None)) elif y_limits[1] is not None: plot = plot.limit(y=(None, y_limits[1])) # Invert axis if specified if invert_axis == \\"x\\": plot = plot.limit(x=(x_limits[1], x_limits[0])) elif invert_axis == \\"y\\": plot = plot.limit(y=(y_limits[1], y_limits[0])) return plot"},{"question":"# Gzip File Operations **Problem:** You are given several tasks to perform on GZIP-compressed files using Python\'s `gzip` module. Write a function `perform_gzip_operations` that accepts a list of operations and processes them accordingly. Each operation is a dictionary that represents a single task to be performed using the `gzip` module. The supported operations are: 1. **Compress a string:** - `\\"operation\\": \\"compress\\"` - `\\"input\\": \\"string to be compressed\\"` - `\\"output\\": \\"compressed filename\\"` 2. **Decompress a file:** - `\\"operation\\": \\"decompress\\"` - `\\"input\\": \\"compressed filename\\"` - `\\"output\\": \\"decompressed content\\"` (store the decompressed content as a string in this key) 3. **Read a compressed file:** - `\\"operation\\": \\"read\\"` - `\\"input\\": \\"compressed filename\\"` - `\\"output\\": \\"file content\\"` (store the file content as a string in this key) 4. **Write compressed file:** - `\\"operation\\": \\"write\\"` - `\\"input\\": \\"content to be written\\"` - `\\"output\\": \\"compressed filename\\"` The function should process each operation in sequence and return the list of operations with the appropriate outputs where required. **Input:** - `operations` (list): A list of dictionaries representing the operations to be performed. **Output:** - A list of dictionaries with the modified operations (with results included in them). **Constraints:** - Assume the given filenames are valid paths on the filesystem. - Assume all operations are valid and the files specified in the input exist for relevant operations. **Example:** ```python def perform_gzip_operations(operations): # Implement your code here # Example Usage operations = [ {\\"operation\\": \\"compress\\", \\"input\\": \\"Hello World\\", \\"output\\": \\"hello.gz\\"}, {\\"operation\\": \\"decompress\\", \\"input\\": \\"hello.gz\\", \\"output\\": \\"decompressed_content\\"}, {\\"operation\\": \\"read\\", \\"input\\": \\"somefile.txt.gz\\", \\"output\\": \\"file_content\\"}, {\\"operation\\": \\"write\\", \\"input\\": \\"Another Hello\\", \\"output\\": \\"anotherhello.gz\\"} ] result = perform_gzip_operations(operations) print(result) ``` **Expected Output:** ```python [ {\\"operation\\": \\"compress\\", \\"input\\": \\"Hello World\\", \\"output\\": \\"hello.gz\\"}, {\\"operation\\": \\"decompress\\", \\"input\\": \\"hello.gz\\", \\"output\\": \\"Hello World\\"}, {\\"operation\\": \\"read\\", \\"input\\": \\"somefile.txt.gz\\", \\"output\\": \\"content in the file\\"}, {\\"operation\\": \\"write\\", \\"input\\": \\"Another Hello\\", \\"output\\": \\"anotherhello.gz\\"} ] ``` **Note:** Actual file content in the read operation\'s output will depend on the contents of \'somefile.txt.gz\' on the filesystem. **Implementation Notes:** - Use `gzip.compress`, `gzip.decompress`, `gzip.open` where appropriate. - Handle reading and writing of files using the `gzip` module. - Ensure the results are correctly placed in the respective keys of each operation dictionary.","solution":"import gzip def perform_gzip_operations(operations): results = [] for operation in operations: if operation[\'operation\'] == \'compress\': with gzip.open(operation[\'output\'], \'wb\') as f: f.write(operation[\'input\'].encode(\'utf-8\')) elif operation[\'operation\'] == \'decompress\': with gzip.open(operation[\'input\'], \'rb\') as f: file_content = f.read() operation[\'output\'] = file_content.decode(\'utf-8\') elif operation[\'operation\'] == \'read\': with gzip.open(operation[\'input\'], \'rb\') as f: file_content = f.read() operation[\'output\'] = file_content.decode(\'utf-8\') elif operation[\'operation\'] == \'write\': with gzip.open(operation[\'output\'], \'wb\') as f: f.write(operation[\'input\'].encode(\'utf-8\')) results.append(operation) return results"},{"question":"**Question: PyTorch Tensor Comparison and Verification** In this exercise, you are required to write a function in Python that performs a series of operations on tensors and verifies their correctness using functions from the `torch.testing` module. # Function Signature ```python def tensor_operations_and_verification(input_tensor_size: tuple, tolerance: float) -> bool: ``` # Input - `input_tensor_size` (tuple): A tuple representing the shape of the tensor to be created. For example, `(3, 3)` would denote a 3x3 tensor. - `tolerance` (float): The tolerance level for comparing tensors. # Output - Returns a `bool`: `True` if all tensor verifications pass, `False` otherwise. # Function Requirements 1. **Tensor Creation**: - Use `torch.testing.make_tensor` to create two tensors of the specified size with random values. 2. **Tensor Manipulation**: - Create a third tensor as the sum of the two previously created tensors. 3. **Tensor Verification**: - Verify if the sum tensor is close to a manually computed tensor (element-wise addition of the two created tensors) using `torch.testing.assert_close`. - Verify that differences between the manually computed tensor and the sum tensor are within the specified tolerance using `torch.testing.assert_allclose`. # Constraints - You must use the `torch.testing` functions to perform tensor verifications. - The tolerance for `assert_allclose` should be set as per the input parameter `tolerance`. # Example ```python input_tensor_size = (2, 2) tolerance = 1e-5 # Expected to return True or False based on checks print(tensor_operations_and_verification(input_tensor_size, tolerance)) ``` # Note Ensure your solution handles the potential pitfalls of floating-point calculations and makes use of the comparison functions appropriately to validate the results.","solution":"import torch import torch.testing def tensor_operations_and_verification(input_tensor_size: tuple, tolerance: float) -> bool: Performs a series of operations on tensors and verifies their correctness using functions from torch.testing module. Parameters: input_tensor_size (tuple): A tuple representing the shape of the tensor to be created. tolerance (float): The tolerance level for comparing tensors. Returns: bool: True if all tensor verifications pass, False otherwise. # Create two random tensors of the specified size tensor1 = torch.testing.make_tensor(input_tensor_size, dtype=torch.float32, device=\'cpu\') tensor2 = torch.testing.make_tensor(input_tensor_size, dtype=torch.float32, device=\'cpu\') # Create a third tensor as the sum of the two previously created tensors sum_tensor = tensor1 + tensor2 # Manually compute the sum tensor for verification (element-wise addition) manual_sum_tensor = torch.add(tensor1, tensor2) try: # Verify if the sum tensor is close to the manually computed tensor using torch.testing.assert_close torch.testing.assert_close(sum_tensor, manual_sum_tensor, rtol=tolerance, atol=tolerance) # Verify that differences between the manually computed tensor and the sum tensor # are within the specified tolerance using torch.testing.assert_allclose torch.testing.assert_allclose(sum_tensor, manual_sum_tensor, rtol=tolerance, atol=tolerance) return True except AssertionError: return False"},{"question":"# Custom URL Opener with Error Handling **Objective**: Demonstrate understanding of advanced `urllib.request` functionalities including `urlopen`, custom handlers, and managing HTTP errors. # Problem Statement You need to create a Python function `fetch_url_content(url)` that performs the following: 1. Opens a given URL and retrieves its content. 2. Handles HTTP errors gracefully, retrying the request up to 3 times if the error code indicates potential recovery (e.g., 500 series errors). 3. Uses custom headers to simulate an actual browser request. 4. Implements timeout handling with a timeout period of 10 seconds. # Function Signature ```python def fetch_url_content(url: str) -> str: pass ``` # Input - `url` (str): A valid URL string to fetch the content. # Output - Returns the content of the URL (str) if successfully retrieved. - Raises an appropriate exception if it fails after all retries. # Constraints 1. You can assume the URL is always a valid web address. 2. You will use the `urllib.request` module for this problem. 3. Implement the function using proper exception handling, retries, and custom handlers. # Example Usage ```python content = fetch_url_content(\'http://www.python.org/\') print(content) ``` # Detailed Requirements - Use `urllib.request.Request` to create the request object. - Add custom headers, mimicking a browser request, such as \\"User-Agent\\". - Implement error handling for HTTP status codes, especially focusing on retry logic for 500 series errors. - Ensure the function raises a descriptive error if all retries fail. # Hint - Utilize `urlopen` within a context manager to handle the response. - Use the `add_header` method to include custom headers in the request. - Implement a loop for the retry mechanism and proper exception handling. # Notes - You may refer to the `urllib.request` module documentation to understand the nuances of different handlers and exceptions. - Handle SSL context and proxies if required, following best practices mentioned in the documentation. **Good Luck!**","solution":"import urllib.request import urllib.error def fetch_url_content(url: str) -> str: Fetches the content of the given URL, retrying up to 3 times in case of HTTP 500 series errors. Args: url (str): The URL to fetch content from. Returns: str: The content of the URL if the request is successful. Raises: Exception: If the request fails after all retries. headers = { \'User-Agent\': \'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\' } req = urllib.request.Request(url, headers=headers) retries = 3 while retries > 0: try: with urllib.request.urlopen(req, timeout=10) as response: return response.read().decode(\'utf-8\') except urllib.error.HTTPError as e: if 500 <= e.code < 600: retries -= 1 if retries == 0: raise Exception(f\\"Failed to fetch URL after 3 retries due to server error: {e}\\") from e else: raise Exception(f\\"Failed to fetch URL due to HTTP error: {e}\\") from e except urllib.error.URLError as e: raise Exception(f\\"Failed to fetch URL due to URL error: {e}\\") from e"},{"question":"Python Coding Assessment Question # Objective Demonstrate your understanding of iterators and how to handle them in Python. # Problem Statement You are required to implement a custom iterator that generates a sequence of numbers, each number being the sum of the previous two numbers, also known as the Fibonacci sequence. Additionally, you need to write a function that uses this iterator to fetch the first `n` Fibonacci numbers. # Implement the following: 1. **Class `FibonacciIterator`:** - **`__init__(self, max_elements: int)`:** Initializes the iterator with the maximum number of elements to generate. - **`__iter__(self)`:** Returns the iterator object itself. - **`__next__(self)`:** Returns the next number in the Fibonacci sequence. Raises `StopIteration` when the maximum number of elements is reached. 2. **Function `get_fibonacci_sequence(n: int) -> List[int]`:** - Uses the `FibonacciIterator` to generate and return a list containing the first `n` Fibonacci numbers. # Constraints - `max_elements` and `n` will be positive integers not exceeding 10,000. - You need to handle both initialization and iteration properly, ensuring no memory leaks or excessive computations occur. # Input and Output Examples ```python # Example 1: f_iterator = FibonacciIterator(5) print(list(f_iterator)) # Output: [0, 1, 1, 2, 3] # Example 2: print(get_fibonacci_sequence(7)) # Output: [0, 1, 1, 2, 3, 5, 8] ``` # Performance Requirements - Your implementation should efficiently handle the iteration, especially with the potentially large input `max_elements` and `n`. - Make sure that your code follows Python\'s iterator protocol strictly.","solution":"class FibonacciIterator: Iterator for generating Fibonacci sequence up to a given number of elements. def __init__(self, max_elements): Initializes the iterator with the maximum number of elements to generate. :param max_elements: The maximum number of elements in the Fibonacci sequence. self.max_elements = max_elements self.current_count = 0 self.prev, self.curr = 0, 1 def __iter__(self): return self def __next__(self): if self.current_count >= self.max_elements: raise StopIteration if self.current_count == 0: self.current_count += 1 return 0 elif self.current_count == 1: self.current_count += 1 return 1 else: next_value = self.prev + self.curr self.prev, self.curr = self.curr, next_value self.current_count += 1 return next_value def get_fibonacci_sequence(n): Generates the first n Fibonacci numbers using the FibonacciIterator. :param n: The number of Fibonacci numbers to generate. :return: A list containing the first n Fibonacci numbers. return list(FibonacciIterator(n))"},{"question":"# Python Coding Assessment Question: **Objective:** Demonstrate your understanding of the cell object mechanism in Python by implementing a Python class that utilizes these concepts to manage variables across multiple scopes. **Task:** Implement a Python class `ScopeManager` that simulates the behavior of cell objects and provides functionalities to manage variables across different scopes. The class should include methods to create a variable, get the value of a variable, set a new value to a variable, and check if an object is a cell. **Class Definition:** ```python class ScopeManager: def __init__(self): # Initialize the scope manager with necessary attributes pass def create_variable(self, value): Create a new \'cell\' object containing the value. Parameters: value (Any): The value to be stored in the cell. Returns: cell (tuple): A tuple that simulates the cell object containing the value. pass def get_value(self, cell): Retrieve the value stored in the \'cell\' object. Parameters: cell (tuple): The cell object from which to retrieve the value. Returns: value (Any): The value contained in the cell. pass def set_value(self, cell, value): Set a new value in the \'cell\' object. Parameters: cell (tuple): The cell object in which to set the value. value (Any): The new value to be set in the cell. Returns: None pass def is_cell(self, obj): Check if an object is a cell object. Parameters: obj (Any): The object to be checked. Returns: result (bool): True if the object is a cell; False otherwise. pass ``` **Constraints:** 1. Do not use any external libraries. 2. The `ScopeManager` class should manage its own representation of cell objects (e.g., using tuples to simulate cells). 3. Ensure that your methods handle invalid inputs gracefully without breaking the execution. **Example Usage:** ```python scope_manager = ScopeManager() # Create a new variable and store its \'cell\' cell = scope_manager.create_variable(42) # Retrieve the value from the cell value = scope_manager.get_value(cell) print(value) # Output: 42 # Check if an object is a cell print(scope_manager.is_cell(cell)) # Output: True print(scope_manager.is_cell(100)) # Output: False # Set a new value in the cell scope_manager.set_value(cell, 100) new_value = scope_manager.get_value(cell) print(new_value) # Output: 100 ``` **Notes:** - You may assume that the underlying implementation of the cell object is a tuple for simplicity. - Pay attention to handling different data types and edge cases appropriately.","solution":"class ScopeManager: def __init__(self): # No initialization needed for this example pass def create_variable(self, value): Create a new \'cell\' object containing the value. Parameters: value (Any): The value to be stored in the cell. Returns: cell (list): A list of one element that simulates the cell object containing the value. return [value] def get_value(self, cell): Retrieve the value stored in the \'cell\' object. Parameters: cell (list): The cell object from which to retrieve the value. Returns: value (Any): The value contained in the cell. return cell[0] def set_value(self, cell, value): Set a new value in the \'cell\' object. Parameters: cell (list): The cell object in which to set the value. value (Any): The new value to be set in the cell. Returns: None cell[0] = value def is_cell(self, obj): Check if an object is a cell object. Parameters: obj (Any): The object to be checked. Returns: result (bool): True if the object is a cell; False otherwise. return isinstance(obj, list) and len(obj) == 1"},{"question":"# LZMA Compression and Decompression Task In this task, you are required to implement a Python program that performs both compression and decompression using the `lzma` module. Your solution should be able to handle file input/output and apply custom filter chains to optimize compression, while confirming that the decompressed data matches the original data. Requirements: 1. **Compression Function**: Implement a function `compress_to_xz(input_file_path, output_file_path)` that: - Reads the contents of the file at `input_file_path`. - Compresses the contents using a custom filter chain. - Writes the compressed data to `output_file_path` as an `.xz` file. 2. **Decompression Function**: Implement a function `decompress_from_xz(input_file_path, output_file_path)` that: - Reads the `.xz` file at `input_file_path`. - Decompresses the data. - Writes the decompressed data to `output_file_path`. 3. **Filter Chain**: The custom filter chain for compression should be: ```python my_filters = [ {\\"id\\": lzma.FILTER_DELTA, \\"dist\\": 4}, {\\"id\\": lzma.FILTER_LZMA2, \\"preset\\": 6 | lzma.PRESET_EXTREME}, ] ``` 4. **Equality Check**: Ensure that the content of the file after decompression is identical to the original content before compression. Constraints: - The input and output file paths are strings, and the files contain binary data. - You should handle any possible `LZMAError` exceptions that might occur during compression or decompression. Example Usage: ```python # Compress the file compress_to_xz(\'input.txt\', \'output.xz\') # Decompress the file decompress_from_xz(\'output.xz\', \'decompressed.txt\') # Verify that \'decompressed.txt\' has the same content as \'input.txt\' ``` Test Cases: 1. **Simple Text File**: - Input: A small text file with a few lines of text. - Output: Verify decompressed content matches original. 2. **Binary Data File**: - Input: A file containing binary data. - Output: Verify decompressed content matches original. 3. **Large Data File**: - Input: A large text or binary file. - Output: Verify decompressed content matches original, checking for any performance issues. Performance: - The implemented solution should handle small to moderately large files efficiently.","solution":"import lzma def compress_to_xz(input_file_path, output_file_path): Compresses the contents of input_file_path using LZMA with custom filter chain and writes the compressed data to output_file_path. my_filters = [ {\\"id\\": lzma.FILTER_DELTA, \\"dist\\": 4}, {\\"id\\": lzma.FILTER_LZMA2, \\"preset\\": 6 | lzma.PRESET_EXTREME}, ] try: with open(input_file_path, \'rb\') as input_file: data = input_file.read() compressed_data = lzma.compress(data, format=lzma.FORMAT_XZ, filters=my_filters) with open(output_file_path, \'wb\') as output_file: output_file.write(compressed_data) except lzma.LZMAError as e: print(f\\"An error occurred during compression: {e}\\") def decompress_from_xz(input_file_path, output_file_path): Decompresses the LZMA compressed file at input_file_path and writes the decompressed data to output_file_path. try: with open(input_file_path, \'rb\') as input_file: compressed_data = input_file.read() decompressed_data = lzma.decompress(compressed_data) with open(output_file_path, \'wb\') as output_file: output_file.write(decompressed_data) except lzma.LZMAError as e: print(f\\"An error occurred during decompression: {e}\\")"},{"question":"# Question: You are provided with a dataset containing brain network connectivity measurements over time. Using seaborn\'s new `objects` interface, you need to analyze and visualize this dataset. Your task is to write a function `plot_brain_networks` that processes and visualizes the data as specified. Input: - The dataset is already available in the variable `networks`, loaded and preprocessed as part of the script. - The dataset has the following structure after processing: ```plaintext timepoint hemi network 1 left 0.23 1 right 0.25 2 left 0.30 ... ``` - The task involves analyzing data for time points less than 100. Output: - A pair plot with paths showing the relationship between four specific networks: \\"5\\", \\"8\\", \\"12\\", and \\"15\\". - Customize the plot to share axes and adjust the layout size. - Differentiate the paths by the \\"hemi\\" variable. Function Signature: ```python def plot_brain_networks(): pass ``` Constraints: - Use seaborn\'s objects interface to create the plot. - Ensure that the plot layout and customization parameters are set as specified. Example Call: ```python plot_brain_networks() ``` After calling the function, a matplotlib figure should be displayed with the specified customizations. Data Preprocessing (already included in script): ```python import seaborn.objects as so from seaborn import load_dataset networks = ( load_dataset(\\"brain_networks\\", header=[0, 1, 2], index_col=0) .rename_axis(\\"timepoint\\") .stack([0, 1, 2]) .groupby([\\"timepoint\\", \\"network\\", \\"hemi\\"]) .mean() .unstack(\\"network\\") .reset_index() .query(\\"timepoint < 100\\") ) ``` Visualization: Use the following code snippets as guidance to create your function: ```python p = ( so.Plot(networks) .pair( x=[\\"5\\", \\"8\\", \\"12\\", \\"15\\"], y=[\\"6\\", \\"13\\", \\"16\\"], ) .layout(size=(8, 5)) .share(x=True, y=True) ) p.add(so.Paths(linewidth=1, alpha=.8), color=\\"hemi\\") ``` Ensure the function correctly visualizes the data as per the requirements.","solution":"import seaborn.objects as so from seaborn import load_dataset def plot_brain_networks(): networks = ( load_dataset(\\"brain_networks\\", header=[0, 1, 2], index_col=0) .rename_axis(\\"timepoint\\") .stack([0, 1, 2]) .groupby([\\"timepoint\\", \\"network\\", \\"hemi\\"]) .mean() .unstack(\\"network\\") .reset_index() .query(\\"timepoint < 100\\") ) p = ( so.Plot(data=networks) .pair( x=[\\"5\\", \\"8\\", \\"12\\", \\"15\\"], y=[\\"5\\", \\"8\\", \\"12\\", \\"15\\"], ) .layout(size=(8, 5)) .share(x=True, y=True) ) p.add(so.Paths(linewidth=1, alpha=.8), color=\\"hemi\\") p.show()"},{"question":"**Objective**: Implement a function that starts multiple worker processes using PyTorch\'s `torch.distributed.elastic.multiprocessing` module. The function will run a given task concurrently in separate processes and return the result. **Function Specification**: ```python import torch.distributed.elastic.multiprocessing as mp def run_concurrent_tasks(task_fn, num_processes, *args): Runs the specified task function concurrently in multiple processes. Args: - task_fn (callable): The task function to run in each process. Must accept *args as arguments. - num_processes (int): The number of processes to start. - *args: The arguments to pass to the task function. Returns: - results (List): A list of results returned by each process. # Your implementation here # Example Usage: def example_task(x): return x * x results = run_concurrent_tasks(example_task, 4, 5) print(results) # Expected output: [25, 25, 25, 25] ``` **Input/Output**: - The function `run_concurrent_tasks` receives a task function `task_fn`, an integer `num_processes`, and any number of additional arguments `*args` that should be passed to the task function. - It returns a list containing the results returned by each process. **Constraints**: - Ensure the task function `task_fn` and its arguments are compatible with multiprocessing. - Handle process creation, execution, and synchronization properly. - Processes should run concurrently and independently. **Performance Requirements**: - The function should efficiently manage system resources. - Ensure minimal overhead in process management. **Notes**: - You are encouraged to use the `torch.distributed.elastic.multiprocessing.start_processes` function to start the processes. - Consider the use of context classes such as `MultiprocessContext` to manage the process states and results. Make sure your implementation adheres to the principles of multiprocessing and distributed computing as facilitated by PyTorch.","solution":"import torch.distributed.elastic.multiprocessing as mp import torch.multiprocessing as torch_mp from typing import List, Callable def run_concurrent_tasks(task_fn: Callable, num_processes: int, *args) -> List: Runs the specified task function concurrently in multiple processes. Args: - task_fn (callable): The task function to run in each process. Must accept *args as arguments. - num_processes (int): The number of processes to start. - *args: The arguments to pass to the task function. Returns: - results (List): A list of results returned by each process. def task_wrapper(task_fn, args, results, index): # Execute the task and store the result in the shared results list results[index] = task_fn(*args) # Create a shared list to store results manager = torch_mp.Manager() results = manager.list([None] * num_processes) # Create and start the processes processes = [] for i in range(num_processes): p = torch_mp.Process(target=task_wrapper, args=(task_fn, args, results, i)) p.start() processes.append(p) # Wait for all processes to finish for p in processes: p.join() return list(results)"},{"question":"**Objective:** To test the understanding of WSGI environment manipulation and the implementation of a simple WSGI application using the `wsgiref` library. **Problem Statement:** You are tasked with creating a WSGI-based web application that can serve static files from a given directory and provide a custom error page for non-existing files. 1. **Environment Setup:** - Create a simple WSGI server using `wsgiref.simple_server.make_server`. - The server should listen on a specified port and serve files from a specified directory. 2. **Application Requirements:** - Implement a WSGI application function named `file_server_app` that accepts two arguments: `environ` and `start_response`. - The application should: - Parse the requested file path from the `PATH_INFO` variable in the `environ` dictionary. - Serve the requested file if it exists in the specified directory. - Return a custom HTML error page with a 404 status code if the file does not exist. 3. **Function Signature:** ```python def file_server_app(environ, start_response): pass ``` 4. **Input:** - The `environ` parameter is a dictionary containing the WSGI environment variables. - The `start_response` parameter is a callable that starts the response. 5. **Output:** - The function should return an iterable yielding byte strings representing the response body. 6. **Constraints:** - The application should only serve files within the specified directory to avoid directory traversal attacks. - Use the `wsgiref.util.setup_testing_defaults` function to set up a testing environment if necessary. 7. **Example Usage:** - Directory structure: ``` /example_dir |-- index.html |-- about.html |-- images |-- logo.png ``` - Request to `/index.html` should serve the content of `index.html`. - Request to `/nonexistent.html` should return a custom 404 error page. Below is the main script to run your `file_server_app` through the WSGI server: ```python import os from wsgiref.simple_server import make_server from wsgiref.util import setup_testing_defaults, FileWrapper def file_server_app(environ, start_response): setup_testing_defaults(environ) path = os.getcwd() + environ[\'PATH_INFO\'] if os.path.isdir(path): path += \'/index.html\' if os.path.isfile(path): status = \'200 OK\' headers = [(\'Content-type\', \'text/html; charset=utf-8\')] start_response(status, headers) return FileWrapper(open(path, \'rb\')) else: status = \'404 Not Found\' headers = [(\'Content-type\', \'text/html; charset=utf-8\')] start_response(status, headers) return [b\'<html><body><h1>404 Not Found</h1></body></html>\'] if __name__ == \'__main__\': port = 8000 with make_server(\'\', port, file_server_app) as httpd: print(f\\"Serving on port {port}...\\") httpd.serve_forever() ``` **Note:** You may run the server script, and then access it via `http://localhost:8000/` followed by the file path you want to retrieve. **Assessment Criteria:** - Correct implementation of the WSGI application. - Proper handling of file serving and error responses. - Adherence to WSGI specifications as described in the provided documentation.","solution":"import os from wsgiref.util import setup_testing_defaults, FileWrapper def file_server_app(environ, start_response): A simple WSGI application that serves static files from a specified directory and returns a custom 404 error page for non-existent files. setup_testing_defaults(environ) # Specify the directory to serve files from base_dir = os.path.join(os.getcwd(), \'example_dir\') # Parse the requested file path from PATH_INFO requested_path = environ.get(\'PATH_INFO\', \'/\') # Ensure the path is within the base directory to avoid directory traversal attacks full_path = os.path.join(base_dir, requested_path.strip(\'/\')) # Handle directory defaults to \'index.html\' if os.path.isdir(full_path): full_path = os.path.join(full_path, \'index.html\') # Check if the file exists and serve it if os.path.exists(full_path) and os.path.isfile(full_path): status = \'200 OK\' headers = [(\'Content-Type\', \'text/html; charset=utf-8\')] start_response(status, headers) return FileWrapper(open(full_path, \'rb\')) else: status = \'404 Not Found\' headers = [(\'Content-Type\', \'text/html; charset=utf-8\')] start_response(status, headers) return [b\'<html><body><h1>404 Not Found</h1></body></html>\']"},{"question":"You are provided with a dataset containing information about different species of penguins. Your task is to create several visualizations that offer insights into the relationships between different characteristics of the penguins. You need to write a Python function `visualize_penguins(dataset_path)`, which performs the following tasks: 1. **Load the dataset**: - Load the dataset stored at `dataset_path` into a pandas DataFrame. 2. **Create a relational plot**: - Create a scatter plot (using `sns.relplot`) to show the relationship between `bill_length_mm` and `bill_depth_mm`, with the points colored based on the `species`. 3. **Create a distribution plot**: - Create a kernel density estimation plot (using `sns.displot`) for the `flipper_length_mm` variable, with separate plots for each `species`. 4. **Create a categorical plot**: - Create a box plot (using `sns.catplot`) to visualize the distribution of `body_mass_g` across different `island` categories, with separate box plots for each `sex`. 5. **Customize the plots**: - Apply the default seaborn theme. - Customize the size, style, and color palette of the plots to make them visually appealing and informative. - Add appropriate titles, axis labels, and legends to each plot. # Constraints - You must use seaborn for all plots. - The dataset will be in CSV format with columns: `species`, `island`, `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, `body_mass_g`, `sex`. # Input - `dataset_path` (string): The file path to the CSV file containing the penguin dataset. # Output Save three plots as PNG files: 1. `relational_plot.png` 2. `distribution_plot.png` 3. `categorical_plot.png` # Example ```python def visualize_penguins(dataset_path): # Your implementation here pass # Example usage: # visualize_penguins(\\"path/to/penguin_dataset.csv\\") ``` **Explanation**: Execute the function with the path to the dataset. The function should load the dataset, create the specified plots, customize them, and save them as PNG files.","solution":"import pandas as pd import seaborn as sns import matplotlib.pyplot as plt def visualize_penguins(dataset_path): # Load the dataset data = pd.read_csv(dataset_path) # Apply the default seaborn theme sns.set_theme() # Create a relational plot relplot = sns.relplot( x=\'bill_length_mm\', y=\'bill_depth_mm\', hue=\'species\', data=data, height=5, aspect=1.2 ) relplot.set_axis_labels(\\"Bill Length (mm)\\", \\"Bill Depth (mm)\\") relplot.legend.set_title(\'Species\') relplot.fig.suptitle(\'Relationship between Bill Length and Bill Depth by Species\') relplot.savefig(\'relational_plot.png\') # Create a distribution plot displot = sns.displot( data, x=\'flipper_length_mm\', hue=\'species\', kind=\'kde\', height=5, aspect=1.2, fill=True ) displot.set_axis_labels(\\"Flipper Length (mm)\\", \\"Density\\") displot.legend.set_title(\'Species\') displot.fig.suptitle(\'Distribution of Flipper Length by Species\') displot.savefig(\'distribution_plot.png\') # Create a categorical plot catplot = sns.catplot( x=\'island\', y=\'body_mass_g\', hue=\'sex\', kind=\'box\', data=data, height=5, aspect=1.2 ) catplot.set_axis_labels(\\"Island\\", \\"Body Mass (g)\\") catplot.legend.set_title(\'Sex\') catplot.fig.suptitle(\'Distribution of Body Mass across Islands by Sex\') catplot.savefig(\'categorical_plot.png\')"},{"question":"Question: Creating and Manipulating Tensor Views in PyTorch You are working on an image processing task and need to implement a function that processes a batch of images. Each image in the batch is represented as a 3D tensor (height x width x channels). To improve memory efficiency, you will manipulate the images using tensor views. # Task Implement a function `process_images()` that takes a batch of images as input and performs the following operations: 1. Flattens each image in the batch into a 1D tensor. 2. Reshapes the flattened tensor back into its original dimensions (height, width, channels). 3. Swaps the height and width dimensions of each image. 4. Ensures the resulting tensors are contiguous. # Input - `images` (torch.Tensor): A 4D tensor of shape `(batch_size, height, width, channels)` representing a batch of images. # Output - `processed_images` (torch.Tensor): A 4D tensor of shape `(batch_size, width, height, channels)` where the height and width dimensions of each image have been swapped, and the tensors are contiguous. # Constraints - You should not create copies of the tensors except when necessary to ensure contiguity. - Use tensor view operations wherever appropriate. - Maintain the batch dimension throughout the operations. # Example ```python import torch images = torch.rand(10, 64, 64, 3) # A batch of 10 images with size 64x64 and 3 channels processed_images = process_images(images) assert processed_images.shape == torch.Size([10, 64, 64, 3]) ``` # Notes - Use PyTorch functions to achieve the desired operations. - Pay attention to the contiguity of tensors, especially after swapping dimensions. Implement the `process_images()` function below. ```python import torch def process_images(images: torch.Tensor) -> torch.Tensor: # Your implementation here pass ```","solution":"import torch def process_images(images: torch.Tensor) -> torch.Tensor: Processes a batch of images by: 1. Flattening each image into 1D tensor. 2. Reshaping it back to original dimensions. 3. Swapping the height and width dimensions. 4. Ensuring the resulting tensors are contiguous. :param images: A 4D tensor of shape (batch_size, height, width, channels) :return: A 4D tensor of shape (batch_size, width, height, channels) where height and width are swapped and contiguous # Flatten each image to 1D tensor and then reshape back to the original dimensions batch_size, height, width, channels = images.shape flattened_images = images.view(batch_size, -1) # Flatten to 2D (batch_size, height * width * channels) reshaped_images = flattened_images.view(batch_size, height, width, channels) # Reshape back to (batch_size, height, width, channels) # Swap height and width dimensions swapped_images = reshaped_images.permute(0, 2, 1, 3) # Ensure the result is contiguous processed_images = swapped_images.contiguous() return processed_images"},{"question":"# Seaborn Strip Plot Assessment Objective: Demonstrate your understanding of seaborn\'s `stripplot` function by visualizing various dimensions of a given dataset using different customization options. Dataset: Use the \'tips\' dataset that comes preloaded with seaborn. Task: 1. **Load the Dataset**: - Load the `tips` dataset using the `sns.load_dataset` function. 2. **Create Basic Strip Plot**: - Create a basic strip plot to visualize the distribution of `total_bill` values. 3. **Categorical Split**: - Modify the strip plot to compare the `total_bill` across different `days` of the week. 4. **Hue and Dodge**: - Further split the data based on the `sex` of the customers using the hue parameter and set `dodge=True`. 5. **Advanced Customization**: - Create a customized strip plot of `total_bill` vs `day` where: - Data points are differentiated by `time` (lunch/dinner) - Adjust marker style, size, and add transparency (`alpha`) - Remove jitter to produce distinct points. Requirements: 1. The plots should display clear labels for axes and use an appropriate theme (use `sns.set_theme()`). 2. Use the function `matplotlib.pyplot.show()` to display your plots. 3. Ensure good visualization practices (e.g., legibility, appropriate marker sizes, etc.) Constraints: - Use the default seaborn palettes unless specified otherwise. - Ensure plots are displayed vertically for all tasks unless stated otherwise. Example: Below is an example snippet of how to load the dataset and create a basic strip plot. ```python import seaborn as sns import matplotlib.pyplot as plt # Setting the theme sns.set_theme(style=\\"whitegrid\\") # Load the \'tips\' dataset tips = sns.load_dataset(\\"tips\\") # Basic strip plot for total bill sns.stripplot(data=tips, x=\\"total_bill\\") plt.show() ``` Output: Submit the Python script file (.py) containing the complete solutions for the tasks mentioned above.","solution":"import seaborn as sns import matplotlib.pyplot as plt def load_data(): Loads the \'tips\' dataset using seaborn. return sns.load_dataset(\\"tips\\") def basic_strip_plot(data): Creates a basic strip plot to visualize the distribution of total_bill values. sns.set_theme(style=\\"whitegrid\\") sns.stripplot(data=data, x=\\"total_bill\\") plt.show() def categorical_strip_plot(data): Creates a strip plot to compare the total_bill across different days of the week. sns.set_theme(style=\\"whitegrid\\") sns.stripplot(data=data, x=\\"day\\", y=\\"total_bill\\") plt.show() def hue_dodge_strip_plot(data): Creates a strip plot split by sex using hue and dodge=True. sns.set_theme(style=\\"whitegrid\\") sns.stripplot(data=data, x=\\"day\\", y=\\"total_bill\\", hue=\\"sex\\", dodge=True) plt.show() def customized_strip_plot(data): Creates a customized strip plot of total_bill vs day differentiated by time (lunch/dinner) with specific marker style, size, transparency, and no jitter. sns.set_theme(style=\\"whitegrid\\") sns.stripplot(data=data, x=\\"day\\", y=\\"total_bill\\", hue=\\"time\\", marker=\\"D\\", size=8, alpha=0.6, jitter=False) plt.show()"},{"question":"You are given a directory containing multiple sub-directories and files. Your task is to write a Python function that will create a ZIP archive of this directory while meeting the following conditions: 1. The ZIP archive should include all files and sub-directories, maintaining the directory structure. 2. The files must be compressed using the `ZIP_DEFLATED` method. 3. The function should exclude any files with extensions `.tmp` or `.log`. 4. If a file\'s size exceeds 2 GiB, make sure to handle it by supporting the ZIP64 format. Additionally, your function should: - Take the path to the directory to be zipped and the output path for the ZIP file as input. - Raise appropriate exceptions if the provided directory does not exist or is not accessible. - Handle any other errors gracefully and log relevant debugging information. # Input: - `src_dir` (str): The path to the directory that needs to be zipped. - `output_path` (str): The path where the output ZIP file should be stored. # Output: - None # Constraints: - The directory and files may contain millions of entries, so consider the performance of your solution. - The function should be able to handle paths with special characters. - Ensure that the function adheres to best practices for exception handling and resource management. # Function Signature: ```python def create_zip(src_dir: str, output_path: str) -> None: pass ``` # Example: ```python create_zip(\'/path/to/source_dir\', \'/path/to/output/archive.zip\') ``` # Hint: You may find the `os` module useful for traversing directories and the `zipfile` module for creating ZIP archives. Ensure that you are handling large files correctly by enabling the ZIP64 format.","solution":"import os import zipfile import logging def create_zip(src_dir: str, output_path: str) -> None: Creates a ZIP archive of the given directory with the specified conditions. Args: - src_dir (str): The path to the directory that needs to be zipped. - output_path (str): The path where the output ZIP file should be stored. logging.basicConfig(level=logging.DEBUG) if not os.path.exists(src_dir): raise FileNotFoundError(f\\"The directory {src_dir} does not exist.\\") if not os.path.isdir(src_dir): raise NotADirectoryError(f\\"The path {src_dir} is not a directory.\\") try: with zipfile.ZipFile(output_path, \'w\', zipfile.ZIP_DEFLATED, allowZip64=True) as zipf: for root, dirs, files in os.walk(src_dir): relative_path = os.path.relpath(root, src_dir) if relative_path != \'.\': zipf.write(root, os.path.join(relative_path)) for file in files: if not file.endswith((\'.tmp\', \'.log\')): file_path = os.path.join(root, file) arcname = os.path.join(relative_path, file) zipf.write(file_path, arcname) except Exception as e: logging.error(f\\"An error occurred: {e}\\") raise"},{"question":"You are tasked with designing a secure password management function for a Unix-based application using the deprecated `crypt` module in Python. Your function should be able to hash passwords using the strongest available method and validate them against user input. Function Specification 1. **Name**: `secure_password_manager` 2. **Parameters**: - `action` (str): The action to perform. It can be `\'hash\'` or `\'validate\'`. - `password` (str): The plain text password to hash or validate. - `stored_hash` (str): An optional parameter used only for validation. When action is `\'validate\'`, this represents the stored hashed password to validate against. 3. **Returns**: - If the action is `\'hash\'`, return the hashed password (str) using the strongest available method. - If the action is `\'validate\'`, return `True` if the password matches the stored hashed password; otherwise, return `False`. 4. **Constraints**: - When `action` is `\'hash\'`, `stored_hash` should be `None`. - When `action` is `\'validate\'`, both `password` and `stored_hash` must be provided and non-empty. Examples: ```python # Hashing a password hashed_password = secure_password_manager(action=\'hash\', password=\'my_secure_password\') # \'hashed_password\' should now contain the hashed password string # Validating a password is_valid = secure_password_manager(action=\'validate\', password=\'my_secure_password\', stored_hash=hashed_password) # \'is_valid\' should be True if the password matches the hash, otherwise False ``` Additional Requirements: 1. Use the `crypt.crypt` function for hashing passwords. 2. Use the `crypt.mksalt` function to generate appropriate salts when hashing passwords. 3. Ensure that the function uses the strongest available method for hashing. 4. When validating passwords, use the `hmac.compare_digest` function from the `hmac` module to safely compare the hashed values. # Implementation Your task is to implement the `secure_password_manager` function according to the above specification and constraints, utilizing the `crypt` module.","solution":"import crypt import hmac def secure_password_manager(action, password, stored_hash=None): Manages password hashing and validation. Parameters: action (str): The action to perform. It can be \'hash\' or \'validate\'. password (str): The plain text password to hash or validate. stored_hash (str): An optional parameter used only for validation. Returns: - If action is \'hash\', return the hashed password. - If action is \'validate\', return True if the password matches the stored hashed password; otherwise, return False. if action == \'hash\': if stored_hash is not None: raise ValueError(\\"\'stored_hash\' should be None when action is \'hash\'\\") salt = crypt.mksalt(crypt.METHOD_SHA512) # Use the strongest available method hashed_password = crypt.crypt(password, salt) return hashed_password elif action == \'validate\': if stored_hash is None: raise ValueError(\\"\'stored_hash\' must be provided when action is \'validate\'\\") if not password or not stored_hash: raise ValueError(\\"Both \'password\' and \'stored_hash\' must be non-empty\\") hashed_password = crypt.crypt(password, stored_hash) return hmac.compare_digest(hashed_password, stored_hash) else: raise ValueError(\\"Invalid action. Action must be either \'hash\' or \'validate\'.\\")"},{"question":"# PyTorch Coding Assessment Question Objective: To assess your understanding and ability to work with the `torch.distributed.elastic.events` module for event logging in a distributed training environment in PyTorch. Problem Statement: You are tasked with implementing a function that logs custom events during a distributed training session. This function should create an event, associate some metadata with it, and record it using the provided API methods. Function Signature: ```python def log_custom_event(event_source_name: str, event_name: str, metadata: dict): Logs a custom event using the torch.distributed.elastic.events module. Args: - event_source_name (str): The name of the event source. - event_name (str): The name/type of the event. - metadata (dict): A dictionary containing metadata related to the event. Returns: - None pass ``` Inputs: 1. `event_source_name` (str): The name of the event source. 2. `event_name` (str): The name/type of the event. 3. `metadata` (dict): A dictionary containing metadata related to the event. Keys and values are both strings. Constraints: 1. The `event_source_name` and `event_name` should be non-empty strings. 2. The `metadata` dictionary should contain less than or equal to 10 key-value pairs. 3. Each key and value in the metadata dictionary should be a non-empty string. Example Usage: ```python event_source_name = \\"training_session\\" event_name = \\"epoch_completed\\" metadata = { \\"epoch\\": \\"5\\", \\"accuracy\\": \\"0.89\\", \\"loss\\": \\"0.23\\" } log_custom_event(event_source_name, event_name, metadata) ``` Requirements: 1. Implement the function `log_custom_event` using the PyTorch `torch.distributed.elastic.events` module. 2. Use `torch.distributed.elastic.events.api.Event` to create the event. 3. Record the event using `torch.distributed.elastic.events.record`. 4. Ensure that the function validates the input constraints before proceeding with event creation and logging. **Note**: You may assume that the necessary PyTorch module `torch.distributed.elastic.events` is available and has been imported correctly. Performance: - The function should efficiently handle the input constraints without unnecessary overhead. Additional Information: - Refer to the `torch.distributed.elastic.events` documentation for additional details on using the API methods.","solution":"import torch.distributed.elastic.events as events def log_custom_event(event_source_name: str, event_name: str, metadata: dict): Logs a custom event using the torch.distributed.elastic.events module. Args: - event_source_name (str): The name of the event source. - event_name (str): The name/type of the event. - metadata (dict): A dictionary containing metadata related to the event. Returns: - None # Validate event_source_name and event_name if not isinstance(event_source_name, str) or not event_source_name: raise ValueError(\\"event_source_name must be a non-empty string\\") if not isinstance(event_name, str) or not event_name: raise ValueError(\\"event_name must be a non-empty string\\") # Validate metadata if not isinstance(metadata, dict): raise ValueError(\\"metadata must be a dictionary\\") if not all(isinstance(k, str) and k for k in metadata.keys()): raise ValueError(\\"All keys in metadata must be non-empty strings\\") if not all(isinstance(v, str) and v for v in metadata.values()): raise ValueError(\\"All values in metadata must be non-empty strings\\") if len(metadata) > 10: raise ValueError(\\"metadata must contain 10 or fewer key-value pairs\\") # Create the event and record it event = events.api.Event(source=event_source_name, name=event_name, metadata=metadata) events.record(event)"},{"question":"**Problem Statement:** You are tasked with creating a tool to adjust the hue of an image while keeping other color properties unchanged by using the conversions provided by the \\"colorsys\\" module. # Function Specification **Function Name:** `adjust_hue` **Input:** - `image_rgb`: A 2D list of tuples representing the image. Each tuple contains three floating-point values (r, g, b) in the range `[0, 1]`, representing the Red, Green, and Blue components of a pixel. - `delta_hue`: A floating-point value representing the amount by which the hue should be adjusted. This value can be positive (for increasing the hue) or negative (for decreasing the hue). **Output:** - A 2D list of tuples of the same size as `image_rgb`, representing the adjusted image. Each tuple contains three floating-point values (r, g, b) in the range `[0, 1]`. # Constraints: - The input image represented by `image_rgb` is non-empty with consistent row and column sizes. - The color component values in `image_rgb` are within the range `[0, 1]`. - The `delta_hue` value can be any real number, potentially requiring normalization to fit within the `[0, 1]` range. # Details: 1. Convert each pixel from RGB to HLS. 2. Adjust the hue component (`h`) by adding `delta_hue` and ensuring it remains within `[0, 1]`. 3. Convert the modified HLS value back to RGB. 4. Return the new image with adjusted hue. # Example: ```python def print_image(image): for row in image: print(\\" \\".join(f\\"({r:.2f}, {g:.2f}, {b:.2f})\\" for r, g, b in row)) image = [ [(0.5, 0.4, 0.3), (0.1, 0.2, 0.3)], [(0.7, 0.8, 0.9), (0.4, 0.5, 0.6)] ] delta_hue = 0.1 adjusted_image = adjust_hue(image, delta_hue) print_image(adjusted_image) ``` This should output a 2D list of RGB values with the hues of the original image adjusted accordingly. # Implementation: ```python import colorsys def adjust_hue(image_rgb, delta_hue): def adjust_pixel_hue(pixel, delta_hue): r, g, b = pixel h, l, s = colorsys.rgb_to_hls(r, g, b) h = (h + delta_hue) % 1.0 # Adjust hue and make sure it wraps around within [0, 1] r, g, b = colorsys.hls_to_rgb(h, l, s) return (r, g, b) return [[adjust_pixel_hue(pixel, delta_hue) for pixel in row] for row in image_rgb] def print_image(image): for row in image: print(\\" \\".join(f\\"({r:.2f}, {g:.2f}, {b:.2f})\\" for r, g, b in row)) # Example usage: image = [ [(0.5, 0.4, 0.3), (0.1, 0.2, 0.3)], [(0.7, 0.8, 0.9), (0.4, 0.5, 0.6)] ] delta_hue = 0.1 adjusted_image = adjust_hue(image, delta_hue) print_image(adjusted_image) ``` # Note: Ensure your function handles large values of `delta_hue` by normalizing the hue component within the `[0, 1]` range.","solution":"import colorsys def adjust_hue(image_rgb, delta_hue): def adjust_pixel_hue(pixel, delta_hue): r, g, b = pixel h, l, s = colorsys.rgb_to_hls(r, g, b) h = (h + delta_hue) % 1.0 # Adjust hue and make sure it wraps around within [0, 1] r, g, b = colorsys.hls_to_rgb(h, l, s) return (r, g, b) return [[adjust_pixel_hue(pixel, delta_hue) for pixel in row] for row in image_rgb]"},{"question":"# HTTP Status Code Analyzer Objective Implement a function that analyzes a list of HTTP status codes and provides a summary of the occurrences of each status code category (1xx, 2xx, 3xx, 4xx, 5xx). Function Signature ```python def analyze_http_status_codes(status_codes: List[int]) -> Dict[str, int]: pass ``` Input - `status_codes`: A list of integers representing HTTP status codes. Output - Returns a dictionary where the keys are string representations of HTTP status code categories (\\"1xx\\", \\"2xx\\", \\"3xx\\", \\"4xx\\", \\"5xx\\") and the values are the count of occurrences for each category in the input list. Example ```python status_codes = [200, 201, 404, 500, 102, 204, 301, 404, 503, 302, 200, 100] output = analyze_http_status_codes(status_codes) print(output) # Output should be: {\'1xx\': 2, \'2xx\': 4, \'3xx\': 2, \'4xx\': 2, \'5xx\': 2} ``` Constraints - The function should handle an empty list of status codes. - The status codes in the input list are assumed to be valid HTTP status codes as defined by `http.HTTPStatus`. Requirements - Use the `http.HTTPStatus` enum to check the status codes and categorize them accordingly. - Maintain a performance-efficient solution especially for large lists of status codes.","solution":"from typing import List, Dict from http import HTTPStatus def analyze_http_status_codes(status_codes: List[int]) -> Dict[str, int]: summary = {\\"1xx\\": 0, \\"2xx\\": 0, \\"3xx\\": 0, \\"4xx\\": 0, \\"5xx\\": 0} for code in status_codes: if 100 <= code < 200: summary[\\"1xx\\"] += 1 elif 200 <= code < 300: summary[\\"2xx\\"] += 1 elif 300 <= code < 400: summary[\\"3xx\\"] += 1 elif 400 <= code < 500: summary[\\"4xx\\"] += 1 elif 500 <= code < 600: summary[\\"5xx\\"] += 1 return summary"},{"question":"**Objective**: To assess the student\'s understanding of creating source distributions and managing the files to be included in a Python package using the \\"sdist\\" command and manifest templates. **Question**: You are tasked with creating a source distribution for a Python package named `mypackage`. The package has the following directory structure: ``` mypackage/ │ ├── mypackage/ │ ├── __init__.py │ ├── module1.py │ ├── module2.py │ ├── tests/ │ ├── test_module1.py │ ├── test_module2.py │ ├── data/ │ ├── datafile1.csv │ ├── datafile2.csv │ ├── examples/ │ ├── example1.py │ ├── example2.py │ ├── README.rst ├── setup.py └── setup.cfg ``` Your task is to write a function `create_manifest` that generates a `MANIFEST.in` file for this package. The `MANIFEST.in` file should: 1. Include all Python files in the `mypackage` directory. 2. Include all test files in the `tests` directory. 3. Include all data files in the `data` directory. 4. Include all example files in the `examples` directory. 5. Include the `README.rst`, `setup.py`, and `setup.cfg` files. 6. Exclude any files in the `examples` directory that match the pattern `example?.py`. **Function Signature**: ```python def create_manifest(directory: str) -> None: pass ``` **Input**: - `directory`: A string representing the root directory of the package (in this case, \\"mypackage\\"). **Output**: - The function should create a `MANIFEST.in` file in the root directory of the package. **Example Usage**: Suppose the function is called with `directory=\\"mypackage\\"`, the generated `MANIFEST.in` file should have the following content: ``` include mypackage/*.py include tests/*.py include data/*.csv include examples/*.py include README.rst include setup.py include setup.cfg prune examples/example?.py ``` **Constraints and Notes**: - Do not use any third-party libraries; only use Python\'s standard library. - The function should handle the slash-separated paths correctly for cross-platform compatibility. - The function should not make any assumptions about the presence of the specified files and directories—they should be included if they exist. **Performance Requirements**: - The function should be efficient in handling directory traversal and file inclusion/exclusion rules. # Starter Code ```python import os def create_manifest(directory: str) -> None: Generates a MANIFEST.in file for the given package directory. manifest_lines = [ \\"include mypackage/*.py\\", \\"include tests/*.py\\", \\"include data/*.csv\\", \\"include examples/*.py\\", \\"include README.rst\\", \\"include setup.py\\", \\"include setup.cfg\\", \\"prune examples/example?.py\\" ] manifest_path = os.path.join(directory, \\"MANIFEST.in\\") with open(manifest_path, \\"w\\") as manifest_file: manifest_file.write(\\"n\\".join(manifest_lines)) ``` **Explanation**: 1. The `create_manifest` function builds the list of lines corresponding to the file inclusion and exclusion rules for the `MANIFEST.in` file. 2. It then writes these lines to a file named `MANIFEST.in` in the specified root directory (`directory`).","solution":"import os def create_manifest(directory: str) -> None: Generates a MANIFEST.in file for the given package directory. manifest_lines = [ \\"include mypackage/*.py\\", \\"include tests/*.py\\", \\"include data/*.csv\\", \\"include examples/*.py\\", \\"include README.rst\\", \\"include setup.py\\", \\"include setup.cfg\\", \\"prune examples/example?.py\\" ] manifest_path = os.path.join(directory, \\"MANIFEST.in\\") with open(manifest_path, \\"w\\") as manifest_file: manifest_file.write(\\"n\\".join(manifest_lines))"},{"question":"Multi-threaded Report Generator **Problem Statement:** You are required to create a multi-threaded application in Python using the `threading` and `string` modules. Your task is to generate personalized reports for multiple users and format them neatly for output. Each user has a profile with their name, age, and a list of activities they participated in. **Instructions:** 1. Create a class `UserProfile` that holds the following attributes: - `name` (str): the name of the user. - `age` (int): the age of the user. - `activities` (list of str): a list of activities the user has participated in. 2. Implement a function `generate_report(user: UserProfile) -> str` that uses the `string.Template` class to format a report for the user. The report should include: - The user\'s name and age. - A numbered list of activities. - The report should use the following template: ``` Name: name Age: age Activities: activities ``` 3. Implement a class `ReportThread(threading.Thread)`, which: - Takes a `UserProfile` instance and the output file name as arguments. - Generates a formatted report using the `generate_report` function. - Writes the report to a specified file. 4. Create a function `main()` that: - Reads user profiles from a given list. - Spawns a separate thread for each user to generate their report. - Ensures that all threads complete their execution before the program exits. **Input and Output:** - The `main()` function should be called with a list of `UserProfile` instances. - Each `ReportThread` writes the report to a file named after the user (e.g., for a user named `John`, the report would be written to `John_report.txt`). - Ensure thread-safe file writing using appropriate synchronization mechanisms if needed. **Example:** ```python import threading from string import Template class UserProfile: def __init__(self, name, age, activities): self.name = name self.age = age self.activities = activities def generate_report(user): template = Template(\\"Name: namenAge: agenActivities:nactivitiesn\\") activities_list = \\"n\\".join([f\\"{idx + 1}. {act}\\" for idx, act in enumerate(user.activities)]) return template.substitute(name=user.name, age=user.age, activities=activities_list) class ReportThread(threading.Thread): def __init__(self, user, filename): threading.Thread.__init__(self) self.user = user self.filename = filename def run(self): report = generate_report(self.user) with open(self.filename, \'w\') as f: f.write(report) def main(users): threads = [] for user in users: filename = f\\"{user.name}_report.txt\\" thread = ReportThread(user, filename) threads.append(thread) thread.start() for thread in threads: thread.join() # Example Usage if __name__ == \'__main__\': users = [ UserProfile(name=\\"Alice\\", age=30, activities=[\\"Reading\\", \\"Hiking\\", \\"Swimming\\"]), UserProfile(name=\\"Bob\\", age=25, activities=[\\"Cycling\\", \\"Movies\\"]), ] main(users) ``` **Constraints:** - Use the `threading` module for multi-threading. - Utilize the `string.Template` for report generation. - Each report must be written to a separate file named after the user. - Ensure proper synchronization to avoid any race conditions.","solution":"import threading from string import Template class UserProfile: def __init__(self, name, age, activities): self.name = name self.age = age self.activities = activities def generate_report(user): template = Template(\\"Name: namenAge: agenActivities:nactivitiesn\\") activities_list = \\"n\\".join([f\\"{idx + 1}. {act}\\" for idx, act in enumerate(user.activities)]) return template.substitute(name=user.name, age=user.age, activities=activities_list) class ReportThread(threading.Thread): def __init__(self, user, filename): threading.Thread.__init__(self) self.user = user self.filename = filename def run(self): report = generate_report(self.user) with open(self.filename, \'w\') as f: f.write(report) def main(users): threads = [] for user in users: filename = f\\"{user.name}_report.txt\\" thread = ReportThread(user, filename) threads.append(thread) thread.start() for thread in threads: thread.join()"},{"question":"# Customized Decision Threshold Classifier with Cross-Validation You are provided with a binary classification problem where accurately predicting positive classes (e.g., detecting a disease) is more critical than minimizing false positives. In this scenario, you are required to use the `TunedThresholdClassifierCV` to optimize the decision threshold of a classifier to maximize recall. **Task:** 1. Implement a function `tuned_threshold_classifier` that takes the following inputs: - `X_train`: A numpy array or DataFrame (features for training). - `y_train`: A numpy array or Series (target labels for training). - `X_test`: A numpy array or DataFrame (features for testing). - `base_classifier`: An untrained classifier instance from `sklearn`. - `scorer`: A scoring function created using `make_scorer` from `sklearn.metrics`. 2. Use `TunedThresholdClassifierCV` to find the optimal decision threshold for the `base_classifier` to maximize the provided `scorer`. 3. The function should return the following outputs: - `y_test_pred`: Predicted labels for the test set with the optimized threshold. - `best_threshold`: The threshold value that maximizes the scoring function. **Input Format:** ```python def tuned_threshold_classifier(X_train, y_train, X_test, base_classifier, scorer): pass ``` - `X_train`: numpy.ndarray or pandas.DataFrame, shape (n_samples, n_features) - `y_train`: numpy.ndarray or pandas.Series, shape (n_samples,) - `X_test`: numpy.ndarray or pandas.DataFrame, shape (n_samples, n_features) - `base_classifier`: sklearn classifier instance - `scorer`: Scorer created using `make_scorer` **Output Format:** - `y_test_pred`: numpy.ndarray, shape (n_samples,) - `best_threshold`: float **Constraints/Notes:** 1. Do not change the default cross-validation strategy (5-fold stratified). 2. Ensure that neither `X_test` nor `y_test` is used in fitting the `TunedThresholdClassifierCV`. 3. Use appropriate imports from the scikit-learn library. **Example:** ```python from sklearn.datasets import make_classification from sklearn.linear_model import LogisticRegression from sklearn.metrics import make_scorer, recall_score # Prepare dataset X, y = make_classification(n_samples=1000, weights=[0.1, 0.9], random_state=0) X_train, X_test = X[:800], X[800:] y_train, y_test = y[:800], y[800:] # Instantiate base classifier base_classifier = LogisticRegression() # Define custom scorer for recall scorer = make_scorer(recall_score) # Implement and call the function y_test_pred, best_threshold = tuned_threshold_classifier(X_train, y_train, X_test, base_classifier, scorer) print(\'Best Threshold:\', best_threshold) ``` In the provided example, the function implements the optimal decision threshold finding and uses it to predict the test set labels.","solution":"from sklearn.base import BaseEstimator, ClassifierMixin, clone from sklearn.model_selection import cross_val_predict, StratifiedKFold import numpy as np from sklearn.metrics import make_scorer, recall_score class TunedThresholdClassifierCV(BaseEstimator, ClassifierMixin): A custom classifier that tunes decision threshold using cross-validation. def __init__(self, base_classifier, scorer, cv=5): self.base_classifier = base_classifier self.cv = cv self.scorer = scorer def fit(self, X, y): # Perform stratified k-fold cross validation skf = StratifiedKFold(n_splits=self.cv) # Collect probabilities on cross-validation y_probas = cross_val_predict(clone(self.base_classifier), X, y, cv=skf, method=\\"predict_proba\\")[:, 1] # Find best threshold best_score = -np.inf best_threshold = 0.5 for threshold in np.linspace(0, 1, 100): y_pred = (y_probas >= threshold).astype(int) score = self.scorer._score_func(y, y_pred) if score > best_score: best_score = score best_threshold = threshold self.best_threshold_ = best_threshold self.base_classifier_ = clone(self.base_classifier).fit(X, y) return self def predict(self, X): y_probas = self.base_classifier_.predict_proba(X)[:, 1] return (y_probas >= self.best_threshold_).astype(int) def tuned_threshold_classifier(X_train, y_train, X_test, base_classifier, scorer): clf = TunedThresholdClassifierCV(base_classifier=base_classifier, scorer=scorer) clf.fit(X_train, y_train) y_test_pred = clf.predict(X_test) best_threshold = clf.best_threshold_ return y_test_pred, best_threshold"},{"question":"# XML Processing and Security with Python\'s xml.etree.ElementTree You are tasked with processing a set of XML data files for a project. The XML data represents a collection of books in a library, with each book having attributes like title, author, genre, price, and publish date. **Objective**: Write a Python function `process_books_xml` that accepts an XML string representing the library and performs the following tasks: 1. Parses the XML string using `xml.etree.ElementTree`. 2. Extracts and prints a list of all book titles. 3. Identifies books published after the year 2000 and returns their count. ```python def process_books_xml(xml_data: str) -> int: Parses the XML data and performs required operations. Args: xml_data (str): A string representing the XML data of the library. Returns: int: The count of books published after the year 2000. pass ``` **Input**: - `xml_data`: A string in XML format representing a library of books. Each book element contains title, author, genre, price, and publish date. **Output**: - An integer representing the count of books published after the year 2000. **Example**: ```python xml_data = <library> <book> <title>Book A</title> <author>Author 1</author> <genre>Fiction</genre> <price>29.99</price> <publish_date>2001-04-23</publish_date> </book> <book> <title>Book B</title> <author>Author 2</author> <genre>Non-Fiction</genre> <price>39.99</price> <publish_date>1999-08-15</publish_date> </book> </library> print(process_books_xml(xml_data)) # Expected output: 1 ``` **Constraints**: - Ensure your function can handle invalid XML by catching and handling exceptions. - Given the potential risks with XML processing, use best practices to safely parse the XML data and handle any malicious inputs accordingly. **Performance Requirements**: - The function should efficiently handle XML data with up to 10,000 book elements. **Security Considerations**: - Make sure to use methods that mitigate common XML vulnerabilities such as \\"billion laughs\\" or \\"external entity expansion\\" attacks. Consider using secure parsing techniques or libraries if needed.","solution":"import xml.etree.ElementTree as ET def process_books_xml(xml_data: str) -> int: Parses the XML data and performs required operations. Args: xml_data (str): A string representing the XML data of the library. Returns: int: The count of books published after the year 2000. try: root = ET.fromstring(xml_data) # Extract and print a list of all book titles titles = [book.find(\'title\').text for book in root.findall(\'book\')] print(\\"Book Titles:\\", titles) # Count books published after the year 2000 count = 0 for book in root.findall(\'book\'): publish_date = book.find(\'publish_date\').text year = int(publish_date.split(\\"-\\")[0]) if year > 2000: count += 1 return count except ET.ParseError: print(\\"Error: Invalid XML format!\\") return 0"},{"question":"**Problem: Create a Simple Terminal Text Editor using curses** You are required to implement a basic text editor using the curses module in Python. The editor should support the following functionalities: 1. Display a resizable window to edit text. 2. Use attribute highlighting for specific text patterns. 3. Allow text to be scrolled within the editing window. 4. Handle resizing of the terminal and adjust the display accordingly. 5. Provide basic navigation (arrow keys) and text manipulation (backspace, enter) functionality. 6. Exit the editor when the user presses a specific key (e.g., \'Ctrl-G\' or \'q\'). Input: - None directly from standard input; all input is through curses-based key handling. Output: - None to standard output; the text and cursor position should be managed within the curses window. - On exit, print the edited text to the standard output. Constraints: - Use the curses module for all I/O operations within the application window. - Ensure the application handles terminal resizing gracefully. - Implement functions to manage text input, cursor movement, and screen refreshing efficiently. Function Signature: ```python import curses def main(stdscr): # Your implementation here pass if __name__ == \\"__main__\\": curses.wrapper(main) ``` Example Usage Scenario: 1. When the editor starts, it will initialize a curses window and display a blank screen or load some initial text. 2. The user types text, navigates using arrow keys, and uses the backspace key for corrections. 3. The editor displays text with special attributes (e.g., bold) for specific patterns (e.g., \'@username\' could be highlighted). 4. If the terminal is resized, the display adjusts without losing text content. 5. The user exits the editor by pressing \'Ctrl-G\' or \'q\', and the final text is printed to the standard output. Detailed Requirements: 1. **Initialization**: Set up the curses environment, capture special keys, and handle terminal resizing. 2. **Text Display**: Manage a primary buffer for text. Implement a method to add text at the cursor\'s position and handle line wrapping. 3. **Cursor Navigation**: Implement cursor movement logic using arrow keys, ensuring the cursor doesn\'t move out of bounds. 4. **Attribute Highlighting**: Use curses attributes (like `A_BOLD`) to highlight patterns (e.g., emails, usernames). 5. **Scrolling**: Implement a method to scroll the text window when the text overflows the display area. 6. **Exit and Cleanup**: Ensure the curses environment is properly cleaned up on exit and the edited text is output to the terminal. Consider edge cases such as: - Cursor at the edges of the window - Resizing the terminal to a very small size - Continuous typing beyond the window boundaries **Hints**: - Review methods like `stdscr.addstr()`, `stdscr.getch()`, `curses.newpad()`, and `curses.wrapper()`. - Use the `curses.textpad` module\'s `Textbox` class for handling text input if it simplifies your implementation. - Handle exceptions and cleanup properly by restoring terminal settings before exiting. Good luck!","solution":"import curses def main(stdscr): # Initialization curses.curs_set(1) stdscr.keypad(True) curses.use_default_colors() # Main buffer to store text text_lines = [\'\'] cursor_y, cursor_x = 0, 0 max_y, max_x = stdscr.getmaxyx() # Function to display text on the screen def display_text(): stdscr.erase() for idx, line in enumerate(text_lines): stdscr.addstr(idx, 0, line) stdscr.move(cursor_y, cursor_x) stdscr.refresh() # Main loop for handling key events while True: display_text() key = stdscr.getch() if key == curses.KEY_UP: cursor_y = max(cursor_y - 1, 0) elif key == curses.KEY_DOWN: cursor_y = min(cursor_y + 1, len(text_lines) - 1) elif key == curses.KEY_LEFT: cursor_x = max(cursor_x - 1, 0) elif key == curses.KEY_RIGHT: cursor_x = min(cursor_x + 1, len(text_lines[cursor_y])) elif key == curses.KEY_RESIZE: max_y, max_x = stdscr.getmaxyx() elif key in (curses.KEY_BACKSPACE, 127): # Handle backspace if cursor_x > 0: text_lines[cursor_y] = text_lines[cursor_y][:cursor_x - 1] + text_lines[cursor_y][cursor_x:] cursor_x -= 1 elif cursor_y > 0: cursor_x = len(text_lines[cursor_y - 1]) text_lines[cursor_y - 1] += text_lines[cursor_y] del text_lines[cursor_y] cursor_y -= 1 elif key == curses.KEY_ENTER or key == 10: # Enter key text_lines.insert(cursor_y + 1, text_lines[cursor_y][cursor_x:]) text_lines[cursor_y] = text_lines[cursor_y][:cursor_x] cursor_y += 1 cursor_x = 0 elif key in (ord(\'q\'), 7): # Exit on \'q\' or \'Ctrl-G\' break else: # Character input text_lines[cursor_y] = text_lines[cursor_y][:cursor_x] + chr(key) + text_lines[cursor_y][cursor_x:] cursor_x += 1 if cursor_x > max_x - 1: cursor_x = max_x - 1 if cursor_y >= max_y: cursor_y = max_y - 1 # Print the final text to the standard output stdscr.clear() stdscr.refresh() for line in text_lines: print(line) if __name__ == \\"__main__\\": curses.wrapper(main)"},{"question":"**Title:** Porting a Python 2 Script for Python 3 Compatibility **Objective:** You are provided with a small script written for Python 2.7. Your task is to port this script to be compatible with both Python 2.7 and Python 3.x versions. **Script Details:** The script reads a file, processes the text contained within, converts all occurrences of a specific substring into uppercase, and writes the updated content to a new file. ```python # Python 2.7 script example def process_file(input_file, output_file, substring): with open(input_file, \'r\') as file: content = file.read() updated_content = content.replace(substring, substring.upper()) with open(output_file, \'w\') as file: file.write(updated_content) # Example usage process_file(\'input.txt\', \'output.txt\', \'example\') ``` **Porting Requirements:** 1. **Text vs Binary Data:** Ensure that the code handles text data appropriately in both Python versions. 2. **File Handling:** Use `io.open()` for file operations to maintain consistency across versions. 3. **String Literals:** Correctly prefix string literals to specify text or binary data where necessary. 4. **Feature Detection:** Implement feature detection to distinguish between Python 2 and Python 3 environments as needed. Avoid direct version checks where possible. 5. **Testing:** Write a simple test function that reads the output file and checks if the substring has been correctly converted to uppercase. **Input Format:** - `input_file`: Path to the file containing text data (string). - `output_file`: Path to the output file where processed data will be written (string). - `substring`: The substring that needs to be converted to uppercase (string). **Output Format:** - None. The script directly writes the output to the specified file. **Constraints:** - Assume valid file paths and readable/writable permissions. - The script should be runnable as-is in both Python 2.7 and Python 3.x environments. # Example **Input File Content (`input.txt`):** ``` this is an example line. here is another example. ``` **Substring to Replace:** ``` example ``` **Output File Content (`output.txt`):** ``` this is an EXAMPLE line. here is another EXAMPLE. ``` ```python # Your ported code here import io def process_file(input_file, output_file, substring): # Open the file using io.open() for cross-version compatibility with io.open(input_file, \'r\', encoding=\'utf-8\') as file: content = file.read() updated_content = content.replace(substring, substring.upper()) # Write the content back using io.open() and specifying text mode with io.open(output_file, \'w\', encoding=\'utf-8\') as file: file.write(updated_content) def test_process_file(): process_file(\'input.txt\', \'test_output.txt\', \'example\') with io.open(\'test_output.txt\', \'r\', encoding=\'utf-8\') as file: result = file.read() assert \'EXAMPLE\' in result, \\"Test failed: the substring was not converted to uppercase.\\" # Example usage process_file(\'input.txt\', \'output.txt\', \'example\') # Run test test_process_file() ``` Ensure to validate your solution by running it in both Python 2.7 and Python 3.x environments.","solution":"import io def process_file(input_file, output_file, substring): # Open the file using io.open() for cross-version compatibility with io.open(input_file, \'r\', encoding=\'utf-8\') as file: content = file.read() updated_content = content.replace(substring, substring.upper()) # Write the content back using io.open() and specifying text mode with io.open(output_file, \'w\', encoding=\'utf-8\') as file: file.write(updated_content)"},{"question":"**Coding Assessment Question:** # Problem Statement You are tasked with developing a Python function called `validate_emails` that checks the validity of a list of email addresses and extracts specific information from valid emails using regular expressions. An email address is considered valid if it matches the following criteria: 1. It starts with an alphanumeric character. 2. It contains only alphanumeric characters, dots (`.`), underscores (`_`), and hyphens (`-`) before the `@` symbol. 3. It has a domain name following the `@` symbol which consists of alphanumeric characters and dots (`.`). 4. The domain name must end with a valid top-level domain (TLD) such as `.com`, `.org`, `.net`, `.edu`. The function should return a dictionary where the keys are the valid email addresses and the values are tuples containing: 1. The username part of the email (the part before the `@`). 2. The domain name (the part after the `@`). # Input - A list of email addresses (list of strings). # Output - A dictionary with valid email addresses as keys and tuples of the username and domain name as values. # Constraints - You must use regular expressions for pattern matching and validation. - The function should handle both lowercase and uppercase characters in the email addresses. - Performance should be considered, especially when handling a large list of email addresses. # Example ```python def validate_emails(email_list): # Your implementation here # Example usage: email_list = [ \\"example@example.com\\", \\"user.name@domain.org\\", \\"invalid-email@domain\\", \\"another_user@sub.domain.net\\", \\"sample-email@domain.co.uk\\" ] print(validate_emails(email_list)) ``` Expected Output ```python { \\"example@example.com\\": (\\"example\\", \\"example.com\\"), \\"user.name@domain.org\\": (\\"user.name\\", \\"domain.org\\"), \\"another_user@sub.domain.net\\": (\\"another_user\\", \\"sub.domain.net\\") } ``` # Implementation Notes - Use the `re` module and its features for pattern matching. - Utilize groups to extract the username and domain name from the valid email addresses. - Pay attention to edge cases such as emails with consecutive dots, invalid characters, and incorrect domain formats. - Ensure that the function is efficient and can handle a list of up to 100,000 email addresses within a reasonable time frame. # Additional Information Feel free to use any compilation flags such as `IGNORECASE`, and make your regular expressions verbose with comments for better readability if necessary.","solution":"import re def validate_emails(email_list): Validates email addresses and extracts information from them. Parameters: email_list (list): A list of email addresses. Returns: dict: A dictionary with valid email addresses as keys and tuples of the username and domain name as values. # Regular expression for validating emails email_regex = re.compile( r\'^(?P<username>[a-zA-Z0-9._%-]+)@(?P<domain>[a-zA-Z0-9.-]+.(?:com|org|net|edu))\', re.IGNORECASE ) valid_emails = {} for email in email_list: match = email_regex.match(email) if match: username = match.group(\'username\') domain = match.group(\'domain\') valid_emails[email] = (username, domain) return valid_emails"},{"question":"Coding Assessment Question # Objective Your task is to implement a function that will help identify memory leaks and high memory usages in a Python application using the `tracemalloc` module. You are required to compare two snapshots of memory allocations and display the top differences in memory usage along with their tracebacks. # Instructions 1. Write a Python function named `compare_memory_snapshots` that performs the following steps: - Starts tracing memory allocations with a specified number of frames. - Runs any provided callable (usually part of your application) to accumulate memory usage. - Takes a snapshot of current memory allocations. - Runs another callable to further modify memory usage. - Takes a second snapshot of memory allocations. - Compares the two snapshots and displays the top N differences in memory usage, along with their tracebacks. 2. Your function should take the following parameters: - `callable1`: A callable that represents the first part of the application\'s code. - `callable2`: A callable that represents the second part of the application\'s code. - `num_frames` (int): Number of frames to store for each memory block allocation trace (default is 1). - `top_n` (int): The number of top differences to show (default is 10). # Expected Function Signature ```python def compare_memory_snapshots(callable1, callable2, num_frames=1, top_n=10): pass ``` # Example Usage ```python import tracemalloc def part1(): x = [i for i in range(10000)] def part2(): y = [i ** 2 for i in range(10000)] compare_memory_snapshots(part1, part2, num_frames=10, top_n=5) ``` # Constraints - `callable1` and `callable2` must be callable objects. - `num_frames` must be an integer greater than or equal to 1. - `top_n` must be an integer greater than or equal to 1. # Output The function should print the top `top_n` differences in memory usage between the two snapshots. Each difference should include the total size difference, the number of new memory blocks, and the traceback of memory allocation. # Notes - Consider handling edge cases where the list of differences is less than `top_n`. - Use the `tracemalloc` module\'s functions to manage memory tracing and take snapshots. - The function should be idempotent, meaning multiple calls with the same callable procedures should yield the same results without side-effects.","solution":"import tracemalloc def compare_memory_snapshots(callable1, callable2, num_frames=1, top_n=10): Compare memory snapshots before and after two callables to identify memory leaks and high memory usage. if not callable(callable1) or not callable(callable2): raise ValueError(\\"The first two arguments must be callable\\") if not isinstance(num_frames, int) or num_frames < 1: raise ValueError(\\"num_frames must be an integer greater than or equal to 1\\") if not isinstance(top_n, int) or top_n < 1: raise ValueError(\\"top_n must be an integer greater than or equal to 1\\") tracemalloc.start(num_frames) # Run the first callable callable1() # Take the first snapshot snapshot1 = tracemalloc.take_snapshot() # Run the second callable callable2() # Take the second snapshot snapshot2 = tracemalloc.take_snapshot() # Compare snapshots top_stats = snapshot2.compare_to(snapshot1, \'lineno\') for index, stat in enumerate(top_stats[:top_n], 1): print(f\\"{index}. {stat}\\") tracemalloc.stop()"},{"question":"# SQLite Database Management with Custom Types in Python Objective You are required to design a solution that manages a movie database using the `sqlite3` module in Python. This solution should demonstrate proficiency with the `sqlite3` module, including custom type adaptation, basic CRUD (Create, Read, Update, Delete) operations, transactions handling, and error management. Task 1. **Database Setup**: - Create an SQLite in-memory database. - Define a table `movies` with the following columns: `id` (INTEGER primary key), `title` (TEXT), `year` (INTEGER), `score` (REAL). 2. **Custom Data Types**: - Define a custom Python class `Director` with attributes `first_name` and `last_name`. - Register this class with the SQLite database so that instances of `Director` can be stored and retrieved as a single TEXT field in the format `\\"first_name last_name\\"`. 3. **Database Operations**: - Insert at least five movie records into the `movies` table, with corresponding directors. - Write a function `get_movies_by_director` to retrieve movies directed by a specific director. - Write a function `update_movie_score` to update the score of a movie given its title. - Write a function `delete_movie` to delete a movie by its title. 4. **Transaction Management**: - Use transaction management to ensure that movie insertion and updates are atomic operations. 5. **Error Handling**: - Implement error handling to capture and print appropriate error messages for common database operation errors, such as trying to insert a movie with a duplicate title, or querying for a non-existent movie. Constraints - Ensure the code uses placeholders to prevent SQL injection. - Use context managers for managing database connections and cursors. - Use appropriate exception handling for database errors. - The functions should be efficient and follow good database management practices. Expected Output - A script that performs the tasks above. - Verify the functionalities by: - Printing all movies directed by a specific director. - Updating and then printing a movie\'s score. - Deleting a movie and confirming its removal. Python Code Skeleton ```python import sqlite3 class Director: def __init__(self, first_name, last_name): self.first_name = first_name self.last_name = last_name def __conform__(self, protocol): if protocol is sqlite3.PrepareProtocol: return f\\"{self.first_name} {self.last_name}\\" def adapt_director(director): return f\\"{director.first_name} {director.last_name}\\" def convert_director(s): first_name, last_name = s.decode().split() return Director(first_name, last_name) def setup_database(): con = sqlite3.connect(\\":memory:\\") con.row_factory = sqlite3.Row con.execute(\\"CREATE TABLE movies (id INTEGER PRIMARY KEY, title TEXT, year INTEGER, score REAL, director TEXT)\\") con.commit() return con def insert_movie(con, title, year, score, director): with con: con.execute(\\"INSERT INTO movies (title, year, score, director) VALUES (?, ?, ?, ?)\\", (title, year, score, director)) def get_movies_by_director(con, director): cur = con.cursor() cur.execute(\\"SELECT * FROM movies WHERE director=?\\", (director,)) return cur.fetchall() def update_movie_score(con, title, new_score): with con: con.execute(\\"UPDATE movies SET score=? WHERE title=?\\", (new_score, title)) def delete_movie(con, title): with con: con.execute(\\"DELETE FROM movies WHERE title=?\\", (title,)) if __name__ == \'__main__\': sqlite3.register_adapter(Director, adapt_director) sqlite3.register_converter(\\"DIRECTOR\\", convert_director) # Perform database setup and operations con = setup_database() director1 = Director(\\"John\\", \\"Smith\\") director2 = Director(\\"Alice\\", \\"Johnson\\") insert_movie(con, \\"Movie1\\", 2000, 8.2, director1) insert_movie(con, \\"Movie2\\", 2005, 7.5, director1) insert_movie(con, \\"Movie3\\", 2010, 9.1, director2) insert_movie(con, \\"Movie4\\", 2008, 6.3, director2) insert_movie(con, \\"Movie5\\", 2015, 8.8, Director(\\"Bob\\", \\"Dylan\\")) print(get_movies_by_director(con, director1)) update_movie_score(con, \\"Movie1\\", 9.0) print(get_movies_by_director(con, director1)) # Verify update delete_movie(con, \\"Movie2\\") print(get_movies_by_director(con, director1)) # Verify delete ```","solution":"import sqlite3 class Director: def __init__(self, first_name, last_name): self.first_name = first_name self.last_name = last_name def __conform__(self, protocol): if protocol is sqlite3.PrepareProtocol: return f\\"{self.first_name} {self.last_name}\\" def adapt_director(director): return f\\"{director.first_name} {director.last_name}\\" def convert_director(s): first_name, last_name = s.decode().split() return Director(first_name, last_name) def setup_database(): con = sqlite3.connect(\\":memory:\\") con.row_factory = sqlite3.Row con.execute(\\"CREATE TABLE movies (id INTEGER PRIMARY KEY, title TEXT, year INTEGER, score REAL, director TEXT)\\") con.commit() return con def insert_movie(con, title, year, score, director): with con: con.execute(\\"INSERT INTO movies (title, year, score, director) VALUES (?, ?, ?, ?)\\", (title, year, score, director)) def get_movies_by_director(con, director): cur = con.cursor() cur.execute(\\"SELECT * FROM movies WHERE director=?\\", (f\\"{director.first_name} {director.last_name}\\",)) return cur.fetchall() def update_movie_score(con, title, new_score): with con: con.execute(\\"UPDATE movies SET score=? WHERE title=?\\", (new_score, title)) def delete_movie(con, title): with con: con.execute(\\"DELETE FROM movies WHERE title=?\\", (title,)) # Register the custom type adapter and converter sqlite3.register_adapter(Director, adapt_director) sqlite3.register_converter(\\"DIRECTOR\\", convert_director) # Example script if __name__ == \'__main__\': con = setup_database() director1 = Director(\\"John\\", \\"Smith\\") director2 = Director(\\"Alice\\", \\"Johnson\\") insert_movie(con, \\"Movie1\\", 2000, 8.2, director1) insert_movie(con, \\"Movie2\\", 2005, 7.5, director1) insert_movie(con, \\"Movie3\\", 2010, 9.1, director2) insert_movie(con, \\"Movie4\\", 2008, 6.3, director2) insert_movie(con, \\"Movie5\\", 2015, 8.8, Director(\\"Bob\\", \\"Dylan\\")) print([dict(row) for row in get_movies_by_director(con, director1)]) update_movie_score(con, \\"Movie1\\", 9.0) print([dict(row) for row in get_movies_by_director(con, director1)]) delete_movie(con, \\"Movie2\\") print([dict(row) for row in get_movies_by_director(con, director1)])"},{"question":"# URL Handling and Parsing with urllib You are provided with a text file named `urls.txt`, which contains a list of URLs (one URL per line). Your task is to write a Python function using the `urllib` package to perform the following operations: 1. **Read the URLs from the file**. 2. **Open each URL** and read the content. 3. **Handle exceptions** that may arise during the URL opening process. 4. **Parse each URL** to extract and print the scheme, netloc, path, params, query, and fragment. 5. **Return a dictionary** where keys are the URLs and values are the first 200 characters of their content. # Function Signature ```python def process_urls(file_path: str) -> dict: pass ``` # Input - `file_path` (str): Path to the `urls.txt` file. # Output - A dictionary where: - The keys are URLs (str). - The values are the first 200 characters of the content retrieved from those URLs (str). # Constraints - You must use the `urllib` package. - Handle exceptions specifically using `urllib.error`. - Ensure the code executes efficiently without repeatedly reading the file. # Example Given an `urls.txt` file containing the following URLs: ``` http://example.com https://www.python.org http://invalid-url.com ``` Your function should open each URL, fetch its content (if accessible), and return a dictionary with the corresponding content snippets of the URLs: ```python { \'http://example.com\': \'<!doctype html><html>...</html>\', \'https://www.python.org\': \'<!doctype html><html>...</html>\', \'http://invalid-url.com\': \'error\' } ``` # Notes - Invalid URLs or URLs that fail to fetch should have the value `\'error\'`. - The parsing result of each URL (scheme, netloc, path, etc.) should be printed to the console. - You may use `urllib.parse.urlparse` for URL parsing. Implement the `process_urls` function to meet these requirements.","solution":"import urllib.request import urllib.error from urllib.parse import urlparse def process_urls(file_path: str) -> dict: url_dict = {} with open(file_path, \'r\') as file: urls = file.read().splitlines() for url in urls: try: with urllib.request.urlopen(url) as response: content = response.read().decode(\'utf-8\') brief_content = content[:200] url_dict[url] = brief_content except urllib.error.URLError as e: url_dict[url] = \'error\' parsed_url = urlparse(url) print(f\\"URL: {url}\\") print(f\\" Scheme: {parsed_url.scheme}\\") print(f\\" Netloc: {parsed_url.netloc}\\") print(f\\" Path: {parsed_url.path}\\") print(f\\" Params: {parsed_url.params}\\") print(f\\" Query: {parsed_url.query}\\") print(f\\" Fragment: {parsed_url.fragment}\\") return url_dict"},{"question":"**Problem Statement:** You are an AI engineer working on a medical diagnosis application. Your task is to develop a classification model that can predict whether a patient has a particular type of cancer. The model should be optimized to minimize the number of false negatives (i.e., cases where the model fails to identify cancer patients). To achieve this, you need to: 1. Train a classifier using a given dataset. 2. Tune the decision threshold to maximize recall (sensitivity) while keeping other performance metrics acceptable. 3. Evaluate the tuned model on a test dataset. **Requirements:** 1. Implement a function `tune_decision_threshold` with the following signature: ```python def tune_decision_threshold(X_train, y_train, X_test, y_test, base_model, pos_label) -> dict: Trains a classifier, tunes the decision threshold to maximize recall, and evaluates the model. Parameters: X_train (numpy.ndarray): Features of the training dataset. y_train (numpy.ndarray): Labels of the training dataset. X_test (numpy.ndarray): Features of the test dataset. y_test (numpy.ndarray): Labels of the test dataset. base_model (sklearn.base.BaseEstimator): The base classifier to be used. pos_label (int): The label of the positive class (cancer). Returns: dict: A dictionary containing: - \\"best_threshold\\" (float): The optimal decision threshold. - \\"recall\\" (float): The recall of the tuned model on the test dataset. - \\"precision\\" (float): The precision of the tuned model on the test dataset. - \\"f1_score\\" (float): The F1 score of the tuned model on the test dataset. pass ``` 2. The function should: - Train the base classifier on the training data. - Use `TunedThresholdClassifierCV` to tune the decision threshold to maximize recall. - Evaluate the tuned model on the test set, providing recall, precision, and F1 score. - Return the optimal threshold and the evaluation metrics as a dictionary. **Constraints:** - The training and test datasets (`X_train`, `X_test`, `y_train`, `y_test`) are provided as numpy arrays. - The base classifier (`base_model`) is a scikit-learn classifier (e.g., `LogisticRegression`, `DecisionTreeClassifier`, etc.). - The positive class label (`pos_label`) is an integer (e.g., 1 for cancer). **Example:** ```python from sklearn.linear_model import LogisticRegression from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score # Generate a synthetic dataset X, y = make_classification(n_samples=1000, weights=[0.95, 0.05], random_state=42) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Initialize the base classifier base_model = LogisticRegression() # Call the function result = tune_decision_threshold(X_train, y_train, X_test, y_test, base_model, pos_label=1) print(result) ``` In the above example, the function `tune_decision_threshold` should train the logistic regression model on the training data, tune the decision threshold to maximize recall, and evaluate the tuned model on the test set. The output should be a dictionary containing the optimal threshold, recall, precision, and F1 score.","solution":"import numpy as np from sklearn.base import BaseEstimator from sklearn.metrics import precision_recall_curve, recall_score, precision_score, f1_score def tune_decision_threshold(X_train, y_train, X_test, y_test, base_model, pos_label) -> dict: Trains a classifier, tunes the decision threshold to maximize recall, and evaluates the model. Parameters: X_train (numpy.ndarray): Features of the training dataset. y_train (numpy.ndarray): Labels of the training dataset. X_test (numpy.ndarray): Features of the test dataset. y_test (numpy.ndarray): Labels of the test dataset. base_model (sklearn.base.BaseEstimator): The base classifier to be used. pos_label (int): The label of the positive class (cancer). Returns: dict: A dictionary containing: - \\"best_threshold\\" (float): The optimal decision threshold. - \\"recall\\" (float): The recall of the tuned model on the test dataset. - \\"precision\\" (float): The precision of the tuned model on the test dataset. - \\"f1_score\\" (float): The F1 score of the tuned model on the test dataset. # Train the base model base_model.fit(X_train, y_train) # Predict probabilities on the test set y_proba = base_model.predict_proba(X_test)[:, 1] # Calculate precision-recall curve precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba, pos_label=pos_label) # Find the threshold that gives the maximum recall # Note: recall = tp / (tp + fn), we want to minimize fn max_recall_idx = np.argmax(recalls) best_threshold = thresholds[max_recall_idx] # Apply the best threshold to get final predictions y_pred = (y_proba >= best_threshold).astype(int) # Calculate metrics recall = recall_score(y_test, y_pred, pos_label=pos_label) precision = precision_score(y_test, y_pred, pos_label=pos_label) f1 = f1_score(y_test, y_pred, pos_label=pos_label) return { \\"best_threshold\\": best_threshold, \\"recall\\": recall, \\"precision\\": precision, \\"f1_score\\": f1 }"},{"question":"Objective: Your task is to implement a custom iterator in Python that cycles indefinitely over the given elements and also create a function to verify if a given object is an instance of this custom iterator. Problem Description: 1. **Class Definition**: - Create a class `CycleIterator` that mimics the behavior of a sequence iterator but cycles indefinitely over the given elements. 2. **Function Implementation**: - Implement a function `is_cycle_iterator(obj)` that checks whether a given object is an instance of the `CycleIterator` class. Requirements: 1. **CycleIterator Class**: - **Initialization**: - The class should accept a sequence (list, tuple, string, etc.) during initialization. - **`__iter__` Method**: - Return the iterator object itself. - **`__next__` Method**: - Cycle through the sequence indefinitely, restarting from the first element after reaching the last element. 2. **is_cycle_iterator Function**: - Accept an object as an argument. - Return `True` if the object is an instance of `CycleIterator`, otherwise return `False`. Constraints: - You should not use any external libraries or modules except the standard library. - The sequence provided to `CycleIterator` will always be non-empty. Examples: ```python # Example Usage cycle_iter = CycleIterator([1, 2, 3]) print(next(cycle_iter)) # Output: 1 print(next(cycle_iter)) # Output: 2 print(next(cycle_iter)) # Output: 3 print(next(cycle_iter)) # Output: 1 print(next(cycle_iter)) # Output: 2 # Checking the iterator type print(is_cycle_iterator(cycle_iter)) # Output: True print(is_cycle_iterator([1, 2, 3])) # Output: False ``` Implementation: ```python class CycleIterator: def __init__(self, sequence): self.sequence = sequence self.index = 0 def __iter__(self): return self def __next__(self): if self.index >= len(self.sequence): self.index = 0 result = self.sequence[self.index] self.index += 1 return result def is_cycle_iterator(obj): return isinstance(obj, CycleIterator) ``` Note: Make sure your implementation adheres to the given requirements and constraints. All instance variables and methods should be defined within the `CycleIterator` class.","solution":"class CycleIterator: def __init__(self, sequence): self.sequence = sequence self.index = 0 def __iter__(self): return self def __next__(self): if self.index >= len(self.sequence): self.index = 0 result = self.sequence[self.index] self.index += 1 return result def is_cycle_iterator(obj): return isinstance(obj, CycleIterator)"},{"question":"# **Coding Assessment Question** **Objective:** Demonstrate your understanding of Python lists, their methods, and comprehensions by implementing a transformation function. **Problem Statement:** You are required to write a function `transform_matrix(matrix: List[List[int]]) -> List[List[int]]` that takes a 2-D list `matrix` (a list of lists of integers) as input and performs the following operations: 1. **Transpose:** Transpose the matrix, turning rows into columns. 2. **Sort Rows:** After transposing, each row of the resultant matrix should be sorted in ascending order. 3. **Unique Elements:** Replace each row with only the unique elements, maintaining their sorted order. 4. **Filter Rows:** Filter out rows that are now empty after removing duplicates. # **Function Signature:** ```python from typing import List def transform_matrix(matrix: List[List[int]]) -> List[List[int]]: pass ``` # **Input Format:** - A list of lists of integers, `matrix`. Each sublist represents a row in the matrix. # **Output Format:** - A transformed list of lists where each sublist represents a row in the processed matrix. # **Constraints:** - `1 <= len(matrix) <= 100` - `1 <= len(row) <= 100` - `-10^6 <= matrix[i][j] <= 10^6` # **Example:** ```python # Input matrix = [ [4, 5, 6, 6], [3, 2, 1, 1], [8, 8, 8, 4] ] # Step-by-Step Transformation # 1. Transpose: # [ # [4, 3, 8], # [5, 2, 8], # [6, 1, 8], # [6, 1, 4] # ] # 2. Sort Rows: # [ # [3, 4, 8], # [2, 5, 8], # [1, 6, 8], # [1, 4, 6] # ] # 3. Unique Elements: # [ # [3, 4, 8], # [2, 5, 8], # [1, 6, 8], # [1, 4, 6] # ] # 4. Filter Rows: (No empty rows in this case) # [ # [3, 4, 8], # [2, 5, 8], # [1, 6, 8], # [1, 4, 6] # ] # Output [ [3, 4, 8], [2, 5, 8], [1, 6, 8], [1, 4, 6] ] ``` # **Notes:** - You must use list comprehensions wherever applicable. - Think about performance and efficiency while implementing the solution. - Consider edge cases, such as matrices with all identical elements or single-element matrices. Implement the above-specified function to pass all the given constraints and examples.","solution":"from typing import List def transform_matrix(matrix: List[List[int]]) -> List[List[int]]: # Step 1: Transpose the matrix transposed = list(map(list, zip(*matrix))) # Step 2: Sort each row in the transposed matrix sorted_rows = [sorted(row) for row in transposed] # Step 3: Remove duplicates while maintaining the sorted order unique_sorted_rows = [sorted(set(row)) for row in sorted_rows] # Step 4: Filter out empty rows filtered_rows = [row for row in unique_sorted_rows if row] return filtered_rows"},{"question":"**Objective:** Demonstrate your understanding of seaborn\'s `Plot` class and its integration with matplotlib by creating a composite plot using a specific dataset. Your task will be to generate a multi-panel figure with various plot types and customize it with annotations. **Problem Statement:** You are given the `diamonds` dataset available in seaborn\'s data repository. Your task is to create a composite plot with the following specifications: 1. Create a matplotlib figure with two subfigures arranged horizontally (side by side). 2. On the left subfigure: - Plot a scatter plot (dots) of `carat` vs. `price`. 3. On the right subfigure: - Plot histograms of the `price` distribution, faceted by the `cut` of the diamonds. - Scale the x-axis of the histograms logarithmically. 4. Customize the plots by adding an annotation in the scatter plot: - Draw a rectangle at the top-right corner with a width of 0.4, height of 0.1, and color `C1` with 20% transparency. - Add text inside the rectangle that reads \\"Diamonds: very sparkly!\\" centered within the rectangle. 5. Annotate the histograms by adding a red vertical line at x = 5000 in each facet. **Constraints:** - Do not modify the global matplotlib rcParams. - Ensure that the x-axis scale of the histograms is logarithmic after the composition. # Expected Input and Output - **Input:** None (The diamonds dataset will be loaded using seaborn\'s `load_dataset` function within the function). - **Output:** Display the composite plot with the specified customizations. # Function Signature ```python def create_composite_diamond_plot(): import seaborn as sns import seaborn.objects as so import matplotlib.pyplot as plt import matplotlib as mpl # Load the diamonds dataset diamonds = sns.load_dataset(\\"diamonds\\") # Create the matplotlib figure with two subfigures figure = mpl.figure.Figure(figsize=(14, 7), dpi=100, layout=\\"constrained\\") subfig_left, subfig_right = figure.subfigures(1, 2) # Left subfigure: Scatter plot using seaborn objects scatter_plot = so.Plot(diamonds, x=\\"carat\\", y=\\"price\\").add(so.Dots()) scatter_plot.on(subfig_left).plot() # Add rectangle and text annotation to the scatter plot ax_left = subfig_left.axes[0] rectangle = mpl.patches.Rectangle( xy=(0.6, 0.9), width=0.4, height=0.1, color=\\"C1\\", alpha=0.2, transform=ax_left.transAxes, clip_on=False, ) ax_left.add_artist(rectangle) ax_left.text( x=0.8, y=0.95, s=\\"Diamonds: very sparkly!\\", size=12, ha=\\"center\\", va=\\"center\\", transform=ax_left.transAxes, ) # Right subfigure: Histograms faceted by cut using seaborn objects histogram_plot = ( so.Plot(diamonds, x=\\"price\\") .add(so.Bars(), so.Hist()) .facet(row=\\"cut\\") .scale(x=\\"log\\") .share(y=False) ) histogram_plot.on(subfig_right).plot() # Add vertical line annotation to each histogram facet for ax_right in subfig_right.axes: ax_right.axvline(x=5000, color=\'red\', linestyle=\'--\') # Show the final composite plot plt.show() ``` The function `create_composite_diamond_plot` does not take any input parameters and generates a composite plot as described when executed.","solution":"import seaborn as sns import seaborn.objects as so import matplotlib.pyplot as plt import matplotlib as mpl def create_composite_diamond_plot(): # Load the diamonds dataset diamonds = sns.load_dataset(\\"diamonds\\") # Create the matplotlib figure with two subfigures figure = mpl.figure.Figure(figsize=(14, 7), dpi=100) subfig_left, subfig_right = figure.subfigures(1, 2) # Left subfigure: Scatter plot scatter_plot = so.Plot(diamonds, x=\\"carat\\", y=\\"price\\").add(so.Dots()) scatter_plot.on(subfig_left).plot() # Add rectangle and text annotation to the scatter plot ax_left = subfig_left.axes[0] rectangle = mpl.patches.Rectangle( xy=(0.6, 0.9), width=0.4, height=0.1, color=\\"C1\\", alpha=0.2, transform=ax_left.transAxes, clip_on=False, ) ax_left.add_artist(rectangle) ax_left.text( x=0.8, y=0.95, s=\\"Diamonds: very sparkly!\\", size=12, ha=\\"center\\", va=\\"center\\", transform=ax_left.transAxes, ) # Right subfigure: Histograms faceted by cut histogram_plot = ( so.Plot(diamonds, x=\\"price\\") .add(so.Bars(), so.Hist()) .facet(row=\\"cut\\") .scale(x=\\"log\\") .share(y=False) ) histogram_plot.on(subfig_right).plot() # Add vertical line annotation to each histogram facet for ax_right in subfig_right.axes: ax_right.axvline(x=5000, color=\'red\', linestyle=\'--\') # Show the final composite plot plt.show()"},{"question":"You are tasked with creating a Python C-extension module that provides a function to concatenate two bytes objects and return the result. We will call this function `concat_bytes`. # Requirements 1. The function should be defined in a module named `byteconcat`. 2. The function `concat_bytes` should accept two bytes objects as its parameters. 3. The function will return a new bytes object which is the concatenation of the two input bytes objects. 4. Proper error handling must be implemented to check whether the inputs are valid bytes objects. # Detailed Steps 1. Create a file named `byteconcat.c`: - Include the Python header. - Define the function `concat_bytes` using the `PyBytes_Concat()` function. - Handle reference counting and error-checking as necessary. 2. Create a `setup.py` script to build the C-extension module: - Use `setuptools` to define the build setup. 3. Provide a sample script to test the `concat_bytes` function after building the extension. # Constraints - Focus on handling memory efficiently and ensuring no memory leaks. - Make sure each input is verified to be of bytes type before performing any operation. - Detailed error messages should be returned when the input types are invalid. # Example ```python import byteconcat # Valid concatenation result = byteconcat.concat_bytes(b\'hello\', b\'world\') print(result) # Output: b\'helloworld\' # Invalid input handling try: result = byteconcat.concat_bytes(\'hello\', b\'world\') except TypeError as e: print(e) # Output: Both arguments must be bytes objects ``` You are required to submit: 1. The `byteconcat.c` file. 2. The `setup.py` file. 3. A Python script named `test_byteconcat.py` that demonstrates the usage and testing of the `concat_bytes` function. Good luck!","solution":"def add(a, b): Returns the sum of a and b. return a + b"},{"question":"You are given a neural network that uses `BatchNorm2d` layers. However, due to compatibility issues when using `functorch`\'s `vmap`, you need to replace `BatchNorm2d` with `GroupNorm` in certain situations. Your task is to implement a function that modifies a PyTorch nn.Module neural network to use GroupNorm instead of BatchNorm2d. Requirements: 1. Implement a function `replace_batch_norm_with_group_norm` that takes the following arguments: - `model` (nn.Module): The neural network model containing BatchNorm2d layers. - `num_groups` (int): The number of groups to use in GroupNorm. 2. The function should replace all BatchNorm2d layers within the model with GroupNorm layers using the specified number of groups. 3. Ensure that the replacement maintains the dimensions and functionality by setting `num_channels` in GroupNorm appropriately. 4. To verify the implementation, you should also write a simple test case to demonstrate the replacement. Function Signature ```python import torch.nn as nn def replace_batch_norm_with_group_norm(model: nn.Module, num_groups: int): Replace BatchNorm2d layers with GroupNorm layers in a PyTorch model. Args: model (nn.Module): The input neural network model. num_groups (int): Number of groups to divide channels into for GroupNorm. Returns: nn.Module: The updated model with GroupNorm layers. pass # Example usage class SimpleNet(nn.Module): def __init__(self): super(SimpleNet, self).__init__() self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(64) self.relu = nn.ReLU() self.fc = nn.Linear(64 * 32 * 32, 10) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = x.view(x.size(0), -1) x = self.fc(x) return x model = SimpleNet() num_groups = 8 replace_batch_norm_with_group_norm(model, num_groups) ``` Example Test Case: The following test case can be used to verify your implementation: ```python import torch def test_replace_batch_norm_with_group_norm(): model = SimpleNet() num_groups = 8 updated_model = replace_batch_norm_with_group_norm(model, num_groups) for module in updated_model.modules(): assert not isinstance(module, nn.BatchNorm2d), \\"Model still contains BatchNorm2d\\" assert isinstance(module, nn.GroupNorm) or not isinstance(module, nn.Module), \\"All BatchNorm2d layers should be replaced with GroupNorm\\" print(\\"All tests passed!\\") test_replace_batch_norm_with_group_norm() ``` Constraints: - Assume the input model will only contain `BatchNorm2d` layers that need replacing. - Use only PyTorch\'s built-in functionality to solve the problem. **Performance Requirements**: - Handle models of typical complexity and size used in practice within a reasonable time frame (e.g., models up to 100 layers with varying dimensions).","solution":"import torch import torch.nn as nn def replace_batch_norm_with_group_norm(model: nn.Module, num_groups: int): Replace BatchNorm2d layers with GroupNorm layers in a PyTorch model. Args: model (nn.Module): The input neural network model. num_groups (int): Number of groups to divide channels into for GroupNorm. Returns: nn.Module: The updated model with GroupNorm layers. for name, module in model.named_children(): if isinstance(module, nn.BatchNorm2d): # Getting the number of channels from the BatchNorm2d layer num_channels = module.num_features group_norm_layer = nn.GroupNorm(num_groups=num_groups, num_channels=num_channels) setattr(model, name, group_norm_layer) else: replace_batch_norm_with_group_norm(module, num_groups) return model # Example usage class SimpleNet(nn.Module): def __init__(self): super(SimpleNet, self).__init__() self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(64) self.relu = nn.ReLU() self.fc = nn.Linear(64 * 32 * 32, 10) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = x.view(x.size(0), -1) x = self.fc(x) return x model = SimpleNet() num_groups = 8 replace_batch_norm_with_group_norm(model, num_groups)"},{"question":"**Coding Assessment Question**: # Objective You are tasked with visualizing different aspects of a dataset containing information about tips received by waitstaff in a restaurant. You should demonstrate a thorough understanding of Seaborn\'s categorical plotting capabilities by implementing functions that generate specific plots with various customizations. # Dataset You will use the \\"tips\\" dataset available in Seaborn. Load the dataset as follows: ```python import seaborn as sns tips = sns.load_dataset(\\"tips\\") ``` # Requirements 1. **Strip Plot with Jitter**: - Write a function `strip_plot_with_jitter()` that generates a strip plot with jitter disabled, showing the `total_bill` against the `day` of the week. ```python def strip_plot_with_jitter(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"day\\", y=\\"total_bill\\", jitter=False) ``` 2. **Swarm Plot with Hue**: - Write a function `swarm_plot_with_hue()` that generates a swarm plot showing `total_bill` against `day`, with points colored by `sex`. ```python def swarm_plot_with_hue(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"day\\", y=\\"total_bill\\", hue=\\"sex\\", kind=\\"swarm\\") ``` 3. **Box Plot with Custom Order**: - Write a function `box_plot_custom_order()` that generates a box plot showing `tip` against `smoker`, ordering the `smoker` categories as [\\"No\\", \\"Yes\\"]. ```python def box_plot_custom_order(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"smoker\\", y=\\"tip\\", order=[\\"No\\", \\"Yes\\"], kind=\\"box\\") ``` 4. **Violin Plot with KDE Tuning**: - Write a function `violin_plot_kde_tuning()` that generates a violin plot showing `total_bill` against `day`, separating by `sex` and adjusting the bandwidth (`bw_adjust`) to 0.5 and limiting the KDE curve (`cut`) to 0. ```python def violin_plot_kde_tuning(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"total_bill\\", y=\\"day\\", hue=\\"sex\\", kind=\\"violin\\", bw_adjust=0.5, cut=0) ``` 5. **Bar Plot of Survival Rate**: - Write a function `bar_plot_survival_rate()` that generates a bar plot using the \\"titanic\\" dataset (also available in Seaborn), showing the survival rate (`survived`) against `sex`, separated by `class`. Display 95% confidence intervals (default). ```python def bar_plot_survival_rate(): import seaborn as sns titanic = sns.load_dataset(\\"titanic\\") sns.catplot(data=titanic, x=\\"sex\\", y=\\"survived\\", hue=\\"class\\", kind=\\"bar\\") ``` # Submission Guidelines - Implement each function as described. - Ensure your code runs without errors. - Use Seaborn documentation and examples provided to understand the functions better. - Test each function to make sure the plots are generated correctly. # Constraints - Use only Seaborn and other necessary basic libraries (e.g., matplotlib for plotting). - Do not use additional datasets or libraries. - Maintain consistent plot aesthetics as in the examples. - Functions should not take any parameters and should directly generate the plots when called. # Expected Output When calling each of the functions individually, they should display the corresponding plot. **Example**: ```python strip_plot_with_jitter() ``` Should generate a strip plot for `total_bill` vs `day` with no jitter.","solution":"def strip_plot_with_jitter(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"day\\", y=\\"total_bill\\", jitter=False, kind=\\"strip\\") def swarm_plot_with_hue(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"day\\", y=\\"total_bill\\", hue=\\"sex\\", kind=\\"swarm\\") def box_plot_custom_order(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"smoker\\", y=\\"tip\\", order=[\\"No\\", \\"Yes\\"], kind=\\"box\\") def violin_plot_kde_tuning(): import seaborn as sns tips = sns.load_dataset(\\"tips\\") sns.catplot(data=tips, x=\\"day\\", y=\\"total_bill\\", hue=\\"sex\\", kind=\\"violin\\", bw_adjust=0.5, cut=0) def bar_plot_survival_rate(): import seaborn as sns titanic = sns.load_dataset(\\"titanic\\") sns.catplot(data=titanic, x=\\"sex\\", y=\\"survived\\", hue=\\"class\\", kind=\\"bar\\")"},{"question":"**Objective: Working with PyTorch MPS Backend** You are tasked with implementing a function that utilizes several features provided by the `torch.mps` module for optimization and profiling on MPS devices. Your task includes: 1. Checking the available MPS devices. 2. Setting a manual seed for reproducibility. 3. Allocating memory efficiently. 4. Profiling the computation to ensure it operates within the expected performance limits. # Function Signature ```python def mps_computation_profile(n: int): Performs a computation on the MPS device, profiles the execution, and ensures it operates efficiently. Parameters: n (int): The size of the tensor to be used in the computation. Returns: dict: A dictionary with memory usage statistics and profiling information. pass ``` # Instructions 1. **Device Check**: - Use the `torch.mps.device_count()` function to ensure at least one MPS device is available. If no device is available, the function should raise a `RuntimeError`. 2. **Manual Seeding**: - Set the seed for the random number generator to a fixed value (e.g., `42`) using `torch.mps.manual_seed()` to ensure reproducibility. 3. **Memory Management**: - Allocate memory for a tensor of size `n x n` using the best practices for memory management. Use functions such as `torch.mps.empty_cache()` to clear cache if necessary, and ensure the current allocated memory and the driver allocated memory are within the recommended limits. 4. **Profiling**: - Use the MPS profiler to profile the operation of matrix multiplication between two randomly generated tensors of size `n x n`. Capture profiling information and any Metal-specific captures. - Use `torch.mps.profiler.start()` and `torch.mps.profiler.stop()` to control the profiling session. 5. **Return Results**: - The function should return a dictionary with at least the following keys and their corresponding values: - `\'current_allocated_memory\'`: The current allocated memory. - `\'driver_allocated_memory\'`: The total memory allocated by the driver. - `\'recommended_max_memory\'`: The recommended maximum memory usage for the current device. - `\'profiling_output\'`: A summary of the profiling results. - `\'metal_capture_active\'`: A boolean indicating if Metal capture was active during profiling. # Constraints - Assume that the `torch` module is imported and the `torch.mps` submodule is available. - The tensor operations should be performed on the MPS device. # Example ```python result = mps_computation_profile(1000) print(result) ``` The output dictionary should contain detailed information about the memory usage and profiling results.","solution":"import torch import time def mps_computation_profile(n: int): Performs a computation on the MPS device, profiles the execution, and ensures it operates efficiently. Parameters: n (int): The size of the tensor to be used in the computation. Returns: dict: A dictionary with memory usage statistics and profiling information. if torch.mps.device_count() == 0: raise RuntimeError(\\"No MPS devices available.\\") torch.mps.manual_seed(42) device = torch.device(\\"mps\\") # Clear cache torch.mps.empty_cache() current_allocated_memory_start = torch.mps.current_allocated_memory() driver_allocated_memory_start = torch.mps.driver_allocated_memory() recommended_max_memory = torch.mps.recommended_max_memory_usage() # Allocate tensors a = torch.randn((n, n), device=device) b = torch.randn((n, n), device=device) # Start profiling torch.mps.profiler.start() start_time = time.time() c = torch.matmul(a, b) end_time = time.time() torch.mps.profiler.stop() current_allocated_memory_end = torch.mps.current_allocated_memory() profiling_output = { \\"computation_time\\": end_time - start_time, \\"matrix_size\\": n, \\"current_allocated_memory_start\\": current_allocated_memory_start, \\"current_allocated_memory_end\\": current_allocated_memory_end, \\"growth_in_memory_usage\\": current_allocated_memory_end - current_allocated_memory_start, } return { \'current_allocated_memory\': current_allocated_memory_end, \'driver_allocated_memory\': driver_allocated_memory_start, \'recommended_max_memory\': recommended_max_memory, \'profiling_output\': profiling_output, \'metal_capture_active\': False # Assuming MPS profiler\'s Metal capture is not active }"},{"question":"# Advanced Coding Assessment Question on Scikit-learn Datasets Objective: To assess your understanding and ability to load, manipulate, and use datasets from the `sklearn.datasets` package in scikit-learn. Problem: You are provided with a requirement to perform the following tasks: 1. **Load** the \\"Iris\\" dataset using the appropriate loader function from scikit-learn. 2. **Generate** a synthetic dataset with similar dimensions (number of samples and features) as the Iris dataset but with controlled properties. 3. **Analyze** and **Compare** the two datasets using basic statistical measures (mean, standard deviation) for each feature. Instructions: 1. **Function Definition:** Implement a function `compare_datasets` that performs the tasks listed above and returns relevant statistics. ```python def compare_datasets(): Loads the Iris dataset, generates a synthetic dataset with the same dimensions, compares them using basic statistics. Returns: dict: A dictionary with the statistical comparison of the original and synthetic datasets. pass ``` 2. **Expected Steps:** a) **Load Iris Dataset:** - Use `sklearn.datasets.load_iris` to load the Iris dataset. - Extract the data (`X`) and the target (`y`). b) **Generate Synthetic Dataset:** - Use `sklearn.datasets.make_classification` to generate a synthetic dataset with the same number of samples and features as the Iris dataset. - Ensure the label distribution is roughly similar (3 classes). c) **Compute Statistics:** - Calculate the mean and standard deviation for each feature in both datasets. - Create a summary dictionary to represent these statistics. 3. **Example Output Format:** ```python { \\"iris\\": { \\"mean\\": [array_of_means], \\"std_dev\\": [array_of_stds] }, \\"synthetic\\": { \\"mean\\": [array_of_means], \\"std_dev\\": [array_of_stds] } } ``` Constraints: - You must use appropriate functions from `sklearn.datasets` for loading and generating datasets. - Avoid using any dataset-specific functions or attributes that are not mentioned in the provided documentation. Performance Requirements: - The function should compute statistics in a time-efficient manner. - The comparison should handle datasets efficiently even if they are larger than the iris dataset. # Evaluation Criteria: - Correctness: The implementation correctly loads, generates, and compares the datasets. - Coding Style: The code is clean, well-documented, and follows Python best practices. - Efficiency: The implementation is efficient in terms of computation and memory usage.","solution":"from sklearn.datasets import load_iris, make_classification import numpy as np def compare_datasets(): Loads the Iris dataset, generates a synthetic dataset with the same dimensions, compares them using basic statistics. Returns: dict: A dictionary with the statistical comparison of the original and synthetic datasets. # Load the Iris dataset iris = load_iris() X_iris = iris.data y_iris = iris.target # Generate a synthetic dataset with similar dimensions and properties n_samples, n_features = X_iris.shape n_classes = len(np.unique(y_iris)) X_synthetic, y_synthetic = make_classification(n_samples=n_samples, n_features=n_features, n_informative=n_features, n_redundant=0, n_clusters_per_class=1, n_classes=n_classes, random_state=42) # Compute statistics (mean and standard deviation) for each feature iris_stats = { \\"mean\\": np.mean(X_iris, axis=0).tolist(), \\"std_dev\\": np.std(X_iris, axis=0).tolist() } synthetic_stats = { \\"mean\\": np.mean(X_synthetic, axis=0).tolist(), \\"std_dev\\": np.std(X_synthetic, axis=0).tolist() } # Prepare the result dictionary result = { \\"iris\\": iris_stats, \\"synthetic\\": synthetic_stats } return result"},{"question":"# **Coding Assessment Question** You are provided with a file containing multiple chunks in the EA IFF 85 format. Your task is to implement a function called `extract_chunks` that reads all chunk IDs and their sizes from the file and returns them in a list of tuples. Each tuple will contain the chunk ID and its corresponding size. **Function Signature** ```python def extract_chunks(file_path: str) -> list[tuple[str, int]]: ``` **Parameters** - `file_path` (str): The path to the file containing the chunked data. **Returns** - `list[tuple[str, int]]`: A list of tuples where each tuple contains the chunk ID (str) and chunk size (int). **Constraints** - You can assume the file is well-formed and follows the EA IFF 85 specifications. - The file may contain multiple chunks. - The function should handle reading the entire file efficiently. **Example** Suppose we have a file `example.aiff` with chunks structured as follows: - Chunk 1: ID = \\"FORM\\", Size = 12 - Chunk 2: ID = \\"COMM\\", Size = 18 - Chunk 3: ID = \\"SSND\\", Size = 24 Calling the function: ```python result = extract_chunks(\'example.aiff\') ``` This should return: ```python [(\'FORM\', 12), (\'COMM\', 18), (\'SSND\', 24)] ``` **Implementation Notes** - Use the `chunk.Chunk` class to parse through the file and extract the required information. - Remember to handle the end of file scenario where attempting to create a new chunk should lead to an `EOFError` exception. **Hint:** Utilize a `while` loop to iterate through the chunks and handle exceptions appropriately.","solution":"import chunk def extract_chunks(file_path: str) -> list[tuple[str, int]]: Extracts chunk IDs and their sizes from a file in EA IFF 85 format. Args: file_path (str): The path to the file containing the chunked data. Returns: list[tuple[str, int]]: A list of tuples, each containing a chunk ID (str) and chunk size (int). chunks = [] with open(file_path, \'rb\') as f: try: while True: current_chunk = chunk.Chunk(f, bigendian=True, align=True) chunk_id = current_chunk.getname().decode(\'ascii\') chunk_size = current_chunk.chunksize chunks.append((chunk_id, chunk_size)) current_chunk.skip() except EOFError: pass return chunks"},{"question":"# Question: You are tasked with creating a data visualization dashboard that helps analyze the `diamonds` dataset provided by seaborn. Your goal is to create a composite figure consisting of multiple plots to visualize the relationships and distributions of different features graphically. Follow the instructions to accomplish this: 1. **Load the `diamonds` dataset** from seaborn. 2. **Create a composite figure with two subfigures** arranged in a single row. The left subfigure should display the relationship between `carat` and `price` using a scatter plot. The right subfigure should display histograms for the `price` of diamonds faceted by their `cut` quality, with the `price` axis scaled logarithmically. 3. For the scatter plot (left subfigure), **add a customized annotation** inside the plot area — a rectangle with the text \\"Diamonds: very sparkly!\\". 4. Customize the theme or RC parameters if necessary to match seaborn\'s default styles. # Input: There are no specific inputs required as the dataset is internally loaded and used within the script. # Output: An interactive Matplotlib figure combining both described visualizations in a single composite frame. # Example Implementation: ```python import seaborn as sns import seaborn.objects as so import matplotlib as mpl import matplotlib.pyplot as plt # Load the diamonds dataset diamonds = sns.load_dataset(\\"diamonds\\") # Initialize the main figure with two subfigures f = mpl.figure.Figure(figsize=(12, 6), dpi=100, layout=\\"constrained\\") sf1, sf2 = f.subfigures(1, 2) # Left subfigure: scatter plot of carat vs price p1 = so.Plot(diamonds, \\"carat\\", \\"price\\").add(so.Dots()) p1.on(sf1).plot() # Adding customized annotation to the left subfigure ax1 = sf1.axes[0] rect = mpl.patches.Rectangle( xy=(0, 1), width=.4, height=.1, color=\\"C1\\", alpha=.2, transform=ax1.transAxes, clip_on=False, ) ax1.add_artist(rect) ax1.text( x=rect.get_width() / 2, y=1 + rect.get_height() / 2, s=\\"Diamonds: very sparkly!\\", size=12, ha=\\"center\\", va=\\"center\\", transform=ax1.transAxes, ) # Right subfigure: histogram of price faceted by cut so.Plot(diamonds, x=\\"price\\") .add(so.Bars(), so.Hist()) .facet(row=\\"cut\\") .scale(x=\\"log\\") .share(y=False) .on(sf2) # Show the composite figure plt.show(f) ``` # Constraints: - Ensure the generated figure is clear and uses appropriate scaling (e.g., logarithmic scale for histogram). - Use the seaborn themes or customize the Matplotlib RC parameters to maintain a consistent and visually appealing style. - Include detailed inline comments explaining each major step of your implementation.","solution":"import seaborn as sns import matplotlib.pyplot as plt import matplotlib.patches as patches def create_diamonds_dashboard(): Creates a composite figure to visualize the diamonds dataset. The figure will contain a scatter plot of carat vs price and histograms of price faceted by cut with logarithmic scaling. # Load the diamonds dataset diamonds = sns.load_dataset(\\"diamonds\\") # Initialize the main figure with two subplots arranged in one row fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), constrained_layout=True) # Left subplot: scatter plot of carat vs price sns.scatterplot(ax=ax1, x=\'carat\', y=\'price\', data=diamonds) ax1.set_title(\'Carat vs Price\') ax1.set_xlabel(\'Carat\') ax1.set_ylabel(\'Price\') # Adding customized annotation to the scatter plot annotation_text = \\"Diamonds: very sparkly!\\" bbox_props = dict(boxstyle=\\"round,pad=0.3\\", edgecolor=\\"black\\", facecolor=\\"orange\\", alpha=0.5) ax1.text(1.5, 15000, annotation_text, fontsize=12, bbox=bbox_props) # Right subplot: histogram of price faceted by cut with logarithmic scale sns.histplot(ax=ax2, x=\'price\', hue=\'cut\', data=diamonds, multiple=\'stack\', log_scale=(True, False)) ax2.set_title(\'Price Distribution by Cut (Log Scale)\') ax2.set_xlabel(\'Price\') ax2.set_ylabel(\'Count\') # Display the plot plt.show()"},{"question":"# Unix User and Group Information Retrieval **Objective**: Write a Python function that retrieves and displays user and group information from the Unix password and group databases. Function Signature ```python def retrieve_user_group_info(username: str) -> dict: pass ``` Input - `username`: A string representing the username whose information needs to be retrieved. Output - A dictionary containing the following key-value pairs: - `\\"uid\\"`: The user\'s ID (an integer). - `\\"gid\\"`: The user\'s primary group ID (an integer). - `\\"groups\\"`: A list of group names that the user belongs to. Constraints - The function should raise a `ValueError` if the username does not exist. - Use the `pwd` and `grp` modules to interact with the Unix password and group databases. Example ```python # Example invocation retrieve_user_group_info(\'john\') # Expected output (assuming \'john\' exists and belongs to groups \'users\' and \'admins\') { \\"uid\\": 1001, \\"gid\\": 100, \\"groups\\": [\\"users\\", \\"admins\\"] } ``` Requirements - Ensure your function handles errors gracefully and provides meaningful error messages. - Optimize the function for performance with respect to accessing and processing database information. - You may assume that the necessary Unix-specific modules are available and do not need to be installed. Write your implementation in the cell below:","solution":"import pwd import grp def retrieve_user_group_info(username: str) -> dict: Retrieves and displays user and group information from the Unix password and group databases. Parameters: username (str): The username whose information needs to be retrieved. Returns: dict: A dictionary containing the user\'s ID, primary group ID, and a list of group names the user belongs to. try: # Retrieve user information from the password database user_info = pwd.getpwnam(username) # Retrieve user id and primary group id from user_info uid = user_info.pw_uid gid = user_info.pw_gid # Get the list of groups the user belongs to all_groups = grp.getgrall() user_groups = [group.gr_name for group in all_groups if username in group.gr_mem] # Make sure to include the primary group name in the groups list primary_group_name = grp.getgrgid(gid).gr_name if primary_group_name not in user_groups: user_groups.append(primary_group_name) return { \\"uid\\": uid, \\"gid\\": gid, \\"groups\\": user_groups } except KeyError: raise ValueError(f\\"Username \'{username}\' does not exist.\\")"},{"question":"You are tasked with writing a Python script that connects to an IMAP server, fetches specific emails, extracts certain parts of the messages, and handles potential exceptions that might occur during the process. Use the \\"imaplib\\" module to accomplish the following tasks. # Task Details 1. **Establish a Secure Connection:** - Connect to an IMAP server using an SSL connection with the provided hostname and port. - Use the `IMAP4_SSL` class for this purpose. 2. **Login to the Server:** - Authenticate using a username and password. For simplicity, you can assume these credentials are provided as input arguments to your function. 3. **Select the Mailbox:** - Select the \\"INBOX\\" mailbox. This should be done in a read-only mode to avoid making unintended changes. 4. **Search for Specific Emails:** - Search for all emails received from a specific email address. The email address should be provided as an input argument to your function. 5. **Fetch and Print Parts of the Emails:** - Fetch the subject, date, and body of each email that matches the search criteria. - Print the subject, date, and the first 100 characters of the body for each email. 6. **Handle Exceptions:** - Implement appropriate exception handling for potential issues such as connection errors, authentication failures, and other IMAP errors using the exceptions defined in `imaplib`. # Inputs - `hostname` (str): The hostname of the IMAP server. - `port` (int): The port number for the IMAP SSL connection. - `username` (str): The username for authentication. - `password` (str): The password for authentication. - `search_email` (str): The email address to search for. # Output - Print the subject, date, and the first 100 characters of the body for each email that matches the search criteria. # Function Signature ```python def fetch_emails(hostname: str, port: int, username: str, password: str, search_email: str) -> None: pass ``` # Example Usage ```python fetch_emails( hostname=\'imap.example.com\', port=993, username=\'user@example.com\', password=\'password123\', search_email=\'sender@example.com\' ) ``` # Constraints - You must use the `IMAP4_SSL` class from the `imaplib` module. - Use exception handling for `IMAP4.error`, `IMAP4.abort`, and `IMAP4.readonly` to manage potential errors. Implement the `fetch_emails` function to meet the criteria provided above.","solution":"import imaplib import email from email.header import decode_header def fetch_emails(hostname: str, port: int, username: str, password: str, search_email: str) -> None: try: # Establish connection to the IMAP server connection = imaplib.IMAP4_SSL(hostname, port) # Login to the server connection.login(username, password) # Select the desired mailbox connection.select(\\"INBOX\\", readonly=True) # Search for emails from the specified email address search_criteria = f\'(FROM \\"{search_email}\\")\' status, messages = connection.search(None, search_criteria) if status != \'OK\': raise imaplib.IMAP4.error(\\"Failed to search for emails.\\") # Convert the result to a list of email IDs email_ids = messages[0].split() for email_id in email_ids: # Fetch the email data status, msg_data = connection.fetch(email_id, \\"(RFC822)\\") if status != \'OK\': raise imaplib.IMAP4.error(\\"Failed to fetch email data.\\") for response_part in msg_data: if isinstance(response_part, tuple): msg = email.message_from_bytes(response_part[1]) # Decode the email subject raw_subject, encoding = decode_header(msg[\\"Subject\\"])[0] subject = raw_subject.decode(encoding) if encoding else raw_subject # Get the email date date = msg[\\"Date\\"] # Get the email body if msg.is_multipart(): for part in msg.walk(): if part.get_content_type() == \\"text/plain\\": body = part.get_payload(decode=True).decode() break else: body = msg.get_payload(decode=True).decode() # Print the required parts of the email print(\\"Subject:\\", subject) print(\\"Date:\\", date) print(\\"Body:\\", body[:100]) print(\\"-\\" * 50) # Close the connection connection.close() connection.logout() except imaplib.IMAP4.error as e: print(f\\"IMAP error: {e}\\") except imaplib.IMAP4.abort as e: print(f\\"IMAP abort error: {e}\\") except imaplib.IMAP4.readonly as e: print(f\\"IMAP readonly error: {e}\\") except Exception as e: print(f\\"An unexpected error occurred: {e}\\")"},{"question":"# Pandas Copy-on-Write Assessment Background Starting with pandas version 3.0, the Copy-on-Write (CoW) mechanism ensures that DataFrame and Series operations do not lead to unintended side effects by preventing shared data mutations. This change mitigates unpredictable behaviors that previously arose from some operations returning views and others returning copies. With CoW, modifications are deferred until necessary, significantly improving performance and memory efficiency. Problem Statement You are tasked with writing a function that processes sales data stored in a `pandas.DataFrame` to generate a summary of total sales per category. To comply with the Copy-on-Write mechanism, your function should avoid unintended data mutations and handle any read-only array issues appropriately. Function Signature ```python def summarize_sales(data: pd.DataFrame) -> pd.DataFrame: Summarizes the total sales per category. Args: - data (pd.DataFrame): A pandas DataFrame with columns [\'Category\', \'Product\', \'Sales\']. Returns: - pd.DataFrame: A pandas DataFrame with columns [\'Category\', \'Total_Sales\']. pass ``` Input - `data`: A `pandas.DataFrame` containing at least the following columns: - `\'Category\'`: A string indicating the category of the product. - `\'Product\'`: A string indicating the product name. - `\'Sales\'`: A float indicating the sales amount for the product. Output - Returns a `pandas.DataFrame` containing: - `\'Category\'`: The product category. - `\'Total_Sales\'`: The total sales amount for each category. Constraints 1. Do not mutate the original DataFrame `data`. 2. Use the Copy-on-Write principles to ensure no unintended side effects. 3. You should avoid any explicit copy operations unless necessary. Example ```python import pandas as pd # Sample DataFrame data = pd.DataFrame({ \'Category\': [\'Electronics\', \'Furniture\', \'Electronics\', \'Furniture\', \'Toys\'], \'Product\': [\'Laptop\', \'Chair\', \'Smartphone\', \'Table\', \'Teddy Bear\'], \'Sales\': [1200.50, 340.00, 850.75, 200.00, 150.50] }) result = summarize_sales(data) print(result) ``` Expected Output: ``` Category Total_Sales 0 Electronics 2051.25 1 Furniture 540.00 2 Toys 150.50 ``` Notes - Ensure your solution adheres to the Copy-on-Write principles. - Consider performance and memory usage in your implementation. - Use appropriate pandas functions to achieve the desired output.","solution":"import pandas as pd def summarize_sales(data: pd.DataFrame) -> pd.DataFrame: Summarizes the total sales per category. Args: - data (pd.DataFrame): A pandas DataFrame with columns [\'Category\', \'Product\', \'Sales\']. Returns: - pd.DataFrame: A pandas DataFrame with columns [\'Category\', \'Total_Sales\']. # Group the data by \'Category\' and sum the \'Sales\' summary = data.groupby(\'Category\', as_index=False)[\'Sales\'].sum() # Rename the \'Sales\' column to \'Total_Sales\' summary.rename(columns={\'Sales\': \'Total_Sales\'}, inplace=True) return summary"},{"question":"**Question:** You have been assigned the task of working with Python version information in a system that processes version data in both human-readable and machine-readable formats. The machine-readable format uses a single 32-bit hexadecimal number (PY_VERSION_HEX) to encode the Python version, as described below: 1. PY_MAJOR_VERSION: Bits 1-8 2. PY_MINOR_VERSION: Bits 9-16 3. PY_MICRO_VERSION: Bits 17-24 4. PY_RELEASE_LEVEL: Bits 25-28 (0xA for alpha, 0xB for beta, 0xC for release candidate, 0xF for final) 5. PY_RELEASE_SERIAL: Bits 29-32 For example, the version \\"3.4.1a2\\" is encoded as `0x030401a2`. Write the following two functions: 1. `version_to_hex(version: str) -> int`: This function takes a version string (e.g., \\"3.4.1a2\\") and returns the corresponding hexadecimal version number. 2. `hex_to_version(hex_version: int) -> str`: This function takes a hexadecimal version number and returns the corresponding version string. # Input and Output Formats: - `version_to_hex(version: str) -> int` - Input: A string representing the version (e.g., \\"3.10.0f0\\"). - Output: An integer representing the hexadecimal version number (e.g., 0x030a00f0). - `hex_to_version(hex_version: int) -> str` - Input: An integer representing the hexadecimal version number (e.g., 0x030a00f0). - Output: A string representing the version (e.g., \\"3.10.0f0\\"). # Constraints: 1. The version string will be in the correct format: major.minor.micro(level)(serial), where: - major, minor, and micro are integers. - level is one of the characters \'a\' (alpha), \'b\' (beta), \'c\' (release candidate), or \'f\' (final). - serial is an integer. 2. The hexadecimal version number will fit within a 32-bit unsigned integer. # Example: ```python assert version_to_hex(\\"3.4.1a2\\") == 0x030401a2 assert hex_to_version(0x030401a2) == \\"3.4.1a2\\" ``` Implement the `version_to_hex` and `hex_to_version` functions in Python.","solution":"def version_to_hex(version: str) -> int: parts = version.split(\\".\\") major = int(parts[0]) minor = int(parts[1]) rest = parts[2] micro = int(rest[:-2]) level_char = rest[-2] serial = int(rest[-1]) if level_char == \'a\': level = 0xA elif level_char == \'b\': level = 0xB elif level_char == \'c\': level = 0xC elif level_char == \'f\': level = 0xF else: raise ValueError(\\"Invalid release level\\") version_hex = (major << 24) | (minor << 16) | (micro << 8) | (level << 4) | serial return version_hex def hex_to_version(hex_version: int) -> str: major = (hex_version >> 24) & 0xFF minor = (hex_version >> 16) & 0xFF micro = (hex_version >> 8) & 0xFF level = (hex_version >> 4) & 0xF serial = hex_version & 0xF if level == 0xA: level_char = \'a\' elif level == 0xB: level_char = \'b\' elif level == 0xC: level_char = \'c\' elif level == 0xF: level_char = \'f\' else: raise ValueError(\\"Invalid release level\\") version = f\\"{major}.{minor}.{micro}{level_char}{serial}\\" return version"},{"question":"Objective: Write a function `concat_and_resize_bytes(bytes_list: list, sizes: list) -> bytes` that concatenates a list of byte strings (`bytes_list`) and then resizes the resulting byte string according to the given sizes in `sizes` list. Description: 1. **Function Signature**: ```python def concat_and_resize_bytes(bytes_list: list, sizes: list) -> bytes: ``` 2. **Parameters**: - `bytes_list`: A list of byte strings (each element of type `bytes`). - `sizes`: A list of integers that dictate the size to which the resultant byte string needs to be resized successively. 3. **Returns**: - A resized bytes object after successive concatenation and resizing operations. 4. **Execution Requirements**: - Initially concatenate all byte strings in `bytes_list`. - Successively resize the resultant byte string according to each size provided in the `sizes` list. - Ensure all provided sizes are valid and capable of handling by applying memory error checks. - Raise `ValueError` if any given size is invalid during resizing. 5. **Constraints**: - The length of `bytes_list` and `sizes` can range from 1 to 1000. - Each byte string in `bytes_list` can have a maximum length of 1000 bytes. - Lengths in `sizes` will always be non-negative and reasonable for memory allocation. Example: ```python bytes_list = [b\'abc\', b\'def\', b\'ghi\'] sizes = [10, 5, 8] result = concat_and_resize_bytes(bytes_list, sizes) print(result) # Expected Output: a resized bytes-object with final size 8 after successive operations ``` Notes: - You can use the functions provided in the documentation such as `PyBytes_FromStringAndSize`, `PyBytes_Size`, `_PyBytes_Resize`, and `PyBytes_Concat` to implement this function. - Implement and test your function thoroughly to ensure correctness and memory safety.","solution":"def concat_and_resize_bytes(bytes_list: list, sizes: list) -> bytes: Concatenates a list of byte strings and then resizes the resulting byte string according to the given sizes in successive steps. Parameters: bytes_list (list): A list of byte strings. sizes (list): A list of integers specifying the sizes for successive resizing. Returns: bytes: The final resized bytes object. Raises: ValueError: If any given size is invalid during resizing. # Concatenate all byte strings in the bytes_list concatenated = b\'\'.join(bytes_list) # Successively resize the concatenated bytes object according to each size in sizes for size in sizes: if size < 0: raise ValueError(\\"Size must be non-negative\\") concatenated = concatenated[:size].ljust(size, b\'x00\') return concatenated"},{"question":"# Question: Implementing Advanced Named Tensor Manipulations in PyTorch Objective: Your task is to implement a function that demonstrates your understanding of named tensors in PyTorch. You will create named tensors, perform operations while preserving the names, and manipulate the dimensions\' order and structure. Detailed Instructions: 1. **Function Signature**: ```python def manipulate_named_tensors(): pass ``` 2. **Tasks**: - Create a 4-dimensional tensor of shape `(1, 2, 2, 3)` with the names `(\'N\', \'C\', \'H\', \'W\')`. - Rename the dimensions \'H\' to \'Height\' and \'W\' to \'Width\'. - Create another tensor of shape `(2, 3)` with the names `(\'Height\', \'Width\')`. - Align the second tensor to match the dimensions of the first tensor for multiplication. - Multiply the two tensors and ensure the resulting tensor maintains appropriate names. - Flatten the resulting tensor\'s dimensions \'C\', \'Height\', and \'Width\' into a single dimension called \'features\'. - Finally, unflatten the \'features\' dimension back to the original dimensions \'C\', \'Height\', and \'Width\'. 3. **Output**: - The function should print the dimensions and names of the tensor at each key step: 1. Initial tensor creation. 2. After renaming dimensions. 3. After aligning for multiplication. 4. After multiplication. 5. After flattening. 6. After unflattening. 4. **Constraints**: - You must use named tensor operations to manipulate and align tensors. - Ensure that names are consistently used and correctly propagated through the operations. - Follow the performance guidelines specified in PyTorch documentation for named tensors. Example Output: ```python Initial tensor: Shape: torch.Size([1, 2, 2, 3]), Names: (\'N\', \'C\', \'H\', \'W\') After renaming dimensions: Shape: torch.Size([1, 2, 2, 3]), Names: (\'N\', \'C\', \'Height\', \'Width\') Second tensor aligned for multiplication: Shape: torch.Size([1, 2, 2, 3]), Names: (\'N\', \'C\', \'Height\', \'Width\') After multiplication: Shape: torch.Size([1, 2, 2, 3]), Names: (\'N\', \'C\', \'Height\', \'Width\') After flattening: Shape: torch.Size([1, 6]), Names: (\'N\', \'features\') After unflattening: Shape: torch.Size([1, 2, 2, 3]), Names: (\'N\', \'C\', \'Height\', \'Width\') ``` Implement the `manipulate_named_tensors` function following the detailed instructions and ensure the correct use of named tensor operations. Note: - The named tensor API is experimental and subject to change. Ensure you use the current version of PyTorch when testing your solution. - Refer to the provided documentation on named tensors for additional details and guidance.","solution":"import torch def manipulate_named_tensors(): # Step 1: Create a 4D tensor of shape (1, 2, 2, 3) with names (\'N\', \'C\', \'H\', \'W\') tensor1 = torch.randn((1, 2, 2, 3), names=(\'N\', \'C\', \'H\', \'W\')) print(\\"Initial tensor:n\\", tensor1) print(\\"Shape:\\", tensor1.size(), \\"Names:\\", tensor1.names) # Step 2: Rename dimensions \'H\' to \'Height\' and \'W\' to \'Width\' tensor1 = tensor1.rename(H=\'Height\', W=\'Width\') print(\\"nAfter renaming dimensions:n\\", tensor1) print(\\"Shape:\\", tensor1.size(), \\"Names:\\", tensor1.names) # Step 3: Create another tensor of shape (2, 3) with names (\'Height\', \'Width\') tensor2 = torch.randn((2, 3), names=(\'Height\', \'Width\')) # Align the second tensor to match the dimensions of the first tensor for multiplication tensor2_aligned = tensor2.align_as(tensor1) print(\\"nSecond tensor aligned for multiplication:n\\", tensor2_aligned) print(\\"Shape:\\", tensor2_aligned.size(), \\"Names:\\", tensor2_aligned.names) # Step 4: Multiply the two tensors tensor3 = tensor1 * tensor2_aligned print(\\"nAfter multiplication:n\\", tensor3) print(\\"Shape:\\", tensor3.size(), \\"Names:\\", tensor3.names) # Step 5: Flatten \'C\', \'Height\', and \'Width\' into a single dimension called \'features\' tensor_flattened = tensor3.flatten([\'C\', \'Height\', \'Width\'], \'features\') print(\\"nAfter flattening:n\\", tensor_flattened) print(\\"Shape:\\", tensor_flattened.size(), \\"Names:\\", tensor_flattened.names) # Step 6: Unflatten the \'features\' dimension back to \'C\', \'Height\', and \'Width\' tensor_unflattened = tensor_flattened.unflatten(\'features\', ((\'C\', 2), (\'Height\', 2), (\'Width\', 3))) print(\\"nAfter unflattening:n\\", tensor_unflattened) print(\\"Shape:\\", tensor_unflattened.size(), \\"Names:\\", tensor_unflattened.names) # Call the function to see the result manipulate_named_tensors()"},{"question":"# Question: Implementing a Custom Neural Network Layer with Dynamic Control Flow Context: In this exercise, you will implement a custom PyTorch neural network module that employs dynamic control flow using `torch.cond`. The purpose is to create a layer whose behavior changes based on the input tensor properties. Task: 1. Implement a custom PyTorch module called `AdaptiveLayer` that changes its behavior based on: - The sum of all elements in the input tensor. 2. Define the following: - If the sum of elements in the input tensor is greater than 10, apply a combination of cosine and sine operations to the input tensor. - Otherwise, apply only the sine operation to the input tensor. Implementation Details: - Your module should inherit from `torch.nn.Module`. - Inside the `forward` method, use `torch.cond` to apply the operations based on the sum of input tensor elements. - Use `torch.sum` to compute the sum of elements in the input tensor. - Define two functions: 1. `apply_cos_sin`: to return `x.cos() + x.sin()` 2. `apply_sin`: to return `x.sin()` Ensure the module meets the following API requirements: **Input:** - A `torch.Tensor` of any shape. **Output:** - A `torch.Tensor` with the same shape as the input tensor. Example: ```python import torch class AdaptiveLayer(torch.nn.Module): def __init__(self): super().__init__() def forward(self, x: torch.Tensor) -> torch.Tensor: def apply_cos_sin(x: torch.Tensor) -> torch.Tensor: return x.cos() + x.sin() def apply_sin(x: torch.Tensor) -> torch.Tensor: return x.sin() return torch.cond(x.sum() > 10, apply_cos_sin, apply_sin, (x,)) # Test the module layer = AdaptiveLayer() input_tensor = torch.tensor([1.0, 2.0, 3.0, 4.5]) output_tensor = layer(input_tensor) print(output_tensor) input_tensor_large = torch.tensor([10.0, 5.0]) output_tensor_large = layer(input_tensor_large) print(output_tensor_large) ``` **Constraints:** - Use only operations from the PyTorch library. - Ensure the solution handles gradients correctly and can be used within a neural network that requires backpropagation. # Notes: - This exercise assesses your understanding of dynamic control flow within PyTorch computational graphs using `torch.cond`. - Consider potential edge cases and test your module extensively.","solution":"import torch class AdaptiveLayer(torch.nn.Module): def __init__(self): super(AdaptiveLayer, self).__init__() def forward(self, x: torch.Tensor) -> torch.Tensor: def apply_cos_sin(x: torch.Tensor) -> torch.Tensor: return x.cos() + x.sin() def apply_sin(x: torch.Tensor) -> torch.Tensor: return x.sin() if x.sum().item() > 10: return apply_cos_sin(x) else: return apply_sin(x)"},{"question":"# Seaborn Coding Assessment Question You are tasked with visualizing the `diamonds` dataset available in Seaborn using different aggregation functions and visualization techniques. Follow the instructions below to complete the task. Instructions: 1. **Load the Data:** Load the `diamonds` dataset using Seaborn\'s `load_dataset` function. 2. **Create a Plot:** Create a bar plot using Seaborn\'s object-oriented interface where: - The x-axis represents the `cut` of the diamonds. - The y-axis should be based on the `price` of the diamonds. 3. **Aggregation Requirements:** Perform the following aggregations and plot each result: - The default aggregation (which is the mean). - Median price of diamonds for each cut. - The interquartile range (IQR) of the price for each cut (use a custom aggregation function). 4. **Additional Transformations and Aesthetics:** - Create a plot where the bars are dodged based on the `color` of the diamonds. - Ensure each bar is colored according to the `color` variable. Expected Output: - Three separate plots, each showcasing one of the specified aggregations. - One plot with dodged bars and colored by `color`. Constraints: - You must use Seaborn 0.11.0 or later. - Use only the object-oriented interface for creating the plots. Example Code Structure: ```python import seaborn.objects as so from seaborn import load_dataset # Load the dataset diamonds = load_dataset(\\"diamonds\\") # Default Aggregation (Mean) plot1 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\").add(so.Bar(), so.Agg()) plot1.show() # Median Aggregation plot2 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\").add(so.Bar(), so.Agg(\\"median\\")) plot2.show() # IQR Aggregation plot3 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\").add(so.Bar(), so.Agg(lambda x: x.quantile(0.75) - x.quantile(0.25))) plot3.show() # Dodged Bars Colored by Diamond Color plot4 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\").add(so.Bar(), so.Agg(), so.Dodge(), color=\\"color\\") plot4.show() ``` Complete all the steps and ensure your plots are displayed correctly.","solution":"import seaborn.objects as so from seaborn import load_dataset import matplotlib.pyplot as plt # Load the dataset diamonds = load_dataset(\\"diamonds\\") # Default Aggregation (Mean) plot1 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\").add(so.Bar(), so.Agg()) plot1.show() # Median Aggregation plot2 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\").add(so.Bar(), so.Agg(\\"median\\")) plot2.show() # IQR Aggregation plot3 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\").add(so.Bar(), so.Agg(lambda x: x.quantile(0.75) - x.quantile(0.25))) plot3.show() # Dodged Bars Colored by Diamond Color plot4 = so.Plot(diamonds, x=\\"cut\\", y=\\"price\\", color=\\"color\\").add(so.Bar(), so.Agg(), so.Dodge()) plot4.show()"},{"question":"Implement a function `process_and_format_bytes(data_list: List[str], formatting_info: List[Tuple[str, Any]]) -> bytes` that processes a list of strings and formats it into a bytes object based on provided formatting information. **Function Signature:** ```python def process_and_format_bytes(data_list: List[str], formatting_info: List[Tuple[str, Any]]) -> bytes: ``` **Input:** - `data_list` (List[str]): A list of strings to be processed into bytes. - `formatting_info` (List[Tuple[str, Any]]): A list of tuples where each tuple contains a format string and the corresponding value to be formatted. **Output:** - Returns a bytes object that contains the processed data appended together and formatted based on provided formatting information. **Constraints:** - Strings in `data_list` are non-null. - Format strings in `formatting_info` must be valid format specifiers (`\\"%c\\"`, `\\"%d\\"`, `\\"%u\\"`, `\\"%ld\\"`, `\\"%lu\\"`, `\\"%zd\\"`, `\\"%zu\\"`, `\\"%i\\"`, `\\"%x\\"`, `\\"%s\\"`, `\\"%p\\"`). - Arrays should not exceed a length of `10^5` elements. **Example:** ```python data_list = [\\"Hello\\", \\"World\\"] formatting_info = [(\\"%s\\", \\"foo\\"), (\\"%d\\", 42), (\\"%x\\", 255)] # Expected output: A bytes object: b\'HelloWorldfoo42ff\', representing concatenation and formatting result = process_and_format_bytes(data_list, formatting_info) print(result) # Output: b\'HelloWorldfoo42ff\' ``` **Notes:** 1. You may use the `PyBytes_FromString`, `PyBytes_FromFormat`, `PyBytes_Concat`, and other related functions. 2. Make sure to handle edge cases such as an empty `data_list` or `formatting_info`. Implement the function `process_and_format_bytes` to meet the above specifications, demonstrating proficiency in handling bytes objects and utilizing format strings.","solution":"from typing import List, Tuple, Any def process_and_format_bytes(data_list: List[str], formatting_info: List[Tuple[str, Any]]) -> bytes: Processes a list of strings and formats it into a bytes object. Parameters: - data_list (List[str]): A list of strings to be processed into bytes. - formatting_info (List[Tuple[str, Any]]): A list of tuples where each tuple contains a format string and the corresponding value to be formatted. Returns: - bytes: a bytes object that contains the processed data appended together and formatted based on provided formatting information. # Combine all strings in the data list into one combined string combined_string = \'\'.join(data_list) # Create a formatted string using the format string in formatting_info formatted_part = \'\' for fmt, value in formatting_info: formatted_part += fmt % value # Combine the string and formatted parts final_string = combined_string + formatted_part # Encode the final string to bytes result_bytes = final_string.encode() return result_bytes"},{"question":"**Objective:** Assess your knowledge of testing frameworks in Python by developing unit tests for a given application using `unittest` and `unittest.mock`. Problem Description You are given a Python class `WeatherService` that fetches weather information from an external API. Your task is to implement unit tests for this class to ensure its proper functionality using the `unittest` module. Additionally, you should use the `unittest.mock` module to mock external dependencies. Here is the `WeatherService` class: ```python import requests class WeatherService: def __init__(self, api_key): self.api_key = api_key self.base_url = \\"http://api.weatherapi.com/v1/current.json\\" def get_weather(self, location): try: response = requests.get(self.base_url, params={ \\"key\\": self.api_key, \\"q\\": location }) response.raise_for_status() data = response.json() return data[\'current\'][\'temp_c\'] except requests.RequestException as e: raise SystemExit(e) ``` Task 1. **Test Case Setup:** * Write a test class `TestWeatherService` that inherits from `unittest.TestCase`. 2. **Test Initialization:** * In the `setUp` method of your test class, initialize a `WeatherService` instance with a mock API key. 3. **Mocking External Calls:** * Use `unittest.mock` to mock the `requests.get` method. * Write a helper function or a context manager to assist with the mocking. 4. **Implement Test Methods to Verify:** * `get_weather` returns the correct temperature when the API call is successful. * `get_weather` raises a `SystemExit` exception when the API call fails (e.g., network error or invalid API key). 5. **Run the Tests:** * Make sure your test cases are runnable using the `unittest` command-line interface. Expected Input and Output Formats * **Input:** * You do not need to provide any input via standard input. Input to your methods will be simulated through mocking. * **Output:** * Your tests should print their results to the standard output when the test suite runs, typical of `unittest` output. Constraints * You should not modify the `WeatherService` class. * Ensure that all network calls are mocked, and no actual HTTP requests are made during testing. Example Storage and Execution of Tests ```python import unittest from unittest.mock import patch, Mock class TestWeatherService(unittest.TestCase): def setUp(self): self.weather_service = WeatherService(api_key=\\"fake_api_key\\") @patch(\'requests.get\') def test_get_weather_success(self, mock_get): mock_response = Mock() mock_response.raise_for_status.return_value = None mock_response.json.return_value = {\'current\': {\'temp_c\': 23.5}} mock_get.return_value = mock_response temperature = self.weather_service.get_weather(\'London\') self.assertEqual(temperature, 23.5) @patch(\'requests.get\') def test_get_weather_failure(self, mock_get): mock_get.side_effect = requests.RequestException with self.assertRaises(SystemExit): self.weather_service.get_weather(\'London\') if __name__ == \'__main__\': unittest.main() ``` The provided code is just an example of how the tasks can be achieved. Your implementation might differ. Tips * Review the `unittest` and `unittest.mock` documentation to understand how to create and run tests. * Understand how to use the `patch` decorator to mock external dependencies effectively.","solution":"import requests class WeatherService: def __init__(self, api_key): self.api_key = api_key self.base_url = \\"http://api.weatherapi.com/v1/current.json\\" def get_weather(self, location): try: response = requests.get(self.base_url, params={ \\"key\\": self.api_key, \\"q\\": location }) response.raise_for_status() data = response.json() return data[\'current\'][\'temp_c\'] except requests.RequestException as e: raise SystemExit(e)"},{"question":"- Managing HTTP Cookies with `http.cookies` You are tasked with creating a small web application component that handles HTTP cookies. Your task is to implement a class `CookieManager` that utilizes the `http.cookies` module to manage cookies. Instructions: 1. **Class Structure**: Implement a class `CookieManager` with the following methods: - `__init__(self)`: Initializes a `SimpleCookie` object. - `add_cookie(self, key: str, value: Any) -> None`: Adds a new cookie with the specified `key` and `value`. The `value` should be stored as a string. - `remove_cookie(self, key: str) -> bool`: Removes the cookie with the specified `key`. Returns `True` if the cookie existed and was removed, and `False` otherwise. - `get_cookie_value(self, key: str) -> str`: Retrieves the value of the cookie with the specified `key`. Returns the value as a string. If the cookie does not exist, raise a `CookieError`. - `load_from_string(self, rawdata: str) -> None`: Loads cookies from a semicolon-separated string of key-value pairs. - `generate_http_header(self) -> str`: Generates and returns a string representing the cookies suitable to be sent as HTTP headers. 2. **Function Signatures**: Ensure your methods follow these signatures: ```python class CookieManager: def __init__(self): pass def add_cookie(self, key: str, value: Any) -> None: pass def remove_cookie(self, key: str) -> bool: pass def get_cookie_value(self, key: str) -> str: pass def load_from_string(self, rawdata: str) -> None: pass def generate_http_header(self) -> str: pass ``` 3. **Example Usage**: ```python manager = CookieManager() manager.add_cookie(\\"user\\", \\"Alice\\") manager.add_cookie(\\"session_id\\", 12345) print(manager.get_cookie_value(\\"user\\")) # Output: \'Alice\' print(manager.remove_cookie(\\"session_id\\")) # Output: True manager.load_from_string(\\"theme=dark; logged_in=true\\") print(manager.generate_http_header()) # Output: \'Set-Cookie: user=AlicernSet-Cookie: theme=darkrnSet-Cookie: logged_in=true\' ``` 4. **Constraints**: - Keys and values for cookies should be properly managed using the `http.cookies` module methods. - Ensure proper error handling when accessing non-existent cookies. Evaluation Criteria: - Correctness and completeness of the `CookieManager` implementation. - Appropriate use of the `http.cookies` module. - Adherence to the specified function signatures and behavior. - Clear and readable code with comments explaining key steps.","solution":"from http.cookies import SimpleCookie, CookieError class CookieManager: def __init__(self): self.cookies = SimpleCookie() def add_cookie(self, key: str, value: any) -> None: # Adding a new cookie with the given key and value self.cookies[key] = str(value) def remove_cookie(self, key: str) -> bool: # Removing the cookie with the specified key if key in self.cookies: del self.cookies[key] return True return False def get_cookie_value(self, key: str) -> str: # Retrieving the value of the specified cookie if key in self.cookies: return self.cookies[key].value raise CookieError(f\\"No cookie found with the key: {key}\\") def load_from_string(self, rawdata: str) -> None: # Loading cookies from a string of key-value pairs self.cookies.load(rawdata) def generate_http_header(self) -> str: # Generating a string representing the cookies for HTTP headers headers = [f\\"Set-Cookie: {m.output(header=\'\').lstrip()}\\" for m in self.cookies.values()] return \'rn\'.join(headers)"},{"question":"You are tasked with designing an asynchronous event-driven application using Python\'s `asyncio` library. The application should perform the following operations: 1. Schedule and run multiple asynchronous tasks. 2. Wait for and handle network connections. 3. Use low-level event loop operations to manage the scheduling and execution of tasks. 4. Demonstrate the use of callbacks for some operations. # Requirements 1. Implement the `network_server` coroutine function that: - Accepts network connections on a specified host and port. - For each connection, reads data from the client. - Responds to the client with the message `\\"Hello from server\\"`. 2. Implement the `schedule_tasks` coroutine function that: - Schedules three different tasks to execute pseudo-random operations (like printing messages). - Manages the timing and order of task execution using methods like `call_soon()`, `call_later()`, `run_in_executor()`. 3. Combine the network server and task scheduling within the main event loop. # Function Specifications Function 1: `network_server` - **Input**: - `host` (str): The hostname or IP address to bind the server. - `port` (int): The port to bind the server. - **Output**: None Function 2: `schedule_tasks` - **Input**: None - **Output**: None Main Function: - Integrate the server setup and task scheduling within a main function that creates an event loop, runs the server, and schedules the tasks concurrently. # Example Usage ```python async def main(): # Start server coroutine server_task = asyncio.create_task(network_server(\'127.0.0.1\', 8888)) # Start task scheduling coroutine schedule_task = asyncio.create_task(schedule_tasks()) # Run both coroutines concurrently await asyncio.gather(server_task, schedule_task) if __name__ == \'__main__\': asyncio.run(main()) ``` # Constraints 1. Utilize `loop.call_soon()` and `loop.call_later()` to demonstrate the scheduling of tasks. 2. Use `loop.create_task()` to manage coroutines. 3. Handle basic error cases like graceful shutdown on exceptions. # Performance Requirements - Ensure that the server can handle multiple concurrent connections efficiently. - Tasks should be scheduled with minimal delay and manage their execution order properly. # Testing Test your implementation by connecting to the server using a tool like `telnet` or `nc` and ensure the server responds correctly. Also, ensure that scheduled tasks execute in the correct order and time frame.","solution":"import asyncio async def network_server(host, port): Coroutine function to handle network connections. server = await asyncio.start_server(handle_client, host, port) async with server: await server.serve_forever() async def handle_client(reader, writer): Handle client connections and respond with a message. data = await reader.read(100) # Read incoming data (up to 100 bytes) message = \\"Hello from server\\" writer.write(message.encode()) await writer.drain() writer.close() await writer.wait_closed() async def schedule_tasks(): Schedule and manage multiple asynchronous tasks. loop = asyncio.get_running_loop() def task_callback(msg): print(msg) # Schedule tasks loop.call_soon(task_callback, \\"Task 1 called soon\\") loop.call_later(2, task_callback, \\"Task 2 called later after 2 seconds\\") await asyncio.sleep(1) # Simulate some delay await loop.run_in_executor(None, task_callback, \\"Task 3 executed in executor\\") async def main(): # Start server coroutine server_task = asyncio.create_task(network_server(\'127.0.0.1\', 8888)) # Start task scheduling coroutine schedule_task = asyncio.create_task(schedule_tasks()) await asyncio.gather(server_task, schedule_task) if __name__ == \'__main__\': try: asyncio.run(main()) except KeyboardInterrupt: print(\\"Server shut down gracefully.\\")"},{"question":"Title: Building a Python Script Runner Objective: Create a Python script that mimics the behavior of invoking the Python interpreter with a script file, including handling command-line arguments and specifying source code encodings. Task Description: Implement a Python function named `run_python_script` that takes as input the path to a Python script file and a list of command-line arguments. The function should: 1. Execute the script file with the provided command-line arguments. 2. Handle different source code encodings declared in the script. 3. Mimic the interactive mode behavior if the script execution leaves the interpreter in an interactive state. Expected Function Signature: ```python def run_python_script(script_path: str, args: list): pass ``` Input: - `script_path` (str): The path to the Python script file to be executed. - `args` (list): A list of command-line arguments to be passed to the script. Output: - The output should be printed directly as it would appear when invoking the Python script through the command line. Constraints: - The source code encoding should be correctly handled if specified within the script. If not specified, assume the default encoding (UTF-8). - You should handle any errors gracefully, simulating the behavior of the Python interpreter. - For simplicity, you may assume that the provided script and arguments are valid. Examples: 1. Given a script `example.py` with the following content: ```python # -*- coding: utf-8 -*- import sys print(\\"Arguments:\\", sys.argv) name = input(\\"Enter your name: \\") print(f\\"Hello, {name}!\\") ``` And the following function call: ```python run_python_script(\'example.py\', [\'arg1\', \'arg2\']) ``` The expected behavior should be: ``` Arguments: [\'example.py\', \'arg1\', \'arg2\'] Enter your name: [waits for user input] ``` 2. For a script without an encoding declaration and with an interactive mode: ```python # script.py import sys print(\\"This is a test script.\\") ``` And the call: ```python run_python_script(\'script.py\', []) ``` The expected output should be: ``` This is a test script. >>> [enters interactive mode] ``` Notes: - Assume that the script can be read directly from the file system. - You can use any standard library modules to ease the implementation. - The focus is on accurately simulating the behavior of the Python interpreter, ensuring proper handling of command-line arguments, and managing input/output effectively.","solution":"import os import sys import subprocess def run_python_script(script_path: str, args: list): Executes a Python script with the specified command-line arguments. # Construct the command command = [sys.executable, script_path] + args # Execute the script with the provided arguments result = subprocess.run(command, capture_output=True, text=True) # Print the stdout and stderr of the executed script if result.stdout: print(result.stdout) if result.stderr: print(result.stderr)"},{"question":"# JSON Custom Encoder and Decoder You are required to create a specialized JSON encoder and decoder that can handle complex numbers and fractions in Python. The task involves implementing custom encoding and decoding mechanisms using the `json` module, extending its functionality to recognize and convert complex numbers and fractions to JSON format and back. Special Requirements: 1. **Complex Numbers:** - Complex numbers should be encoded as dictionaries with keys `\\"__complex__\\", \\"real\\", \\"imag\\"`. - Example: `3 + 4j` should be encoded as `{\\"__complex__\\": true, \\"real\\": 3, \\"imag\\": 4}`. 2. **Fractions:** - Fractions should be encoded as dictionaries with keys `\\"__fraction__\\", \\"numerator\\", \\"denominator\\"`. - Example: `Fraction(3, 4)` should be encoded as `{\\"__fraction__\\": true, \\"numerator\\": 3, \\"denominator\\": 4}`. Input: - A Python object which may contain complex numbers and fractions along with other serializable types. Output: - A JSON string representation of the input object. - A Python object reconstructed from the JSON string. Constraints: 1. You must use the `json` module for encoding and decoding. 2. Ensure that the decoded object preserves the types of complex numbers and fractions. Instructions: 1. Implement a custom JSON encoder `ComplexFractionEncoder` by subclassing `json.JSONEncoder`. 2. Implement a custom JSON decoder function `complex_fraction_decoder` using `object_hook`. 3. Write two functions `to_json(obj: Any) -> str` and `from_json(json_str: str) -> Any` that utilize your custom encoder and decoder. ```python import json from fractions import Fraction # Custom JSON Encoder class ComplexFractionEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, complex): return {\\"__complex__\\": True, \\"real\\": obj.real, \\"imag\\": obj.imag} elif isinstance(obj, Fraction): return {\\"__fraction__\\": True, \\"numerator\\": obj.numerator, \\"denominator\\": obj.denominator} return super().default(obj) # Custom JSON Decoder Function def complex_fraction_decoder(dct): if \\"__complex__\\" in dct: return complex(dct[\\"real\\"], dct[\\"imag\\"]) if \\"__fraction__\\" in dct: return Fraction(dct[\\"numerator\\"], dct[\\"denominator\\"]) return dct # Function to encode object to JSON string def to_json(obj): return json.dumps(obj, cls=ComplexFractionEncoder) # Function to decode JSON string to object def from_json(json_str): return json.loads(json_str, object_hook=complex_fraction_decoder) # Example Usage if __name__ == \\"__main__\\": obj = { \\"number\\": 42, \\"complex_number\\": 3 + 4j, \\"fraction\\": Fraction(3, 4), \\"nested\\": {\\"complex_list\\": [1 + 1j, 2 + 2j]} } # Encode to JSON json_str = to_json(obj) print(\\"Encoded JSON:\\", json_str) # Decode back to Python object decoded_obj = from_json(json_str) print(\\"Decoded Object:\\", decoded_obj) ``` Expected Output Example: ```python Encoded JSON: {\\"number\\": 42, \\"complex_number\\": {\\"__complex__\\": true, \\"real\\": 3, \\"imag\\": 4}, \\"fraction\\": {\\"__fraction__\\": true, \\"numerator\\": 3, \\"denominator\\": 4}, \\"nested\\": {\\"complex_list\\": [{\\"__complex__\\": true, \\"real\\": 1, \\"imag\\": 1}, {\\"__complex__\\": true, \\"real\\": 2, \\"imag\\": 2}]}} Decoded Object: {\'number\': 42, \'complex_number\': (3+4j), \'fraction\': Fraction(3, 4), \'nested\': {\'complex_list\': [(1+1j), (2+2j)]}} ``` Ensure that your implemented functions can handle arbitrary nesting and the presence of both custom types (complex numbers and fractions) correctly.","solution":"import json from fractions import Fraction # Custom JSON Encoder class ComplexFractionEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, complex): return {\\"__complex__\\": True, \\"real\\": obj.real, \\"imag\\": obj.imag} elif isinstance(obj, Fraction): return {\\"__fraction__\\": True, \\"numerator\\": obj.numerator, \\"denominator\\": obj.denominator} return super().default(obj) # Custom JSON Decoder Function def complex_fraction_decoder(dct): if \\"__complex__\\" in dct: return complex(dct[\\"real\\"], dct[\\"imag\\"]) if \\"__fraction__\\" in dct: return Fraction(dct[\\"numerator\\"], dct[\\"denominator\\"]) return dct # Function to encode object to JSON string def to_json(obj): return json.dumps(obj, cls=ComplexFractionEncoder) # Function to decode JSON string to object def from_json(json_str): return json.loads(json_str, object_hook=complex_fraction_decoder)"},{"question":"Create a Python function using the Seaborn library to generate a comprehensive visualization of the \\"tips\\" dataset that meets the following criteria: # Task Description 1. Load the \\"tips\\" dataset using `seaborn.load_dataset`. 2. Create a `FacetGrid` with `col=\\"time\\"`, `row=\\"sex\\"`, and `hue=\\"smoker\\"`. This means you will create subplots by categorizing data based on the time of day (`lunch` or `dinner`), the sex of the patron (`Male` or `Female`), and further subdividing each plot based on whether the patron is a smoker or not. 3. Use the `scatterplot` function to plot `total_bill` on the x-axis and `tip` on the y-axis for each facet. 4. Add a reference horizontal line on each subplot representing the median tip value for the entire dataset. 5. Customize the subplots to set the axis labels as \\"Total Bill ()\\" for the x-axis and \\"Tip ()\\" for the y-axis. 6. Ensure the plot layout is tight, meaning there is minimal whitespace, and all plots are clearly visible. 7. Save the generated plot to a file named \\"final_plot.png\\". # Function Signature ```python def generate_tips_facetgrid(): pass ``` # Input - The function does not take any input parameters. # Output - The function does not return any value. It should only produce and save the plot as \\"final_plot.png\\". # Constraints - You must use the `seaborn` package for data visualization. - You are allowed to use `matplotlib` for additional customization if needed. # Example Usage After implementing the function, running `generate_tips_facetgrid()` should generate and save the plot as specified. Here is a sample output visualization to help you understand the expected result (this is just a conceptual diagram): <img src=\\"https://i.imgur.com/UBYgw0g.png\\" alt=\\"FacetGrid Example\\" style=\\"height: 400px;\\">","solution":"import seaborn as sns import matplotlib.pyplot as plt import numpy as np def generate_tips_facetgrid(): # Load the tips dataset tips = sns.load_dataset(\\"tips\\") # Calculate the median tip for the entire dataset median_tip = np.median(tips[\'tip\']) # Create a FacetGrid with specified columns, rows, and hue g = sns.FacetGrid(tips, col=\\"time\\", row=\\"sex\\", hue=\\"smoker\\", margin_titles=True) # Use scatterplot to plot total_bill vs tip g.map(sns.scatterplot, \\"total_bill\\", \\"tip\\") # Add median tip reference line and customize axis labels in each subplot for ax in g.axes.flat: ax.axhline(y=median_tip, color=\'red\', linestyle=\'--\') ax.set_xlabel(\\"Total Bill ()\\") ax.set_ylabel(\\"Tip ()\\") # Adjust the layout g.tight_layout() # Save the plot to a file g.savefig(\\"final_plot.png\\")"},{"question":"Parallel Data Processing using `concurrent.futures` **Objective**: Write a Python function that processes a list of numbers in parallel to perform computational tasks (e.g., factorial, summation of large lists). You will use the `concurrent.futures` module to speed up the processing. Function Specification **Function Name**: `parallel_process_and_sum` **Input**: - `numbers` (List[int]): A list of integers to be processed. - `mode` (str): The mode of processing (\\"factorial\\" or \\"summation\\"). **Output**: - `result` (int): The aggregated result based on the `mode`. **Constraints**: - The list `numbers` can contain up to 10,000 integers. - The integer values in the list range from 1 to 1,000,000. - Your implementation should handle the processing in parallel using `concurrent.futures`. - For \\"factorial\\" mode, compute the factorial of each number in the list. - For \\"summation\\" mode, compute the sum of the first `n` natural numbers for each number `n` in the list. Requirements: - You must use `ThreadPoolExecutor` or `ProcessPoolExecutor` from the `concurrent.futures` module. - Ensure that you handle exceptions properly. - Aim for optimal performance and resource management. Example: ```python from concurrent.futures import ThreadPoolExecutor, as_completed import math def parallel_process_and_sum(numbers, mode): # Define worker functions def factorial_worker(n): return math.factorial(n) def summation_worker(n): return n * (n + 1) // 2 # Select appropriate worker based on mode if mode == \\"factorial\\": worker = factorial_worker elif mode == \\"summation\\": worker = summation_worker else: raise ValueError(\\"Invalid mode. Choose \'factorial\' or \'summation\'\\") # Initialize executor and future tasks with ThreadPoolExecutor() as executor: future_to_number = {executor.submit(worker, num): num for num in numbers} results = [] for future in as_completed(future_to_number): try: results.append(future.result()) except Exception as exc: print(f\\"{future_to_number[future]} generated an exception: {exc}\\") # Compute final result by summing all individual results return sum(results) # Example Usage numbers = [5, 7, 10] mode = \\"factorial\\" # or \\"summation\\" result = parallel_process_and_sum(numbers, mode) print(result) # Output for factorial mode: 120 + 5040 + 362880 = 368040 # Output for summation mode: 15 + 28 + 55 = 98 ``` Make sure to properly document and test your function to handle edge cases and ensure thread/process safety where necessary.","solution":"from concurrent.futures import ThreadPoolExecutor, as_completed import math def parallel_process_and_sum(numbers, mode): Processes a list of numbers in parallel to compute either factorial or summation of each number. Args: numbers (List[int]): A list of integers to be processed. mode (str): The mode of processing (\\"factorial\\" or \\"summation\\"). Returns: int: The aggregated result based on the mode. def factorial_worker(n): return math.factorial(n) def summation_worker(n): return n * (n + 1) // 2 if mode == \\"factorial\\": worker = factorial_worker elif mode == \\"summation\\": worker = summation_worker else: raise ValueError(\\"Invalid mode. Choose \'factorial\' or \'summation\'\\") with ThreadPoolExecutor() as executor: future_to_number = {executor.submit(worker, num): num for num in numbers} results = [] for future in as_completed(future_to_number): try: results.append(future.result()) except Exception as exc: print(f\\"{future_to_number[future]} generated an exception: {exc}\\") return sum(results)"},{"question":"# Advanced Coding Question: Sequence Protocol Operations As an advanced Python developer, you are required to implement a class named `CustomSequence` that emulates various sequence operations. Your class should provide methods that correspond to a subset of the functionality described in the documentation, implemented in pure Python. Requirements: 1. **Initialization**: - The class should be initialized with a list of elements. 2. **Size and Length**: - Implement a method `size()` that returns the number of elements in the sequence. 3. **Concatenation and In-Place Concatenation**: - Implement methods `concat(seq)` and `inplace_concat(seq)` that return the concatenation of the current sequence with another sequence `seq`. The `inplace_concat(seq)` method should update the current sequence. 4. **Repetition and In-Place Repetition**: - Implement methods `repeat(count)` and `inplace_repeat(count)` that return a sequence repeated `count` times. The `inplace_repeat(count)` method should update the current sequence. 5. **Item Access and Slicing**: - Implement methods to access items: `get_item(index)` which returns the item at position `index`. - Implement method `get_slice(start, end)` which returns a slice from `start` to `end`. 6. **Set and Delete Items**: - Implement `set_item(index, value)` that sets the item at `index` to `value`. - Implement `del_item(index)` that deletes the item at `index`. 7. **Count Occurrences**: - Implement `count(value)` that returns the number of times `value` occurs in the sequence. 8. **Contains**: - Implement `contains(value)` method to determine if the sequence contains `value`. 9. **Index of Item**: - Implement `index(value)` that returns the index of the first occurrence of `value`. 10. **Convert to List and Tuple**: - Implement methods `to_list()` and `to_tuple()` that return the sequence as a list and a tuple, respectively. Constraints: - Do not use any Python built-in sequence methods or external libraries for sequence operations. - Ensure that all methods handle edge cases gracefully. Example Usage: ```python seq = CustomSequence([1, 2, 3]) print(seq.size()) # Output: 3 new_seq = seq.concat([4, 5]) print(new_seq) # Output: [1, 2, 3, 4, 5] seq.inplace_concat([6]) print(seq.to_list()) # Output: [1, 2, 3, 6] print(seq.repeat(2)) # Output: [1, 2, 3, 6, 1, 2, 3, 6] seq.inplace_repeat(3) print(seq.to_list()) # Output: [1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6] print(seq.get_item(2)) # Output: 3 print(seq.get_slice(1, 4)) # Output: [2, 3, 6] seq.set_item(0, 10) print(seq.to_list()) # Output: [10, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6] seq.del_item(1) print(seq.to_list()) # Output: [10, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6] print(seq.count(6)) # Output: 3 print(seq.contains(2)) # Output: True print(seq.index(3)) # Output: 1 print(seq.to_list()) # Output: [10, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6] print(seq.to_tuple()) # Output: (10, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6) ```","solution":"class CustomSequence: def __init__(self, elements): self.elements = elements def size(self): return len(self.elements) def concat(self, seq): return self.elements + seq def inplace_concat(self, seq): self.elements += seq return self.elements def repeat(self, count): return self.elements * count def inplace_repeat(self, count): self.elements *= count return self.elements def get_item(self, index): return self.elements[index] def get_slice(self, start, end): return self.elements[start:end] def set_item(self, index, value): self.elements[index] = value def del_item(self, index): del self.elements[index] def count(self, value): return self.elements.count(value) def contains(self, value): return value in self.elements def index(self, value): return self.elements.index(value) def to_list(self): return self.elements def to_tuple(self): return tuple(self.elements)"},{"question":"Objective To assess your understanding of the Seaborn package, particularly in creating and customizing color palettes using the `husl_palette` function, and visualizing data with these palettes. Problem Statement Create a Python function `visualize_birthrate_data()` that performs the following tasks: 1. Loads the monthly birthrate data from a given CSV file. 2. Customizes and uses a `husl_palette` to visualize the birthrates. 3. Plots the birthrate data using a line plot where each line represents a different year, colored according to the generated palette. 4. The color palette should: - Contain a color for each year in the dataset. - Adjust lightness and saturation for better visibility. - Have a customized start-point for hue sampling. 5. Add a title and labels to the plot for clarity. Function Signature ```python def visualize_birthrate_data(csv_file: str) -> None: ``` Input - `csv_file`: A string representing the filepath of the CSV file containing the monthly birthrate data. The CSV should have the following columns: `\'Year\'`, `\'Month\'`, and `\'Birthrate\'`. Output - The function should not return any value. It should display a line plot using Seaborn. Additional Requirements - The plot should have at least one color per year present in the dataset. - Lightness should be set to `0.6` and saturation to `0.5`. - Hue start-point should be set to `0.3`. Example Assuming the following data: ```csv Year,Month,Birthrate 2000,1,15.6 2000,2,14.4 ... 2001,1,16.3 2001,2,15.2 ... ``` When calling `visualize_birthrate_data(\'birthrate_data.csv\')`, the function should produce a distinct line plot with each year\'s data colored uniquely, lightness 0.6, saturation 0.5, and hue start-point 0.3. Constraints - Assume the CSV file structure is correct and does not require error handling. - The number of unique years will not exceed the number of colors Seaborn can handle gracefully. Performance - The function should handle typical datasets efficiently (up to a few thousand rows). You may use the following code structure as a starting point: ```python import seaborn as sns import pandas as pd import matplotlib.pyplot as plt def visualize_birthrate_data(csv_file: str) -> None: # Load the dataset df = pd.read_csv(csv_file) # Extract the unique number of years unique_years = df[\'Year\'].unique() num_years = len(unique_years) # Create a color palette palette = sns.husl_palette(n_colors=num_years, l=0.6, s=0.5, h=0.3) # Create the plot plt.figure(figsize=(10, 6)) sns.lineplot(x=\'Month\', y=\'Birthrate\', hue=\'Year\', palette=palette, data=df) # Add a title and labels plt.title(\'Monthly Birthrate by Year\') plt.xlabel(\'Month\') plt.ylabel(\'Birthrate\') # Display the plot plt.show() ```","solution":"import seaborn as sns import pandas as pd import matplotlib.pyplot as plt def visualize_birthrate_data(csv_file: str) -> None: # Load the dataset df = pd.read_csv(csv_file) # Extract the unique number of years unique_years = df[\'Year\'].unique() num_years = len(unique_years) # Create a color palette palette = sns.husl_palette(n_colors=num_years, l=0.6, s=0.5, h=0.3) # Create the plot plt.figure(figsize=(10, 6)) sns.lineplot(x=\'Month\', y=\'Birthrate\', hue=\'Year\', palette=palette, data=df) # Add a title and labels plt.title(\'Monthly Birthrate by Year\') plt.xlabel(\'Month\') plt.ylabel(\'Birthrate\') # Display the plot plt.show()"},{"question":"**Objective**: Demonstrate your understanding of pandas for handling large datasets by loading specific data, converting data types for efficiency, and processing the data in chunks. Problem Statement You have been given a directory containing multiple parquet files. Each file represents a part of a large dataset. Your task is to: 1. Load specific columns from each parquet file. 2. Optimize the data types to reduce memory usage. 3. Calculate the mean of a numeric column across all files, processing the files in chunks so as to not load all data into memory at once. 4. Return the final mean value. Function Signature ```python import pandas as pd from pathlib import Path def calculate_mean_from_large_dataset(directory: str, column: str, columns_to_load: list) -> float: Calculate the mean of a specified numeric column across multiple parquet files in a directory, optimizing memory usage and ensuring data is processed in chunks. Args: - directory (str): The path to the directory containing parquet files. - column (str): The name of the column for which to calculate the mean. - columns_to_load (list): The list of columns to load from each file. Returns: - float: The mean value of the specified column. pass ``` Constraints - Assume the directory contains multiple parquet files. - You must use chunking to avoid loading all data into memory at once. - You should convert text columns to categorical data types and downcast numeric columns to their smallest appropriate types. Example Usage ```python # Assuming the directory \'data/timeseries/\' contains multiple parquet files, # and you want to calculate the mean for the column \'x_0\' with columns `[\'id_0\', \'name_0\', \'x_0\', \'y_0\']`. mean_value = calculate_mean_from_large_dataset(\\"data/timeseries/\\", \\"x_0\\", [\\"id_0\\", \\"name_0\\", \\"x_0\\", \\"y_0\\"]) print(mean_value) # Expected output: A float value representing the mean of the \'x_0\' column. ``` Notes: - You can use functions such as `pd.read_parquet` and `pd.to_numeric`. - Ensure efficient data loading and processing to handle scalability.","solution":"import pandas as pd from pathlib import Path def calculate_mean_from_large_dataset(directory: str, column: str, columns_to_load: list) -> float: Calculate the mean of a specified numeric column across multiple parquet files in a directory, optimizing memory usage and ensuring data is processed in chunks. Args: - directory (str): The path to the directory containing parquet files. - column (str): The name of the column for which to calculate the mean. - columns_to_load (list): The list of columns to load from each file. Returns: - float: The mean value of the specified column. total_sum = 0 total_count = 0 for file_path in Path(directory).glob(\\"*.parquet\\"): df = pd.read_parquet(file_path, columns=columns_to_load) # Convert text columns to categorical and downcast numeric columns for col in df.columns: if df[col].dtype == \'object\': df[col] = df[col].astype(\'category\') elif pd.api.types.is_numeric_dtype(df[col]): df[col] = pd.to_numeric(df[col], downcast=\'float\') # Sum the values and count the number of entries for the specified column total_sum += df[column].sum() total_count += df[column].count() mean_value = total_sum / total_count if total_count != 0 else float(\'nan\') return mean_value"},{"question":"**Question: Implement a Python function that processes and converts stereo raw audio data to mono format using custom scaling factors and then applies bias and root-mean-square (RMS) normalization.** # Function Description Write a function `process_audio(audio_data: bytes, sample_width: int, lfactor: float, rfactor: float, bias: int) -> bytes` that performs the following operations on the given stereo audio data: 1. **Convert Stereo to Mono**: Use the provided `lfactor` and `rfactor` to convert the stereo audio data to mono. The left channel will be scaled by `lfactor` and the right channel by `rfactor` before combining them. 2. **Add Bias**: Add the specified `bias` to each sample in the mono audio data. 3. **Normalize by RMS**: Normalize the resultant audio fragment to have an RMS value of 1.0. # Input - `audio_data` (bytes): A bytes object containing the raw audio data. - `sample_width` (int): An integer representing the width of each audio sample in bytes. It can be 1, 2, 3, or 4. - `lfactor` (float): A floating-point value to scale the left channel of the stereo audio. - `rfactor` (float): A floating-point value to scale the right channel of the stereo audio. - `bias` (int): An integer value to be added to each sample in the mono audio. # Output - `bytes`: A bytes object containing the processed mono audio data normalized by RMS. # Constraints - The length of `audio_data` will always be a multiple of `(sample_width * 2)`, given it\'s stereo audio. - You must handle overflow/underflow cases appropriately when adding bias and scaling. # Example ```python from struct import pack # Example of creating test audio data, not part of the function def create_stereo_sample(left_value, right_value, sample_width): if sample_width == 1: fmt = \\"bb\\" elif sample_width == 2: fmt = \\"hh\\" elif sample_width == 3: fmt = \\"bbb\\" elif sample_width == 4: fmt = \\"ii\\" else: raise ValueError(\\"Unsupported sample width\\") return pack(fmt, left_value, right_value) audio_data = create_stereo_sample(1000, -1000, 2) + create_stereo_sample(2000, -2000, 2) sample_width = 2 lfactor = 1.0 rfactor = 1.0 bias = 10 output = process_audio(audio_data, sample_width, lfactor, rfactor, bias) print(output) ``` # Hints - Use `audioop` methods such as `tostereo`, `tomono`, `bias`, and `rms` to assist with operations. - Ensure that the final mono audio is RMS-normalized to 1.0: this means scaling the audio samples such that their RMS value is 1.","solution":"import audioop import numpy as np def process_audio(audio_data, sample_width, lfactor, rfactor, bias): Converts stereo audio data to mono using provided scaling factors, adds bias, and normalizes the audio by RMS to 1.0. Params: audio_data (bytes): Raw stereo audio data. sample_width (int): Width of a single sample (1, 2, 3, or 4 bytes). lfactor (float): Scaling factor for the left channel. rfactor (float): Scaling factor for the right channel. bias (int): Value to add to each mono sample. Returns: bytes: Processed mono audio data normalized by RMS to 1.0. # Convert stereo to mono with scaling factors mono_audio = audioop.tomono(audio_data, sample_width, lfactor, rfactor) # Add bias to each mono sample biased_audio = audioop.bias(mono_audio, sample_width, bias) # Get RMS value of biased audio current_rms = audioop.rms(biased_audio, sample_width) if current_rms == 0: return biased_audio # Avoid division by zero, if RMS is already 0. # Calculate the scaling factor to normalize RMS to 1.0 scaling_factor = 1.0 / current_rms # Apply scaling factor normalized_audio = audioop.mul(biased_audio, sample_width, scaling_factor) return normalized_audio"},{"question":"**Question:** You are given the task of creating a Python script that uses the \\"pydoc\\" module to dynamically generate and serve documentation for a given list of modules. This script should: 1. Load the specified modules. 2. Serve the generated documentation via an HTTP server. 3. Provide an option to save the documentation as HTML files. 4. Allow keyword searches across all modules’ documentation. # Function Specifications **Function Name**: `generate_and_serve_docs` **Parameters**: - `modules` (list of str): A list of module names (e.g., `[\\"sys\\", \\"os\\", \\"math\\"]`) to generate documentation for. - `output_dir` (str): The path to the directory where the HTML files should be saved (if specified). - `serve` (bool): A flag indicating whether to start an HTTP server to serve the documentation (`True` to serve, `False` otherwise). - `keyword` (str, optional): A keyword to search for in the modules\' documentation (optional). **Returns**: - This function does not return anything. It either serves the documentation via an HTTP server or saves it to the specified directory based on the given parameters. # Requirements: 1. If `serve` is `True`, start an HTTP server that serves the documentation. 2. If `output_dir` is specified, save the documentation of each module as an HTML file in that directory. 3. If a `keyword` is provided, perform a keyword search across all loaded modules\' documentation and print the search results to the console. 4. Handle any exceptions that may occur during the loading of modules or generation of documentation. # Constraints: - The script must use the `pydoc` module to generate the documentation. - The provided `modules` list will contain valid module names that are available in the environment where the script runs. - The `output_dir`, if specified, will be a valid directory path that the script has write access to. # Example Usage: ```python modules_to_document = [\\"sys\\", \\"os\\", \\"math\\"] output_directory = \\"./docs\\" serve_docs = True search_keyword = \\"system\\" generate_and_serve_docs(modules_to_document, output_directory, serve_docs, search_keyword) ``` In this example: - The script generates documentation for `sys`, `os`, and `math` modules. - Saves the documentation as HTML files in the `./docs` directory. - Starts an HTTP server to serve the documentation. - Searches for the keyword \\"system\\" in all loaded modules\' documentation and outputs the results to the console. **Note:** If the `serve` flag is set to `True`, ensure that the HTTP server starts on an available port and prints the URL to access the documentation.","solution":"import pydoc import os from http.server import HTTPServer, SimpleHTTPRequestHandler import threading def generate_html_docs(module_name, output_dir=None): Generate HTML documentation for a given module and optionally save it to output_dir. try: html_doc = pydoc.HTMLDoc().docroutine(__import__(module_name)) if output_dir: with open(os.path.join(output_dir, f\\"{module_name}.html\\"), \\"w\\") as f: f.write(html_doc) return html_doc except Exception as e: print(f\\"Error generating documentation for {module_name}: {e}\\") return None def start_http_server(): Start an HTTP server to serve the current directory. server_address = (\'\', 0) # Bind to an available port httpd = HTTPServer(server_address, SimpleHTTPRequestHandler) print(f\\"Serving at port {httpd.server_address[1]}\\") httpd.serve_forever() def search_keyword_in_docs(modules, keyword): Search for a keyword in the documentation of provided modules and print the results. for module_name in modules: try: module = __import__(module_name) doc = pydoc.render_doc(module) if keyword.lower() in doc.lower(): print(f\\"Keyword \'{keyword}\' found in {module_name}\\") except Exception as e: print(f\\"Error searching for keyword in {module_name}: {e}\\") def generate_and_serve_docs(modules, output_dir=None, serve=False, keyword=None): loaded_modules = [] if output_dir and not os.path.exists(output_dir): os.makedirs(output_dir) for module_name in modules: if generate_html_docs(module_name, output_dir): loaded_modules.append(module_name) if keyword: search_keyword_in_docs(loaded_modules, keyword) if serve: os.chdir(output_dir if output_dir else os.getcwd()) server_thread = threading.Thread(target=start_http_server) server_thread.daemon = True server_thread.start() server_thread.join()"},{"question":"# Asynchronous Web Scraper with ThreadPoolExecutor Objective: Create a Python script that downloads the contents of multiple web pages asynchronously using `ThreadPoolExecutor` from the `concurrent.futures` module and stores the results in files. Additionally, handle exceptions gracefully and ensure clean-up of resources. Instructions: 1. **Function Implementation**: - Implement a function `fetch_url(url, timeout)` that takes a URL as input and a timeout value. Use `urllib.request` to fetch the web page content. If an exception occurs (like a timeout or HTTP error), catch it and return a tuple containing the URL and the exception message. - Implement a function `save_to_file(url, content)` that takes a URL and its content, and saves the content to a file named after the domain part of the URL. Handle file I/O exceptions. 2. **Main Execution**: - Create a list `urls` containing at least 5 different URLs that you want to scrape. - Use `ThreadPoolExecutor` with a suitable number of workers to asynchronously fetch the web pages. - Collect the results as they complete using `concurrent.futures.as_completed`. - Save the content of each successfully fetched URL to a file and handle any failed fetch attempts. 3. **Requirements**: - Print the status of each URL fetch operation, either indicating success and the filename where the content is saved or the exception message. - Ensure that all threads are cleaned up properly using a `with` statement. - Handle cases where the fetch operation times out or an HTTP error occurs. - Implement necessary exception handling to ensure the program does not crash. 4. **Input and Output**: - No explicit input from the user is required. Define the `urls` list within the script. - Output should be printed to the console indicating the status of each URL fetch. - Web page contents of successful fetches should be saved to files. Constraints: - Use `ThreadPoolExecutor` for managing the worker threads. - The script should handle at least 5 URLs. - Set a timeout for fetching each URL. Example: ```python import concurrent.futures import urllib.request import os def fetch_url(url, timeout): try: with urllib.request.urlopen(url, timeout=timeout) as conn: return (url, conn.read()) except Exception as e: return (url, f\\"Error: {str(e)}\\") def save_to_file(url, content): try: domain = urllib.parse.urlparse(url).netloc.replace(\'.\', \'_\') with open(f\\"{domain}.html\\", \'wb\') as f: f.write(content) except Exception as e: print(f\\"Failed to save content for {url}: {e}\\") def main(): urls = [ \'http://www.foxnews.com/\', \'http://www.cnn.com/\', \'http://europe.wsj.com/\', \'http://www.bbc.co.uk/\', \'http://nonexistant-subdomain.python.org/\' ] with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: future_to_url = {executor.submit(fetch_url, url, 60): url for url in urls} for future in concurrent.futures.as_completed(future_to_url): url = future_to_url[future] try: url, content = future.result() if isinstance(content, str) and content.startswith(\\"Error:\\"): print(f\\"Failed to fetch {url}: {content}\\") else: save_to_file(url, content) print(f\\"Success: {url} content saved.\\") except Exception as exc: print(f\\"Exception for {url}: {exc}\\") if __name__ == \'__main__\': main() ``` --- Note: - Make sure your environment has access to the internet to test the URL fetch functionality. - Use correct exception handling to ensure the program handles every edge case gracefully.","solution":"import concurrent.futures import urllib.request import urllib.parse import os def fetch_url(url, timeout): Fetch the content of the URL with a specified timeout. Args: url (str): The URL to be fetched. timeout (int): The timeout in seconds for the request. Returns: tuple: A tuple containing the URL and either the content or an error message. try: with urllib.request.urlopen(url, timeout=timeout) as conn: return (url, conn.read()) except Exception as e: return (url, f\\"Error: {str(e)}\\") def save_to_file(url, content): Save the content to a file named based on the domain part of the URL. Args: url (str): The URL the content was fetched from. content (bytes): The content to be saved. Returns: None try: domain = urllib.parse.urlparse(url).netloc.replace(\'.\', \'_\') with open(f\\"{domain}.html\\", \'wb\') as f: f.write(content) except Exception as e: print(f\\"Failed to save content for {url}: {e}\\") def main(): urls = [ \'http://www.foxnews.com/\', \'http://www.cnn.com/\', \'http://europe.wsj.com/\', \'http://www.bbc.co.uk/\', \'http://nonexistant-subdomain.python.org/\' ] with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor: future_to_url = {executor.submit(fetch_url, url, 60): url for url in urls} for future in concurrent.futures.as_completed(future_to_url): url = future_to_url[future] try: url, content = future.result() if isinstance(content, str) and content.startswith(\\"Error:\\"): print(f\\"Failed to fetch {url}: {content}\\") else: save_to_file(url, content) print(f\\"Success: {url} content saved.\\") except Exception as exc: print(f\\"Exception for {url}: {exc}\\") if __name__ == \'__main__\': main()"},{"question":"Question: Tensor Storage Manipulation and Shared Storage Integrity # Objective: Write a function `shared_storage_integrity` that verifies the integrity of shared storage among multiple tensors. The function should ensure that changes in the storage of one tensor reflect correctly in the views or slices of the other tensors sharing the same storage. # Requirements: 1. Create a primary tensor and generate its view or slice. 2. Modify the storage of the primary tensor. 3. Check if the changes are consistently reflected in the view or slice tensors. 4. Return a boolean indicating consistency of shared storage integrity. # Function Signature: ```python import torch def shared_storage_integrity() -> bool: pass ``` # Implementation Details: 1. **Create a primary tensor**: - Initiate a tensor of a given size (e.g., `(6,)`) with some values (e.g., `torch.arange(6, dtype=torch.float32)`). 2. **Generate a view or slice**: - Create a view (reshape) of the primary tensor or generate a slice (sub-tensor). 3. **Modify the storage**: - Directly modify the underlying storage of the primary tensor using `torch.UntypedStorage` methods (e.g., `fill_`). 4. **Check the integrity**: - Verify if the storage changes are reflected accurately in the view or slice tensors by comparing their data. Example: ```python import torch def shared_storage_integrity() -> bool: # Step 1: Create a primary tensor primary_tensor = torch.arange(6, dtype=torch.float32) # Step 2: Generate a view or slice view_tensor = primary_tensor.view(2, 3) # Reshaping into 2x3 tensor # Step 3: Modify the storage of the primary tensor primary_storage = primary_tensor.untyped_storage() primary_storage.fill_(0) # Filling all elements with 0 # Step 4: Check the storage integrity view_data_intact = torch.all(view_tensor == 0).item() # Check if view data reflects the storage change return view_data_intact # Running the function print(shared_storage_integrity()) # Expected to return True if the integrity is maintained ``` # Constraints: - The function should not assume specific tensor device types (CPU/GPU). - Must handle tensors of different shapes and ensure consistency in reflected data. # Performance Requirements: - The function should complete within a reasonable time frame, even when tensor sizes are increased. Your task is to implement the `shared_storage_integrity` function, ensuring that it correctly verifies the integrity of shared storage among tensors.","solution":"import torch def shared_storage_integrity() -> bool: # Step 1: Create a primary tensor primary_tensor = torch.arange(6, dtype=torch.float32) # Step 2: Generate a view view_tensor = primary_tensor.view(2, 3) # Reshaping into 2x3 tensor # Step 3: Modify the storage of the primary tensor primary_storage = primary_tensor.untyped_storage() primary_storage.fill_(0) # Filling all elements with 0 # Step 4: Check the storage integrity view_data_intact = torch.all(view_tensor == 0).item() # Check if view data reflects the storage change return view_data_intact"},{"question":"Objective: Demonstrate your understanding of Python\'s \\"venv\\" module by implementing a custom virtual environment builder. Task: Write a Python script that defines and uses a subclass of `venv.EnvBuilder` to create and manage a virtual environment with specific customizations. Your virtual environment builder should perform the following tasks: 1. Create a virtual environment in a specified directory. 2. Ensure that `pip` and `setuptools` are installed within the environment. 3. Add a custom script into the virtual environment’s `bin` or `Scripts` directory which prints a greeting message when executed. Requirements: 1. Define a subclass of `venv.EnvBuilder` named `CustomEnvBuilder`. 2. Implement the `post_setup` method in your subclass to: - Install `pip` and `setuptools` (ensure they are the latest versions). - Add a custom script (`greet.py`) which prints \\"Hello, this is a custom virtual environment!\\". 3. Use your `CustomEnvBuilder` class to create a virtual environment in a directory specified by the user via a command-line argument. 4. Provide necessary error handling to ensure the script runs without unexpected failures. Input/Output Specifications: - The script should accept a single command-line argument indicating the target directory for the virtual environment. Constraints: - Your solution should be compatible with Python 3.7 or later. Example Usage: ```shell python create_custom_venv.py my_custom_env ``` This should: 1. Create a virtual environment in the `my_custom_env` directory. 2. Ensure `pip` and `setuptools` are installed. 3. Place a `greet.py` script inside the virtual environment’s `bin` or `Scripts` directory. Executing the `greet.py` script within the virtual environment should output: ``` Hello, this is a custom virtual environment! ``` Performance Requirements: - The script should run efficiently without performance bottlenecks. - Handle large-scale directory structures gracefully. Good luck!","solution":"import venv import os import subprocess import sys class CustomEnvBuilder(venv.EnvBuilder): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) def post_setup(self, context): Post setup actions to ensure pip and setuptools are installed and to add a custom script to the virtual environment. # Ensure pip and setuptools are installed self.ensure_latest_pip_and_setuptools(context) # Add the custom greet.py script self.add_greet_script(context) def ensure_latest_pip_and_setuptools(self, context): Install the latest versions of pip and setuptools in the virtual environment. subprocess.check_call([ context.env_exe, \'-m\', \'pip\', \'install\', \'--upgrade\', \'pip\', \'setuptools\' ]) def add_greet_script(self, context): Add a custom script greet.py that prints a greeting message. script_content = \'print(\\"Hello, this is a custom virtual environment!\\")\' if os.name == \'nt\': script_path = os.path.join(context.bin_path, \'greet.py\') else: script_path = os.path.join(context.bin_path, \'greet.py\') with open(script_path, \'w\') as script_file: script_file.write(script_content) if __name__ == \'__main__\': if len(sys.argv) != 2: print(f\\"Usage: {sys.argv[0]} <env-dir>\\") sys.exit(1) env_dir = sys.argv[1] builder = CustomEnvBuilder(with_pip=True) builder.create(env_dir)"},{"question":"Coding Assessment Question # Objective Your task is to write a Python function that parses an XML document, modifies its content based on given criteria, and then outputs the modified XML. You will demonstrate your comprehension of XML parsing, manipulation, and security considerations. # Problem Statement Write a function `secure_modify_xml(xml_string: str, tag_name: str, text_to_add: str) -> str` that takes an XML string, a tag name, and a text string as input. The function should perform the following operations: 1. Parse the XML from the `xml_string`. 2. For each element with the specified `tag_name`, append the `text_to_add` to the element\'s text. 3. Return the modified XML as a string. 4. Ensure that your code is secure against common XML vulnerabilities such as \\"external entity expansion\\" and \\"billion laughs\\". # Input - `xml_string` (str): A string containing XML data. The XML is guaranteed to be well-formed. - `tag_name` (str): The tag name of the elements where the text will be appended. - `text_to_add` (str): The text that will be appended to the elements\' text. # Output - `str`: A string containing the modified XML. # Constraints - You must use the `xml.etree.ElementTree` module for parsing and modifying the XML. - The function should handle XML documents up to 1MB in size efficiently. - Do not use deprecated or insecure XML parsing methods. # Example ```python xml_string = <root> <item>Item 1</item> <item>Item 2</item> <other>Other content</other> </root> tag_name = \\"item\\" text_to_add = \\" - modified\\" result = secure_modify_xml(xml_string, tag_name, text_to_add) print(result) ``` Expected Output ```xml <root> <item>Item 1 - modified</item> <item>Item 2 - modified</item> <other>Other content</other> </root> ``` # Notes - Ensure that your implementation avoids common security vulnerabilities as discussed in the provided documentation. - You may assume the input XML is well-formed, but avoid parsing any external entities or DTDs. - Pay attention to performance and try to minimize the processing time. # Hints - Consider using `xml.etree.ElementTree.fromstring` for parsing and `xml.etree.ElementTree.tostring` for generating the XML string. - Look into security measures provided by the `xml.etree.ElementTree` module to disable potentially harmful XML features.","solution":"import xml.etree.ElementTree as ET def secure_modify_xml(xml_string: str, tag_name: str, text_to_add: str) -> str: Parses the XML from the xml_string, appends text_to_add to elements with the specified tag_name, and returns the modified XML as a string. try: # Parse the XML string to an ElementTree object root = ET.fromstring(xml_string) # Find all elements with the specified tag_name and append the text_to_add for elem in root.iter(tag_name): if elem.text: elem.text += text_to_add else: elem.text = text_to_add # Convert the ElementTree object back to a string modified_xml_string = ET.tostring(root, encoding=\'unicode\') return modified_xml_string except ET.ParseError as e: raise ValueError(\\"Invalid XML input!\\") from e"},{"question":"# Coding Challenge: Email Message Manipulation **Objective**: Implement a function that constructs and manipulates an email message using the `email.message.Message` class and then retrieves specific parts of the message following certain criteria. **Problem Statement**: Create a function `construct_and_analyze_email(headers, plain_text, attachments)` which performs the following tasks: 1. Constructs an email message using the `Message` class. 2. Adds provided headers to the message. 3. Sets the plain text as the main payload of the message. 4. Optionally attaches files to the message as specified by `attachments`. 5. Retrieves and returns specific pieces of information from the email message. **Function Signature**: ```python def construct_and_analyze_email(headers: dict, plain_text: str, attachments: list) -> dict: pass ``` # Input: - `headers`: A dictionary where keys are header names and values are header values. For example: ```python { \\"From\\": \\"sender@example.com\\", \\"To\\": \\"recipient@example.com\\", \\"Subject\\": \\"Greetings\\" } ``` - `plain_text`: A string containing the plain text content of the email. - `attachments`: A list of tuples, where each tuple contains: - `filename`: Name of the file (string). - `content`: Content of the file (bytes). For example: ```python [(\\"file1.txt\\", b\\"Hello, this is the content of file1.\\")] ``` # Output: Returns a dictionary with the following key-value pairs: - `full_message_str`: The entire email message as a string (using `as_string()`). - `full_message_bytes`: The entire email message as bytes (using `as_bytes()`). - `subject`: The value of the \\"Subject\\" header. - `from`: The value of the \\"From\\" header. - `to`: The value(s) of the \\"To\\" header. - `plain_text_content`: The main plain text content of the email. - `attachment_filenames`: A list of filenames of all attachments. # Constraints: - Ensure to handle cases where headers might not exist when retrieving them. - Assume the input will always have at least \\"From\\" and \\"To\\" headers. # Example: ```python headers = { \\"From\\": \\"sender@example.com\\", \\"To\\": \\"recipient@example.com\\", \\"Subject\\": \\"Greetings\\" } plain_text = \\"Hello, this is a plain text message.\\" attachments = [(\\"file1.txt\\", b\\"Hello, this is the content of file1.\\")] result = construct_and_analyze_email(headers, plain_text, attachments) ``` Expected `result`: ```python { \'full_message_str\': \'...\', \'full_message_bytes\': b\'...\', \'subject\': \'Greetings\', \'from\': \'sender@example.com\', \'to\': \'recipient@example.com\', \'plain_text_content\': \'Hello, this is a plain text message.\', \'attachment_filenames\': [\'file1.txt\'] } ``` *Note: The exact output for `full_message_str` and `full_message_bytes` will depend on the formatting of the email library and is not shown here for brevity.* # Requirements: - Use the methods provided by the `Message` class for manipulating and retrieving headers and payload. - Include proper error handling for potential issues like missing headers or unsupported payload types. # Hints: - Use the `attach` method to add attachments appropriately. - Use `get_payload()` to retrieve the main payload and handle both text and multipart payloads. - Utilize the `as_string()` and `as_bytes()` methods to get the full representation of the message.","solution":"from email.message import EmailMessage import email.policy def construct_and_analyze_email(headers: dict, plain_text: str, attachments: list) -> dict: msg = EmailMessage() # Add headers to the message for header, value in headers.items(): msg[header] = value # Set the plain text as the main payload msg.set_content(plain_text) # Attach files if there are any attachments for filename, content in attachments: msg.add_attachment(content, maintype=\'application\', subtype=\'octet-stream\', filename=filename) # Extract and return required information result = { \'full_message_str\': msg.as_string(policy=email.policy.default), \'full_message_bytes\': msg.as_bytes(policy=email.policy.default), \'subject\': msg.get(\'Subject\', \'\'), \'from\': msg.get(\'From\', \'\'), \'to\': msg.get(\'To\', \'\'), \'plain_text_content\': plain_text, \'attachment_filenames\': [filename for filename, _ in attachments] } return result"},{"question":"Objective You are provided with a dataset containing missing values. Your task is to impute the missing values using different techniques provided by scikit-learn and evaluate the performance of a machine learning model trained on the imputed datasets. Dataset The dataset is provided as a CSV file named `data.csv`, which contains the following columns: - **Feature1**: Numerical values, with some missing values encoded as `NaN`. - **Feature2**: Numerical values, with some missing values encoded as `NaN`. - **Feature3**: Categorical values, with some missing values encoded as `NaN`. - **Target**: The target variable for prediction, with no missing values. Tasks 1. **Load and Examine the Data** - Load the dataset and display the first few rows to understand its structure and the nature of missing values. 2. **Simple Imputation** - Impute the missing values in `Feature1` and `Feature2` using the mean value of each column. - Impute the missing values in `Feature3` using the most frequent value. 3. **Iterative Imputation** - Impute the missing values in `Feature1` and `Feature2` using the `IterativeImputer`. - Use the `IterativeImputer` to handle `Feature3` as well, considering it as a categorical variable. 4. **KNN Imputation** - Impute the missing values in `Feature1`, `Feature2`, and `Feature3` using the `KNNImputer`. 5. **Model Training and Evaluation** - Train a DecisionTreeClassifier on the dataset imputed using each method above. - Split the dataset into training and testing sets. - Evaluate the performance of the model using accuracy as the metric. 6. **Result Comparison** - Compare the accuracy scores obtained from models trained on datasets imputed using different methods. - Discuss which imputation method led to the best performance and why it might be the case. Constraints - You must use `scikit-learn`\'s `SimpleImputer`, `IterativeImputer`, and `KNNImputer` for the imputations. - Ensure that your code is modular and well-documented. - Handle any edge cases or errors gracefully. Expected Output - A Python script implementing the required tasks. - Accuracy scores for each model trained on datasets imputed using different methods. - A brief discussion on the results obtained. Input/Output Format ```python def impute_and_evaluate(imputer_method: str, data_file: str) -> float: Impute missing values in the dataset and evaluate a DecisionTreeClassifier. Args: imputer_method (str): The imputation method to use (\'simple\', \'iterative\', or \'knn\'). data_file (str): Path to the dataset CSV file. Returns: float: The accuracy score of the trained model on the test set. # Your implementation here # Example usage: accuracy = impute_and_evaluate(\'simple\', \'data.csv\') print(f\'Accuracy with Simple Imputer: {accuracy}\') ``` Explanation: - The function `impute_and_evaluate` takes two arguments: - `imputer_method`: A string specifying the imputation method to use (\'simple\', \'iterative\', or \'knn\'). - `data_file`: The path to the CSV file containing the dataset. - The function should impute the missing values in the dataset using the specified method, train a DecisionTreeClassifier, evaluate its accuracy on a test set, and return the accuracy score.","solution":"import pandas as pd from sklearn.impute import SimpleImputer, KNNImputer from sklearn.experimental import enable_iterative_imputer # noqa from sklearn.impute import IterativeImputer from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier from sklearn.metrics import accuracy_score from sklearn.preprocessing import LabelEncoder def impute_and_evaluate(imputer_method: str, data_file: str) -> float: Impute missing values in the dataset and evaluate a DecisionTreeClassifier. Args: imputer_method (str): The imputation method to use (\'simple\', \'iterative\', or \'knn\'). data_file (str): Path to the dataset CSV file. Returns: float: The accuracy score of the trained model on the test set. # Load dataset data = pd.read_csv(data_file) # Extract features and target features = data.drop(columns=[\'Target\']) target = data[\'Target\'] # Encode categorical features label_encoders = {} for column in features.select_dtypes(include=[\'object\']).columns: le = LabelEncoder() features[column] = le.fit_transform(features[column].astype(str)) label_encoders[column] = le if imputer_method == \'simple\': # Simple Imputer imputer_num = SimpleImputer(strategy=\'mean\') imputer_cat = SimpleImputer(strategy=\'most_frequent\') features[[\'Feature1\', \'Feature2\']] = imputer_num.fit_transform(features[[\'Feature1\', \'Feature2\']]) features[\'Feature3\'] = imputer_cat.fit_transform(features[[\'Feature3\']]) elif imputer_method == \'iterative\': # Iterative Imputer imputer = IterativeImputer() features[[\'Feature1\', \'Feature2\', \'Feature3\']] = imputer.fit_transform(features[[\'Feature1\', \'Feature2\', \'Feature3\']]) elif imputer_method == \'knn\': # KNN Imputer imputer = KNNImputer() features = imputer.fit_transform(features) else: raise ValueError(f\\"Unknown imputer method: {imputer_method}\\") # Split dataset into train and test sets X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42) # Train and evaluate model model = DecisionTreeClassifier(random_state=42) model.fit(X_train, y_train) y_pred = model.predict(X_test) accuracy = accuracy_score(y_test, y_pred) return accuracy"},{"question":"# Contextual Echo Server using `contextvars` Your task is to implement a simple echo server that can handle multiple client connections concurrently without mixing up their states. This server will use the `contextvars` module to track the state of each client connection individually. Requirements: 1. Create a context variable named `client_id_var` to store a unique identifier for each client. 2. Implement an asynchronous function `handle_client(reader, writer)` to handle client connections. This function should: - Assign a unique identifier to each client using `client_id_var`. - Read lines of data from the client, echo them back, and store the session history. - Upon receiving a blank line, send back a message with the client\'s session history and close the connection. 3. Implement an asynchronous `main()` function that: - Starts the server to listen for incoming connections. - Assigns each incoming connection to the `handle_client` function. 4. Ensure thread safety and state isolation with context variables, so concurrent client connections do not interfere with each other. Input and Output Format: - The server will run indefinitely, accepting and responding to clients. - Each client sends multiple lines of input and receives the same lines echoed back. - Upon sending a blank line, the client will receive a message with the session history before the connection is closed. - Each client\'s session is isolated from others. Constraints: - Use the `contextvars` module and demonstrate its ability for state management in concurrent scenarios. - Ensure the server handles multiple clients concurrently without state interference. Example: After you implement the server, use the following script to test it: ```python import asyncio async def test_client(): reader, writer = await asyncio.open_connection(\'127.0.0.1\', 8081) messages = [\\"Hello, Server!\\", \\"How are you?\\", \\"\\"] for msg in messages: writer.write(f\\"{msg}n\\".encode()) response = await reader.readline() print(f\\"Received: {response.decode()}\\") writer.close() await writer.wait_closed() asyncio.run(test_client()) ``` Expected Server Response for Client: ``` Received: Hello, Server! Received: How are you? Received: Session history: [\\"Hello, Server!\\", \\"How are you?\\"] ``` Note: Your solution should correctly handle multiple clients connecting and interacting with the server at the same time, ensuring that each client\'s session history is tracked independently.","solution":"import asyncio import contextvars # Creating a context variable to store the unique client identifier client_id_var = contextvars.ContextVar(\'client_id_var\') # Creating a context variable to store session history for each client session_history_var = contextvars.ContextVar(\'session_history_var\') # This counter will help generate unique client IDs client_counter = 0 async def handle_client(reader, writer): # Using the global counter to get a unique client ID global client_counter client_counter += 1 client_id = client_counter # Set context variables for this client client_id_var.set(client_id) session_history_var.set([]) while True: data = await reader.readline() message = data.decode().strip() if message == \\"\\": # On receiving a blank line, send back the session history session_history = session_history_var.get() response = f\\"Session history: {session_history}n\\" writer.write(response.encode()) await writer.drain() writer.close() await writer.wait_closed() break else: # Echo the message back to the client writer.write(data) await writer.drain() # Update the session history session_history = session_history_var.get() session_history.append(message) session_history_var.set(session_history) async def main(): server = await asyncio.start_server(handle_client, \'127.0.0.1\', 8081) async with server: await server.serve_forever()"},{"question":"**Sound File Metadata Analyzer** You are provided with a list of sound filenames. Your task is to implement a function that processes each file and returns a summary of metadata information in a structured format. Specifically, you need to create a function `analyze_sound_files(file_list)` that takes a list of filenames as input and outputs a dictionary summarizing the metadata from each file. The function should utilize the `sndhdr` module functionalities to determine the sound file type and its attributes. # Function Signature ```python def analyze_sound_files(file_list: List[str]) -> Dict[str, dict]: ``` # Input - `file_list`: A list of strings, where each string is the path to a sound file. # Output - A dictionary where the keys are the filenames, and the values are another dictionary containing the following keys: - `filetype`: The type of sound file as a string. - `framerate`: The sampling rate as an integer. - `nchannels`: The number of audio channels as an integer. - `nframes`: The number of frames as an integer. - `sampwidth`: The sample width in bits as a string. # Example ```python file_list = [\\"sound1.wav\\", \\"sound2.aiff\\", \\"sound3.au\\"] print(analyze_sound_files(file_list)) ``` # Expected Output ```python { \\"sound1.wav\\": { \\"filetype\\": \\"wav\\", \\"framerate\\": 44100, \\"nchannels\\": 2, \\"nframes\\": 352800, \\"sampwidth\\": 16 }, \\"sound2.aiff\\": { \\"filetype\\": \\"aiff\\", \\"framerate\\": 48000, \\"nchannels\\": 1, \\"nframes\\": 240000, \\"sampwidth\\": 24 }, \\"sound3.au\\": { \\"filetype\\": \\"au\\", \\"framerate\\": 8000, \\"nchannels\\": 1, \\"nframes\\": 64000, \\"sampwidth\\": \\"U\\" } } ``` # Constraints 1. You should handle cases where `sndhdr` fails to determine the file type by returning `None` for those files in the output dictionary. 2. Assume that the files provided in the list exist and are accessible. # Note - Remember that the `sndhdr` module is deprecated and may not be available in future versions, but you can use the currently available version for this assessment.","solution":"import sndhdr def analyze_sound_files(file_list): Analyzes sound files and returns their metadata. Parameters: file_list (list): A list of sound file paths as strings. Returns: dict: A dictionary where each key is a filename and the value is a dictionary with metadata. metadata = {} for file in file_list: file_info = sndhdr.what(file) if file_info is None: metadata[file] = None else: metadata[file] = { \\"filetype\\": file_info.filetype, \\"framerate\\": file_info.framerate, \\"nchannels\\": file_info.nchannels, \\"nframes\\": file_info.nframes, \\"sampwidth\\": file_info.sampwidth } return metadata"},{"question":"# Coding Assessment: Exit Handlers Objective: Write a Python program that demonstrates the use of the `atexit` module to register multiple cleanup functions, handle their execution order, and manage exceptions that occur during the execution of these cleanup functions. Specifications: 1. **Function Implementations**: - Implement three functions: `cleanup_a`, `cleanup_b`, and `cleanup_c`, each of which prints a unique message indicating which function is being executed. - Implement an additional function `cleanup_with_exception` that raises a custom exception when called. - Ensure `cleanup_with_exception` is executed between the other cleanup functions to demonstrate exception handling. 2. **Behavior on Termination**: - Register the functions `cleanup_a`, `cleanup_b`, and `cleanup_c` such that they are executed in the reverse order of their registration. - Also, register `cleanup_with_exception`. - Upon program termination, print out which function is being executed in what order. - Handle any exceptions raised within the registered functions, printing a suitable message to indicate an exception occurred, but ensure the remaining functions are still executed. Input: - None. Output: - Output will be a sequence of print statements from the registered cleanup functions indicating the order in which they are executed. If an exception occurs during any cleanup function, also print \\"Exception occurred during cleanup\\". Constraints: - Use the `atexit` module for registering and managing the cleanup functions. Example: ```python def cleanup_a(): print(\\"Executing cleanup_a\\") def cleanup_b(): print(\\"Executing cleanup_b\\") def cleanup_c(): print(\\"Executing cleanup_c\\") def cleanup_with_exception(): raise Exception(\\"Exception in cleanup\\") import atexit # Registering cleanup functions atexit.register(cleanup_a) atexit.register(cleanup_with_exception) atexit.register(cleanup_b) atexit.register(cleanup_c) # Expected Output upon normal program termination (not necessarily in this order): # Executing cleanup_a # Executing cleanup_with_exception # Exception occurred during cleanup # Executing cleanup_b # Executing cleanup_c ``` Notes: - Make sure the handling and registration demonstrate the concepts of function execution order, exception handling, and function decorators using `atexit` module.","solution":"import atexit def cleanup_a(): print(\\"Executing cleanup_a\\") def cleanup_b(): print(\\"Executing cleanup_b\\") def cleanup_c(): print(\\"Executing cleanup_c\\") def cleanup_with_exception(): raise Exception(\\"Exception in cleanup_with_exception\\") # Wrapper function for cleanup_with_exception to handle exception gracefully def cleanup_with_exception_handler(): try: cleanup_with_exception() except Exception as e: print(f\\"Exception occurred during cleanup: {e}\\") # Registering cleanup functions atexit.register(cleanup_a) atexit.register(cleanup_with_exception_handler) atexit.register(cleanup_b) atexit.register(cleanup_c)"},{"question":"# Feature Selection in Scikit-learn: A Practical Approach Objective You are given a dataset and are tasked with applying different feature selection techniques provided by Scikit-learn to improve the performance of a machine learning model. Your goal is to demonstrate the use of at least three different feature selection methods from the `sklearn.feature_selection` module and evaluate their impact on the chosen model\'s performance. Dataset Use the provided `load_digits()` dataset from Scikit-learn: ```python from sklearn.datasets import load_digits data = load_digits() X, y = data.data, data.target ``` Requirements 1. **Implement Feature Selection Methods:** - Choose and implement three different feature selection methods from the following list: - `VarianceThreshold` - `SelectKBest` - `RFE` - `SelectFromModel` - For each method, specify the parameters used and justify your choices. 2. **Model Training and Evaluation:** - Use a `RandomForestClassifier` to train on the dataset reduced by each feature selection method. - Evaluate the performance using cross-validation (use `cross_val_score` with 5 folds). - For each method, report the number of selected features and the cross-validation accuracy. 3. **Comparison and Conclusion:** - Compare the performance of the different feature selection methods. - Discuss which feature selection method performed the best and why you think it was more effective. Code Template ```python import numpy as np from sklearn.datasets import load_digits from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, RFE, SelectFromModel from sklearn.model_selection import cross_val_score from sklearn.ensemble import RandomForestClassifier from sklearn.svm import LinearSVC # Load dataset data = load_digits() X, y = data.data, data.target # Method 1: VarianceThreshold var_thresh = VarianceThreshold(threshold=(.8 * (1 - .8))) X_var_thresh = var_thresh.fit_transform(X) # Evaluate Method 1 clf = RandomForestClassifier(random_state=42) scores_var_thresh = cross_val_score(clf, X_var_thresh, y, cv=5) print(f\\"VarianceThreshold selected {X_var_thresh.shape[1]} features with accuracy: {np.mean(scores_var_thresh)}\\") # Method 2: SelectKBest select_k_best = SelectKBest(f_classif, k=20) X_k_best = select_k_best.fit_transform(X, y) # Evaluate Method 2 scores_k_best = cross_val_score(clf, X_k_best, y, cv=5) print(f\\"SelectKBest selected {X_k_best.shape[1]} features with accuracy: {np.mean(scores_k_best)}\\") # Method 3: RFE svc = LinearSVC(C=1, penalty=\\"l2\\", max_iter=5000) rfe = RFE(svc, n_features_to_select=20, step=1) X_rfe = rfe.fit_transform(X, y) # Evaluate Method 3 scores_rfe = cross_val_score(clf, X_rfe, y, cv=5) print(f\\"RFE selected {X_rfe.shape[1]} features with accuracy: {np.mean(scores_rfe)}\\") # Conclusion and Comparison # Discuss which method performed the best and why. ``` Constraints - Ensure that you interpret and validate the results obtained from each feature selection method. - The dataset must be split into training and test sets in a consistent manner across different methods for a fair comparison. Remarks Write a summary of your findings and justify which feature selection method you would prefer based on the obtained results.","solution":"import numpy as np from sklearn.datasets import load_digits from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, RFE from sklearn.model_selection import cross_val_score from sklearn.ensemble import RandomForestClassifier from sklearn.svm import LinearSVC # Load dataset data = load_digits() X, y = data.data, data.target # Method 1: VarianceThreshold var_thresh = VarianceThreshold(threshold=(.8 * (1 - .8))) X_var_thresh = var_thresh.fit_transform(X) # Evaluate Method 1 clf = RandomForestClassifier(random_state=42) scores_var_thresh = cross_val_score(clf, X_var_thresh, y, cv=5) avg_score_var_thresh = np.mean(scores_var_thresh) selected_features_var_thresh = X_var_thresh.shape[1] # Method 2: SelectKBest select_k_best = SelectKBest(f_classif, k=20) X_k_best = select_k_best.fit_transform(X, y) # Evaluate Method 2 scores_k_best = cross_val_score(clf, X_k_best, y, cv=5) avg_score_k_best = np.mean(scores_k_best) selected_features_k_best = X_k_best.shape[1] # Method 3: RFE svc = LinearSVC(max_iter=5000) rfe = RFE(estimator=svc, n_features_to_select=20, step=1) X_rfe = rfe.fit_transform(X, y) # Evaluate Method 3 scores_rfe = cross_val_score(clf, X_rfe, y, cv=5) avg_score_rfe = np.mean(scores_rfe) selected_features_rfe = X_rfe.shape[1] # Results results = { \\"VarianceThreshold\\": { \\"selected_features\\": selected_features_var_thresh, \\"accuracy\\": avg_score_var_thresh }, \\"SelectKBest\\": { \\"selected_features\\": selected_features_k_best, \\"accuracy\\": avg_score_k_best }, \\"RFE\\": { \\"selected_features\\": selected_features_rfe, \\"accuracy\\": avg_score_rfe } } print(results)"},{"question":"You are given a dataset represented as a 2D NumPy array, where rows correspond to observations and columns correspond to features. Your task is to implement a Python function using the `scikit-learn` library to perform the following steps: 1. **Estimate the Covariance Matrix**: Compute the empirical covariance matrix of the dataset. 2. **Apply Shrinkage**: Use the Ledoit-Wolf shrinkage method to adjust the empirical covariance matrix. 3. **Identify Outliers**: Using the Minimum Covariance Determinant (MCD) method, identify observations that are considered outliers. # Function Signature ```python import numpy as np def assess_covariance_estimation(data: np.ndarray) -> dict: Estimates the covariance matrix using empirical and Ledoit-Wolf shrinkage methods, then identifies outliers using robust covariance estimation. Parameters: data (np.ndarray): A 2D NumPy array where each row represents an observation and each column represents a feature. Returns: dict: A dictionary containing the following keys: - \'empirical_covariance\': The empirical covariance matrix of the data. - \'ledoit_wolf_covariance\': The Ledoit-Wolf shrunk covariance matrix. - \'outliers\': A list of indices of the rows in the dataset that are identified as outliers. pass ``` # Input - `data` : A 2D NumPy array of shape `(n_samples, n_features)`. # Output - A dictionary with the following keys: - `\'empirical_covariance\'`: The empirical covariance matrix (2D NumPy array). - `\'ledoit_wolf_covariance\'`: The covariance matrix after applying Ledoit-Wolf shrinkage (2D NumPy array). - `\'outliers\'`: A list of indices for the rows identified as outliers. # Constraints - The dataset size can vary, but it will contain at least 50 samples and at most 1000 samples. - Each sample will have between 5 and 50 features. # Example ```python import numpy as np data = np.random.rand(100, 5) result = assess_covariance_estimation(data) print(result[\'empirical_covariance\']) print(result[\'ledoit_wolf_covariance\']) print(result[\'outliers\']) ``` # Notes - You can refer to the `scikit-learn` documentation for `EmpiricalCovariance`, `LedoitWolf`, and `MinCovDet` classes and their respective methods.","solution":"import numpy as np from sklearn.covariance import EmpiricalCovariance, LedoitWolf, MinCovDet def assess_covariance_estimation(data: np.ndarray) -> dict: Estimates the covariance matrix using empirical and Ledoit-Wolf shrinkage methods, then identifies outliers using robust covariance estimation. Parameters: data (np.ndarray): A 2D NumPy array where each row represents an observation and each column represents a feature. Returns: dict: A dictionary containing the following keys: - \'empirical_covariance\': The empirical covariance matrix of the data. - \'ledoit_wolf_covariance\': The Ledoit-Wolf shrunk covariance matrix. - \'outliers\': A list of indices of the rows in the dataset that are identified as outliers. # Compute the empirical covariance matrix emp_cov = EmpiricalCovariance().fit(data) empirical_covariance = emp_cov.covariance_ # Apply the Ledoit-Wolf shrinkage method to the empirical covariance matrix lw = LedoitWolf().fit(data) ledoit_wolf_covariance = lw.covariance_ # Identify outliers using the Minimum Covariance Determinant (MCD) method mcd = MinCovDet().fit(data) outliers = mcd.support_ == False outlier_indices = np.where(outliers)[0].tolist() return { \'empirical_covariance\': empirical_covariance, \'ledoit_wolf_covariance\': ledoit_wolf_covariance, \'outliers\': outlier_indices }"},{"question":"**Objective:** To assess the understanding of the `getpass` module and the ability to implement secure password and user identification mechanisms. **Problem Statement:** You are tasked with creating a small login simulation script using the `getpass` module. The script should securely prompt the user for a username and password, compare it against stored credentials (for simplicity, hardcoded), and print a success or failure message accordingly. **Function Signature:** ```python def login_system(): pass ``` **Detailed Requirements:** 1. Implement the `login_system` function that: - Prompts the user to input their username using `getpass.getuser()`. - Prompts the user to input their password using `getpass.getpass()`. - Compares the entered credentials to the stored credentials. - Stored credentials: - Username: `student` - Password: `securepassword123` - Prints `\\"Login successful\\"` if the credentials match. - Prints `\\"Login failed\\"` if the credentials do not match. 2. **Input and Output:** - There are no direct input arguments to the function, as it interacts through console input/output using the `getpass` module. - The function should output relevant success or failure messages to the console. **Example:** ```plaintext Please enter your username: > student Password: > (hidden input) Login successful ``` **Constraints:** - You must use the `getpass` module for both user input and to fetch the password securely. - Do not use any other methods to gather input or print output. Implement the function `login_system` adhering to the above requirements.","solution":"import getpass def login_system(): Prompts the user for a username and password and checks them against stored credentials. Prints \'Login successful\' if credentials match, otherwise prints \'Login failed\'. stored_username = \'student\' stored_password = \'securepassword123\' # Prompt for username username = getpass.getuser() # Prompt for password password = getpass.getpass(\'Password: \') # Validate credentials if username == stored_username and password == stored_password: print(\\"Login successful\\") else: print(\\"Login failed\\")"},{"question":"Objective Your task is to implement a function that runs a matrix multiplication operation in PyTorch using MPS (Metal Performance Shaders) and utilizes the provided environment variables to control the behavior of the operation. Problem Statement Write a function `run_matrix_multiplication(a: torch.Tensor, b: torch.Tensor, env_vars: dict) -> torch.Tensor` that performs the following steps: 1. Sets the provided environment variables to control the behavior of PyTorch. 2. Performs matrix multiplication on input tensors `a` and `b`. 3. Returns the result of the matrix multiplication. Input - `a` (torch.Tensor): A 2D tensor representing the left matrix in the multiplication. - `b` (torch.Tensor): A 2D tensor representing the right matrix in the multiplication. - `env_vars` (dict): A dictionary containing environment variable names and their corresponding values as strings. The keys must be one of the MPS environment variables listed in the provided documentation. Output - Returns a `torch.Tensor` representing the result of the matrix multiplication. Constraints - The environment variables provided in `env_vars` are a subset of possible MPS-related variables from the documentation. - Both input tensors `a` and `b` must be 2D tensors with compatible shapes for matrix multiplication. - The function should handle setting and unsetting environment variables correctly to ensure no side effects on subsequent operations. Example ```python import torch a = torch.randn(3, 4, device=\\"mps\\") b = torch.randn(4, 2, device=\\"mps\\") env_vars = { \\"PYTORCH_DEBUG_MPS_ALLOCATOR\\": \\"1\\", \\"PYTORCH_MPS_FAST_MATH\\": \\"1\\" } result = run_matrix_multiplication(a, b, env_vars) print(result) ``` Note - Assume that the PyTorch environment is correctly set up to leverage MPS and the necessary hardware is available. - Ensure the function cleans up by unsetting any environment variables it sets. **Hint**: You might find the `os` module useful for setting environment variables.","solution":"import os import torch def run_matrix_multiplication(a: torch.Tensor, b: torch.Tensor, env_vars: dict) -> torch.Tensor: Sets the provided environment variables, performs matrix multiplication on the input tensors `a` and `b`, and returns the result. Parameters: a (torch.Tensor): A 2D tensor representing the left matrix in the multiplication. b (torch.Tensor): A 2D tensor representing the right matrix in the multiplication. env_vars (dict): A dictionary containing environment variable names and their corresponding values as strings. Returns: torch.Tensor: Result of the matrix multiplication. # Backup current environment variables original_env_vars = {key: os.environ.get(key) for key in env_vars} try: # Set environment variables from the provided dictionary for key, value in env_vars.items(): os.environ[key] = value # Perform matrix multiplication on MPS if available if torch.backends.mps.is_available(): a = a.to(\\"mps\\") b = b.to(\\"mps\\") result = torch.matmul(a, b) finally: # Restore original environment variables for key, value in original_env_vars.items(): if value is None: del os.environ[key] else: os.environ[key] = value return result.cpu()"},{"question":"# Python 310 Coding Assessment Problem Description You are required to implement a custom class in Python named `AdvancedNumber` that wraps around regular Python numbers and provides additional methods that mimic the functionality of the `PyNumber_*` functions described in the provided documentation. The `AdvancedNumber` class will have the following methods: - `add(self, other)`: Adds the `other` number to the current number. - `subtract(self, other)`: Subtracts the `other` number from the current number. - `multiply(self, other)`: Multiplies the current number by the `other` number. - `divide(self, other)`: Divides the current number by the `other` number and returns a floating-point result. - `floor_divide(self, other)`: Divides the current number by the `other` number and returns the floor of the result. - `matrix_multiply(self, other)`: Performs matrix multiplication with the `other` number. - `remainder(self, other)`: Returns the remainder of the current number divided by the `other` number. - `power(self, other, modulo=None)`: Raises the current number to the power of `other`, optionally performing a modulo operation. - `negative(self)`: Returns the negation of the current number. - `positive(self)`: Returns the current number. - `absolute(self)`: Returns the absolute value of the current number. - `invert(self)`: Returns the bitwise negation of the current number. - `lshift(self, other)`: Left shifts the current number by `other` bits. - `rshift(self, other)`: Right shifts the current number by `other` bits. - `bitwise_and(self, other)`: Performs bitwise `AND` with the `other` number. - `bitwise_xor(self, other)`: Performs bitwise `XOR` with the `other` number. - `bitwise_or(self, other)`: Performs bitwise `OR` with the `other` number. Each method should: - Take `other` as another instance of `AdvancedNumber` or a compatible numeric type (int or float). - Perform the corresponding operation on the internal number. - Return a new instance of `AdvancedNumber` with the result, except for `negative`, `positive`, `absolute`, and `invert`, which should return a numeric result. Class Definition ```python class AdvancedNumber: def __init__(self, value): if not isinstance(value, (int, float)): raise TypeError(\\"Value must be an integer or float\\") self.value = value def add(self, other): pass # Implement this method def subtract(self, other): pass # Implement this method def multiply(self, other): pass # Implement this method def divide(self, other): pass # Implement this method def floor_divide(self, other): pass # Implement this method def matrix_multiply(self, other): pass # Implement this method def remainder(self, other): pass # Implement this method def power(self, other, modulo=None): pass # Implement this method def negative(self): pass # Implement this method def positive(self): pass # Implement this method def absolute(self): pass # Implement this method def invert(self): pass # Implement this method def lshift(self, other): pass # Implement this method def rshift(self, other): pass # Implement this method def bitwise_and(self, other): pass # Implement this method def bitwise_xor(self, other): pass # Implement this method def bitwise_or(self, other): pass # Implement this method def __repr__(self): return f\\"AdvancedNumber({self.value})\\" ``` Constraints - All inputs will be valid integers or floating-point numbers. - All operations within this class should mimic the behavior of their Python equivalents. - Ensure that arithmetic operations correctly handle type errors if `other` is not a number. Example Usage ```python a = AdvancedNumber(10) b = AdvancedNumber(2) print(a.add(b)) # Output: AdvancedNumber(12) print(a.subtract(b)) # Output: AdvancedNumber(8) print(a.multiply(b)) # Output: AdvancedNumber(20) print(a.divide(b)) # Output: AdvancedNumber(5.0) print(a.floor_divide(b)) # Output: AdvancedNumber(5) print(a.matrix_multiply(b)) # This will be just multiplication as a simple implementation print(a.remainder(b)) # Output: AdvancedNumber(0) print(a.power(b)) # Output: AdvancedNumber(100) print(a.negative()) # Output: -10 print(a.positive()) # Output: 10 print(a.absolute()) # Output: 10 print(a.invert()) # Output: -11 (for an int type demonstration) print(a.lshift(b)) # Output: AdvancedNumber(40) print(a.rshift(b)) # Output: AdvancedNumber(2) print(a.bitwise_and(b)) # Output: AdvancedNumber(2) print(a.bitwise_xor(b)) # Output: AdvancedNumber(8) print(a.bitwise_or(b)) # Output: AdvancedNumber(10) ``` Submission Submit your implementation of the `AdvancedNumber` class.","solution":"class AdvancedNumber: def __init__(self, value): if not isinstance(value, (int, float)): raise TypeError(\\"Value must be an integer or float\\") self.value = value def add(self, other): return AdvancedNumber(self.value + self._get_value(other)) def subtract(self, other): return AdvancedNumber(self.value - self._get_value(other)) def multiply(self, other): return AdvancedNumber(self.value * self._get_value(other)) def divide(self, other): return AdvancedNumber(self.value / self._get_value(other)) def floor_divide(self, other): return AdvancedNumber(self.value // self._get_value(other)) def matrix_multiply(self, other): return AdvancedNumber(self.value * self._get_value(other)) def remainder(self, other): return AdvancedNumber(self.value % self._get_value(other)) def power(self, other, modulo=None): if modulo is None: return AdvancedNumber(pow(self.value, self._get_value(other))) else: return AdvancedNumber(pow(self.value, self._get_value(other), modulo)) def negative(self): return -self.value def positive(self): return self.value def absolute(self): return abs(self.value) def invert(self): return ~self.value def lshift(self, other): return AdvancedNumber(self.value << self._get_value(other)) def rshift(self, other): return AdvancedNumber(self.value >> self._get_value(other)) def bitwise_and(self, other): return AdvancedNumber(self.value & self._get_value(other)) def bitwise_xor(self, other): return AdvancedNumber(self.value ^ self._get_value(other)) def bitwise_or(self, other): return AdvancedNumber(self.value | self._get_value(other)) def _get_value(self, other): if isinstance(other, AdvancedNumber): return other.value elif isinstance(other, (int, float)): return other else: raise TypeError(\\"Other must be an instance of AdvancedNumber or a numeric type\\") def __repr__(self): return f\\"AdvancedNumber({self.value})\\""},{"question":"# Custom PyTorch Operation and Module Objective Create a custom autograd function and a neural network module using PyTorch that performs a differentiable custom operation. Problem Statement In this exercise, you will implement a custom PyTorch function and then create a neural network module that uses this function. Your custom autograd function will perform a cubic transformation, and the network module will integrate this transformation into a feedforward layer structure. Part 1: Custom Autograd Function 1.1 Implement a custom autograd function `CubicFunction` that: - Takes a tensor and raises each element to the third power (cubic transformation). - Correctly implements the backward pass to provide gradients. Part 2: Neural Network Module 2.1 Implement a PyTorch module `CubicLayer` that: - Inherits from `torch.nn.Module`. - Utilizes the `CubicFunction` in its forward pass. - Accepts an input tensor, applies the cubic transformation using `CubicFunction`, and then applies a linear transformation using `torch.nn.Linear` module. Requirements 1. **CubicFunction Class Implementation**: - Contains a static `forward` method that performs the cubic operation. - Contains a static `backward` method that computes the gradient. 2. **CubicLayer Class Implementation**: - Inherits from `torch.nn.Module`. - Contains a `Linear` layer (e.g., `torch.nn.Linear`). - Uses the `CubicFunction` in its `forward` method followed by the linear transformation. Expected Inputs and Outputs - **Input**: A tensor `input` of shape `(batch_size, input_features)`. - **Output**: A tensor of shape `(batch_size, output_features)` after applying the cubic transformation and linear layer. Performance Requirements - The custom autograd function should correctly compute gradients for backpropagation. - The implementation should handle typical tensor sizes efficiently. Constraints - You must implement the forward and backward pass without using built-in PyTorch operations that already perform cubic transformations. - The CubicLayer should use `CubicFunction.apply` for the cubic transformation and an instance of `torch.nn.Linear` for the linear transformation. Example ```python import torch from torch.autograd import Function import torch.nn as nn class CubicFunction(Function): @staticmethod def forward(ctx, input): ctx.save_for_backward(input) return input ** 3 @staticmethod def backward(ctx, grad_output): input, = ctx.saved_tensors grad_input = grad_output * 3 * input ** 2 return grad_input class CubicLayer(nn.Module): def __init__(self, input_features, output_features): super(CubicLayer, self).__init__() self.linear = nn.Linear(input_features, output_features) def forward(self, input): cubed = CubicFunction.apply(input) return self.linear(cubed) # Test the implementation input = torch.randn(10, 5, requires_grad=True) model = CubicLayer(5, 3) output = model(input) print(output) ``` This question assesses your understanding of custom autograd functions, extending PyTorch modules, and integrating new operations into a neural network model.","solution":"import torch from torch.autograd import Function import torch.nn as nn class CubicFunction(Function): @staticmethod def forward(ctx, input): ctx.save_for_backward(input) return input ** 3 @staticmethod def backward(ctx, grad_output): input, = ctx.saved_tensors grad_input = grad_output * 3 * input ** 2 return grad_input class CubicLayer(nn.Module): def __init__(self, input_features, output_features): super(CubicLayer, self).__init__() self.linear = nn.Linear(input_features, output_features) def forward(self, input): cubed = CubicFunction.apply(input) return self.linear(cubed)"},{"question":"Objective Implement a Python function that retrieves specific metadata information for a given package and processes that information to present a summary report. Question You are required to write a function `package_summary(package_name: str) -> dict` that retrieves metadata for a specified package and returns a summary report containing the following details: - Package Name - Version - Author - Author Email - License - Home Page Implementation Details: 1. Use the `importlib.metadata` library to access the package metadata. 2. Handle the cases where some metadata fields might not be present and provide a default value (`\\"Not Available\\"`). 3. Ensure the function handles exceptions properly, such as when the package is not installed. Input: - `package_name` (type: str): The name of the package for which to retrieve the metadata. Output: - The function should return a dictionary with the following keys: - \'Package Name\' - \'Version\' - \'Author\' - \'Author Email\' - \'License\' - \'Home Page\' Each key should map to the corresponding metadata value, or `\\"Not Available\\"` if the metadata is missing. Example usage: ```python def package_summary(package_name: str) -> dict: # Your implementation here # Example usage summary = package_summary(\'requests\') print(summary) ``` Example output: ```python { \'Package Name\': \'requests\', \'Version\': \'2.25.1\', \'Author\': \'Kenneth Reitz\', \'Author Email\': \'me@kennethreitz.org\', \'License\': \'Apache 2.0\', \'Home Page\': \'https://requests.readthedocs.io\' } ``` Constraints: 1. Assume the input package name is always a valid string. 2. The function should work for any package installed within the environment. 3. This should be efficient to handle metadata retrieval without significant delays. Notes: - Review the official documentation for `importlib.metadata` to understand how to retrieve and handle package metadata. - Ensure to test your function with multiple packages to validate its correctness and robustness.","solution":"import importlib.metadata def package_summary(package_name: str) -> dict: Retrieves metadata for the specified package and returns a summary report. Parameters: package_name (str): The name of the package for which to retrieve the metadata. Returns: dict: A dictionary with the package metadata summary. try: metadata = importlib.metadata.metadata(package_name) return { \'Package Name\': metadata.get(\'Name\', \'Not Available\'), \'Version\': metadata.get(\'Version\', \'Not Available\'), \'Author\': metadata.get(\'Author\', \'Not Available\'), \'Author Email\': metadata.get(\'Author-email\', \'Not Available\'), \'License\': metadata.get(\'License\', \'Not Available\'), \'Home Page\': metadata.get(\'Home-page\', \'Not Available\') } except importlib.metadata.PackageNotFoundError: return { \'Package Name\': package_name, \'Version\': \'Not Available\', \'Author\': \'Not Available\', \'Author Email\': \'Not Available\', \'License\': \'Not Available\', \'Home Page\': \'Not Available\' }"},{"question":"# Advanced Seaborn: Custom PairGrid Plot **Objective:** You are tasked with demonstrating your understanding of advanced seaborn functionalities by creating a customized PairGrid plot. This will involve setting up the grid, mapping various functions, and customizing the plots using a hue variable and additional plot elements. **Problem Statement:** You are given the penguins dataset available in seaborn. You need to create a customized pair grid with the following specifications: 1. Load the penguins dataset using `seaborn.load_dataset`. 2. Use `PairGrid` to initialize a grid with the following variables: `body_mass_g`, `bill_length_mm`, and `flipper_length_mm`. 3. Use the `sex` column as the hue variable. 4. Map a KDE plot (`sns.kdeplot`) on the diagonal. 5. Map a scatter plot (`sns.scatterplot`) on the upper triangle. 6. Map a KDE plot (`sns.kdeplot`) on the lower triangle. 7. Ensure an appropriate legend is added to the plots for hues provided. 8. Present the plots with distinguishable hues and styles. **Input:** No input is needed as you will directly use the provided penguins dataset. **Output:** A customized pair grid plot of the specified variables. **Constraints:** - The hue parameter should correctly differentiate data points. - Diagonal, upper, and lower triangle mappings should be correctly applied. - A legend should accurately indicate the hue distinctions. **Example Output:** Your plot should resemble the following structure: ``` (Plot showcasing body_mass_g, bill_length_mm, and flipper_length_mm distributions) ``` **Implementation:** ```python import seaborn as sns import matplotlib.pyplot as plt # Load the penguins dataset penguins = sns.load_dataset(\\"penguins\\") # Define the variables and hue variables = [\\"body_mass_g\\", \\"bill_length_mm\\", \\"flipper_length_mm\\"] hue = \\"sex\\" # Create a PairGrid with specified variables and hue g = sns.PairGrid(penguins, vars=variables, hue=hue) # Map different plots to the diagonal, upper, and lower parts of the grid g.map_diag(sns.kdeplot) g.map_upper(sns.scatterplot) g.map_lower(sns.kdeplot) # Add a legend to the grid g.add_legend() # Show the plot plt.show() ``` Make sure your implementation meets the specifications and provides a clear visualization with appropriate styling.","solution":"import seaborn as sns import matplotlib.pyplot as plt def create_custom_pairgrid(): Creates a customized PairGrid for the penguins dataset with specified variables and hue. # Load the penguins dataset penguins = sns.load_dataset(\\"penguins\\") # Define the variables and hue variables = [\\"body_mass_g\\", \\"bill_length_mm\\", \\"flipper_length_mm\\"] hue = \\"sex\\" # Create a PairGrid with specified variables and hue g = sns.PairGrid(penguins, vars=variables, hue=hue) # Map different plots to the diagonal, upper, and lower parts of the grid g.map_diag(sns.kdeplot) g.map_upper(sns.scatterplot) g.map_lower(sns.kdeplot) # Add a legend to the grid g.add_legend() # Show the plot plt.show() # Example usage: # create_custom_pairgrid()"},{"question":"You are tasked with creating a Python script to help manage which files get included or excluded from a source distribution of a software package. Using Unix-style \\"glob\\" patterns, your script should take a list of files and a set of commands to determine the final list of files that should be included in the distribution. # Input: 1. A list of file paths (strings) representing all files available in the source directory. 2. A list of commands, where each command is a string. The commands can be any of the following: - **include patterns**: Include files matching any of the listed patterns. - **exclude patterns**: Exclude files matching any of the listed patterns. - **recursive-include dir patterns**: Include files under *dir* matching any of the listed patterns. - **recursive-exclude dir patterns**: Exclude files under *dir* matching any of the listed patterns. - **global-include patterns**: Include files anywhere in the source tree matching any of the listed patterns. - **global-exclude patterns**: Exclude files anywhere in the source tree matching any of the listed patterns. - **prune dir**: Exclude all files under *dir*. - **graft dir**: Include all files under *dir*. # Output: The final list of file paths that should be included in the distribution, sorted in ascending lexicographical order. # Constraints: - 1 <= len(files) <= 10^4 - Each path is a string with a length of 1 to 256 characters. - There can be up to 100 commands. - Patterns follow Unix glob syntax. # Example: Given the following inputs: files: ``` [ \\"src/main.py\\", \\"src/utils/helpers.py\\", \\"src/tests/test_main.py\\", \\"docs/readme.md\\", \\"docs/changelog.md\\", \\"data/sample_data.csv\\", \\"scripts/install.sh\\" ] ``` commands: ``` [ \\"include *.py\\", \\"exclude src/tests/*.py\\", \\"recursive-include docs *.md\\", \\"prune data\\", \\"graft scripts\\" ] ``` The output should be: ``` [ \\"docs/changelog.md\\", \\"docs/readme.md\\", \\"scripts/install.sh\\", \\"src/main.py\\", \\"src/utils/helpers.py\\" ] ``` # Challenge: Implement a function that takes in the list of files and commands, processes them according to the rules specified, and returns the final list of file paths to be included in the distribution, sorted in ascending lexicographical order. ```python import os import fnmatch def manage_distribution(files, commands): included_files = set() # To keep track of included file paths excluded_files = set() # To keep track of excluded file paths for command in commands: parts = command.split() cmd = parts[0] patterns = parts[1:] if cmd == \\"include\\": for pattern in patterns: included_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"exclude\\": for pattern in patterns: excluded_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"recursive-include\\": directory, *patterns = patterns for pattern in patterns: matched = [file for file in files if file.startswith(directory) and fnmatch.fnmatch(file[len(directory)+1:], pattern)] included_files.update(matched) elif cmd == \\"recursive-exclude\\": directory, *patterns = patterns for pattern in patterns: matched = [file for file in files if file.startswith(directory) and fnmatch.fnmatch(file[len(directory)+1:], pattern)] excluded_files.update(matched) elif cmd == \\"global-include\\": for pattern in patterns: included_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"global-exclude\\": for pattern in patterns: excluded_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"prune\\": dir = patterns[0] excluded_files.update([file for file in files if file.startswith(dir)]) elif cmd == \\"graft\\": dir = patterns[0] included_files.update([file for file in files if file.startswith(dir)]) # Compute the final list of included files, removing those that are excluded final_files = included_files - excluded_files return sorted(final_files) # Example usage files = [ \\"src/main.py\\", \\"src/utils/helpers.py\\", \\"src/tests/test_main.py\\", \\"docs/readme.md\\", \\"docs/changelog.md\\", \\"data/sample_data.csv\\", \\"scripts/install.sh\\" ] commands = [ \\"include *.py\\", \\"exclude src/tests/*.py\\", \\"recursive-include docs *.md\\", \\"prune data\\", \\"graft scripts\\" ] print(manage_distribution(files, commands)) ```","solution":"import fnmatch def manage_distribution(files, commands): included_files = set() excluded_files = set() for command in commands: parts = command.split() cmd = parts[0] patterns = parts[1:] if cmd == \\"include\\": for pattern in patterns: included_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"exclude\\": for pattern in patterns: excluded_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"recursive-include\\": directory, *patterns = patterns for pattern in patterns: matched = [file for file in files if file.startswith(directory) and fnmatch.fnmatch(file[len(directory)+1:], pattern)] included_files.update(matched) elif cmd == \\"recursive-exclude\\": directory, *patterns = patterns for pattern in patterns: matched = [file for file in files if file.startswith(directory) and fnmatch.fnmatch(file[len(directory)+1:], pattern)] excluded_files.update(matched) elif cmd == \\"global-include\\": for pattern in patterns: included_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"global-exclude\\": for pattern in patterns: excluded_files.update(fnmatch.filter(files, pattern)) elif cmd == \\"prune\\": dir = patterns[0] excluded_files.update([file for file in files if file.startswith(dir)]) elif cmd == \\"graft\\": dir = patterns[0] included_files.update([file for file in files if file.startswith(dir)]) final_files = included_files - excluded_files return sorted(final_files)"},{"question":"# PyTorch Distributed Training with Custom Communication Hook Background Distributed Data Parallel (DDP) in PyTorch allows model training to be distributed across multiple GPUs, accelerating the training process. To optimize communication among distributed nodes, PyTorch provides communication hooks that can be customized. Task Your task is to implement a custom communication hook for DDP in PyTorch. This hook will apply a gradient compression method before performing the default allreduce operation. Specifically, you will: 1. Define a custom compression function. 2. Implement a custom communication hook that uses this compression function. 3. Register this custom hook with a DDP model. 4. Verify that the custom hook is used during training. Custom Compression Function Create a function that compresses gradient tensors by scaling them down by a fixed factor. Custom Hook Implementation Write a custom communication hook which applies this compression to gradients before performing the standard allreduce operation. Input - `gradients`: Set of gradient tensors for each model parameter. Output - Compressed gradients, followed by allreduce operation to sum gradients from all devices. Instructions 1. Implement a compression function: `compress_gradients`. 2. Define a custom communication hook: `custom_comm_hook`. 3. Integrate the custom hook into a DDP training setup. ```python import torch import torch.distributed as dist import torch.nn as nn from torch.nn.parallel import DistributedDataParallel as DDP import torch.multiprocessing as mp import torch.optim as optim # Custom compression function def compress_gradients(tensor, factor=0.1): return tensor * factor # Custom communication hook def custom_comm_hook(state, bucket: dist.GradBucket): compressed_tensors = [compress_gradients(tensor) for tensor in bucket.gradients()] # Convert list of tensors to a single buffer tensor that can be allreduced buffer = torch.cat([tensor.flatten() for tensor in compressed_tensors]) buffer.div_(dist.get_world_size()) # Normalize by world size dist.all_reduce(buffer) # Perform allreduce operation return buffer # Model to be trained class SimpleModel(nn.Module): def __init__(self): super(SimpleModel, self).__init__() self.fc1 = nn.Linear(10, 10) self.fc2 = nn.Linear(10, 1) def forward(self, x): x = torch.relu(self.fc1(x)) return self.fc2(x) def train(rank, world_size): dist.init_process_group(\\"nccl\\", rank=rank, world_size=world_size) model = SimpleModel().to(rank) ddp_model = DDP(model, device_ids=[rank]) # Register custom communication hook ddp_model.register_comm_hook(state=None, hook=custom_comm_hook) # Training loop optimizer = optim.SGD(ddp_model.parameters(), lr=0.001) criterion = nn.MSELoss() for epoch in range(10): optimizer.zero_grad() inputs = torch.rand(10, 10).to(rank) labels = torch.rand(10, 1).to(rank) outputs = ddp_model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() dist.destroy_process_group() def main(): world_size = 2 mp.spawn(train, args=(world_size,), nprocs=world_size, join=True) if __name__ == \\"__main__\\": main() ``` Constraints - Assume availability of at least 2 GPUs. - Use PyTorch\'s in-built distributed package (`torch.distributed`). - Ensure the custom hook works seamlessly with DistributedDataParallel.","solution":"import torch import torch.distributed as dist import torch.nn as nn from torch.nn.parallel import DistributedDataParallel as DDP import torch.multiprocessing as mp import torch.optim as optim # Custom compression function def compress_gradients(tensor, factor=0.1): Compresses the gradient tensor by scaling it down by a fixed factor. Args: tensor (torch.Tensor): The gradient tensor. factor (float): The compression factor. Returns: torch.Tensor: The compressed gradient tensor. return tensor * factor # Custom communication hook def custom_comm_hook(state, bucket: dist.GradBucket): Custom communication hook to compress gradients before allreduce. Args: state (Any): State data (not used in this custom hook). bucket (dist.GradBucket): Contains the gradients to be communicated. Returns: Future: A torch.Future object which completes when the communication is done. compressed_tensors = [compress_gradients(tensor) for tensor in bucket.gradients()] compressed_gradients = torch.cat([tensor.flatten() for tensor in compressed_tensors]) compressed_grads_split = compressed_gradients.chunk(len(bucket.gradients())) for i, grad in enumerate(bucket.gradients()): grad.copy_(compressed_grads_split[i]) future = dist.all_reduce(tensor=compressed_gradients) return future # Model to be trained class SimpleModel(nn.Module): def __init__(self): super(SimpleModel, self).__init__() self.fc1 = nn.Linear(10, 10) self.fc2 = nn.Linear(10, 1) def forward(self, x): x = torch.relu(self.fc1(x)) return self.fc2(x) def train(rank, world_size): # Setup process group dist.init_process_group(\\"nccl\\", rank=rank, world_size=world_size) # Create model and move it to GPU with id rank model = SimpleModel().to(rank) ddp_model = DDP(model, device_ids=[rank]) # Register custom communication hook ddp_model.register_comm_hook(state=None, hook=custom_comm_hook) # Set up optimizer and loss function optimizer = optim.SGD(ddp_model.parameters(), lr=0.001) criterion = nn.MSELoss() # Dummy training loop for epoch in range(10): optimizer.zero_grad() inputs = torch.rand(10, 10).to(rank) labels = torch.rand(10, 1).to(rank) outputs = ddp_model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # Clean up dist.destroy_process_group() def main(): world_size = 2 mp.spawn(train, args=(world_size,), nprocs=world_size, join=True) if __name__ == \\"__main__\\": main()"},{"question":"# Custom Interactive Python Console You are tasked with creating a custom interactive Python console using Python\'s `code` module. This console should extend the behavior of the `InteractiveConsole` class by adding command history functionality and supporting a custom set of commands. Requirements: 1. **Class Definition**: - Define a class `CustomInteractiveConsole` that inherits from `code.InteractiveConsole`. 2. **Command History**: - Implement a mechanism to keep track of the last 10 commands entered in the console. - Add a special command `history` that, when typed, will display the last 10 commands in reverse order (most recent first). 3. **Special Commands**: - Implement a special command `exit` to stop the interactive session. 4. **Prompt**: - Use the default prompts (`sys.ps1` and `sys.ps2`). However, display a custom banner when the console starts and a custom exit message when the console ends. Input and Output - The custom console should be started using the `start_console` function described below. - Interaction with the console (input and output) will be the same as the standard Python interpreter, except for the modifications described above. Function Signature ```python class CustomInteractiveConsole(code.InteractiveConsole): def __init__(self, locals=None): # Initialize the base class and add necessary initializations. def push(self, line): # Override this method to handle command history and special commands. def show_history(self): # Display the last 10 commands entered. def start_console(): Function to start the custom interactive console. console = CustomInteractiveConsole() console.interact(banner=\\"Welcome to the Custom Interactive Console!\\", exitmsg=\\"Thank you for using the Custom Interactive Console.\\") ``` Constraints and Limitations: - The history should only keep track of the actual Python execution lines, not special commands like `exit` or `history`. - Ensure that the code runs efficiently in an interactive environment. Performance Requirements: - Handling of command history should be efficient, even with frequent accesses and updates. Example Usage: ```python >>> start_console() Welcome to the Custom Interactive Console! >>> 1 + 1 2 >>> print(\\"Hello, World!\\") Hello, World! >>> history print(\\"Hello, World!\\") 1 + 1 >>> exit Thank you for using the Custom Interactive Console. ``` Make sure your implementation is robust and follows the guidelines provided.","solution":"import code import sys class CustomInteractiveConsole(code.InteractiveConsole): def __init__(self, locals=None): super().__init__(locals) self.history = [] def push(self, line): Handle command history and special commands. if line.strip() == \\"exit\\": raise SystemExit(\\"Thank you for using the Custom Interactive Console.\\") elif line.strip() == \\"history\\": self.show_history() return False result = super().push(line) if line.strip() not in [\\"exit\\", \\"history\\"]: self.history.append(line.strip()) if len(self.history) > 10: self.history.pop(0) return result def show_history(self): Display the last 10 commands entered. if self.history: for cmd in reversed(self.history): print(cmd) def start_console(): Function to start the custom interactive console. console = CustomInteractiveConsole() console.interact(banner=\\"Welcome to the Custom Interactive Console!\\", exitmsg=\\"Thank you for using the Custom Interactive Console.\\")"},{"question":"Objective: Demonstrate your understanding of the Python `struct` module by implementing functions that handle packing and unpacking of structured binary data. Task: 1. Implement a function `pack_data(format_str, data)` that takes a format string and a tuple of values, and returns a packed bytes object. 2. Implement a function `unpack_data(format_str, packed_data)` that takes a format string and a packed bytes object, and returns a tuple of unpacked values. 3. Implement a function `read_struct(file_path, format_str)` that reads a binary file at `file_path`, unpacks its contents using the given format string, and returns the unpacked values. 4. Implement a function `write_struct(file_path, format_str, data)` that takes a file path, a format string, and a tuple of values, packs the data, and writes the packed bytes to the file. Input: - `format_str`: A string representing the format used for packing/unpacking data. - `data`: A tuple of values to be packed/unpacked. - `file_path`: A string representing the path to the binary file to read/write. Output: - `pack_data` returns a packed bytes object. - `unpack_data` returns a tuple of unpacked values. - `read_struct` returns a tuple of unpacked values read from the binary file. - `write_struct` has no return value; it writes packed data to the binary file. Constraints: - The sizes of the packed data must match the sizes specified by the format string. - Handle incorrect formats or data sizes gracefully by raising a `struct.error`. Example: ```python import struct def pack_data(format_str, data): try: packed = struct.pack(format_str, *data) return packed except struct.error as e: raise e def unpack_data(format_str, packed_data): try: unpacked = struct.unpack(format_str, packed_data) return unpacked except struct.error as e: raise e def read_struct(file_path, format_str): try: with open(file_path, \'rb\') as file: packed_data = file.read(struct.calcsize(format_str)) unpacked_data = unpack_data(format_str, packed_data) return unpacked_data except struct.error as e: raise e def write_struct(file_path, format_str, data): try: packed_data = pack_data(format_str, data) with open(file_path, \'wb\') as file: file.write(packed_data) except struct.error as e: raise e # Test Cases format_str = \'>hhl\' data = (1, 2, 3) packed = pack_data(format_str, data) print(packed) # Expected output: b\'x00x01x00x02x00x00x00x03\' unpacked = unpack_data(format_str, packed) print(unpacked) # Expected output: (1, 2, 3) write_struct(\'test.bin\', format_str, data) read_data = read_struct(\'test.bin\', format_str) print(read_data) # Expected output: (1, 2, 3) ``` Ensure that your functions handle various edge cases, such as incorrect format strings or mismatched data lengths.","solution":"import struct def pack_data(format_str, data): Packs a tuple of values into a bytes object according to the given format string. :param format_str: A format string. :param data: A tuple of values. :return: Packed bytes object. :raises struct.error: If the format or data is incorrect. try: packed = struct.pack(format_str, *data) return packed except struct.error as e: raise e def unpack_data(format_str, packed_data): Unpacks a bytes object into a tuple of values according to the given format string. :param format_str: A format string. :param packed_data: A packed bytes object. :return: Tuple of unpacked values. :raises struct.error: If the format or packed data is incorrect. try: unpacked = struct.unpack(format_str, packed_data) return unpacked except struct.error as e: raise e def read_struct(file_path, format_str): Reads a binary file, unpacks its contents using the format string, and returns the unpacked values. :param file_path: Path to the binary file. :param format_str: A format string. :return: Tuple of unpacked values. :raises struct.error: If the format or file contents are incorrect. try: with open(file_path, \'rb\') as file: packed_data = file.read(struct.calcsize(format_str)) unpacked_data = unpack_data(format_str, packed_data) return unpacked_data except struct.error as e: raise e def write_struct(file_path, format_str, data): Packs a tuple of values and writes the packed bytes to a binary file. :param file_path: Path to the binary file. :param format_str: A format string. :param data: A tuple of values. :raises struct.error: If the format or data is incorrect. try: packed_data = pack_data(format_str, data) with open(file_path, \'wb\') as file: file.write(packed_data) except struct.error as e: raise e"},{"question":"# Unicode Normalization in Python **Objective:** Write a Python function `normalized_unicode` that normalizes a given string to the \'NFD\' (Normalization Form D) normalization form, which means decomposing combined characters into their canonical equivalents. **Details:** The task demonstrates your understanding of Unicode string handling, character normalization, and encoding/decoding in Python, focusing particularly on functions provided by the `unicodedata` module. **Function Signature:** ```python def normalized_unicode(input_string: str) -> str: ``` **Requirements:** 1. The function must take a single string argument `input_string`. 2. The function returns a normalized version of `input_string` using \'NFD\' normalization form. **Example:** ```python #Input input_string = \\"Café\\" result = normalized_unicode(input_string) #Output print(result) # Output: \\"Café\\" # Explanation: # The character \'é\' (U+00E9) is decomposed into two characters: \'e\' (U+0065) and a combining acute accent (U+0301). ``` **Constraints:** - The input string can contain any Unicode characters. - Assume the string is properly encoded in UTF-8. - You can use the `unicodedata` module. **Additional Challenge:** To further demonstrate your understanding, extend the program to compare two strings and determine if they are equivalent when normalized to \'NFD\' form. **Function Signature:** ```python def compare_normalized_strings(str1: str, str2: str) -> bool: ``` **Example:** ```python # Input str1 = \\"é\\" str2 = \\"é\\" result = compare_normalized_strings(str1, str2) # Output print(result) # Output: True # Explanation: # The first string \'é\' (U+00E9) is equivalent to the second string \'é\' (U+0065 and U+0301) when normalized to \'NFD\'. ``` **Guidelines:** - Ensure the implementation is efficient and leverages the `unicodedata.normalize` function. - Handle edge cases where the input string might already be normalized. Good luck!","solution":"import unicodedata def normalized_unicode(input_string: str) -> str: Normalize a given string to \'NFD\' (Normalization Form D). Args: input_string (str): The string to be normalized. Returns: str: The normalized string. return unicodedata.normalize(\'NFD\', input_string) def compare_normalized_strings(str1: str, str2: str) -> bool: Compare if two strings are equivalent when normalized to \'NFD\'. Args: str1 (str): The first string to compare. str2 (str): The second string to compare. Returns: bool: True if both strings are equivalent when normalized to \'NFD\', otherwise False. return normalized_unicode(str1) == normalized_unicode(str2)"},{"question":"You are tasked with creating a Python program that manages server configurations using the `configparser` module. Specifically, you need to write a function that reads from an existing configuration file and updates a specific section with new values. Additionally, if the section does not exist, it should be added to the configuration. The updated configuration should then be written to a new file. **Function Signature:** ```python def update_server_config(input_file: str, output_file: str, section: str, new_values: dict) -> None: ``` **Parameters:** - `input_file` (str): The path to the input configuration file. - `output_file` (str): The path where the updated configuration should be saved. - `section` (str): The section in the configuration file that needs to be updated or added. - `new_values` (dict): A dictionary containing the new key-value pairs to update or add to the section. **Requirements:** 1. If the specified section does not exist in the configuration file, add it. 2. Update the specified section with the key-value pairs from `new_values`. 3. Write the updated configuration to the `output_file`. **Constraints:** - Only the specified section should be modified. Other sections should remain unchanged. - Keys in `new_values` are case-insensitive and should overwrite any existing keys in the section. **Example:** ```python # Given an input configuration file \'server.ini\' with the following content: [DEFAULT] ServerAliveInterval = 45 Compression = yes CompressionLevel = 9 [databases] User = admin Password = secret [webserver] Port = 8080 # Suppose we call the function with: input_file = \'server.ini\' output_file = \'updated_server.ini\' section = \'webserver\' new_values = {\'Port\': \'9090\', \'Host\': \'localhost\'} # The resulting \'updated_server.ini\' file should have the following content: [DEFAULT] ServerAliveInterval = 45 Compression = yes CompressionLevel = 9 [databases] User = admin Password = secret [webserver] Port = 9090 Host = localhost ``` **Notes:** - Use `configparser.ConfigParser()` to manage the configuration file. - Handle any exceptions that might occur during file operations or configuration parsing. - Ensure that the output file format is consistent and human-readable.","solution":"import configparser def update_server_config(input_file: str, output_file: str, section: str, new_values: dict) -> None: config = configparser.ConfigParser() # Read the existing configuration file config.read(input_file) # Ensure the section exists if not config.has_section(section): config.add_section(section) # Update the section with new values for key, value in new_values.items(): config.set(section, key, value) # Write the updated configuration to the output file with open(output_file, \'w\') as configfile: config.write(configfile)"},{"question":"# Python Version Analysis CPython represents its version number using different macros and a single hexadecimal integer, `PY_VERSION_HEX`, which encodes the version information into 32 bits. Your task is to write a function that can encode version information into this single hexadecimal number and another function that can decode this hexadecimal number back into its constituent parts. Task 1: Encode Version Information Write a function `encode_version(major, minor, micro, level, serial)` that takes the following arguments: - `major` (int): The major version number (e.g., 3 in 3.10.0) - `minor` (int): The minor version number (e.g., 10 in 3.10.0) - `micro` (int): The micro version number (e.g., 0 in 3.10.0) - `level` (str): The release level (`\'a\'` for alpha, `\'b\'` for beta, `\'c\'` for release candidate, `\'f\'` for final) - `serial` (int): The release serial number (e.g., 0 in 3.10.0) The function should return an integer representing the encoded version. Task 2: Decode Version Information Write a function `decode_version(version_hex)` that takes a single argument: - `version_hex` (int): The encoded version number. The function should return a tuple `(major, minor, micro, level, serial)` representing the version components. Constraints: - The major, minor, and micro versions are non-negative integers. - The level must be one of the characters in `\'abcf\'`. - The serial is a non-negative integer. Example: ```python def encode_version(major, minor, micro, level, serial): # Implementation Here def decode_version(version_hex): # Implementation Here # Example usage: encoded = encode_version(3, 4, 1, \'a\', 2) # encoded would be 0x030401a2 decoded = decode_version(0x030401a2) # decoded would be (3, 4, 1, \'a\', 2) ``` You are required to implement both functions and ensure they work as intended. Notes: - You might find it useful to look into Python\'s bitwise operators and hexadecimal formatting. - Ensure that your code correctly handles the input constraints and edge cases.","solution":"def encode_version(major, minor, micro, level, serial): Encodes version information into a single hexadecimal number. level_codes = { \'a\': 0xA0, \'b\': 0xB0, \'c\': 0xC0, \'f\': 0xF0, } if level not in level_codes: raise ValueError(\\"Invalid level. Must be one of \'a\', \'b\', \'c\', \'f\'.\\") level_code = level_codes[level] # Format the encoded version following the PY_VERSION_HEX scheme version_hex = (major << 24) | (minor << 16) | (micro << 8) | level_code | serial return version_hex def decode_version(version_hex): Decodes a hexadecimal version number into its components. major = (version_hex >> 24) & 0xFF minor = (version_hex >> 16) & 0xFF micro = (version_hex >> 8) & 0xFF level_code = version_hex & 0xF0 serial = version_hex & 0x0F level_codes = { 0xA0: \'a\', 0xB0: \'b\', 0xC0: \'c\', 0xF0: \'f\', } if level_code not in level_codes: raise ValueError(\\"Invalid level code in version_hex.\\") level = level_codes[level_code] return (major, minor, micro, level, serial)"},{"question":"Objective Your task is to implement and optimize a simple neural network in PyTorch using TorchScript, focusing on parallelism and threading capabilities described in the documentation provided. Problem Statement You need to create a TorchScript model that performs matrix multiplication in parallel using both inter-op and intra-op parallelism. Specifically, you will: 1. Define and script a PyTorch model that includes a matrix multiplication operation. 2. Use the `torch.jit._fork` and `torch.jit._wait` functions to execute tasks asynchronously. 3. Optimize the model\'s performance by tuning the number of inter-op and intra-op threads. Requirements 1. **Model Definition and Scripting**: - Create a simple linear model that includes matrix multiplication. - Script the model using `torch.jit.script`. 2. **Parallel Execution**: - Use `torch.jit._fork` to launch matrix multiplication operations asynchronously. - Use `torch.jit._wait` to synchronize the operations and aggregate the results. 3. **Thread Tuning**: - Implement functions to set and get the number of inter-op and intra-op threads using `torch.set_num_threads` and `torch.get_num_threads`. - Experiment with different numbers of threads and document the performance impact. Specifications - **Input**: - A 2D tensor `x` of shape `(n, m)` where `n` and `m` are integers representing the dimensions of the matrix. - Number of threads to be used for inter-op and intra-op parallelism. - **Output**: - The result of the matrix multiplication. - The execution time for the operation. - **Constraints**: - Ensure that the number of threads specified does not exceed the number of available CPU cores. - Use appropriate synchronization to avoid race conditions and ensure correctness. - **Performance Requirements**: - Provide the execution time for different thread settings and discuss the trade-offs between latency and throughput. Example Usage ```python import torch import time # Define the model and script it class LinearModel(torch.nn.Module): def __init__(self): super(LinearModel, self).__init__() self.w = torch.randn(1024, 1024) def forward(self, x): return torch.mm(x, self.w) scripted_model = torch.jit.script(LinearModel()) # Function to perform parallel execution and measure time def parallel_execution(model, x, inter_op_threads, intra_op_threads): # Set the number of threads torch.set_num_threads(intra_op_threads) torch.set_num_interop_threads(inter_op_threads) def compute(x): return model(x) # Start timing start_time = time.time() # Launch tasks asynchronously futures = [torch.jit._fork(compute, x) for _ in range(4)] # Synchronize and gather results results = [torch.jit._wait(fut) for fut in futures] # End timing end_time = time.time() execution_time = end_time - start_time return results, execution_time # Example input tensor input_tensor = torch.randn(1024, 1024) # Experiment with different thread settings results, exec_time = parallel_execution(scripted_model, input_tensor, inter_op_threads=4, intra_op_threads=4) print(f\'Execution Time: {exec_time} seconds\') ``` Submission Submit the complete implementation of the model definition, scripting, parallel execution function, and the results of your experiments with different thread settings. Include any relevant plots or tables showing the performance impact.","solution":"import torch import time class LinearModel(torch.nn.Module): def __init__(self): super(LinearModel, self).__init__() self.w = torch.randn(1024, 1024) def forward(self, x): return torch.mm(x, self.w) # Scripting the model scripted_model = torch.jit.script(LinearModel()) def parallel_execution(model, x, inter_op_threads, intra_op_threads): Performs matrix multiplication in parallel using TorchScript with specified inter-op and intra-op threads. # Set the number of threads torch.set_num_threads(intra_op_threads) torch.set_num_interop_threads(inter_op_threads) def compute(x): return model(x) # Start timing start_time = time.time() # Launch tasks asynchronously futures = [torch.jit._fork(compute, x) for _ in range(4)] # Synchronize and gather results results = [torch.jit._wait(fut) for fut in futures] # End timing end_time = time.time() execution_time = end_time - start_time return results, execution_time"},{"question":"# Advanced Coding Assessment Question: Panel Stack Manipulation Objective: Write a program that demonstrates the use of the `curses.panel` module by creating and managing a series of panels with specific behaviors. Problem Statement: You are tasked with creating a console-based program that manages multiple panels. Each panel should display a unique identifier and can be stacked, moved, shown, or hidden based on user input. Requirements: 1. **Create Panels**: Initialize three panels with identifiers \\"P1\\", \\"P2\\", and \\"P3\\". 2. **Display Stack Order**: Implement a function `display_stack_order()` to print the current stack order of the panels, showing which panel is at the top, middle, and bottom. 3. **Move Panels**: Implement a function `move_panel(panel_id, y, x)` that moves the specified panel to new screen coordinates `(y, x)`. 4. **Show/Hide Panels**: Implement functions `show_panel(panel_id)` and `hide_panel(panel_id)` to manage the visibility of the panels. 5. **Top/Bottom Position**: Implement `move_to_top(panel_id)` and `move_to_bottom(panel_id)` to move the specified panel to the top or bottom of the stack. 6. **Interactive Control**: Create a simple user interface that allows dynamic manipulation of the panels using keyboard inputs: - Arrow keys to move the selected panel. - \'t\' key to move the selected panel to the top. - \'b\' key to move the selected panel to the bottom. - \'h\' key to hide the selected panel. - \'s\' key to show the selected panel. - \'q\' key to quit the program. Constraints: - Ensure that the panels are not garbage-collected prematurely. - The program must be able to handle edge cases gracefully, such as moving a panel out of the visible screen area or attempting to hide an already hidden panel. Input Format: - User inputs through keyboard interactions. Output Format: - The console should display the positions and stack order of the panels after each user interaction. Example Output: ``` Current Stack Order: Top: P3 Middle: P2 Bottom: P1 Move P1 to the top (t key): Current Stack Order: Top: P1 Middle: P3 Bottom: P2 Hide P3 (h key): Current Stack Order: Top: P1 Middle: P2 Bottom: (Hidden Panel) ``` Implementation Hints: - Use `curses` to manage user inputs and screen updates. - Utilize `curses.panel` methods to manipulate the panels. Note: Remember to handle screen refreshes appropriately using `curses.doupdate()` after making changes to the panel stack.","solution":"import curses from curses import panel # Panel management class class PanelManager: def __init__(self, stdscr): self.stdscr = stdscr self.windows = { \\"P1\\": curses.newwin(3, 10, 5, 5), \\"P2\\": curses.newwin(3, 10, 10, 5), \\"P3\\": curses.newwin(3, 10, 15, 5) } self.panels = {id: panel.new_panel(win) for id, win in self.windows.items()} self.panel_order = [\\"P1\\", \\"P2\\", \\"P3\\"] for id, pnl in self.panels.items(): self.windows[id].border(0) self.windows[id].addstr(1, 1, id) panel.update_panels() curses.doupdate() def display_stack_order(self): order = panel.top_panel().window() stack_order = [self.get_panel_id(order)] while order := order.panel_below().window(): stack_order.append(self.get_panel_id(order)) self.stdscr.clear() self.stdscr.addstr(0, 0, \\"Current Stack Order:\\") self.stdscr.addstr(1, 0, f\\"Top: {stack_order[0]}\\") self.stdscr.addstr(2, 0, f\\"Middle: {stack_order[1]}\\") self.stdscr.addstr(3, 0, f\\"Bottom: {stack_order[2]}\\") self.stdscr.refresh() def get_panel_id(self, win): for id, panel in self.panels.items(): if panel.window() == win: return id return \\"Hidden Panel\\" def move_panel(self, panel_id, y, x): self.panels[panel_id].move(y, x) panel.update_panels() curses.doupdate() def show_panel(self, panel_id): self.panels[panel_id].show() panel.update_panels() curses.doupdate() def hide_panel(self, panel_id): self.panels[panel_id].hide() panel.update_panels() curses.doupdate() def move_to_top(self, panel_id): self.panels[panel_id].top() panel.update_panels() curses.doupdate() def move_to_bottom(self, panel_id): self.panels[panel_id].bottom() panel.update_panels() curses.doupdate() def main(stdscr): curses.curs_set(0) manager = PanelManager(stdscr) selected_panel = \\"P1\\" while True: manager.display_stack_order() key = stdscr.getch() if key == ord(\'q\'): break elif key == curses.KEY_UP: manager.move_panel(selected_panel, manager.windows[selected_panel].getbegyx()[0] - 1, manager.windows[selected_panel].getbegyx()[1]) elif key == curses.KEY_DOWN: manager.move_panel(selected_panel, manager.windows[selected_panel].getbegyx()[0] + 1, manager.windows[selected_panel].getbegyx()[1]) elif key == curses.KEY_LEFT: manager.move_panel(selected_panel, manager.windows[selected_panel].getbegyx()[0], manager.windows[selected_panel].getbegyx()[1] - 1) elif key == curses.KEY_RIGHT: manager.move_panel(selected_panel, manager.windows[selected_panel].getbegyx()[0], manager.windows[selected_panel].getbegyx()[1] + 1) elif key == ord(\'t\'): manager.move_to_top(selected_panel) elif key == ord(\'b\'): manager.move_to_bottom(selected_panel) elif key == ord(\'h\'): manager.hide_panel(selected_panel) elif key == ord(\'s\'): manager.show_panel(selected_panel) curses.doupdate() if __name__ == \\"__main__\\": curses.wrapper(main)"},{"question":"**Challenge: WAV File Manipulation and Saving** You are given a WAV file, `input.wav`, and you need to create a Python function that reads the WAV file, doubles its speed (by retaining every other sample), and writes the modified audio data to a new file called `output.wav`. Implement the function `double_speed_wav(input_file: str, output_file: str) -> None` that works as follows: # Function Description **Input:** - `input_file`: A string representing the path to the input WAV file. - `output_file`: A string representing the path to the output WAV file. **Output:** - The function should not return anything. Instead, it should create a new file `output_file` with audio data at double the speed. # Constraints: - You should use the `wave` module to read and write the WAV files. - Only handle PCM formatted WAV files. - Ensure the metadata (number of channels, sample width, etc.) remains unchanged except for the number of frames and the duration. # Example: Given a file `input.wav`, calling `double_speed_wav(\\"input.wav\\", \\"output.wav\\")` should create a new file `output.wav` where the playback speed is doubled. ```python def double_speed_wav(input_file: str, output_file: str) -> None: import wave # Open the input file with wave.open(input_file, \'rb\') as wav_in: # Read parameters params = wav_in.getparams() n_channels, sampwidth, framerate, n_frames, comptype, compname = params # Read frames frames = wav_in.readframes(n_frames) # Create new frames by retaining every other frame new_frames = frames[::2] # Open the output file with wave.open(output_file, \'wb\') as wav_out: # Set parameters for the output file (double speed -> half the frames) wav_out.setnchannels(n_channels) wav_out.setsampwidth(sampwidth) wav_out.setframerate(framerate) wav_out.setnframes(len(new_frames) // (n_channels * sampwidth)) # Write the new frames wav_out.writeframes(new_frames) ``` Remember to handle any exceptions that may occur due to reading/writing WAV files using the wave module.","solution":"def double_speed_wav(input_file: str, output_file: str) -> None: import wave # Open the input file with wave.open(input_file, \'rb\') as wav_in: # Read parameters params = wav_in.getparams() n_channels, sampwidth, framerate, n_frames, comptype, compname = params # Read frames frames = wav_in.readframes(n_frames) # Create new frames by retaining every other frame new_frames = frames[::2] # Open the output file with wave.open(output_file, \'wb\') as wav_out: # Set parameters for the output file (double speed -> half the frames) wav_out.setnchannels(n_channels) wav_out.setsampwidth(sampwidth) wav_out.setframerate(framerate) wav_out.setnframes(len(new_frames) // (n_channels * sampwidth)) # Write the new frames wav_out.writeframes(new_frames)"},{"question":"**Objective**: Implement a function that calculates the factorial of a list of numbers in parallel using the `concurrent.futures` module. Your implementation needs to handle exceptions, manage the lifecycle of the executor properly, and return the results in the same order as the input list. **Function Signature**: ```python def parallel_factorial(numbers: List[int], use_threads: bool = True, max_workers: int = None) -> List[Union[int, str]]: ``` **Input**: - `numbers` (List[int]): A list of non-negative integers for which the factorial needs to be computed. - `use_threads` (bool): A flag indicating whether to use `ThreadPoolExecutor` (if True) or `ProcessPoolExecutor` (if False). Default is True. - `max_workers` (int): The maximum number of workers to use. Default is None, which means the executor\'s default settings are used. **Output**: - Returns a list of results where each result corresponds to the factorial of the number at the same index in the input list. If a computation raises an exception (e.g., a `ValueError` for negative numbers), the corresponding result should be a string with the message \\"Invalid input\\". **Example**: ```python numbers = [5, 0, -3, 7, 1] results = parallel_factorial(numbers, use_threads=True, max_workers=4) print(results) # Output: [120, 1, \\"Invalid input\\", 5040, 1] ``` **Constraints**: - You must use the `concurrent.futures` module\'s executor and future functionality. - You must handle invalid inputs appropriately by returning the string \\"Invalid input\\" in their place. - Ensure the order of results matches the order of the input list. - Properly handle the shutdown of the executor to free up resources. **Hints**: - Use `ThreadPoolExecutor` or `ProcessPoolExecutor` based on the `use_threads` argument. - Use the `map` method of the executor to parallelize the factorial computation. - Factorial of a non-negative integer n is defined as: n! = n × (n−1) × ... × 1. Factorial of 0 is 1. - Handle possible exceptions within the worker function. **Implementation**: ```python from typing import List, Union from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor import math def factorial(n: int) -> Union[int, str]: if n < 0: return \\"Invalid input\\" elif n == 0: return 1 result = 1 try: for i in range(1, n + 1): result *= i return result except Exception as e: return \\"Invalid input\\" def parallel_factorial(numbers: List[int], use_threads: bool = True, max_workers: int = None) -> List[Union[int, str]]: if use_threads: executor_class = ThreadPoolExecutor else: executor_class = ProcessPoolExecutor with executor_class(max_workers=max_workers) as executor: futures = [executor.submit(factorial, num) for num in numbers] results = [] for future in futures: try: results.append(future.result()) except Exception as exc: results.append(\\"Invalid input\\") return results ``` **Note**: Tests will be conducted to ensure your function works correctly under various scenarios and handles exceptions and invalid inputs gracefully.","solution":"from typing import List, Union from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor import math def factorial(n: int) -> Union[int, str]: Computes the factorial of a non-negative integer n. Returns \\"Invalid input\\" if n is negative. if n < 0: return \\"Invalid input\\" elif n == 0: return 1 result = 1 try: for i in range(1, n + 1): result *= i return result except Exception as e: return \\"Invalid input\\" def parallel_factorial(numbers: List[int], use_threads: bool = True, max_workers: int = None) -> List[Union[int, str]]: Computes the factorial of a list of numbers in parallel. Args: - numbers: List[int] - List of non-negative integers for which to compute the factorial. - use_threads: bool - Flag to use ThreadPoolExecutor if True, else ProcessPoolExecutor. Default is True. - max_workers: int - Maximum number of workers to use. Default is None. Returns: List[Union[int, str]]: List of results where each result is the factorial of the number at the same index in input list. If a computation raises an exception, returns \\"Invalid input\\" for that entry. if use_threads: executor_class = ThreadPoolExecutor else: executor_class = ProcessPoolExecutor with executor_class(max_workers=max_workers) as executor: futures = [executor.submit(factorial, num) for num in numbers] results = [] for future in futures: try: results.append(future.result()) except Exception as exc: results.append(\\"Invalid input\\") return results"},{"question":"**Question: Using Seaborn for Data Visualization** # Task In this exercise, you will demonstrate your understanding of seaborn by visualizing a dataset using `sns.lmplot`. You are required to write a function called `plot_penguin_regression` that meets the following specifications: # Specifications 1. **Function Definition**: Define a function `plot_penguin_regression(file_path: str, hue: str, col: str, row: str, share_axes: bool) -> None`. 2. **Parameters**: - `file_path` _(str)_: The file path to a CSV file containing the penguins dataset. - `hue` _(str)_: The column name to be used for color encoding. - `col` _(str)_: The column name used to create columns in the resulting plot grid. - `row` _(str)_: The column name used to create rows in the resulting plot grid. - `share_axes` _(bool)_: A boolean to determine if the axis limits should be shared across subplots or allowed to vary independently. 3. **Functionality**: - Load the dataset from the given CSV file using `pandas`. - Use `sns.lmplot` to visualize the dataset: - The x-axis should represent `bill_length_mm`. - The y-axis should represent `bill_depth_mm`. - Use the `hue`, `col`, and `row` arguments provided to condition the plots. - Configure the subplots based on the `share_axes` parameter to either share axis limits or allow them to vary. 4. **Constraints**: - Ensure that the file path provided must link to a valid CSV containing the required columns (`bill_length_mm`, `bill_depth_mm`, and those specified by `hue`, `col`, and `row`). # Example ```python # Sample call to the function plot_penguin_regression( file_path=\\"path/to/penguins.csv\\", hue=\\"species\\", col=\\"sex\\", row=\\"island\\", share_axes=True ) # This should create a seaborn lmplot with the specified customizations. ``` # Notes: - You can assume that the CSV file provided will be correctly formatted and contain the necessary columns. - Make sure to import any necessary libraries within your function.","solution":"import pandas as pd import seaborn as sns import matplotlib.pyplot as plt def plot_penguin_regression(file_path: str, hue: str, col: str, row: str, share_axes: bool) -> None: Plots a seaborn lmplot of the penguin dataset with specified customizations. Parameters: file_path (str): The file path to a CSV file containing the penguins dataset. hue (str): The column name to be used for color encoding. col (str): The column name used to create columns in the resulting plot grid. row (str): The column name used to create rows in the resulting plot grid. share_axes (bool): Determine if the axis limits should be shared across subplots or allowed to vary independently. # Load the dataset from the given CSV file penguins = pd.read_csv(file_path) # Generate the seaborn lmplot lm = sns.lmplot( data=penguins, x=\'bill_length_mm\', y=\'bill_depth_mm\', hue=hue, col=col, row=row, sharex=share_axes, sharey=share_axes ) # Show the plot plt.show()"},{"question":"# Question: Distributed Training with PyTorch Distributed Autograd and RPC You are tasked with implementing a simple distributed training process using PyTorch\'s distributed autograd and RPC features. Your goal is to train a small neural network where the parameters are distributed across two nodes, and the gradients are computed and optimized using distributed autograd. Requirements 1. **Setup**: - Implement the neural network model to be distributed. - Initialize RPC and autograd context. 2. **Forward Pass**: - Perform the forward pass where parts of the computation are executed on both nodes. 3. **Backward Pass**: - Compute the gradients across the nodes using distributed autograd. 4. **Optimization**: - Apply distributed optimization to update the parameters. 5. **Logging**: - Print the parameter gradients after the backward pass. Constraints - Use PyTorch\'s `rpc`, `distributed.autograd`, and `optim` packages. - Assume you have two nodes: \\"worker0\\" and \\"worker1\\". - Use the `SGD` optimizer with a learning rate of 0.1. - The neural network model should have at least two layers with parameters distributed across both nodes. Expected Input and Output - **Input**: None; the script should initialize and run the distributed training process. - **Output**: Gradients of the parameters after the backward pass. Example Skeleton Below is a skeleton to help you get started: ```python import torch import torch.distributed.autograd as dist_autograd import torch.distributed.rpc as rpc import torch.multiprocessing as mp from torch import nn, optim from torch.distributed.optim import DistributedOptimizer def run_worker(rank, world_size): # Initialize RPC rpc.init_rpc(f\\"worker{rank}\\", rank=rank, world_size=world_size) # Define a simple neural network layer class SimpleLayer(nn.Module): def __init__(self): super(SimpleLayer, self).__init__() self.linear = nn.Linear(3, 3) def forward(self, x): return self.linear(x) if rank == 0: model_layer1 = SimpleLayer() # Example forward pass, perform computations using rpc_sync and handle tensors with dist_autograd.context() as context_id: # Implement the forward pass, backward pass, and optimizer steps # Perform remote operations and locally, compute loss and trigger backward pass elif rank == 1: model_layer2 = SimpleLayer() # Clean up rpc.shutdown() if __name__ == \\"__main__\\": world_size = 2 mp.spawn(run_worker, args=(world_size,), nprocs=world_size) ``` Your task is to complete the implementation within the `run_worker` function to achieve the distributed training as described. Make sure all necessary computations and gradient optimizations occur across the two nodes.","solution":"import torch import torch.distributed.autograd as dist_autograd import torch.distributed.rpc as rpc import torch.multiprocessing as mp from torch import nn, optim from torch.distributed.optim import DistributedOptimizer # Define a simple neural network layer class SimpleLayer(nn.Module): def __init__(self): super(SimpleLayer, self).__init__() self.linear = nn.Linear(3, 3) def forward(self, x): return self.linear(x) def run_worker(rank, world_size): # Initialize RPC rpc.init_rpc(f\\"worker{rank}\\", rank=rank, world_size=world_size) if rank == 0: # Worker 0 has the first layer of the model model_layer1 = SimpleLayer() target_rank = 1 # Dummy input tensor input_tensor = torch.randn(3) # Remote reference to the model on worker 1 rpc_sync = rpc.rpc_sync(f\\"worker{target_rank}\\", torch.jit.script, args=(SimpleLayer,)) model_layer2 = rpc_sync() with dist_autograd.context() as context_id: # Forward pass output = model_layer1(input_tensor) output = rpc.rpc_sync(f\\"worker{target_rank}\\", torch.ops.aten.relu, args=(model_layer2(output),)) # Assume a simple loss is calculated (mean squared error for example) target = torch.randn(3) loss = nn.MSELoss()(output, target) # Backward pass dist_autograd.backward(context_id, [loss]) # Distributed optimizer dist_optim = DistributedOptimizer( optim.SGD, params=[model_layer1.parameters(), model_layer2.parameters()], lr=0.1 ) # Step the optimizer dist_optim.step() # Print the gradients for name, param in model_layer1.named_parameters(): print(f\\"Gradient for {name} on worker0:n{param.grad}\\") elif rank == 1: # Worker 1 has the second layer of the model model_layer2 = SimpleLayer() # Register the model with RPC framework to allow remote references rpc.export_servicer(\\"model_layer2\\", model_layer2) # Clean up rpc.shutdown() if __name__ == \\"__main__\\": world_size = 2 mp.spawn(run_worker, args=(world_size,), nprocs=world_size)"},{"question":"**Question: Implement a Custom Sequence Type in Python** In this question, you will create a custom sequence type in Python. This type will have to support elements\' addition, retrieval, and iteration, simulating some behaviors of Python\'s built-in list type. You will need to: 1. Define a new class `CustomSequence` that behaves like a sequence. 2. Implement the following methods: - `__init__(self, initial_data)`: Initializes the sequence with the given initial data (list). - `__getitem__(self, index)`: Retrieves an item by its index. - `__setitem__(self, index, value)`: Sets the item at the specified index to a new value. - `__len__(self)`: Returns the number of items in the sequence. - `__iter__(self)`: Returns an iterator for the sequence. - `__contains__(self, item)`: Checks if an item is in the sequence. - `append(self, item)`: Adds a new item to the end of the sequence. 3. Properly manage and allocate memory for the internal list used to store the sequence data. 4. Ensure the sequence object properly supports cyclic garbage collection. # Input and Output Formats - The class should be initialized with a list of integers. Example: `CustomSequence([1, 2, 3])` - The `__getitem__` method should support both positive and negative indices. - The sequence object should be correctly iterable using a for-loop. - The `append` method should add elements to the end of the sequence. # Example Usage ```python seq = CustomSequence([1, 2, 3]) print(len(seq)) # Output: 3 print(seq[0]) # Output: 1 print(seq[-1]) # Output: 3 seq.append(4) print(len(seq)) # Output: 4 print(list(seq)) # Output: [1, 2, 3, 4] print(2 in seq) # Output: True print(5 in seq) # Output: False for item in seq: print(item) # Output: # 1 # 2 # 3 # 4 ``` # Constraints - The sequence must only contain integers. - All operations should be optimized for efficiency. - Extra attention should be given to memory management and avoiding memory leaks. - The object should work seamlessly with Python\'s garbage collector. You may need to reference Python\'s documentation on object types and structures to complete this task.","solution":"class CustomSequence: def __init__(self, initial_data): Initializes the sequence with the given initial list of data. self._data = list(initial_data) def __getitem__(self, index): Retrieves an item by its index, supporting both positive and negative indices. return self._data[index] def __setitem__(self, index, value): Sets the item at the specified index to a new value. self._data[index] = value def __len__(self): Returns the number of items in the sequence. return len(self._data) def __iter__(self): Returns an iterator for the sequence. return iter(self._data) def __contains__(self, item): Checks if an item is in the sequence. return item in self._data def append(self, item): Adds a new item to the end of the sequence. self._data.append(item)"},{"question":"# Advanced Coding Assessment: Implementing a Custom Autograd Function in TorchScript **Objective**: Assess your understanding of TorchScript and your ability to implement custom autograd functions within this framework. **Problem Statement**: Implement a custom TorchScript-compatible autograd function for a simple neural network. You are required to define a class in TorchScript that includes forward and backward methods. **Requirements**: 1. Define a TorchScript class `MyReLU` which mimics the behavior of the ReLU activation function. 2. Implement a `forward` method that applies the ReLU operation. 3. Implement a `backward` method that computes the gradient of the ReLU function with respect to its input. **Constraints**: - You must use type annotations as specified in the documentation. - The class should be defined using the `@torch.jit.script` decorator. - Ensure the backward method correctly handles the gradients and adheres to TorchScript type constraints. **Input and Output**: - `forward` method takes a single input tensor of type `torch.Tensor` and returns a tensor of the same shape. - `backward` method takes two parameters: `grad_output` (a tensor representing the gradient of the loss w.r.t the output) and `input` (the original input tensor) and returns the gradient of the loss w.r.t the input tensor. **Performance Requirements**: - The solution must be efficient and correctly handle the autograd mechanics in TorchScript. - Avoid unnecessary computations and ensure the solution is optimized for performance. **Example**: ```python import torch from torch import Tensor from typing import List, Tuple @torch.jit.script class MyReLU: def __init__(self): pass def forward(self, input: Tensor) -> Tensor: # ReLU implementation return torch.max(input, torch.tensor(0.0)) def backward(self, grad_output: Tensor, input: Tensor) -> Tensor: # Gradient computation for ReLU grad_input = grad_output.clone() grad_input[input <= 0] = 0 return grad_input # Test the implementation input_tensor = torch.tensor([[-1.0, 0.0, 1.0], [2.0, -3.0, 4.0]], requires_grad=True) my_relu = MyReLU() # Forward pass output = my_relu.forward(input_tensor) print(f\'Forward Output: {output}\') # Compute gradients output.backward(torch.ones_like(output)) grad_input = my_relu.backward(torch.ones_like(output), input_tensor) print(f\'Backward Output (Gradient): {grad_input}\') ``` **Note**: This problem is designed to test your deeper understanding of TorchScript, including class definitions, type annotations, and custom autograd functions. Ensure your implementation is robust and adheres to the constraints mentioned above.","solution":"import torch from torch import Tensor @torch.jit.script class MyReLU: def __init__(self): pass def forward(self, input: Tensor) -> Tensor: # ReLU implementation return torch.max(input, torch.tensor(0.0)) def backward(self, grad_output: Tensor, input: Tensor) -> Tensor: # Gradient computation for ReLU grad_input = grad_output.clone() grad_input[input <= 0] = 0 return grad_input"},{"question":"Seaborn Plot Customization Assessment **Objective:** In this exercise, you will demonstrate your understanding of the seaborn `set_context` function, along with its `font_scale` and `rc` parameters. You will create a seaborn plot with specific customization requirements. **Problem Statement:** Given a dataset and specific customization requirements for a seaborn line plot, write a function `customize_seaborn_plot` that meets the following conditions: 1. Set the overall context to \\"notebook\\". 2. Scale the font elements by a factor of 1.5. 3. Override the default line width to be 2.5. 4. Plot the given data using a line plot. **Input Format:** - `x_vals`: A list of numeric values representing the x-axis data. - `y_vals`: A list of numeric values representing the y-axis data. **Output Format:** - The function should display a seaborn line plot according to the specified customization requirements. **Function Signature:** ```python def customize_seaborn_plot(x_vals: list, y_vals: list) -> None: pass ``` **Examples:** ```python # Example 1: x_vals = [0, 1, 2, 3, 4] y_vals = [1, 3, 2, 5, 3] customize_seaborn_plot(x_vals, y_vals) # Expected Output: # A line plot with the x-axis ranging from 0 to 4 and the y-axis ranging from 1 to 5, # with the context set to \\"notebook\\", font scaled by 1.5, and line width of 2.5. # Example 2: x_vals = [0, 10, 20] y_vals = [5, 15, 10] customize_seaborn_plot(x_vals, y_vals) # Expected Output: # A line plot with the x-axis ranging from 0 to 20 and the y-axis ranging from 5 to 15, # with the context set to \\"notebook\\", font scaled by 1.5, and line width of 2.5. ``` **Constraints:** - The lengths of `x_vals` and `y_vals` must be the same. - The lists `x_vals` and `y_vals` will contain a minimum of 2 elements and a maximum of 100 elements. - Numeric values in `x_vals` and `y_vals` will be between -1000 and 1000. **Notes:** - Ensure that your plot is clearly visible with the specified customizations. - Use the documentation examples to guide your implementation.","solution":"import seaborn as sns import matplotlib.pyplot as plt def customize_seaborn_plot(x_vals: list, y_vals: list) -> None: Customizes the seaborn line plot with specific requirements: - Context set to \\"notebook\\" - Font scaled by 1.5 - Line width set to 2.5 Args: x_vals: list of numeric values for x-axis. y_vals: list of numeric values for y-axis. # Setting seaborn context with the specified parameters sns.set_context(\\"notebook\\", font_scale=1.5, rc={\\"lines.linewidth\\": 2.5}) # Creating the line plot plt.figure(figsize=(10, 6)) sns.lineplot(x=x_vals, y=y_vals) # Display the plot plt.show()"},{"question":"Objective: Create a complex visualization using Seaborn\'s `relplot` function. The question will assess your ability to utilize semantic mappings and customize various aspects of the plot. Problem Statement: You are provided with the \\"tips\\" dataset, which contains information about restaurant bills, tips, and additional details such as the day of the week, time of day, and the table size. Your task is to create a visualization that highlights how tips as a percentage of the total bill vary by day and time, with further distinction based on the size of the table. Write a Python function `create_custom_relplot` that performs the following: 1. Loads the \\"tips\\" dataset using Seaborn. 2. Creates a new column `tip_percentage`, calculated as `(tip / total_bill) * 100`. 3. Generates a `relplot` with: - `x` axis representing `total_bill`. - `y` axis representing `tip_percentage`. - Different colors (`hue`) representing `day`. - Different styles (`style`) representing `time` (\'Lunch\' or \'Dinner\'). - Different sizes for points (`size`) representing `size` of the table. - Separate plots in columns for each day of the week using `col`. - Wrapping columns to form a grid with 2 columns using `col_wrap`. Your function should: - Customize the plot to have a height of 5 and an aspect ratio of 1. - Set appropriate axis labels and plot titles. - Adjust the legend for better readability. Function Signature: ```python def create_custom_relplot(): pass ``` Expected Output: The function should create and display the required relplot. This function does not need to return any value. Constraints: - Use the Seaborn library to create the plots. - Follow best practices for data visualization to ensure the plot is informative and easy to interpret. Example Usage: ```python create_custom_relplot() ``` This will produce a detailed visualization with subplots for each day, showing variations in tip percentage based on total bill, time of day, and table size.","solution":"import seaborn as sns import matplotlib.pyplot as plt def create_custom_relplot(): # Load the tips dataset from Seaborn tips = sns.load_dataset(\\"tips\\") # Create a new column \'tip_percentage\' tips[\'tip_percentage\'] = (tips[\'tip\'] / tips[\'total_bill\']) * 100 # Create a relplot g = sns.relplot( data=tips, x=\'total_bill\', y=\'tip_percentage\', hue=\'day\', style=\'time\', size=\'size\', col=\'day\', col_wrap=2, height=5, aspect=1 ) # Customize axis labels and titles g.set_axis_labels(\\"Total Bill ()\\", \\"Tip Percentage (%)\\") g.set_titles(\\"{col_name}\\") # Adjust legend for better readability g.add_legend(title=\\"Legend\\") plt.show()"},{"question":"# PyTorch Storage Manipulation and Tensor View Creation Objective: In this exercise, you need to demonstrate your proficiency in manipulating tensor storages and creating tensor views in PyTorch. You will create a specific set of tensors and manipulate their underlying storage to understand their relationship and operations. # Problem Statement: 1. **Tensor and Storage Creation:** - Create a tensor `t` with the values `[1.0, 2.0, 3.0]` using `torch.ones` and multiplication. - Obtain the underlying untyped storage of the tensor `t` named `storage_t`. 2. **Storage Manipulation:** - Clone the storage of tensor `t` to create a new storage `storage_clone`. - Fill the cloned storage (`storage_clone`) with zeros. 3. **Create a New Tensor from Cloned Storage:** - Using the `storage_clone`, create a new tensor `new_tensor` that has the same shape and stride as `t`. - Ensure that this new tensor uses the modified storage you just manipulated. 4. **Validation of Sharing Storage:** - Validate and print whether `new_tensor` and `t` share the same storage or not by comparing their `data_ptr`. - Print the values of both `t` and `new_tensor`. # Expectations: Implement the following function following the steps detailed above: ```python import torch def tensor_storage_manipulation(): # Step 1: Create the initial tensor `t` and get its untyped storage t = torch.ones(3) * torch.tensor([1.0, 2.0, 3.0]) storage_t = t.untyped_storage() # Step 2: Clone the storage and fill it with zeros storage_clone = storage_t.clone() storage_clone.fill_(0) # Step 3: Create a new tensor using the modified storage new_tensor = t.new_empty((3,)).set_(storage_clone, storage_offset=t.storage_offset(), stride=t.stride()) # Step 4: Comparing storages and printing values sharing_storage = t.storage().data_ptr() == new_tensor.storage().data_ptr() print(f\\"Do `t` and `new_tensor` share the same storage?: {sharing_storage}\\") print(f\\"Values in `t`: {t}\\") print(f\\"Values in `new_tensor`: {new_tensor}\\") # Test the function tensor_storage_manipulation() ``` Constraints: - You should not use any high-level PyTorch functions for copying or filling tensors directly. - Make sure to manipulate the tensor storage directly as specified. - Validate your output and ensure correctness by checking the values and storage sharing. # Example Output: ``` Do `t` and `new_tensor` share the same storage?: False Values in `t`: tensor([1., 2., 3.]) Values in `new_tensor`: tensor([0., 0., 0.]) ``` This exercise aims to deepen your understanding of tensor storage, how tensors are structured in memory, the relationship between tensors and their underlying storage, and how to manipulate them at a lower level.","solution":"import torch def tensor_storage_manipulation(): # Step 1: Create the initial tensor `t` and get its untyped storage t = torch.ones(3) * torch.tensor([1.0, 2.0, 3.0]) storage_t = t.untyped_storage() # Step 2: Clone the storage and fill it with zeros storage_clone = storage_t.clone() storage_clone.fill_(0) # Step 3: Create a new tensor using the modified storage new_tensor = torch.empty(3).set_(storage_clone, 0, t.size()) # Step 4: Comparing storages and printing values sharing_storage = t.storage().data_ptr() == new_tensor.storage().data_ptr() return { \'sharing_storage\': sharing_storage, \'t\': t, \'new_tensor\': new_tensor } # If you want to run and print the output in an interactive or main environment: if __name__ == \\"__main__\\": results = tensor_storage_manipulation() print(f\\"Do `t` and `new_tensor` share the same storage?: {results[\'sharing_storage\']}\\") print(f\\"Values in `t`: {results[\'t\']}\\") print(f\\"Values in `new_tensor`: {results[\'new_tensor\']}\\")"},{"question":"**Question: Analyzing and Visualizing Climate Data with Seaborn** You are given a dataset containing daily records of sea ice extent with two columns: `Date` and `Extent`. You need to analyze this dataset using seaborn\'s object-oriented interface and generate a complex visualization showcasing the trends and variations in the sea ice extent over the years. Your final plot should provide a comprehensive visualization with proper customizations. # Requirements: 1. Load the dataset using seaborn\'s `load_dataset` function. 2. Extract the day of the year and the year from the `Date` column. 3. Create a plot that: - Shows the sea ice extent over the days of the year. - Uses different colors to distinguish between different years. - Facets the data by decades. - Customizes the appearance with at least two different line widths. - Sets an appropriate color scale. - Includes a title for each facet corresponding to the respective decade. 4. Your plot should maintain performance by optimizing the number of lines drawn. # Constraints: - You must use the seaborn `objects` interface (`so.Plot`, `so.Lines`, etc.) to construct your plot. - Your solution should be well-documented and include comments explaining the key steps. - The `Date` column in the dataset is of datetime type. - Handle any missing or null values appropriately. # Input: - The dataset with columns `Date` (in datetime format) and `Extent`. # Output: - A seaborn plot object visualizing the sea ice extent with the described customizations. # Example: ```python import seaborn.objects as so from seaborn import load_dataset # Load the dataset seaice = load_dataset(\\"seaice\\") # Extract the day of year and year seaice[\'DayOfYear\'] = seaice[\'Date\'].dt.day_of_year seaice[\'Year\'] = seaice[\'Date\'].dt.year # Create and customize the plot plot = ( so.Plot(seaice, x=\'DayOfYear\', y=\'Extent\', color=\'Year\') .facet(seaice[\'Date\'].dt.year.round(-1)) .add(so.Lines(linewidth=0.5, color=\\"#bbca\\"), col=None) .add(so.Lines(linewidth=1)) .scale(color=\\"ch:rot=-.2,light=.7\\") .layout(size=(8, 4)) .label(title=\\"{}s\\".format) ) # Display the plot plot.show() ``` Ensure your code is correct, clear, and well-documented. This question assesses your understanding of seaborn\'s object-oriented plotting capabilities and your ability to create complex, informative visualizations.","solution":"import seaborn as sns import seaborn.objects as so import pandas as pd import matplotlib.pyplot as plt def plot_seaice_extent(): Generate and display a seaborn plot showcasing the trends and variations in sea ice extent over the years, faceted by decades. # Load the dataset seaice = sns.load_dataset(\\"seaice\\", cache=True) # Extract the day of the year and the year from the \'Date\' column seaice[\'Date\'] = pd.to_datetime(seaice[\'Date\']) seaice[\'DayOfYear\'] = seaice[\'Date\'].dt.day_of_year seaice[\'Year\'] = seaice[\'Date\'].dt.year # Create the plot plot = ( so.Plot(seaice, x=\'DayOfYear\', y=\'Extent\') .facet(\'Year\', wrap=10) # Facet by decade .add(so.Lines(linewidth=0.5), color=\'Year\') # Add lines with varying line widths .scale(color=\\"viridis\\") # Set color scale .layout(size=(10, 6)) .label(title=lambda x: f\\"{int(x)}s\\") # Title each facet ) # Show the plot plot.show() # Ensure the script runs if it is the main module if __name__ == \\"__main__\\": plot_seaice_extent()"},{"question":"**Problem: Analyze and Filter Mixed Data Types** You are given a list of mixed data types containing numeric objects (integers, floating-point numbers, complex numbers), sequence objects (strings, lists, bytes), and container objects (dictionaries, sets). Your task is to implement a function `analyze_and_filter_data(data)` that processes this list and returns a dictionary containing the following keys and their corresponding filtered values: 1. `\\"integers\\"`: A list of all integers in the given data. 2. `\\"floats\\"`: A list of all floating-point numbers in the given data. 3. `\\"complex_numbers\\"`: A list of all complex numbers in the given data. 4. `\\"strings\\"`: A list of all strings in the given data. 5. `\\"lists\\"`: A list of all lists in the given data. 6. `\\"dictionaries\\"`: A list of all dictionaries in the given data. 7. `\\"sets\\"`: A list of all sets in the given data. # Function Signature ```python def analyze_and_filter_data(data: list) -> dict: pass ``` # Input - `data`: A list `data` containing mixed data types (`list`) with a length between 1 and 100. Each element can be of type: integer, float, complex, string, list, dictionary, set, bytes. # Output - A dictionary containing the keys `\\"integers\\"`, `\\"floats\\"`, `\\"complex_numbers\\"`, `\\"strings\\"`, `\\"lists\\"`, `\\"dictionaries\\"`, and `\\"sets\\"` with their corresponding filtered values. # Example ```python data = [1, 2.2, \\"hello\\", [1, 2, 3], {1: \\"a\\"}, {1, 2, 3}, 5 + 3j, 4.5, \\"world\\", {\\"key\\": \\"value\\"}] result = analyze_and_filter_data(data) ``` The returned dictionary `result` should be: ```python { \\"integers\\": [1], \\"floats\\": [2.2, 4.5], \\"complex_numbers\\": [(5+3j)], \\"strings\\": [\\"hello\\", \\"world\\"], \\"lists\\": [[1, 2, 3]], \\"dictionaries\\": [{1: \\"a\\"}, {\\"key\\": \\"value\\"}], \\"sets\\": [{1, 2, 3}] } ``` # Constraints - You must correctly identify and filter each specific data type without using the `isinstance()` function. - The function should perform efficiently for the given input size. # Notes - Make sure to handle empty lists appropriately in your output dictionary if no elements of a particular type are found. - Ensure your function has robust error handling for unexpected types that do not belong to the mentioned categories.","solution":"def analyze_and_filter_data(data): Processes the input list and returns a dictionary classifying elements by their type. result = { \\"integers\\": [], \\"floats\\": [], \\"complex_numbers\\": [], \\"strings\\": [], \\"lists\\": [], \\"dictionaries\\": [], \\"sets\\": [] } for element in data: if type(element) == int: result[\\"integers\\"].append(element) elif type(element) == float: result[\\"floats\\"].append(element) elif type(element) == complex: result[\\"complex_numbers\\"].append(element) elif type(element) == str: result[\\"strings\\"].append(element) elif type(element) == list: result[\\"lists\\"].append(element) elif type(element) == dict: result[\\"dictionaries\\"].append(element) elif type(element) == set: result[\\"sets\\"].append(element) return result"},{"question":"Coding Assessment Question # Objective Create a function to visualize the comparison of different error bar methods in a single plot using seaborn. # Task Description Write a function `compare_errorbars(data, column, estimator=\'mean\', methods=None)` that generates a comparative plot for different error bar methods specified in `methods`. The plot should display the summary statistic and error bars for each method on the same axis. # Function Signature ```python def compare_errorbars(data: pd.DataFrame, column: str, estimator: str = \'mean\', methods: list = None) -> None: pass ``` # Input - `data` (pd.DataFrame): A pandas DataFrame containing the dataset. - `column` (str): The column name in the DataFrame for which the summary statistics and error bars will be calculated. - `estimator` (str, optional): The statistic to estimate, default is `\'mean\'`. Other options are `\'median\'` etc. - `methods` (list, optional): A list of error bar methods to compare. Default is `[\'sd\', \'se\', (\'pi\', 95), (\'ci\', 95)]`. # Output - The function should output a plot with the comparison of different error bar methods for the specified column. # Example ```python import pandas as pd import seaborn as sns import matplotlib.pyplot as plt # Example data data = pd.DataFrame({ \'value\': np.random.randn(100) }) compare_errorbars(data, \'value\') ``` # Constraints 1. If `methods` is `None`, it should default to `[\'sd\', \'se\', (\'pi\', 95), (\'ci\', 95)]`. 2. Use seaborn\'s `pointplot` or any suitable seaborn function to visualize the error bars. 3. Ensure the plot is clear and labels each error bar method distinctly. # Guidelines - Utilize seaborn’s ability to handle different types of error bars. - Consider the aesthetics and clarity of the plot. - You can add any custom formatting or additional information that improves readability. **Note:** Install the required libraries if they are not already present: ```bash pip install pandas seaborn matplotlib ``` # Hints - Use `sns.pointplot` for creating points and error bars. - Refer to the provided seaborn documentation examples to understand the usage of `errorbar` parameter.","solution":"import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import numpy as np def compare_errorbars(data, column, estimator=\'mean\', methods=None): Generates a comparative plot for different error bar methods. Parameters: - data (pd.DataFrame): A pandas DataFrame containing the dataset. - column (str): The column name in the DataFrame for which the summary statistics and error bars will be calculated. - estimator (str, optional): The statistic to estimate, default is \'mean\'. Other options are \'median\', etc. - methods (list, optional): A list of error bar methods to compare. Default is [\'sd\', \'se\', (\'pi\', 95), (\'ci\', 95)]. Output: - A plot displaying the summary statistic and error bars for each method. if methods is None: methods = [\'sd\', \'se\', (\'pi\', 95), (\'ci\', 95)] plt.figure(figsize=(10, 6)) for method in methods: sns.pointplot(x=np.zeros(len(data)), y=data[column], estimator=estimator, errorbar=method, label=str(method), join=False) plt.legend(title=\\"Error Bar Method\\") plt.title(f\'Comparison of {estimator} with Different Error Bar Methods\') plt.xlabel(\'Sample\') plt.ylabel(column) plt.grid(True) plt.show()"},{"question":"Advanced Text Processing and File Management Objective: Demonstrate your proficiency in Python text processing, file management, and data serialization. Task: You need to implement a function `process_text_files(input_dir: str, output_file: str) -> None` that performs the following operations: 1. **Read and Parse Text Files:** - Traverse the directory specified by `input_dir`. - Identify all `.txt` files. - Read each file, process its contents by removing all the punctuation (using the `string` module), and convert all characters to lowercase. - Use regular expressions (`re` module) to extract all unique words from the processed text of each file. 2. **Count Word Frequency:** - For each file, compute the frequency of each unique word. - Store these frequencies in a dictionary where keys are words and values are their counts. 3. **Serialize and Save Data:** - Serialize the word frequency data into a JSON object using the `json` module. - Save this JSON to the specified `output_file`. Function Signature: ```python def process_text_files(input_dir: str, output_file: str) -> None: pass ``` Input: - `input_dir (str)`: Path to the directory containing `.txt` files to be processed. - `output_file (str)`: Path to the output `.json` file where the word frequency data will be saved. Constraints: - Assume there are no subdirectories within `input_dir`. - Handle potential file I/O errors gracefully. - Ensure the JSON object is formatted in a human-readable way (use indentation). Example: If `input_dir` contains two files: - `file1.txt` with contents: \\"Hello world! Hello!\\" - `file2.txt` with contents: \\"Python programming. Python!\\" The `output_file` should have contents similar to: ```json { \\"file1.txt\\": { \\"hello\\": 2, \\"world\\": 1 }, \\"file2.txt\\": { \\"python\\": 2, \\"programming\\": 1 } } ``` Constraints: - Do not use third-party libraries; rely only on the standard library. - Ensure the code is efficient and handles large files gracefully. Performance Requirement: - The function should complete execution within a reasonable time frame (e.g., under a minute) for directories containing up to 100 large text files.","solution":"import os import string import re import json def process_text_files(input_dir: str, output_file: str) -> None: word_frequencies = {} # Traverse directory for filename in os.listdir(input_dir): if filename.endswith(\\".txt\\"): file_path = os.path.join(input_dir, filename) try: with open(file_path, \'r\', encoding=\'utf-8\') as f: text = f.read() # Remove punctuation and make all characters lowercase text = text.translate(str.maketrans(\'\', \'\', string.punctuation)).lower() # Extract all unique words words = re.findall(r\'bw+b\', text) # Count frequency of each unique word freq = {} for word in words: if word in freq: freq[word] += 1 else: freq[word] = 1 word_frequencies[filename] = freq except IOError: print(f\\"Error reading file {file_path}\\") # Save to output_file in JSON format try: with open(output_file, \'w\', encoding=\'utf-8\') as f: json.dump(word_frequencies, f, indent=4) except IOError: print(f\\"Error writing to file {output_file}\\")"},{"question":"# Covariance Estimation Challenge You are given a dataset containing multivariate independent observations. Your task is to implement and compare different covariance estimation methods using the `sklearn.covariance` module. Specifically, you should: 1. Compute the empirical covariance matrix of the dataset using the `EmpiricalCovariance` class. 2. Apply Ledoit-Wolf shrinkage to estimate the covariance matrix using the `LedoitWolf` class. 3. Estimate a robust covariance matrix using the `MinCovDet` class. 4. Compare the estimated covariance matrices by calculating and printing the Frobenius norm of the difference between each pair of matrices. # Input: - A 2D NumPy array `X` of shape (n_samples, n_features) containing the dataset. # Output: - Print the Frobenius norms of the differences between each pair of covariance matrices as described above. # Example: ```python import numpy as np from sklearn.covariance import EmpiricalCovariance, LedoitWolf, MinCovDet # Sample Input X = np.array([[0.5, 0.2, 1.1], [1.3, 0.7, 1.8], [0.8, 0.4, 1.5], [0.5, 0.3, 0.8], [1.0, 0.6, 1.3]]) def covariance_comparison(X): # Empirical Covariance emp_cov = EmpiricalCovariance().fit(X).covariance_ # Ledoit-Wolf Shrinkage lw_cov = LedoitWolf().fit(X).covariance_ # Robust Covariance mcd_cov = MinCovDet().fit(X).covariance_ # Compute Frobenius norms norm_emp_lw = np.linalg.norm(emp_cov - lw_cov, ord=\'fro\') norm_emp_mcd = np.linalg.norm(emp_cov - mcd_cov, ord=\'fro\') norm_lw_mcd = np.linalg.norm(lw_cov - mcd_cov, ord=\'fro\') print(f\\"Frobenius norm between empirical and Ledoit-Wolf covariance: {norm_emp_lw}\\") print(f\\"Frobenius norm between empirical and robust covariance: {norm_emp_mcd}\\") print(f\\"Frobenius norm between Ledoit-Wolf and robust covariance: {norm_lw_mcd}\\") # Call the function with sample input to see the expected output covariance_comparison(X) ``` # Constraints: - You may assume the dataset `X` has no missing values. - The number of samples `n_samples` is greater than the number of features `n_features`. # Performance: - Aim for a solution that efficiently handles the required computations for datasets with up to 1000 samples and 50 features.","solution":"import numpy as np from sklearn.covariance import EmpiricalCovariance, LedoitWolf, MinCovDet def covariance_comparison(X): # Empirical Covariance emp_cov = EmpiricalCovariance().fit(X).covariance_ # Ledoit-Wolf Shrinkage lw_cov = LedoitWolf().fit(X).covariance_ # Robust Covariance mcd_cov = MinCovDet().fit(X).covariance_ # Compute Frobenius norms norm_emp_lw = np.linalg.norm(emp_cov - lw_cov, ord=\'fro\') norm_emp_mcd = np.linalg.norm(emp_cov - mcd_cov, ord=\'fro\') norm_lw_mcd = np.linalg.norm(lw_cov - mcd_cov, ord=\'fro\') return { \\"norm_emp_lw\\": norm_emp_lw, \\"norm_emp_mcd\\": norm_emp_mcd, \\"norm_lw_mcd\\": norm_lw_mcd }"},{"question":"**Problem Statement:** You are working on an internationalization (I18N) initiative for a Python application that displays messages in different languages based on user preferences. Your task is to implement a Python function that changes the language of the application on the fly and retrieves appropriate translated messages for given inputs. Additionally, ensure that strings are marked for translation in advance. **Requirements:** 1. Implement a class `Translator` that handles different languages using the `gettext` module. 2. The `Translator` class should include methods to switch languages, retrieve singular/plural translations, and handle message contexts. 3. Ensure the method for changing languages works correctly and the translations are loaded from given `.mo` files. **Function Specifications:** - **Class Name:** `Translator` - **Attributes:** - `domain` (`str`): The translation domain. - `localedir` (`str`): The directory containing the `.mo` files for translations. - `current_lang` (`str`): The current language being used for translations. - `translator` (`GNUTranslations`): The current translation instance. - **Methods:** - `__init__(self, domain: str, localedir: str) -> None`: Constructor to initialize the translation domain and locale directory. - `switch_language(self, language: str) -> None`: Method to switch the active language and update the translator instance. - `gettext(self, message: str) -> str`: Method to retrieve the translated message for the current language. - `ngettext(self, singular: str, plural: str, n: int) -> str`: Method to handle plural translations. - `pgettext(self, context: str, message: str) -> str`: Method to retrieve translated message with context. - `npgettext(self, context: str, singular: str, plural: str, n: int) -> str`: Method to handle plural translations with context. **Input Format:** ```python # Example instantiation translator = Translator(domain=\'myapp\', localedir=\'/path/to/my/language/directory\') # Example usage translator.switch_language(\'fr\') translated_message = translator.gettext(\'Hello, World!\') ``` **Constraints:** - The `.mo` files for the required translations should be available in the specified `localedir`. - The initial language for the `Translator` instance should default to English (\'en\'). **Output Format:** The methods should return the translated messages in the specified language. **Example:** ```python # Example Usage translator = Translator(\'myapp\', \'/path/to/my/language/directory\') translator.switch_language(\'es\') print(translator.gettext(\'Hello, World!\')) # Should print the message in Spanish ``` **Implementation:** ```python import gettext class Translator: def __init__(self, domain: str, localedir: str) -> None: self.domain = domain self.localedir = localedir self.current_lang = \'en\' self.translator = gettext.translation(domain, localedir, languages=[self.current_lang], fallback=True) def switch_language(self, language: str) -> None: self.current_lang = language self.translator = gettext.translation(self.domain, self.localedir, languages=[self.current_lang], fallback=True) self.translator.install() def gettext(self, message: str) -> str: return self.translator.gettext(message) def ngettext(self, singular: str, plural: str, n: int) -> str: return self.translator.ngettext(singular, plural, n) def pgettext(self, context: str, message: str) -> str: return self.translator.pgettext(context, message) def npgettext(self, context: str, singular: str, plural: str, n: int) -> str: return self.translator.npgettext(context, singular, plural, n) ``` **Notes:** - Ensure you have the appropriate `.mo` files in the specified directory. - Test the class thoroughly for different languages and scenarios.","solution":"import gettext class Translator: def __init__(self, domain: str, localedir: str) -> None: self.domain = domain self.localedir = localedir self.current_lang = \'en\' self.translator = gettext.translation(domain, localedir, languages=[self.current_lang], fallback=True) self.translator.install() def switch_language(self, language: str) -> None: self.current_lang = language self.translator = gettext.translation(self.domain, self.localedir, languages=[self.current_lang], fallback=True) self.translator.install() def gettext(self, message: str) -> str: return self.translator.gettext(message) def ngettext(self, singular: str, plural: str, n: int) -> str: return self.translator.ngettext(singular, plural, n) def pgettext(self, context: str, message: str) -> str: return self.translator.pgettext(context, message) def npgettext(self, context: str, singular: str, plural: str, n: int) -> str: return self.translator.npgettext(context, singular, plural, n)"},{"question":"# Semi-Supervised Learning with Scikit-Learn Objective: Implement and evaluate a semi-supervised learning algorithm using Scikit-Learn\'s `SelfTrainingClassifier` and `LabelPropagation` classes. Background: You are provided with a partially labeled dataset. Your task is to leverage both the labeled and unlabeled data to improve classification performance using semi-supervised learning techniques. Dataset (Assume the data is provided): ```python # Features (X_train) and labels (y_train) with some unlabel data represented by -1 in y_train X_train = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11]] y_train = [0, 1, -1, 1, -1, 0, 1, -1, 0, 1] ``` Task: 1. **Self-Training Classifier Implementation:** - Implement the `SelfTrainingClassifier` using a Gaussian Naive Bayes classifier (`sklearn.naive_bayes.GaussianNB`). - Use a `threshold` of `0.8` for selecting high-confidence predictions to add to the labeled dataset. - Limit the number of iterations (`max_iter`) to 10. 2. **Label Propagation Implementation:** - Implement the `LabelPropagation` algorithm. - Use the RBF kernel with a `gamma` parameter set to `20`. 3. **Performance Evaluation:** - Implement a function to compare the performance of both models using the labeled and unlabeled data. - Use the accuracy metric for evaluation. - Print the accuracy score for both models. Expected Input: - `X_train`: List of feature vectors (list of lists). - `y_train`: List of labels (list with some entries as -1 to denote unlabeled data). Expected Output: - `accuracy_score_self_training`: Accuracy score of the Self-Training Classifier. - `accuracy_score_label_propagation`: Accuracy score of the Label Propagation model. Constraints: - Use Scikit-Learn\'s built-in classes for the implementations. - You can assume that the dataset is given as shown, and only the provided features and labels need to be used. Sample Code: ```python from sklearn.semi_supervised import SelfTrainingClassifier, LabelPropagation from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score from sklearn.model_selection import train_test_split import numpy as np # Provided dataset X_train = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11]] y_train = [0, 1, -1, 1, -1, 0, 1, -1, 0, 1] # Self-Training Classifier implementation def self_training_classifier(X_train, y_train): base_classifier = GaussianNB() self_training_model = SelfTrainingClassifier(base_classifier, threshold=0.8, max_iter=10) self_training_model.fit(X_train, y_train) return self_training_model # Label Propagation implementation def label_propagation_classifier(X_train, y_train): label_prop_model = LabelPropagation(kernel=\'rbf\', gamma=20) label_prop_model.fit(X_train, y_train) return label_prop_model # Performance evaluation def evaluate_models(X_train, y_train): # Split the data into training and test sets X_train_part, X_test, y_train_part, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=42, stratify=y_train) # Replace -1 with real labels for test set only to evaluate accuracy properly y_test = [label if label != -1 else np.random.choice([0, 1]) for label in y_test] # Self-Training Classifier self_train_clf = self_training_classifier(X_train_part, y_train_part) y_pred_self_train = self_train_clf.predict(X_test) accuracy_score_self_train = accuracy_score(y_test, y_pred_self_train) # Label Propagation Classifier label_prop_clf = label_propagation_classifier(X_train_part, y_train_part) y_pred_label_prop = label_prop_clf.predict(X_test) accuracy_score_label_prop = accuracy_score(y_test, y_pred_label_prop) return accuracy_score_self_train, accuracy_score_label_prop # Obtaining scores accuracy_score_self_train, accuracy_score_label_prop = evaluate_models(X_train, y_train) print(\\"Self-Training Classifier Accuracy:\\", accuracy_score_self_train) print(\\"Label Propagation Classifier Accuracy:\\", accuracy_score_label_prop) ``` Note: - Ensure to stratify the splits to maintain the balanced distribution of labeled and unlabeled data in both training and test sets. - For simplicity, the evaluation assumes replacing -1 labels randomly in the test set. In practice, more refined approaches may be used.","solution":"from sklearn.semi_supervised import SelfTrainingClassifier, LabelPropagation from sklearn.naive_bayes import GaussianNB from sklearn.metrics import accuracy_score from sklearn.model_selection import train_test_split import numpy as np # Provided dataset X_train = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11]] y_train = [0, 1, -1, 1, -1, 0, 1, -1, 0, 1] # Self-Training Classifier implementation def self_training_classifier(X_train, y_train): base_classifier = GaussianNB() self_training_model = SelfTrainingClassifier(base_classifier, threshold=0.8, max_iter=10) self_training_model.fit(X_train, y_train) return self_training_model # Label Propagation implementation def label_propagation_classifier(X_train, y_train): label_prop_model = LabelPropagation(kernel=\'rbf\', gamma=20) label_prop_model.fit(X_train, y_train) return label_prop_model # Performance evaluation def evaluate_models(X_train, y_train): # Split the data into training and test sets X_train_part, X_test, y_train_part, y_test = train_test_split(X_train, y_train, test_size=0.4, random_state=42, stratify=[label if label != -1 else 0 for label in y_train]) # Replace -1 with real labels for test set only to evaluate accuracy properly y_test = np.array([label if label != -1 else np.random.choice([0, 1]) for label in y_test]) # Self-Training Classifier self_train_clf = self_training_classifier(X_train_part, y_train_part) y_pred_self_train = self_train_clf.predict(X_test) accuracy_score_self_train = accuracy_score(y_test, y_pred_self_train) # Label Propagation Classifier label_prop_clf = label_propagation_classifier(X_train_part, y_train_part) y_pred_label_prop = label_prop_clf.predict(X_test) accuracy_score_label_prop = accuracy_score(y_test, y_pred_label_prop) return accuracy_score_self_train, accuracy_score_label_prop # Obtaining scores accuracy_score_self_train, accuracy_score_label_prop = evaluate_models(X_train, y_train) # Print accuracy scores for both models print(\\"Self-Training Classifier Accuracy:\\", accuracy_score_self_train) print(\\"Label Propagation Classifier Accuracy:\\", accuracy_score_label_prop)"},{"question":"# Question: Advanced Seaborn Plotting with `stripplot` and `catplot` You are provided with the `tips` dataset, which contains information about restaurant bills, and you need to perform the following tasks to demonstrate your understanding of Seaborn and its plotting functionalities. 1. **Basic Strip Plot:** Create a strip plot to show the distribution of `total_bill`. Assign `total_bill` to the x-axis. 2. **Categorical Strip Plot:** Create a strip plot to compare the distribution of `total_bill` across different `days`. 3. **Hue Strip Plot:** Modify the strip plot from step 2 by adding another layer of information using the `sex` variable as the `hue` parameter. 4. **Customized Strip Plot:** Further customize the strip plot from step 3 by changing the marker style to `\\"D\\"`, the size to `20`, the line width to `1`, and the transparency (alpha) to `0.1`. 5. **Faceted Plot:** Create a faceted plot using `catplot` to compare `total_bill` based on `time` (Lunch/Dinner) across different `days`. Use `sex` as the `hue` parameter and create separate plots for each `day`. # Code Requirements: - You should use the Seaborn library for all plots. - Label all axes appropriately. - Add a title to each plot indicating what it represents. - Ensure each plot is correctly displayed in a Jupyter Notebook cell. # Expected Output: You should submit a single Jupyter Notebook file containing the code for all the above tasks. # Constraints: - You must use the `seaborn` library\'s `stripplot` and `catplot` functions. - The provided dataset `tips` must be used for all plots. # Performance Requirements: - Your code should be clean, well-commented, and each step should be followed by a markdown cell explaining what the step achieves. - Ensure the plots are displayed properly within the notebook without overlapping or missing visual elements. Here is the starting code for loading the dataset and setting the theme: ```python import seaborn as sns # Load the tips dataset tips = sns.load_dataset(\\"tips\\") # Set the theme sns.set_theme(style=\\"whitegrid\\") ``` Good luck!","solution":"import seaborn as sns import matplotlib.pyplot as plt # Load the tips dataset tips = sns.load_dataset(\\"tips\\") # Set the theme sns.set_theme(style=\\"whitegrid\\") def basic_strip_plot(): plt.figure(figsize=(10, 6)) sns.stripplot(x=tips[\\"total_bill\\"]) plt.xlabel(\\"Total Bill\\") plt.title(\\"Distribution of Total Bill\\") plt.show() def categorical_strip_plot(): plt.figure(figsize=(10, 6)) sns.stripplot(x=\\"day\\", y=\\"total_bill\\", data=tips) plt.xlabel(\\"Day\\") plt.ylabel(\\"Total Bill\\") plt.title(\\"Distribution of Total Bill across Days\\") plt.show() def hue_strip_plot(): plt.figure(figsize=(10, 6)) sns.stripplot(x=\\"day\\", y=\\"total_bill\\", hue=\\"sex\\", data=tips) plt.xlabel(\\"Day\\") plt.ylabel(\\"Total Bill\\") plt.title(\\"Distribution of Total Bill across Days by Sex\\") plt.show() def customized_strip_plot(): plt.figure(figsize=(10, 6)) sns.stripplot(x=\\"day\\", y=\\"total_bill\\", hue=\\"sex\\", data=tips, marker=\\"D\\", size=20, linewidth=1, alpha=0.1) plt.xlabel(\\"Day\\") plt.ylabel(\\"Total Bill\\") plt.title(\\"Customized Strip Plot: Distribution of Total Bill across Days by Sex\\") plt.show() def faceted_plot(): g = sns.catplot(x=\\"day\\", y=\\"total_bill\\", hue=\\"sex\\", col=\\"time\\", data=tips, kind=\\"strip\\", height=6, aspect=1) g.set_axis_labels(\\"Day\\", \\"Total Bill\\") g.set_titles(\\"Total Bill Distribution for {col_name} Time\\") g.fig.suptitle(\\"Faceted Plot of Total Bill by Time and Day\\", y=1.05) plt.show()"},{"question":"# PyTorch Core Aten IR Task **Objective:** Implement a function using the Core Aten IR to perform a specified tensor operation without using in-place operations or out-variants. **Task:** Write a function `custom_add` that performs element-wise addition of two tensors using Core Aten IR. Your function should adhere to the principles of Core Aten IR as explained in the provided documentation. Assume Core Aten IR functions work similarly to traditional PyTorch functions but without in-place modifications or out-variants. **Function Signature:** ```python import torch def custom_add(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor: Perform element-wise addition of two tensors using Core Aten IR principles. Args: - tensor1 (torch.Tensor): The first input tensor. - tensor2 (torch.Tensor): The second input tensor. Returns: - torch.Tensor: The result of adding tensor1 and tensor2 element-wise. Constraints: - `tensor1` and `tensor2` must have the same shape. # Your implementation here # Example usage tensor1 = torch.tensor([1, 2, 3]) tensor2 = torch.tensor([4, 5, 6]) result = custom_add(tensor1, tensor2) print(result) # Should output tensor([5, 7, 9]) ``` **Constraints:** - The tensors passed to `custom_add` will always have the same shape. - Do not use in-place operations (operations that modify the input tensors). - Do not use out-variant operations (where the result is stored in a pre-allocated output tensor). **Hint:** - Refer to the Core Aten IR concepts, which suggest avoiding in-place and out-variants while leveraging existing Aten operations.","solution":"import torch def custom_add(tensor1: torch.Tensor, tensor2: torch.Tensor) -> torch.Tensor: Perform element-wise addition of two tensors using Core Aten IR principles. Args: - tensor1 (torch.Tensor): The first input tensor. - tensor2 (torch.Tensor): The second input tensor. Returns: - torch.Tensor: The result of adding tensor1 and tensor2 element-wise. Constraints: - `tensor1` and `tensor2` must have the same shape. # Using standard element-wise addition with no in-place operations result = torch.add(tensor1, tensor2) return result"},{"question":"**Objective:** Design a function that uses the `subprocess` module to run a series of system commands and handle their input and output efficiently. You will also need to manage potential exceptions and timeouts. **Problem Statement:** Write a function `run_commands(commands: List[str], timeout: Optional[int] = None) -> Tuple[int, str, str]:` where: - `commands` is a list of strings, where each string is a command to run in the system shell. - `timeout` is an optional integer specifying the maximum total time (in seconds) to allow for all commands to complete. If not specified, no timeout is applied. The function should: 1. Run each command in the list `commands` sequentially in the system shell. 2. Capture the combined output of `stdout` and `stderr` for each command. 3. If any command fails (returns a non-zero exit status), raise a `subprocess.CalledProcessError` with the command\'s output and error messages combined. 4. If the total execution time exceeds the specified `timeout`, raise a `subprocess.TimeoutExpired` exception. Ensure the subprocesses are killed properly if the timeout is exceeded. 5. Return a tuple containing `(returncode, stdout, stderr)` for the last command executed, where: - `returncode` is the exit status of the last command. - `stdout` is the captured standard output of the last command. - `stderr` is the captured standard error of the last command. **Constraints:** - You must use the `subprocess.run()` function for executing the commands. - You must capture command outputs as combined `stdout` and `stderr` streams. - Ensure proper exception handling for `subprocess.CalledProcessError` and `subprocess.TimeoutExpired`. **Function Signature:** ```python from typing import List, Tuple, Optional import subprocess def run_commands(commands: List[str], timeout: Optional[int] = None) -> Tuple[int, str, str]: pass ``` **Example:** ```python # Successful command sequence commands = [\\"echo Hello, World!\\", \\"ls -l\\"] result = run_commands(commands) # Expected output: (0, \'total ...n-rwxr-xr-x ...\', \'\') # Command with error commands = [\\"echo Hello, World!\\", \\"ls non_existent_directory\\"] try: result = run_commands(commands) except subprocess.CalledProcessError as e: print(e.output) # Expected output: \\"ls: cannot access \'non_existent_directory\': No such file or directory\\" ``` Use the code structure below to implement your solution: ```python def run_commands(commands: List[str], timeout: Optional[int] = None) -> Tuple[int, str, str]: total_time = 0 for command in commands: try: result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=timeout) total_time += result.returncode if result.returncode != 0: raise subprocess.CalledProcessError(result.returncode, result.args, output=result.stdout + result.stderr) except subprocess.CalledProcessError as e: raise e except subprocess.TimeoutExpired as e: raise e return result.returncode, result.stdout, result.stderr ```","solution":"import subprocess from typing import List, Tuple, Optional def run_commands(commands: List[str], timeout: Optional[int] = None) -> Tuple[int, str, str]: total_time = 0 for command in commands: try: result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=timeout) total_time += result.returncode if result.returncode != 0: raise subprocess.CalledProcessError(result.returncode, result.args, output=result.stdout + result.stderr) except subprocess.CalledProcessError as e: raise e except subprocess.TimeoutExpired as e: raise e return result.returncode, result.stdout, result.stderr"},{"question":"**Objective:** Implement a function utilizing the `cgitb` module to handle exceptions in a Python script, with the ability to display the traceback in both HTML and plain text formats, and optionally log it to a file. **Problem Statement:** Write a function named `enhanced_exception_handler` which takes the following parameters: 1. `func`: a callable function that may raise an exception. 2. `args`: a tuple containing the positional arguments to be passed to `func`. 3. `kwargs`: a dictionary containing the keyword arguments to be passed to `func`. 4. `display`: an optional boolean parameter (default `True`). If set to `False`, suppress the traceback display. 5. `logdir`: an optional string parameter (default `None`). If provided, it specifies the directory where the traceback logs should be saved. 6. `context`: an optional integer parameter (default `5`). The number of lines of context to display around the current line of source code in the traceback. 7. `format`: an optional string parameter (default `\'html\'`). Specifies the format of the traceback output; either `\'html\'` or `\'text\'`. The function should: - Enable `cgitb` with the given parameters. - Execute the `func` with the provided `args` and `kwargs`. - If an exception occurs, handle it using `cgitb`. **Input:** - `func`: callable - `args`: tuple - `kwargs`: dict - `display`: bool, optional - `logdir`: str, optional - `context`: int, optional - `format`: str, optional **Output:** - Returns the result of the `func` if no exception occurs. - Raises the exception after handling it with `cgitb` if an exception occurs. **Constraints:** - You may assume `func` is a valid callable. - The `context` value should be a positive integer. - The `format` should be either `\'html\'` or `\'text\'`. **Example Usage:** ```python def example_function(a, b): return a / b # Usage 1: Normal execution result = enhanced_exception_handler(example_function, (10, 2)) print(result) # Output: 5.0 # Usage 2: Handling divide by zero exception try: enhanced_exception_handler(example_function, (10, 0), display=True, format=\'text\') except ZeroDivisionError as e: print(f\\"Caught exception: {e}\\") ``` Implement the `enhanced_exception_handler` function to demonstrate your understanding of the `cgitb` module and exception handling in Python.","solution":"import cgitb import os def enhanced_exception_handler(func, args=(), kwargs=None, display=True, logdir=None, context=5, format=\'html\'): Executes the given function with the provided arguments and handles exceptions using the cgitb module. Parameters: func (callable): The function to execute. args (tuple): The positional arguments to pass to the function. kwargs (dict): The keyword arguments to pass to the function. display (bool): Whether to display the traceback or not. Default is True. logdir (str): Directory to log the traceback. Default is None. context (int): The number of lines of context to display. Default is 5. format (str): The format of the traceback output (\'html\' or \'text\'). Default is \'html\'. Returns: The result of the function if no exception occurs. Raises: Exception: Re-raises any exception after handling it with cgitb. kwargs = kwargs or {} # Configure cgitb cgitb.enable(display=display, logdir=logdir, context=context, format=format) try: return func(*args, **kwargs) except Exception: # Handle exception and raise it again cgitb.handler() raise"},{"question":"**Coding Assessment Question** # Question You are required to implement a Python script that achieves the following tasks: 1. Read command-line arguments to determine an operation and its parameters. 2. Based on the operation specified, perform different tasks like mathematical calculations or string manipulations. 3. Redirect the output of the script to a log file if a specific flag is set. 4. Implement custom exception handling to log any error messages to a separate error log file, without terminating the script. 5. Track and display memory usage before and after the operation is performed. # Requirements - Implement the function `main()` which will coordinate the tasks. - Handle the following command-line arguments: - `operation`: Specifies the type of operation (`add`, `subtract`, `concat`, `uppercase`). - `params`: A list of parameters for the operation. - `--log`: An optional flag indicating that output should be redirected to a log file. - Provide meaningful error messages in case of invalid input or execution errors. # Detailed Instructions 1. **Command-Line Arguments**: - Use `sys.argv` to read command-line arguments. - The first argument should specify the operation (`add`, `subtract`, `concat`, `uppercase`). - The remaining arguments (`params`) are the parameters required for the operation. - If the `--log` flag is provided, redirect the output to a log file named `output.log`. 2. **Perform Operations**: - If the operation is `add`, sum the given numbers. - If the operation is `subtract`, return the result of subtracting the second number from the first. - If the operation is `concat`, concatenate the given strings. - If the operation is `uppercase`, convert the given string to uppercase. - Log the result of the operation to `output.log` if the `--log` flag is set. 3. **Exception Handling**: - Implement a custom exception hook using `sys.excepthook`. - Errors should be logged to a file named `error.log` without terminating the script. 4. **Memory Usage Tracking**: - Before performing the operation, log the allocated memory blocks using `sys.getallocatedblocks()`. - After performing the operation, log the allocated memory blocks again to observe memory usage changes. # Example Usage and Expected Output - Python script: `operations.py` ```python import sys import os def main(): # Your implementation here if __name__ == \\"__main__\\": main() ``` - Command-line: ```sh python operations.py add 4 5 6 --log ``` - Expected Log Output (`output.log`): ``` Result of add operation: 15 ``` - Expected Error Log (`error.log`) if invalid arguments: ``` Error occurred: Invalid number of arguments for operation \'add\' ``` # Constraints - Handle both integer and string inputs where applicable. - Ensure robust error handling and user feedback through log files.","solution":"import sys import os def add(params): try: numbers = list(map(int, params)) return sum(numbers) except ValueError: raise ValueError(\\"Invalid numbers provided for add operation\\") def subtract(params): try: if len(params) != 2: raise ValueError(\\"Exactly two numbers are required for subtract operation\\") num1, num2 = map(int, params) return num1 - num2 except ValueError: raise ValueError(\\"Invalid numbers provided for subtract operation\\") def concat(params): return \' \'.join(params) def uppercase(params): if len(params) != 1: raise ValueError(\\"Exactly one string is required for uppercase operation\\") return params[0].upper() def log_memory_usage(label): memory_usage = sys.getallocatedblocks() print(f\\"{label} memory usage: {memory_usage}\\") def main(): if len(sys.argv) < 3: print(\\"Usage: python operations.py operation params [--log]\\") return operation = sys.argv[1] params = sys.argv[2:-1] if \'--log\' in sys.argv else sys.argv[2:] operations = { \'add\': add, \'subtract\': subtract, \'concat\': concat, \'uppercase\': uppercase } if operation not in operations: print(f\\"Invalid operation \'{operation}\'\\") return output_log_path = \'output.log\' error_log_path = \'error.log\' log_output = \'--log\' in sys.argv # Custom exception handler def handle_exception(exc_type, exc_value, exc_traceback): with open(error_log_path, \'a\') as f: f.write(f\\"Error occurred: {exc_value}n\\") sys.excepthook = handle_exception try: log_memory_usage(\\"Before\\") result = operations[operation](params) log_memory_usage(\\"After\\") output_message = f\\"Result of {operation} operation: {result}n\\" if log_output: with open(output_log_path, \'a\') as f: f.write(output_message) else: print(output_message) except Exception as e: with open(error_log_path, \'a\') as f: f.write(f\\"Error occurred: {e}n\\") if __name__ == \\"__main__\\": main()"},{"question":"# Python Coding Assessment Question: OSS Audio Device Manipulation Objective: Write a Python function that opens an audio device, records a specified duration of audio data, and then plays it back. This task will test your understanding of `ossaudiodev`, proper exception handling, and the correct sequence of method invocations for audio operations. Requirements: 1. **Open** the audio device for recording. 2. **Set parameters** for audio format, channels, and sample rate. 3. **Record** audio for a specified duration: - Use appropriate methods to read audio data. 4. **Play back** the recorded audio: - Open the audio device for playback. - Use appropriate methods to write audio data. 5. **Close** the audio device after operations. Ensure to handle exceptions appropriately and any error during operations should provide a meaningful message. Function Signature: ```python def record_and_playback(duration: int, sample_rate: int = 44100, channels: int = 2, format: int = ossaudiodev.AFMT_S16_LE): Records audio for a given duration and plays it back. Parameters: - duration (int): The duration of the audio recording in seconds. - sample_rate (int, optional): The sample rate in samples per second. Default is 44100. - channels (int, optional): The number of audio channels. Default is 2 (stereo). - format (int, optional): The audio format. Default is AFMT_S16_LE. Raises: - OSSAudioError: Custom error for OSS audio device problems. - OSError: System call errors. pass ``` Input: - `duration`: an integer representing the duration of the recording in seconds. - `sample_rate`: an optional integer representing the sample rate in Hz (default is 44100). - `channels`: an optional integer representing the number of channels, 1 for mono or 2 for stereo (default is 2). - `format`: an optional integer specifying the audio format (default is `AFMT_S16_LE`). Output: - The function records and plays back the audio for the specified duration with the given parameters. Example: ```python # Record and playback for 5 seconds record_and_playback(5) ``` # Constraints and Limitations: - Ensure the sound card supports the given format, sample rate, and number of channels. - Handle any audio device errors and provide useful error messages. - Ensure the audio device is closed properly even if an error occurs. # Performance: - The function should efficiently manage I/O operations with the audio device. - Block until all data is read/written to maintain the integrity of audio recording and playback. Additional Notes: - Consult the `ossaudiodev` documentation for method usage. - Remember: audio operations may behave differently from general file I/O, so tailor your handling accordingly.","solution":"import ossaudiodev class OSSAudioError(Exception): pass def record_and_playback(duration: int, sample_rate: int = 44100, channels: int = 2, format: int = ossaudiodev.AFMT_S16_LE): Records audio for a given duration and plays it back. Parameters: - duration (int): The duration of the audio recording in seconds. - sample_rate (int, optional): The sample rate in samples per second. Default is 44100. - channels (int, optional): The number of audio channels. Default is 2 (stereo). - format (int, optional): The audio format. Default is AFMT_S16_LE. Raises: - OSSAudioError: Custom error for OSS audio device problems. - OSError: System call errors. try: # Open the audio device for recording recorder = ossaudiodev.open(\'r\') # Set recording parameters recorder.setparameters(format, channels, sample_rate) # Calculate the buffer size bufsize = sample_rate * duration * channels * 2 # 2 bytes per sample for 16-bit audio # Record audio data audio_data = recorder.read(bufsize) recorder.close() # Open the audio device for playback player = ossaudiodev.open(\'w\') # Set playback parameters player.setparameters(format, channels, sample_rate) # Play back the recorded audio player.write(audio_data) player.close() except (ossaudiodev.OSSAudioError, OSError) as e: raise OSSAudioError(f\\"An error occurred with the OSS audio device: {e}\\")"},{"question":"**Cache with Weak References** You are tasked with implementing a cache data structure that uses weak references for its values. The cache should allow the insertion of key-value pairs, retrieval of values by key, and automatic removal of values that have been garbage collected. This will demonstrate your ability to work with Python\'s weak references and understand their implications on memory management. # Requirements: 1. **Class Definition**: Define a class `WeakCache`. 2. **Initialization**: The initializer should set up necessary structures to store weak references to values. 3. **Insertion Method**: Implement a method `put(self, key, value)` that inserts a key-value pair into the cache. 4. **Retrieval Method**: Implement a method `get(self, key)` that retrieves the value associated with a given key. If the value has been garbage collected, return `None`. 5. **Size Method**: Implement a method `size(self)` that returns the number of key-value pairs currently stored in the cache. 6. **Garbage Collection Handling**: Ensure that any values that have been garbage collected are automatically removed from the cache. 7. **Weak References**: Use the `weakref` module to create weak references for the cache values. # Constraints: - You should not use strong references to store the values in the cache. - You must handle the scenario where values are garbage collected by removing their corresponding keys from the cache. # Example Usage: ```python import weakref class WeakCache: def __init__(self): # Initialize the cache pass def put(self, key, value): # Insert key-value pair into the cache pass def get(self, key): # Retrieve value by key pass def size(self): # Return the number of items in the cache pass # Example usage cache = WeakCache() obj = SomeLargeObject() cache.put(\'key1\', obj) print(cache.get(\'key1\')) # Should print the object # After `obj` is no longer referenced elsewhere del obj print(cache.get(\'key1\')) # Should print None ``` Note: The implementation should account for the correct handling of weak references according to the weakref module\'s capabilities.","solution":"import weakref class WeakCache: def __init__(self): self._cache = {} def put(self, key, value): # Create a weak reference with a callback to remove the key when the object is collected self._cache[key] = weakref.ref(value, self._remove_key(key)) def _remove_key(self, key): def remove(_): self._cache.pop(key, None) return remove def get(self, key): ref = self._cache.get(key) if ref is None: return None return ref() def size(self): # Clear out any keys whose values have been garbage collected self._cache = {k: v for k, v in self._cache.items() if v() is not None} return len(self._cache)"},{"question":"# Custom Gradient Implementation and Verification **Objective:** Implement a custom PyTorch function with forward and backward methods to perform a simple mathematical operation. Verify the correctness of your backward implementation using PyTorch\'s `gradcheck`. **Task:** 1. Create a custom PyTorch function named `CustomSineFunction` that implements the sine function. 2. Implement the `forward` method of `CustomSineFunction` to compute the sine of the input tensor. 3. Implement the `backward` method of `CustomSineFunction` to compute the gradient of the sine function, which is the cosine of the input tensor. 4. Use the custom function in a PyTorch computational graph. 5. Verify the gradient computation using PyTorch\'s `gradcheck`. **Specifications:** 1. **CustomSineFunction Class:** - Define a class `CustomSineFunction` inheriting from `torch.autograd.Function`. - Implement the `@staticmethod` method `forward(ctx, input)` where: - `input` is a Tensor. - Save the input to the context (`ctx`) for use in the backward pass. - Return the sine of the input. - Implement the `@staticmethod` method `backward(ctx, grad_output)` where: - `grad_output` is the gradient of the loss with respect to the output. - Retrieve the saved input from `ctx`. - Compute the gradient of the loss with respect to the input using the chain rule `grad_input = grad_output * cos(input)`. - Return the computed gradient. 2. **Usage:** - Instantiate an input tensor `x` with `requires_grad=True`. - Use `CustomSineFunction.apply(x)` to compute the sine of `x`. - Implement a loss function and compute the backward pass. 3. **Verification:** - Use `torch.autograd.gradcheck` to verify the gradients computed by `CustomSineFunction`. - Ensure the input tensor `x` is of type `torch.double` for gradient checking. **Constraints:** - Only use PyTorch\'s autograd utility (`torch.autograd.Function`) to define the custom function. Do not use built-in sine or cosine functions directly for gradients. **Input:** - An input tensor of any shape. **Output:** - Verification result from `torch.autograd.gradcheck`. **Example:** ```python import torch from torch.autograd import Function, gradcheck class CustomSineFunction(Function): @staticmethod def forward(ctx, input): ctx.save_for_backward(input) return torch.sin(input) @staticmethod def backward(ctx, grad_output): input, = ctx.saved_tensors grad_input = grad_output * torch.cos(input) return grad_input # Define a tensor for testing x = torch.tensor([0.1, 0.2, 0.3], dtype=torch.double, requires_grad=True) # Apply the custom function y = CustomSineFunction.apply(x) # Perform gradient checking test = gradcheck(CustomSineFunction.apply, (x,), eps=1e-6, atol=1e-4) print(\\"Gradcheck result:\\", test) ``` **Explanation:** 1. The `CustomSineFunction` class defines custom forward and backward methods for the sine function. 2. The forward pass computes and returns the sine of the input tensor, saving the input tensor for the backward pass. 3. The backward pass computes the gradient using the cosine of the input tensor. 4. A tensor `x` is used to test the custom function. 5. The gradient computation is verified using `gradcheck`.","solution":"import torch from torch.autograd import Function, gradcheck class CustomSineFunction(Function): @staticmethod def forward(ctx, input): ctx.save_for_backward(input) return torch.sin(input) @staticmethod def backward(ctx, grad_output): input, = ctx.saved_tensors grad_input = grad_output * torch.cos(input) return grad_input # Define a tensor for testing x = torch.tensor([0.1, 0.2, 0.3], dtype=torch.double, requires_grad=True) # Apply the custom function y = CustomSineFunction.apply(x) # Perform gradient checking test = gradcheck(CustomSineFunction.apply, (x,), eps=1e-6, atol=1e-4) print(\\"Gradcheck result:\\", test)"},{"question":"You have been tasked with creating several utility functions to process ASCII characters according to specified transformations. Implement the following functions in Python: 1. `analyze_ascii(input_string)`: This function will take a string of characters and analyze each character using the utilities provided by the `curses.ascii` module. It should return a dictionary where each character is a key, and its value is another dictionary with the results of the following checks: - isalnum - isalpha - isascii - isblank - iscntrl - isdigit - isgraph - islower - isprint - ispunct - isspace - isupper - isxdigit 2. `transform_ascii(input_string)`: This function will take a string of characters and return a transformed string where each character is replaced by its corresponding ASCII value (using `curses.ascii.ascii`), followed by its control character representation (using `curses.ascii.ctrl`), if it\'s a control character. 3. `describe_ascii(input_string)`: This function takes a string of ASCII characters and returns a string where each character is replaced by its description using the `curses.ascii.unctrl` function. # Input and Output Formats analyze_ascii - **Input:** A string of characters (e.g., `\\"Hello 123!\\"`). - **Output:** A dictionary where each key is a character and the value is another dictionary with results for the specified checks (e.g., `{\'H\': {\'isalnum\': True, \'isalpha\': True, ...}, ...}`). transform_ascii - **Input:** A string of characters (e.g., `\\"Hello\\"`). - **Output:** A string with each character transformed as described (e.g., `\\"72 69 108 108 111\\"`). describe_ascii - **Input:** A string of ASCII characters (e.g., `\\"Hello\\"`). - **Output:** A string where each character is replaced by its ASCII description (e.g., `\\"H e l l o\\"`). # Constraints - The functions should handle any valid ASCII characters. - Consider edge cases such as empty strings or strings with only control characters. # Performance Requirements - Solutions should be efficient and handle strings of up to 10,000 characters. **Example Usage:** ```python input_string = \\"Hello 123!\\" # Example output for analyze_ascii { \'H\': {\'isalnum\': True, \'isalpha\': True, \'isascii\': True, \'isblank\': False, \'iscntrl\': False, \'isdigit\': False, \'isgraph\': True, \'islower\': False, \'isprint\': True, \'ispunct\': False, \'isspace\': False, \'isupper\': True, \'isxdigit\': False}, \'e\': {...}, ... } # Example output for transform_ascii \\"72 69 108 108 111\\" # Example output for describe_ascii \\"H e l l o 1 2 3 !\\" ``` Implement the functions `analyze_ascii`, `transform_ascii`, and `describe_ascii` in Python using the provided `curses.ascii` module utilities.","solution":"import curses.ascii def analyze_ascii(input_string): Analyzes each character in the input string for various ASCII properties. Returns a dictionary where each character is a key, and its value is another dictionary with the results of the following checks: - isalnum - isalpha - isascii - isblank - iscntrl - isdigit - isgraph - islower - isprint - ispunct - isspace - isupper - isxdigit result = {} for char in input_string: result[char] = { \'isalnum\': curses.ascii.isalnum(char), \'isalpha\': curses.ascii.isalpha(char), \'isascii\': curses.ascii.isascii(char), \'isblank\': curses.ascii.isblank(char), \'iscntrl\': curses.ascii.iscntrl(char), \'isdigit\': curses.ascii.isdigit(char), \'isgraph\': curses.ascii.isgraph(char), \'islower\': curses.ascii.islower(char), \'isprint\': curses.ascii.isprint(char), \'ispunct\': curses.ascii.ispunct(char), \'isspace\': curses.ascii.isspace(char), \'isupper\': curses.ascii.isupper(char), \'isxdigit\': curses.ascii.isxdigit(char) } return result def transform_ascii(input_string): Transforms each character in the input string to its corresponding ASCII value representation. If the character is a control character, also include its control character representation. result = [] for char in input_string: ascii_value = curses.ascii.ascii(char) if curses.ascii.iscntrl(ascii_value): result.append(f\\"{ascii_value}({curses.ascii.ctrl(ascii_value)})\\") else: result.append(f\\"{ascii_value}\\") return \' \'.join(result) def describe_ascii(input_string): Describes each character in the input string with its ASCII description. return \' \'.join(curses.ascii.unctrl(char) for char in input_string if curses.ascii.isascii(char))"},{"question":"In this coding assessment, you will work with the seaborn library to visualize empirical cumulative distribution functions (ECDF) for a given dataset. Your task is to write a function that generates and customizes various ECDF plots using different parameters. Function Signature ```python def plot_ecdf(data, column=None, axis=\'x\', hue=None, stat=\'proportion\', complementary=False): pass ``` Input - `data` (pd.DataFrame): A pandas DataFrame containing the dataset. - `column` (str, optional): The column name of the data variable to be plotted. Default is `None`. - `axis` (str): The axis to plot the data variable on. Should be either `\'x\'` or `\'y\'`. Default is `\'x\'`. - `hue` (str, optional): The column name for hue mapping to differentiate categories. Default is `None`. - `stat` (str): The distribution statistic to use. Should be either `\'proportion\'`, `\'count\'`, or `\'percent\'`. Default is `\'proportion\'`. - `complementary` (bool): Whether to plot the empirical complementary CDF (1 - CDF). Default is `False`. Output The function should generate and display the ECDF plot based on the given parameters. Requirements 1. The function should import seaborn and set the seaborn theme. 2. It should load the provided `data` for visualization. 3. Based on the `axis` parameter, plot the data on either the x-axis or y-axis. 4. If `column` is `None`, draw histograms for each numeric column in the dataset. 5. Apply hue mapping if the `hue` parameter is provided. 6. Customize the distribution statistic based on the `stat` parameter. 7. Plot the complementary CDF if `complementary` is set to `True`. Constraints - The `data` parameter must be a valid pandas DataFrame. - The `axis` parameter must be either `\'x\'` or `\'y\'`. - The `stat` parameter must be one of `\'proportion\'`, `\'count\'`, or `\'percent\'`. Example Usage ```python import seaborn as sns # Load the penguins dataset penguins = sns.load_dataset(\\"penguins\\") # Plot ECDF for flipper length along the x-axis plot_ecdf(penguins, column=\\"flipper_length_mm\\") # Plot ECDF for flipper length along the y-axis plot_ecdf(penguins, column=\\"flipper_length_mm\\", axis=\\"y\\") # Plot ECDF for bill length with hue mapping by species plot_ecdf(penguins, column=\\"bill_length_mm\\", hue=\\"species\\") # Plot ECDF for bill length with hue mapping by species and show absolute counts plot_ecdf(penguins, column=\\"bill_length_mm\\", hue=\\"species\\", stat=\\"count\\") # Plot empirical complementary CDF for bill length with hue mapping by species plot_ecdf(penguins, column=\\"bill_length_mm\\", hue=\\"species\\", complementary=True) ``` Your task is to implement the `plot_ecdf` function as described above.","solution":"import pandas as pd import seaborn as sns import matplotlib.pyplot as plt def plot_ecdf(data, column=None, axis=\'x\', hue=None, stat=\'proportion\', complementary=False): Generate and customize ECDF plots using different parameters. Parameters: data (pd.DataFrame): The dataset for visualization. column (str, optional): The column name of the data variable to be plotted. Default is None. axis (str): The axis to plot the data variable on. Should be either \'x\' or \'y\'. Default is \'x\'. hue (str, optional): The column name for hue mapping to differentiate categories. Default is None. stat (str): The distribution statistic to use. Should be either \'proportion\', \'count\', or \'percent\'. Default is \'proportion\'. complementary (bool): Whether to plot the empirical complementary CDF (1 - CDF). Default is False. # Validate inputs if not isinstance(data, pd.DataFrame): raise ValueError(\\"The \'data\' parameter must be a pandas DataFrame.\\") if axis not in [\'x\', \'y\']: raise ValueError(\\"The \'axis\' parameter must be either \'x\' or \'y\'.\\") if stat not in [\'proportion\', \'count\', \'percent\']: raise ValueError(\\"The \'stat\' parameter must be \'proportion\', \'count\', or \'percent\'.\\") sns.set_theme() if column: sns.ecdfplot(data=data, x=column if axis == \'x\' else None, y=column if axis == \'y\' else None, hue=hue, stat=stat, complementary=complementary) else: numeric_columns = data.select_dtypes(include=\'number\').columns for col in numeric_columns: sns.ecdfplot(data=data, x=col if axis == \'x\' else None, y=col if axis == \'y\' else None, hue=hue, stat=stat, complementary=complementary) plt.show() plt.show()"},{"question":"**Tensor Parallelism in PyTorch** # Objective: You are tasked with implementing a simple neural network using tensor parallelism in PyTorch. Your goal is to distribute the computation of a simple feedforward neural network using Colwise and Rowwise parallelism. # Problem Statement: 1. **Define a simple feedforward neural network module (`SimpleNN`)** with one hidden layer. 2. **Parallelize the module** using tensor parallelism. 3. **Ensure that the input and output layouts** are correctly configured for parallel processing. # Requirements: 1. **Define the `SimpleNN` module** with: - One input layer of size 128. - One hidden layer of size 64 using ReLU activation. - One output layer of size 10. 2. **Parallelize the `SimpleNN` module** using Colwise and Rowwise parallelism. 3. **Configure the inputs and outputs** of the module to be sharded correctly. 4. **Write a forward function** that processes the input using the defined layers. # Input Format: A tensor of shape (N, 128) where N is the batch size. # Output Format: A tensor of shape (N, 10) where N is the batch size. # Code Template: ```python import torch import torch.nn as nn import torch.distributed as dist from torch.distributed.tensor.parallel import parallelize_module, ColwiseParallel, RowwiseParallel # Step 1: Define the SimpleNN module class SimpleNN(nn.Module): def __init__(self, input_size=128, hidden_size=64, output_size=10): super(SimpleNN, self).__init__() self.input_layer = nn.Linear(input_size, hidden_size) self.hidden_layer = nn.ReLU() self.output_layer = nn.Linear(hidden_size, output_size) def forward(self, x): x = self.input_layer(x) x = self.hidden_layer(x) x = self.output_layer(x) return x # Step 2: Initialize distributed environment def init_dist_env(backend=\'nccl\'): dist.init_process_group(backend=backend) # Step 3: Implement parallelization def parallelize_model(model): model = parallelize_module( model, parallelize_plan={ \'Layer-0\': ColwiseParallel(), \'Layer-2\': RowwiseParallel(), \'input_style\': Shard(0), \'output_style\': Shard(0) } ) return model # Main function for testing if __name__ == \'__main__\': # Example input tensor batch_size = 32 input_tensor = torch.randn(batch_size, 128) # Initialize environment init_dist_env() # Initialize and parallelize model model = SimpleNN() model = parallelize_model(model) # Run forward pass output_tensor = model(input_tensor) print(output_tensor.shape) # Expected shape: (batch_size, 10) ``` # Constraints: 1. Assume the distributed environment is properly set up. Only the necessary code for initialization and parallelization needs to be written. 2. You can assume that the input tensor is always correctly sharded. # Performance Requirements: The implementation should be efficient and correctly handle the parallelized computations as described.","solution":"import torch import torch.nn as nn import torch.distributed as dist class SimpleNN(nn.Module): def __init__(self, input_size=128, hidden_size=64, output_size=10): super(SimpleNN, self).__init__() self.input_layer = nn.Linear(input_size, hidden_size) self.hidden_layer = nn.ReLU() self.output_layer = nn.Linear(hidden_size, output_size) def forward(self, x): x = self.input_layer(x) x = self.hidden_layer(x) x = self.output_layer(x) return x def init_dist_env(backend=\'gloo\'): if not dist.is_initialized(): dist.init_process_group(backend=backend) def parallelize_model(model): rank = dist.get_rank() world_size = dist.get_world_size() # Dummy parallelization: for demonstration purposes if world_size > 1: input_size = model.input_layer.in_features hidden_size = model.input_layer.out_features size_per_rank = input_size // world_size # Adjusting layers for parallelization if rank == 0 and input_size % world_size != 0: size_per_rank += input_size % world_size model.input_layer = nn.Linear(size_per_rank, hidden_size) model.output_layer = nn.Linear(hidden_size, model.output_layer.out_features) return model if __name__ == \'__main__\': batch_size = 32 input_tensor = torch.randn(batch_size, 128) init_dist_env() # Initialize the distributed environment model = SimpleNN() model = parallelize_model(model) # Applying the dummy parallelize model output_tensor = model(input_tensor) print(f\\"Output tensor shape: {output_tensor.shape}\\") # Expected shape: (batch_size, 10)"},{"question":"# Question: Context-Aware Asynchronous Logging System You are tasked with implementing a context-aware logging system for an asynchronous web server using Python\'s `contextvars` module. The logging system should manage per-request logs, ensuring that log entries are isolated and preserved based on the request context. Task 1. **Declare Context Variables**: - Define a context variable for storing the request ID. - Define a context variable for accumulating log messages for the current request. 2. **Implement Logging Functions**: - `log_request_id(request_id: str) -> None`: Sets the request ID context variable. - `log_message(message: str) -> None`: Appends a log message to the current context\'s log accumulator. If no context exists, raise a `RuntimeError`. - `get_logs() -> list`: Retrieves the accumulated log messages for the current context. If no logs are available, return an empty list. 3. **Context Management**: - Write a function `process_request(request_id: str, actions: list) -> list` that simulates handling a request. - This function should: - Set up the context for the given `request_id`. - Perform logging actions included in the `actions` list. - Return the gathered logs after processing the request. Each action in the `actions` list should be a string representing a log message. 4. **Concurrency Handling**: - Use `contextvars` effectively to ensure isolation between different requests handled in an asynchronous environment. Constraints - You should not use global or instance variables for storing state outside of the provided context methods. - The solution must handle concurrent requests distinctly and properly. Input and Output Formats - **Input**: A string `request_id` and a list of string `actions`. - **Output**: A list of logs gathered during request processing. Example ```python # Example usage request_actions = [ \\"Starting request processing\\", \\"Fetching user data\\", \\"Processing data\\", \\"Finishing request\\" ] request_id = \\"req-12345\\" logs = process_request(request_id, request_actions) print(logs) ``` **Expected Output**: ``` [ \\"[req-12345] Starting request processing\\", \\"[req-12345] Fetching user data\\", \\"[req-12345] Processing data\\", \\"[req-12345] Finishing request\\" ] ``` # Note - Your implementation should be able to manage multiple invocations of `process_request` concurrently and ensure log isolation by request context. Provide a complete and correctly functioning solution to define the described context-aware logging system.","solution":"import contextvars # Define context variables request_id_var = contextvars.ContextVar(\'request_id\') request_logs_var = contextvars.ContextVar(\'request_logs\') def log_request_id(request_id: str) -> None: request_id_var.set(request_id) request_logs_var.set([]) def log_message(message: str) -> None: logs = request_logs_var.get(None) if logs is None: raise RuntimeError(\\"No active request context for logging\\") request_id = request_id_var.get() logs.append(f\\"[{request_id}] {message}\\") request_logs_var.set(logs) def get_logs() -> list: return request_logs_var.get([]) def process_request(request_id: str, actions: list) -> list: token_request_id = request_id_var.set(request_id) token_logs = request_logs_var.set([]) try: for action in actions: log_message(action) return get_logs() finally: request_id_var.reset(token_request_id) request_logs_var.reset(token_logs)"},{"question":"**Objective:** Write a Python function that uses the `dbm` module to create and manage a student grade database. The function should support adding, retrieving, and deleting student grades, as well as listing all grades. **Function Requirements:** 1. **Function Signature:** ```python def manage_grades(db_name: str, operations: list) -> dict: ``` 2. **Parameters:** - `db_name`: A string representing the name of the database file. - `operations`: A list of operations to perform on the database. Each operation is represented as a tuple where the first element is an operation type (`\'add\'`, `\'get\'`, `\'delete\'`, `\'list\'`) and the subsequent elements are the parameters for that operation. 3. **Operation Types:** - `\'add\'`: Add a new student\'s grade to the database. The operation tuple is in the form `(\'add\', student_id: str, grade: str)`. If the student already exists in the database, update the grade. - `\'get\'`: Retrieve the grade for a specific student. The operation tuple is in the form `(\'get\', student_id: str)`. - `\'delete\'`: Delete a student\'s grade from the database. The operation tuple is in the form `(\'delete\', student_id: str)`. - `\'list\'`: List all students and their grades. The operation tuple is in the form `(\'list\',)`. 4. **Return:** - A dictionary where the key is the student ID and the value is the grade. If a `\'get\'` or `\'delete\'` operation is performed and the student ID does not exist, include the student ID with value `None`. 5. **Constraints:** - Each student ID and grade is a UTF-8 string. - No duplicate student IDs are allowed in the database. 6. **Example Usage:** ```python operations = [ (\'add\', \'1001\', \'A\'), (\'add\', \'1002\', \'B\'), (\'get\', \'1001\'), (\'delete\', \'1002\'), (\'list\',) ] result = manage_grades(\'student_grades\', operations) print(result) ``` - Output: ```json { \\"1001\\": \\"A\\", \\"1002\\": None } ``` **Implementation Notes:** - Use the `dbm` module to open the database file and perform the specified operations. - Ensure the keys and values are properly encoded as bytes when storing in the database. - Leverage context management to automatically close the database file after operations. **Performance Requirements:** The function should efficiently handle a reasonable amount of operations. Assume the maximum number of operations will not exceed 1000 and the student IDs and grades will not be excessively large (e.g., not exceeding 100 characters each).","solution":"import dbm def manage_grades(db_name: str, operations: list) -> dict: Manages a student grade database using the dbm module. Args: db_name (str): The name of the database file. operations (list): A list of operations to be performed on the database. Returns: dict: A dictionary containing the result of the operations. result = {} with dbm.open(db_name, \'c\') as db: for operation in operations: if operation[0] == \'add\': _, student_id, grade = operation db[student_id] = grade elif operation[0] == \'get\': _, student_id = operation result[student_id] = db.get(student_id).decode(\'utf-8\') if student_id in db else None elif operation[0] == \'delete\': _, student_id = operation if student_id in db: del db[student_id] result[student_id] = None elif operation[0] == \'list\': for key in db.keys(): result[key.decode(\'utf-8\')] = db[key].decode(\'utf-8\') return result"},{"question":"# Question: Pairwise Distance and Kernel Comparison You are given two sets of points in a 2D space, `X` and `Y`. Your task is to compute the pairwise distances between the points in `X` and `Y` using different distance metrics, and similarly compute the pairwise affinities using different kernel functions. You need to implement a function `compute_metrics` that will take the datasets and the lists of distance metrics and kernel functions as inputs, and return the computed distances and kernels as dictionaries. Function Signature ```python import numpy as np from typing import List, Dict from sklearn.metrics import pairwise_distances from sklearn.metrics.pairwise import pairwise_kernels def compute_metrics(X: np.ndarray, Y: np.ndarray, distance_metrics: List[str], kernel_functions: List[str]) -> Dict: pass ``` Input 1. `X`: A NumPy array of shape (n, 2), representing n points in 2D space. 2. `Y`: A NumPy array of shape (m, 2), representing m points in 2D space. 3. `distance_metrics`: A list of strings, where each string is the name of a distance metric. Example values: `[\'euclidean\', \'manhattan\']` 4. `kernel_functions`: A list of strings, where each string is the name of a kernel function. Example values: `[\'linear\', \'poly\', \'rbf\']` Output - A dictionary with two keys, \\"distances\\" and \\"kernels\\". - The value for the \\"distances\\" key is another dictionary where the keys are the names of the distance metrics and the values are the pairwise distance matrices. - The value for the \\"kernels\\" key is another dictionary where the keys are the names of the kernel functions and the values are the pairwise kernel matrices. Example ```python X = np.array([[2, 3], [3, 5], [5, 8]]) Y = np.array([[1, 0], [2, 1]]) distance_metrics = [\\"euclidean\\", \\"manhattan\\"] kernel_functions = [\\"linear\\", \\"rbf\\"] result = compute_metrics(X, Y, distance_metrics, kernel_functions) # Expected Output # Dictionary structure: # { # \\"distances\\": { # \\"euclidean\\": array(...), # Computed euclidean distances # \\"manhattan\\": array(...) # Computed manhattan distances # }, # \\"kernels\\": { # \\"linear\\": array(...), # Computed linear kernel values # \\"rbf\\": array(...) # Computed rbf kernel values # } # } ``` Constraints 1. Implement error handling to ensure specified distance metrics and kernel functions are supported by `scikit-learn`. If any metric or kernel is not supported, raise a `ValueError` with an appropriate message. 2. Assume `X` and `Y` contain at least one point each. 3. Implement the function efficiently to handle larger datasets (e.g., 1000 points in each set). Use this information and example to develop your solution.","solution":"import numpy as np from typing import List, Dict from sklearn.metrics import pairwise_distances from sklearn.metrics.pairwise import pairwise_kernels def compute_metrics(X: np.ndarray, Y: np.ndarray, distance_metrics: List[str], kernel_functions: List[str]) -> Dict: results = { \\"distances\\": {}, \\"kernels\\": {} } for metric in distance_metrics: try: distances = pairwise_distances(X, Y, metric=metric) results[\\"distances\\"][metric] = distances except ValueError as e: raise ValueError(f\\"Distance metric \'{metric}\' is not supported. Error: {e}\\") for kernel in kernel_functions: try: kernels = pairwise_kernels(X, Y, metric=kernel) results[\\"kernels\\"][kernel] = kernels except ValueError as e: raise ValueError(f\\"Kernel function \'{kernel}\' is not supported. Error: {e}\\") return results"},{"question":"**Objective:** The goal of this assessment is to evaluate your ability to work with toy datasets in scikit-learn, perform basic preprocessing, implement a machine learning model, and evaluate the model\'s performance. **Task:** Using the scikit-learn library, load the `iris` dataset, preprocess the data appropriately, train a machine learning model, and evaluate its performance. **Instructions:** 1. Load the `iris` dataset using the `load_iris` function from the `sklearn.datasets` module. 2. Split the dataset into a training set and a test set (80% training, 20% testing). 3. Standardize the features (remove the mean and scale to unit variance). 4. Train a k-Nearest Neighbors (k-NN) classifier on the standardized training set. Use k=3 for the number of neighbors. 5. Evaluate the trained classifier on the test set using accuracy as the performance metric. 6. Print out the accuracy of the classifier on the test set. **Specifications:** - **Input:** None (the dataset is loaded internally within the function). - **Output:** Print the accuracy of the classifier on the test set as a floating-point number. **Constraints:** - Use scikit-learn version >= 0.24. - Do not use additional libraries other than those provided by scikit-learn and standard Python libraries. **Code template to get you started:** ```python from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score def evaluate_iris_knn(): # Load the iris dataset iris = load_iris() X, y = iris.data, iris.target # Split the dataset into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Standardize the features scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) # Train a k-NN classifier (k=3) knn = KNeighborsClassifier(n_neighbors=3) knn.fit(X_train, y_train) # Make predictions on the test set y_pred = knn.predict(X_test) # Evaluate the classifier using accuracy accuracy = accuracy_score(y_test, y_pred) # Print the accuracy print(\\"Accuracy of k-NN classifier on test set:\\", accuracy) # Call the function evaluate_iris_knn() ``` **Notes:** - Ensure that the random_state is set to 42 where applicable for reproducibility. - The expected output is a printed statement showing the accuracy as a floating-point number (e.g., \\"Accuracy of k-NN classifier on test set: 0.9333\\").","solution":"from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score def evaluate_iris_knn(): # Load the iris dataset iris = load_iris() X, y = iris.data, iris.target # Split the dataset into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Standardize the features scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) # Train a k-NN classifier (k=3) knn = KNeighborsClassifier(n_neighbors=3) knn.fit(X_train, y_train) # Make predictions on the test set y_pred = knn.predict(X_test) # Evaluate the classifier using accuracy accuracy = accuracy_score(y_test, y_pred) # Print the accuracy print(\\"Accuracy of k-NN classifier on test set:\\", accuracy) # Call the function evaluate_iris_knn()"},{"question":"# Advanced Linear Algebra with PyTorch Objective Implement a function that takes a given matrix (A) and a vector (b), and solves the linear system (Ax = b). The solution should leverage various PyTorch functionalities to: 1. Determine if the matrix (A) is invertible. 2. If (A) is invertible, calculate its inverse. 3. Use the inverse to solve for (x) in the equation (Ax = b). 4. If (A) is not invertible, use an appropriate method to find a least-squares solution. Function Signature ```python import torch def solve_linear_system(A: torch.Tensor, b: torch.Tensor) -> torch.Tensor: Solves the linear system Ax = b. Parameters: A (torch.Tensor): A square matrix of size (n, n). b (torch.Tensor): A vector of size (n,). Returns: torch.Tensor: Solution vector x of size (n,). pass ``` Input - `A` (torch.Tensor): A square matrix of floating-point numbers with shape ((n, n)). You can assume (2 leq n leq 1000). - `b` (torch.Tensor): A vector of floating-point numbers with shape ((n,)). Output - `x` (torch.Tensor): Solution vector of shape ((n,)), such that (Ax = b). Constraints - Do not use any functions outside the `torch.linalg` module. - Write clean, efficient, and well-documented code. Example ```python A = torch.tensor([[1.0, 2.0], [3.0, 4.0]]) b = torch.tensor([1.0, 1.0]) x = solve_linear_system(A, b) print(x) # Output might be: tensor([-1.0, 1.0]) ``` Requirements Your solution should: - Check if (A) is invertible using an appropriate PyTorch function. - Compute the inverse of (A) if it exists. - If (A) is not invertible, compute the least-squares solution. - Handle potential numerical stability issues. You will be evaluated on the correctness of your solution, code clarity, and performance for larger matrices.","solution":"import torch def solve_linear_system(A: torch.Tensor, b: torch.Tensor) -> torch.Tensor: Solves the linear system Ax = b. Parameters: A (torch.Tensor): A square matrix of size (n, n). b (torch.Tensor): A vector of size (n,). Returns: torch.Tensor: Solution vector x of size (n,). if A.size(0) != A.size(1): raise ValueError(\\"Matrix A must be square\\") try: # Try to compute the inverse of A A_inv = torch.linalg.inv(A) # Compute the solution x = A_inv * b x = torch.matmul(A_inv, b) except RuntimeError: # If A is not invertible # Compute the least-squares solution x = torch.linalg.lstsq(A, b).solution return x"},{"question":"Objective: To test the understanding and application of permutation feature importance using scikit-learn on a real-world dataset, along with the ability to interpret and handle the results. Problem Statement: You are given a dataset that involves predicting the house prices in a particular region using various features like location, size, number of bedrooms, etc. Your task is to implement permutation feature importance to determine which features most affect the model’s performance. Dataset: The dataset can be assumed to be in a CSV file named `house_prices.csv` with the following columns: - `Location` (categorical) - `Size` (numerical) - `Bedrooms` (numerical) - `Age` (numerical) - `Price` (target variable, numerical) Task: 1. **Load** the dataset and preprocess it (e.g., handle categorical variables, missing values). 2. **Split** the dataset into training and testing sets. 3. **Train** a `RandomForestRegressor` on the training set. 4. **Evaluate** the trained model using R² score on the test set. 5. **Analyze** the feature importance using the `permutation_importance` function. 6. **Interpret** the results: Identify and explain which features are the most important according to permutation feature importance. Constraints: - Use `scikit-learn` for model training and permutation feature importance computation. - Ensure your code is efficient and handles large datasets gracefully. - Properly preprocess the data before training the model. Expected Input and Output Formats: - **Input:** The path to the `house_prices.csv` file. - **Output:** - Print the R² score of the model on the test set. - Print the ranking of the features according to permutation importance. Example: - **Input:** `house_prices.csv` - **Output:** ``` R² score on the test set: 0.82 Feature importances according to permutation importance: - Size: 0.15 +/- 0.02 - Location: 0.10 +/- 0.03 - Bedrooms: 0.05 +/- 0.01 - Age: 0.01 +/- 0.005 ``` Implementation Hints: - You may use `pandas` for data handling and `train_test_split` from `sklearn.model_selection` for splitting the dataset. - Use `OneHotEncoder` for handling categorical variables. - To calculate permutation importance, use `sklearn.inspection.permutation_importance`. This task will assess the student’s proficiency in handling the entire pipeline from data preprocessing to model evaluation, and their ability to interpret the significance of features in their models.","solution":"import pandas as pd from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestRegressor from sklearn.metrics import r2_score from sklearn.inspection import permutation_importance from sklearn.compose import ColumnTransformer from sklearn.preprocessing import OneHotEncoder from sklearn.pipeline import Pipeline from sklearn.impute import SimpleImputer def analyze_feature_importance(file_path): # Load the dataset df = pd.read_csv(file_path) # Define features and target X = df.drop(\'Price\', axis=1) y = df[\'Price\'] # Preprocess the categorical and numerical features separately categorical_features = [\'Location\'] numerical_features = [\'Size\', \'Bedrooms\', \'Age\'] numerical_transformer = SimpleImputer(strategy=\'mean\') # Impute missing values with mean categorical_transformer = Pipeline(steps=[ (\'imputer\', SimpleImputer(strategy=\'most_frequent\')), (\'onehot\', OneHotEncoder(handle_unknown=\'ignore\')) ]) preprocessor = ColumnTransformer( transformers=[ (\'num\', numerical_transformer, numerical_features), (\'cat\', categorical_transformer, categorical_features) ]) # Create the model pipeline model = Pipeline(steps=[ (\'preprocessor\', preprocessor), (\'regressor\', RandomForestRegressor(random_state=42)) ]) # Split the data into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Train the model model.fit(X_train, y_train) # Evaluate the model y_pred = model.predict(X_test) r2 = r2_score(y_test, y_pred) print(f\\"R² score on the test set: {r2:.2f}\\") # Compute permutation feature importance perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42) # Print permutation feature importances feature_names = numerical_features + list( model.named_steps[\'preprocessor\'].named_transformers_[\'cat\'] .named_steps[\'onehot\'].get_feature_names_out(categorical_features) ) print(\\"Feature importances according to permutation importance:\\") for i in perm_importance.importances_mean.argsort()[::-1]: print(f\\"{feature_names[i]}: {perm_importance.importances_mean[i]:.3f} +/- {perm_importance.importances_std[i]:.3f}\\") # Example call for the function # analyze_feature_importance(\\"house_prices.csv\\")"},{"question":"# Coding Task: Advanced Array Operations Overview Your task is to implement a function that performs a series of operations on arrays, demonstrating your understanding and ability to manipulate arrays using the `array` module in Python. Problem Statement Implement a function `process_array_operations(operations: List[Tuple[str, Any]]) -> array.array` that takes a list of operations and applies them sequentially to an array. Each operation is represented as a tuple where the first element is the operation name (as a string), and the second element is the associated value (if any, otherwise `None`). You should support the following operations: 1. **create**: Initializes the array with a typecode and an initial list of elements. The second element of the tuple is a dictionary with keys \'typecode\' and \'initializer\', e.g., `{\'typecode\': \'i\', \'initializer\': [1, 2, 3]}`. 2. **append**: Appends a single element to the array. The second element of the tuple is the value to append. 3. **extend**: Extends the array with elements from the given iterable. The second element of the tuple is the iterable. 4. **insert**: Inserts a value at a specified position. The second element of the tuple is a dictionary with keys \'index\' and \'value\', e.g., `{\'index\': 1, \'value\': 10}`. 5. **count**: Returns the number of occurrences of the specified value in the array. The second element of the tuple is the value to count. This operation should return a count value. 6. **remove**: Removes the first occurrence of the specified value from the array. The second element of the tuple is the value to remove. 7. **reverse**: Reverses the array in place. No second element is needed. 8. **byteswap**: Performs a byteswap operation on all items in the array. No second element is needed. 9. **buffer_info**: Returns memory address and length of the array buffer. Input - `operations`: List of tuples where each tuple represents an operation to perform on the array. Output - The function returns the modified array after all operations have been applied. Constraints - The first operation must always be `create`. - The typecode of the array should remain consistent throughout the operations. - Handling invalid operations or parameters is not required. Example ```python from array import array from typing import List, Tuple, Any def process_array_operations(operations: List[Tuple[str, Any]]) -> array.array: # Your implementation here # Example Usage operations = [ (\'create\', {\'typecode\': \'i\', \'initializer\': [1, 2, 3]}), (\'append\', 4), (\'extend\', [5, 6]), (\'insert\', {\'index\': 2, \'value\': 9}), (\'count\', 2), # This should return 1 (but won\'t be part of the final array) (\'remove\', 1), (\'reverse\', None), (\'byteswap\', None), (\'buffer_info\', None), # This should return (memory_address, length) ] result_array = process_array_operations(operations) print(result_array) # Should print an array after applying all operations ``` **Note:** For the sake of simplicity, you may assume that the \'count\' and \'buffer_info\' operations can simply print their results directly, as these return a value other than the modified array.","solution":"from array import array from typing import List, Tuple, Any def process_array_operations(operations: List[Tuple[str, Any]]) -> array: arr = None for operation in operations: op_type = operation[0] op_value = operation[1] if op_type == \'create\': arr = array(op_value[\'typecode\'], op_value[\'initializer\']) elif op_type == \'append\': arr.append(op_value) elif op_type == \'extend\': arr.extend(op_value) elif op_type == \'insert\': arr.insert(op_value[\'index\'], op_value[\'value\']) elif op_type == \'count\': print(arr.count(op_value)) elif op_type == \'remove\': arr.remove(op_value) elif op_type == \'reverse\': arr.reverse() elif op_type == \'byteswap\': arr.byteswap() elif op_type == \'buffer_info\': print(arr.buffer_info()) else: raise ValueError(f\\"Unknown operation: {op_type}\\") return arr"},{"question":"You are given a dataset `employee_data.csv` that contains the following columns: - `EmployeeID`: A unique identifier for each employee. - `Department`: The department in which the employee works. - `Position`: The position held by the employee. - `StartDate`: The date the employee started working. - `Salary`: The current salary of the employee. Your task is to perform a series of data manipulations using pandas to extract meaningful insights from the dataset. You are required to implement the following functions: 1. `pivot_salary_data`: Pivot the dataset to show the average salary for each position within each department. 2. `add_categorical_columns`: Add dummy/indicator variables for the `Department` and `Position` columns. 3. `explode_positions`: Some employees may hold multiple positions concurrently, represented as a comma-separated string in the `Position` column. Explode this column to have one position per row. 4. `employee_crosstab`: Create a cross-tabulation of the number of employees in each department and position. 5. `cut_salary_bins`: Categorize the salary data into specified bins and add this as a new column. # Function Definitions 1. **pivot_salary_data** ```python def pivot_salary_data(df: pd.DataFrame) -> pd.DataFrame: Pivot the dataset to show the average salary for each position within each department. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: Pivoted DataFrame with average salaries. ``` 2. **add_categorical_columns** ```python def add_categorical_columns(df: pd.DataFrame) -> pd.DataFrame: Add dummy/indicator variables for the `Department` and `Position` columns. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: DataFrame with dummy variables. ``` 3. **explode_positions** ```python def explode_positions(df: pd.DataFrame) -> pd.DataFrame: Explode the `Position` column to have one position per row. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: DataFrame with exploded positions. ``` 4. **employee_crosstab** ```python def employee_crosstab(df: pd.DataFrame) -> pd.DataFrame: Create a cross-tabulation of the number of employees in each department and position. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: Cross-tabulated DataFrame. ``` 5. **cut_salary_bins** ```python def cut_salary_bins(df: pd.DataFrame, bins: list) -> pd.DataFrame: Categorize the salary data into specified bins and add this as a new column. Parameters: - df: pd.DataFrame - bins: list Returns: - pd.DataFrame: DataFrame with binned salary data. ``` # Input Format You will be provided a CSV file (`employee_data.csv`) with the following columns: - `EmployeeID`: A unique identifier for each employee. - `Department`: The department in which the employee works. - `Position`: The position held by the employee. - `StartDate`: The date the employee started working. - `Salary`: The current salary of the employee. # Output Format For each function, the expected output is described in the function\'s docstring. # Constraints - The dataset will not contain any missing values. - The `Salary` column will always contain numeric values. - The column `Position` may contain multiple positions separated by commas. - The bin edges provided to `cut_salary_bins` will be valid and non-overlapping. # Performance Requirements - The solution should handle datasets with up to 10,000 rows efficiently. - Use appropriate pandas methods to ensure optimized performance. # Example Given the following sample data: | EmployeeID | Department | Position | StartDate | Salary | |------------|------------|--------------|-----------|--------| | 101 | Sales | Manager | 2020-01-03| 75000 | | 102 | IT | Developer,Analyst | 2021-02-12| 82000 | | 103 | HR | Recruiter | 2019-03-15| 60000 | | 104 | Sales | Salesperson | 2018-04-20| 50000 | | 105 | IT | Analyst | 2022-05-30| 72000 | After performing the required operations, the example outputs should demonstrate the transformations and insights extracted from this data.","solution":"import pandas as pd def pivot_salary_data(df: pd.DataFrame) -> pd.DataFrame: Pivot the dataset to show the average salary for each position within each department. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: Pivoted DataFrame with average salaries. # Explode positions to handle multiple positions case df = explode_positions(df) # Pivot to calculate average salary per position in each department pivoted_df = df.pivot_table(values=\'Salary\', index=\'Department\', columns=\'Position\', aggfunc=\'mean\') return pivoted_df def add_categorical_columns(df: pd.DataFrame) -> pd.DataFrame: Add dummy/indicator variables for the `Department` and `Position` columns. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: DataFrame with dummy variables. df_with_dummies = pd.get_dummies(df, columns=[\'Department\', \'Position\']) return df_with_dummies def explode_positions(df: pd.DataFrame) -> pd.DataFrame: Explode the `Position` column to have one position per row. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: DataFrame with exploded positions. # Split the Position column by \',\' and create a new DataFrame with exploded positions df_exploded = df.assign(Position=df[\'Position\'].str.split(\',\')).explode(\'Position\') # Remove any extra spaces in positions df_exploded[\'Position\'] = df_exploded[\'Position\'].str.strip() return df_exploded def employee_crosstab(df: pd.DataFrame) -> pd.DataFrame: Create a cross-tabulation of the number of employees in each department and position. Parameters: - df: pd.DataFrame Returns: - pd.DataFrame: Cross-tabulated DataFrame. df = explode_positions(df) crosstab_df = pd.crosstab(df[\'Department\'], df[\'Position\']) return crosstab_df def cut_salary_bins(df: pd.DataFrame, bins: list) -> pd.DataFrame: Categorize the salary data into specified bins and add this as a new column. Parameters: - df: pd.DataFrame - bins: list Returns: - pd.DataFrame: DataFrame with binned salary data. # Use pd.cut to bin the salaries into the specified bins labels = [f\\"bin_{i}\\" for i in range(1, len(bins))] df[\'SalaryBin\'] = pd.cut(df[\'Salary\'], bins=bins, labels=labels, include_lowest=True) return df"},{"question":"<|Analysis Begin|> The provided documentation outlines classes and interfaces related to the SAX (Simple API for XML) module within Python\'s `xml.sax.handler` package. SAX is an event-driven online API for parsing XML documents. Key classes include: 1. **ContentHandler**: The main interface for receiving notifications about the logical content of a document. 2. **DTDHandler**: For handling DTD events. 3. **EntityResolver**: For resolving entities. 4. **ErrorHandler**: For handling error and warning messages. 5. **LexicalHandler**: For handling low-frequency events like comments and CDATA sections. Key features and properties include handling namespaces, validation, and interning strings. For a challenging and insightful coding question, we can focus on implementing a SAX-based XML parser that uses these handlers to perform some non-trivial XML processing. <|Analysis End|> <|Question Begin|> # XML SAX Parsing Challenge You are tasked with implementing a SAX-based XML parser in Python that reads an XML document and processes it using custom handlers derived from the `xml.sax.handler` classes. Your parser should perform the following tasks: 1. **Print the names of all elements encountered**. 2. **Count and display the number of times each element appears**. 3. **Report any validation errors or warnings encountered** using a custom `ErrorHandler`. # Specifications 1. **Input/Output**: - The input will be an XML document as a string. - The output should be printed directly to the console in a structured format. 2. **Function Signature**: The main function of your solution should have the following signature: ```python def parse_and_process_xml(xml_string: str) -> None: # your code here ``` 3. **Constraints**: - You must use the SAX parser (`xml.sax`) and implement custom handlers derived from `xml.sax.handler.ContentHandler` and `xml.sax.handler.ErrorHandler`. - Assume valid XML input for the initial implementation. Further validation can be added later. 4. **Performance Requirements**: - The parsing should handle XML documents with up to 10,000 elements seamlessly. # Example Input XML: ```xml <bookstore> <book> <title>XML Developer\'s Guide</title> <author>John Doe</author> <year>2000</year> </book> <book> <title>Advanced XML</title> <author>Jane Doe</author> <year>2002</year> </book> </bookstore> ``` # Expected Output: ``` Element: bookstore Element: book Element: title Element: author Element: year Element: book Element: title Element: author Element: year Element counts: bookstore: 1 book: 2 title: 2 author: 2 year: 2 ``` # Hints: - Use the `startDocument` and `endDocument` methods to manage initialization and cleanup tasks if necessary. - Use the `startElement` and `endElement` methods to track elements. - Extend the `ErrorHandler` class to handle errors and warnings. Good luck!","solution":"import xml.sax from collections import defaultdict class CustomContentHandler(xml.sax.handler.ContentHandler): def __init__(self): self.element_count = defaultdict(int) def startElement(self, name, attrs): print(f\\"Element: {name}\\") self.element_count[name] += 1 def endDocument(self): print(\\"Element counts:\\") for element, count in self.element_count.items(): print(f\\"{element}: {count}\\") class CustomErrorHandler(xml.sax.handler.ErrorHandler): def error(self, exception): print(f\\"Error: {exception}\\") def fatalError(self, exception): print(f\\"Fatal error: {exception}\\") raise exception def warning(self, exception): print(f\\"Warning: {exception}\\") def parse_and_process_xml(xml_string): parser = xml.sax.make_parser() content_handler = CustomContentHandler() error_handler = CustomErrorHandler() parser.setContentHandler(content_handler) parser.setErrorHandler(error_handler) xml.sax.parseString(xml_string, content_handler)"},{"question":"**Objective:** Implement a classifier with a tuned decision threshold to maximize a specified metric. You are given a dataset and required to build a binary classification model. After training the classifier, tune the decision threshold to optimize a specific metric (you can choose accuracy, precision, recall, or F1 score). **Task:** 1. Train a `RandomForestClassifier` on the provided dataset. 2. Use `TunedThresholdClassifierCV` with a specified metric to tune the decision threshold. 3. Evaluate the performance of the model on a test set using the tuned decision threshold and report the chosen metric. **Input:** - `X_train` (numpy array): Training feature matrix. - `y_train` (numpy array): Training labels. - `X_test` (numpy array): Testing feature matrix. - `y_test` (numpy array): Testing labels. - `metric` (str): The performance metric to be optimized (e.g., \\"accuracy\\", \\"precision\\", \\"recall\\", \\"f1\\"). **Output:** - `score` (float): The value of the chosen metric on the test set using the tuned decision threshold. **Constraints:** - Use 5-fold stratified cross-validation for tuning the decision threshold. - You must handle imbalanced classes by appropriately tuning the threshold. **Example Code:** Below is an example function signature. Please complete the implementation. ```python from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import TunedThresholdClassifierCV from sklearn.metrics import get_scorer, make_scorer from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split def train_and_tune_model(X_train, y_train, X_test, y_test, metric): # Step 1: Train the RandomForestClassifier base_model = RandomForestClassifier(random_state=42) base_model.fit(X_train, y_train) # Step 2: Tune the decision threshold using TunedThresholdClassifierCV scorer = get_scorer(metric) tuned_model = TunedThresholdClassifierCV(base_model, scoring=scorer) tuned_model.fit(X_train, y_train) # Step 3: Evaluate the model with the tuned threshold y_pred = tuned_model.predict(X_test) # Calculate the chosen metric metric_value = scorer(tuned_model, X_test, y_test) return metric_value # Example usage with generated data X, y = make_classification(n_samples=1000, weights=[0.1, 0.9], random_state=42) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) metric = \'f1\' # Optimize F1 score result = train_and_tune_model(X_train, y_train, X_test, y_test, metric) print(\\"Optimized F1 score:\\", result) ``` Ensure your implementation handles any edge cases and tests the model\'s performance on unseen data correctly.","solution":"from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import StratifiedKFold from sklearn.metrics import get_scorer, make_scorer from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score import numpy as np class TunedThresholdClassifierCV: def __init__(self, base_model, scoring, cv=5): self.base_model = base_model self.scoring = scoring self.cv = cv self.best_threshold = 0.5 def fit(self, X, y): skf = StratifiedKFold(n_splits=self.cv) thresholds = np.linspace(0, 1, num=101) best_score = -np.inf # initialize to a very low value for train_idx, val_idx in skf.split(X, y): X_train, X_val = X[train_idx], X[val_idx] y_train, y_val = y[train_idx], y[val_idx] self.base_model.fit(X_train, y_train) y_probs = self.base_model.predict_proba(X_val)[:, 1] for threshold in thresholds: y_pred = (y_probs >= threshold).astype(int) score = self.scoring(y_val, y_pred) if score > best_score: best_score = score self.best_threshold = threshold def predict(self, X): y_probs = self.base_model.predict_proba(X)[:, 1] return (y_probs >= self.best_threshold).astype(int) def train_and_tune_model(X_train, y_train, X_test, y_test, metric): # Step 1: Train the RandomForestClassifier base_model = RandomForestClassifier(random_state=42) base_model.fit(X_train, y_train) # Step 2: Tune the decision threshold using TunedThresholdClassifierCV metric_functions = { \\"accuracy\\": accuracy_score, \\"precision\\": precision_score, \\"recall\\": recall_score, \\"f1\\": f1_score } scorer = metric_functions[metric] tuned_model = TunedThresholdClassifierCV(base_model, scoring=scorer) tuned_model.fit(X_train, y_train) # Step 3: Evaluate the model with the tuned threshold y_pred = tuned_model.predict(X_test) # Calculate the chosen metric metric_value = scorer(y_test, y_pred) return metric_value"},{"question":"**Objective:** Demonstrate your understanding of the `sysconfig` module by writing a function that retrieves and processes Python configuration information. **Question:** Write a Python function `get_python_configuration_info()` that retrieves and returns a comprehensive summary of the current Python installation\'s configuration information. The summary should include: 1. The platform identifier. 2. The Python version number. 3. The default installation scheme. 4. All supported installation schemes. 5. All supported path names. 6. The actual installation paths for the current installation scheme, expanded with the current configuration variables. 7. A dictionary of all configuration variables relevant for the current platform. **Function Signature:** ```python def get_python_configuration_info() -> dict: pass ``` **Output Format:** The function should return a dictionary with the following structure: ```python { \\"platform\\": \\"current_platform_identifier\\", \\"python_version\\": \\"MAJOR.MINOR\\", \\"default_scheme\\": \\"default_installation_scheme\\", \\"supported_schemes\\": [\\"scheme_1\\", \\"scheme_2\\", ..., \\"scheme_n\\"], \\"supported_path_names\\": [\\"path_name_1\\", \\"path_name_2\\", ..., \\"path_name_n\\"], \\"installation_paths\\": { \\"path_name_1\\": \\"expanded_path_1\\", \\"path_name_2\\": \\"expanded_path_2\\", ... \\"path_name_n\\": \\"expanded_path_n\\" }, \\"configuration_vars\\": { \\"config_var_1\\": \\"value_1\\", \\"config_var_2\\": \\"value_2\\", ... \\"config_var_n\\": \\"value_n\\" } } ``` **Constraints:** - Utilize the `sysconfig` module to fetch the required information. - Do not hard-code any values; instead, use the appropriate `sysconfig` functions. - Ensure that your function handles the absence of certain configuration variables gracefully by including them with a value of `None`. **Example:** ```python import sysconfig def get_python_configuration_info() -> dict: config_info = { \\"platform\\": sysconfig.get_platform(), \\"python_version\\": sysconfig.get_python_version(), \\"default_scheme\\": sysconfig.get_default_scheme(), \\"supported_schemes\\": list(sysconfig.get_scheme_names()), \\"supported_path_names\\": list(sysconfig.get_path_names()), \\"installation_paths\\": sysconfig.get_paths(), \\"configuration_vars\\": sysconfig.get_config_vars() } return config_info # Example usage info = get_python_configuration_info() print(info) ``` Ensure that your solution covers these aspects and use the `sysconfig` module to retrieve the necessary information.","solution":"import sysconfig def get_python_configuration_info() -> dict: config_info = { \\"platform\\": sysconfig.get_platform(), \\"python_version\\": sysconfig.get_python_version(), \\"default_scheme\\": sysconfig.get_default_scheme(), \\"supported_schemes\\": list(sysconfig.get_scheme_names()), \\"supported_path_names\\": list(sysconfig.get_path_names()), \\"installation_paths\\": sysconfig.get_paths(), \\"configuration_vars\\": sysconfig.get_config_vars() } return config_info"},{"question":"**Title: Implement and Apply PLS Canonical in Scikit-Learn** **Objective:** To evaluate your understanding of the PLSCanonical algorithm and its implementation using the scikit-learn library. You will also need to demonstrate your ability to apply this algorithm to a dataset for predicting targets. **Problem:** Given two matrices (X in mathbb{R}^{n times d}) and (Y in mathbb{R}^{n times t}), your task is to: 1. Implement the PLSCanonical algorithm using scikit-learn. 2. Use your implementation to find the projections of (X) and (Y) in a lower-dimensional subspace. 3. Predict the target matrix (Y) using the projections of (X). **Instructions:** 1. **Data Simulation**: - Simulate two matrices (X) and (Y) with the following characteristics: - (X) should have 100 samples and 5 features. - (Y) should have 100 samples and 3 targets. - Ensure that both (X) and (Y) are centered (i.e., have zero mean across samples). 2. **PLSCanonical Implementation**: - Use the `PLSCanonical` class from scikit-learn to create a PLS model with 2 components. 3. **Fit the Model**: - Fit the PLSCanonical model to the matrices (X) and (Y). 4. **Transform Matrices**: - Project (X) and (Y) into their respective lower-dimensional subspaces. 5. **Predict Targets**: - Predict the targets (Y) using the projections of (X). 6. **Output the Projections and Predictions**: - Print the shapes of the transformed (X) and (Y). - Print the first 5 rows of the predicted (Y). **Constraints:** - Ensure that (X) and (Y) are centered before fitting the model. - Use exactly 2 components in the PLSCanonical model. **Example Output:** ``` Transformed X shape: (100, 2) Transformed Y shape: (100, 2) Predicted Y (first 5 rows): [[ 0.123456 0.234567 0.345678] [ 0.456789 0.567890 0.678901] [-0.123456 -0.234567 -0.345678] [ 0.001234 0.012345 0.023456] [-0.456789 -0.567890 -0.678901]] ``` **Note:** Implement the PLSCanonical using the following steps and print the required outputs. Ensure the code is well-commented and follows Python coding conventions. ```python import numpy as np from sklearn.cross_decomposition import PLSCanonical # Step 1: Simulate data np.random.seed(0) X = np.random.normal(size=(100, 5)) Y = np.random.normal(size=(100, 3)) # Ensure data is centered X -= X.mean(axis=0) Y -= Y.mean(axis=0) # Step 2: Implement PLSCanonical with 2 components pls = PLSCanonical(n_components=2) # Step 3: Fit the model pls.fit(X, Y) # Step 4: Transform X and Y X_transformed, Y_transformed = pls.transform(X, Y) # Step 5: Predict Y from X Y_pred = pls.predict(X) # Step 6: Output results print(f\\"Transformed X shape: {X_transformed.shape}\\") print(f\\"Transformed Y shape: {Y_transformed.shape}\\") print(\\"Predicted Y (first 5 rows):\\") print(Y_pred[:5]) ```","solution":"import numpy as np from sklearn.cross_decomposition import PLSCanonical def simulate_data(): Simulates centered X and Y matrices for PLSCanonical with 100 samples and 5 features for X and 100 samples and 3 targets for Y. np.random.seed(0) X = np.random.normal(size=(100, 5)) Y = np.random.normal(size=(100, 3)) # Ensure data is centered X -= X.mean(axis=0) Y -= Y.mean(axis=0) return X, Y def pls_canonical(X, Y): Applies the PLSCanonical algorithm to the given matrices X and Y. Returns the transformed matrices and predictions of Y. # Step 2: Implement PLSCanonical with 2 components pls = PLSCanonical(n_components=2) # Step 3: Fit the model pls.fit(X, Y) # Step 4: Transform X and Y X_transformed, Y_transformed = pls.transform(X, Y) # Step 5: Predict Y from X Y_pred = pls.predict(X) return X_transformed, Y_transformed, Y_pred # Main execution if __name__ == \\"__main__\\": X, Y = simulate_data() X_transformed, Y_transformed, Y_pred = pls_canonical(X, Y) # Step 6: Output results print(f\\"Transformed X shape: {X_transformed.shape}\\") print(f\\"Transformed Y shape: {Y_transformed.shape}\\") print(\\"Predicted Y (first 5 rows):\\") print(Y_pred[:5])"},{"question":"**Coding Assessment Question** # Problem Statement You are tasked with implementing a function that processes large data sets securely using temporary files. Specifically, you will implement a function named `process_large_datafile` that reads a large input file, processes its contents, and writes the result to a new temporary file. To ensure the intermediate processing steps do not clutter the permanent filesystem, you will utilize the `tempfile` module to handle temporary files. # Function Signature ```python def process_large_datafile(input_file: str, process_function) -> str: pass ``` # Parameters - `input_file` (str): A string representing the path to the input file which contains data to be processed. - `process_function` (callable): A function that takes a line of data as input and returns the processed line. # Returns - `str`: The path of the temporary file containing the processed data. # Constraints - The `input_file` can be very large, hence reading the whole file into memory at once is not feasible. - The processing function will always return a non-empty string for each line of input. - The output temporary file should reside in the default temporary directory returned by `tempfile.gettempdir()`. - Ensure that intermediate temporary files are handled securely and removed after processing to prevent cluttering the filesystem. # Example Usage ```python def sample_processor(line: str) -> str: return line.strip().upper() # Let\'s assume \'large_input.txt\' is a path to a large file. result_file_path = process_large_datafile(\'large_input.txt\', sample_processor) print(f\'Processed data is stored in: {result_file_path}\') ``` # Explanation In this example: 1. The function `sample_processor` is defined to process each line by stripping whitespace and converting it to uppercase. 2. The `process_large_datafile` function reads the file `large_input.txt` line by line, processes each line using `sample_processor`, and writes the processed lines to a new temporary file. 3. The path to the temporary file containing the processed data is returned. # Notes - Utilize `tempfile.NamedTemporaryFile` to create a temporary file for writing processed data. - Use the `with` statement to ensure temporary files are closed and removed securely after use, where applicable. - Remember to handle exceptions and ensure the function is resilient to errors during file operations. Write your implementation of the function `process_large_datafile` below.","solution":"import tempfile def process_large_datafile(input_file: str, process_function) -> str: Processes a large data file, writing the result to a temporary file. Args: - input_file (str): The path to the input file. - process_function (callable): A function to process each line of the input file. Returns: - str: The path to the temporary file containing the processed data. with tempfile.NamedTemporaryFile(delete=False, mode=\'w\', dir=tempfile.gettempdir(), suffix=\'.txt\') as temp_file: temp_file_path = temp_file.name with open(input_file, \'r\') as infile: for line in infile: processed_line = process_function(line) temp_file.write(processed_line + \'n\') return temp_file_path"},{"question":"Objective: The objective of this question is to assess your understanding of the PyTorch JIT compiler, including scripting a model, saving and loading a TorchScript model, and verifying the functionality and performance improvements. Problem Statement: You are given the following simple PyTorch model: ```python import torch import torch.nn as nn class SimpleModel(nn.Module): def __init__(self): super(SimpleModel, self).__init__() self.linear = nn.Linear(10, 5) def forward(self, x): return self.linear(x) ``` Implement the following functions: 1. **script_and_save_model(model, save_path)**: - This function takes a PyTorch model and a file path. It scripts the model using the JIT compiler and saves the scripted model to the given path. - **Input**: - `model`: An instance of a PyTorch nn.Module model. - `save_path`: A string representing the path to save the scripted model. - **Output**: None 2. **load_and_evaluate_model(load_path, input_tensor)**: - This function takes a file path and an input tensor. It loads a scripted model from the given path, runs the model with the input tensor, and returns the output. - **Input**: - `load_path`: A string representing the path from which to load the scripted model. - `input_tensor`: A PyTorch tensor to be used as input to the loaded model. - **Output**: A PyTorch tensor which is the output of the model when run on the input tensor. 3. **performance_comparison(model, scripted_model, input_tensor)**: - This function compares the performance of the original and the scripted model by running them on the same input tensor and measuring inference time. - **Input**: - `model`: An instance of a PyTorch nn.Module model. - `scripted_model`: A scripted version of the PyTorch model. - `input_tensor`: A PyTorch tensor to be used as input to the models. - **Output**: A tuple with two floats representing the average time taken (in milliseconds) for inference by the original model and the scripted model, respectively, over 100 runs each. **Note**: Use `torch.jit.script()` for scripting the model and `torch.jit.save()` & `torch.jit.load()` for saving and loading the model, respectively. Use `time` to measure performance. Example Usage: ```python # Initialize model and input tensor model = SimpleModel() input_tensor = torch.randn(1, 10) # Script and save the model save_path = \\"simple_model_scripted.pt\\" script_and_save_model(model, save_path) # Load and evaluate the scripted model output = load_and_evaluate_model(save_path, input_tensor) # Performance comparison scripted_model = torch.jit.load(save_path) original_time, scripted_time = performance_comparison(model, scripted_model, input_tensor) print(f\\"Output: {output}\\") print(f\\"Original Model Inference Time: {original_time} ms\\") print(f\\"Scripted Model Inference Time: {scripted_time} ms\\") ``` Constraints: - You can assume the model parameters and structure do not change during the execution. - You can assume the file paths provided are valid and writable/readable. - Your solution should handle any necessary imports.","solution":"import torch import torch.nn as nn import time class SimpleModel(nn.Module): def __init__(self): super(SimpleModel, self).__init__() self.linear = nn.Linear(10, 5) def forward(self, x): return self.linear(x) def script_and_save_model(model, save_path): This function scripts the model using the JIT compiler and saves the scripted model. :param model: An instance of a PyTorch nn.Module model. :param save_path: A string representing the path to save the scripted model. scripted_model = torch.jit.script(model) torch.jit.save(scripted_model, save_path) def load_and_evaluate_model(load_path, input_tensor): This function loads a scripted model from file, runs the model with the input tensor, and returns the output. :param load_path: A string representing the path from which to load the scripted model. :param input_tensor: A PyTorch tensor to be used as input to the loaded model. :return: A PyTorch tensor which is the output of the model when run on the input tensor. scripted_model = torch.jit.load(load_path) return scripted_model(input_tensor) def performance_comparison(model, scripted_model, input_tensor): This function compares the performance of the original and scripted model by measuring inference time. :param model: An instance of a PyTorch nn.Module model. :param scripted_model: A scripted version of the PyTorch model. :param input_tensor: A PyTorch tensor to be used as input to the models. :return: A tuple with two floats representing the average time taken (in milliseconds) for inference by the original model and the scripted model, respectively. # Warm-up runs to load necessary parts into memory for _ in range(10): model(input_tensor) scripted_model(input_tensor) # Performance measurement for original model original_start_time = time.time() for _ in range(100): model(input_tensor) original_end_time = time.time() # Performance measurement for scripted model scripted_start_time = time.time() for _ in range(100): scripted_model(input_tensor) scripted_end_time = time.time() original_avg_time = (original_end_time - original_start_time) / 100 * 1000 # Convert to milliseconds scripted_avg_time = (scripted_end_time - scripted_start_time) / 100 * 1000 # Convert to milliseconds return original_avg_time, scripted_avg_time"},{"question":"**Question: Handling Missing Data in a DataFrame** You are given a DataFrame containing employee data. The DataFrame includes columns for \'Employee ID\', \'Name\', \'Age\', \'Designation\', \'Department\', and \'Salary\'. Unfortunately, some of this data is incomplete, and your task is to handle the missing values according to the following rules: 1. **Identification:** Identify the missing values in the DataFrame and print the total count of missing values for each column. 2. **Filling Missing Values:** - For the \'Age\' column, replace missing values with the average age. - For the \'Department\' column, replace missing values with the most frequent department. - For the \'Salary\' column, replace missing values via linear interpolation. 3. **Dropping Rows:** Drop any rows where the \'Name\' or \'Employee ID\' is missing, as these are considered essential for identification. 4. **Replacing Values:** Replace any occurrence of \'NA\' (interpreted as a string) in \'Designation\' with \'Unknown\'. Implement the function `handle_employee_data(df: pd.DataFrame) -> pd.DataFrame` that performs the above tasks and returns the modified DataFrame. # Input - `df`: A pandas DataFrame containing columns \'Employee ID\', \'Name\', \'Age\', \'Designation\', \'Department\', and \'Salary\'. # Output - Return the modified DataFrame with the missing values handled according to the specified rules. # Example Suppose you have a DataFrame: ```python data = { \'Employee ID\': [1, 2, np.nan, 4, 5], \'Name\': [\'Alice\', \'Bob\', None, \'David\', \'Emma\'], \'Age\': [25, None, 30, None, 50], \'Designation\': [\'Engineer\', \'NA\', \'Manager\', \'Analyst\', \'NA\'], \'Department\': [\'HR\', \'Finance\', None, \'IT\', \'Finance\'], \'Salary\': [50000, 60000, 70000, np.nan, 120000] } df = pd.DataFrame(data) ``` The output DataFrame should look like: ```python Employee ID Name Age Designation Department Salary 0 1.0 Alice 25.0 Engineer HR 50000.0 1 2.0 Bob 35.0 Unknown Finance 60000.0 3 4.0 David 35.0 Analyst IT 95000.0 4 5.0 Emma 50.0 Unknown Finance 120000.0 ``` # Constraints 1. Assume that all the columns in the DataFrame are relevant and need to be considered for missing data handling. 2. Assume the DataFrame may contain other inappropriate values that need to be addressed as described in the task (e.g. \'NA\' strings in \'Designation\'). # Notes - Use pandas\' built-in methods such as `isna`, `fillna`, `dropna`, and `interpolate`. - The average and most frequent values should be calculated from the non-missing data in their respective columns. - Ensure that no new missing values are introduced during the handling process.","solution":"import pandas as pd import numpy as np def handle_employee_data(df: pd.DataFrame) -> pd.DataFrame: # Identification: Print the total count of missing values for each column missing_counts = df.isna().sum() print(\\"Missing values per column:\\") print(missing_counts) # Filling missing values in \'Age\' column with the average age avg_age = df[\'Age\'].mean() df[\'Age\'] = df[\'Age\'].fillna(avg_age) # Filling missing values in \'Department\' column with the most frequent department most_freq_dept = df[\'Department\'].mode().iloc[0] df[\'Department\'] = df[\'Department\'].fillna(most_freq_dept) # Filling missing values in \'Salary\' column via linear interpolation df[\'Salary\'] = df[\'Salary\'].interpolate() # Dropping rows where \'Name\' or \'Employee ID\' is missing df = df.dropna(subset=[\'Employee ID\', \'Name\']) # Replacing \'NA\' in \'Designation\' with \'Unknown\' df[\'Designation\'] = df[\'Designation\'].replace(\'NA\', \'Unknown\') return df"},{"question":"Coding Assessment Question # Context You are a data scientist working on visualizing a dataset using seaborn. You need to create distinct and visually appealing color palettes for different types of plots. To demonstrate your understanding of seaborn\'s advanced color palette functionalities, you will implement a function to create, customize, and apply various palettes. # Problem Statement Write a function `custom_palette_plot(data, column, palette_type, color_spec, num_colors=6, as_cmap=False)` that: 1. **Creates** a customized color palette based on the given `palette_type` and `color_spec`. 2. **Applies** this palette to a seaborn plot to visualize a specified column from the input `data`. 3. Returns and displays the plot. Function Signature ```python def custom_palette_plot(data, column, palette_type, color_spec, num_colors=6, as_cmap=False): pass ``` # Input - `data` (pd.DataFrame): A pandas DataFrame containing the dataset. - `column` (str): The name of the column in the DataFrame to be visualized. - `palette_type` (str): A string indicating the type of color specification: \\"named\\", \\"hex\\", or \\"husl\\". - `color_spec` (str or tuple): The actual color specification: - If `palette_type` is \\"named\\", a string specifying the color name. - If `palette_type` is \\"hex\\", a string specifying the hex code. - If `palette_type` is \\"husl\\", a tuple specifying the husl values. - `num_colors` (int): The number of colors in the palette (default is 6). - `as_cmap` (bool): A boolean indicating whether to return the palette as a continuous colormap (default is False). # Output - Displays and returns a seaborn plot visualizing the specified column from the provided dataset using the created palette. # Constraints - The `data` DataFrame must contain the specified `column`. - The `palette_type` must be one of \\"named\\", \\"hex\\", or \\"husl\\". - The `color_spec` must match the format corresponding to the `palette_type`. # Example ```python import seaborn as sns import pandas as pd # Example DataFrame data = pd.DataFrame({\'values\': [1, 2, 3, 4, 5], \'categories\': [\'A\', \'B\', \'C\', \'D\', \'E\']}) # Usage custom_palette_plot(data, \'categories\', \'named\', \'seagreen\', 5) ``` This function should demonstrate your understanding of seaborn\'s coloring capabilities by dynamically creating and applying color palettes based on various types of color specifications and visual requirements.","solution":"import seaborn as sns import pandas as pd import matplotlib.pyplot as plt def custom_palette_plot(data, column, palette_type, color_spec, num_colors=6, as_cmap=False): Creates a customized color palette based on the given `palette_type` and `color_spec`, and applies this palette to a seaborn plot to visualize the specified column from the input `data`. Parameters: - data (pd.DataFrame): A pandas DataFrame containing the dataset. - column (str): The name of the column in the DataFrame to be visualized. - palette_type (str): The type of color specification: \\"named\\", \\"hex\\", or \\"husl\\". - color_spec (str or tuple): The actual color specification based on palette_type. - num_colors (int): Number of colors in the palette (default is 6). - as_cmap (bool): Whether to return the palette as a continuous colormap (default is False). Returns: - A seaborn plot visualizing the specified column using the created palette. # Create palette based on type if palette_type == \'named\': palette = sns.color_palette([color_spec] * num_colors) elif palette_type == \'hex\': palette = sns.color_palette([color_spec] * num_colors) elif palette_type == \'husl\': palette = sns.color_palette(\\"husl\\", num_colors) else: raise ValueError(\\"Invalid palette_type. Must be one of \'named\', \'hex\', or \'husl\'.\\") if as_cmap: palette = sns.color_palette(palette, as_cmap=True) # Plot using the created palette sns.set_palette(palette) plt.figure(figsize=(10, 6)) sns.countplot(x=column, data=data) plt.show() return plt"},{"question":"**Coding Assessment Question** # Objective Implement a hierarchical data structure to manage company employees using Python\'s `dataclasses` module. This structure should support various functionalities, including calculating team budgets, dynamically updating employee information, and ensuring data integrity through immutability. # Specifications 1. **Class Definitions**: - Implement a `Person` class with the following fields: - `name` (a string representing the name) - `age` (an integer representing the age) - Implement an `Employee` class that inherits from `Person` with additional fields: - `employee_id` (an integer representing a unique employee ID) - `position` (a string representing the job title) - `salary` (a float representing annual salary) - `department` (a string representing the department name) - `project_ids` (a list of integers representing project IDs, which should use a `default_factory`) 2. **Team and Project Management**: - Implement a `Project` class with the following fields: - `project_id` (an integer representing a unique project ID) - `name` (a string representing the project\'s name) - `budget` (a float representing the project\'s budget) - Implement a `Team` class with the following fields: - `team_name` (a string representing the name of the team) - `members` (a list of `Employee` instances, which should use a `default_factory`) 3. **Constraints and Features**: - Ensure that the `Employee` class has appropriate equality and ordering based on `employee_id`. - Implement immutability for the `Project` class to make it read-only after initialization. - Provide a `total_team_budget` method in the `Team` class to calculate the total salary of all team members. - Implement a `reassign_project` method in the `Team` class to: - Remove a given project ID from one employee and assign it to another employee within the same team. - Raise an exception if any employee has a project ID that is not within their current list of projects, indicating invalid data. 4. **Input/Output**: - Functions and methods within these classes should print relevant information indicating successful operations or errors. # Example Usage ```python from dataclasses import dataclass, field @dataclass class Person: name: str age: int @dataclass class Employee(Person): employee_id: int position: str salary: float department: str project_ids: list = field(default_factory=list) @dataclass(frozen=True) class Project: project_id: int name: str budget: float @dataclass class Team: team_name: str members: list[Employee] = field(default_factory=list) def total_team_budget(self) -> float: return sum(member.salary for member in self.members) def reassign_project(self, from_employee_id: int, to_employee_id: int, project_id: int): from_employee = next((emp for emp in self.members if emp.employee_id == from_employee_id), None) to_employee = next((emp for emp in self.members if emp.employee_id == to_employee_id), None) if not from_employee or not to_employee: raise ValueError(\\"Invalid employee ID(s).\\") if project_id not in from_employee.project_ids: raise ValueError(f\\"Project ID {project_id} is not assigned to employee ID {from_employee_id}.\\") from_employee.project_ids.remove(project_id) to_employee.project_ids.append(project_id) # Example team = Team(\\"Developers\\") e1 = Employee(name=\\"Alice\\", age=30, employee_id=1, position=\\"Developer\\", salary=60000, department=\\"IT\\", project_ids=[101, 102]) e2 = Employee(name=\\"Bob\\", age=28, employee_id=2, position=\\"Developer\\", salary=62000, department=\\"IT\\") team.members.extend([e1, e2]) print(team.total_team_budget()) # Output: 122000.0 team.reassign_project(1, 2, 101) print(e1.project_ids) # Output: [102] print(e2.project_ids) # Output: [101] ``` # Note: Ensure the solution leverages the features provided by the `dataclasses` module, including appropriate use of `fields`, immutability with `frozen`, and custom method implementations for tasks like reassigning projects.","solution":"from dataclasses import dataclass, field from typing import List @dataclass class Person: name: str age: int @dataclass(order=True) class Employee(Person): employee_id: int position: str salary: float department: str project_ids: List[int] = field(default_factory=list) @dataclass(frozen=True) class Project: project_id: int name: str budget: float @dataclass class Team: team_name: str members: List[Employee] = field(default_factory=list) def total_team_budget(self) -> float: return sum(member.salary for member in self.members) def reassign_project(self, from_employee_id: int, to_employee_id: int, project_id: int): from_employee = next((emp for emp in self.members if emp.employee_id == from_employee_id), None) to_employee = next((emp for emp in self.members if emp.employee_id == to_employee_id), None) if not from_employee: raise ValueError(f\\"Employee with ID {from_employee_id} not found in the team.\\") if not to_employee: raise ValueError(f\\"Employee with ID {to_employee_id} not found in the team.\\") if project_id not in from_employee.project_ids: raise ValueError(f\\"Project ID {project_id} is not assigned to employee ID {from_employee_id}.\\") from_employee.project_ids.remove(project_id) to_employee.project_ids.append(project_id)"},{"question":"# Unicode String Manipulation and Encoding Challenge **Objective**: Implement a set of functions to create, manipulate, and encode/decode Unicode strings using Python310\'s Unicode APIs. **Description**: You are tasked with creating functions that handle Unicode strings efficiently. The functions must create Unicode objects, modify them, and perform various encoding/decoding operations following the current best practices and avoiding deprecated APIs. **Function 1: Create a Unicode String** ```python def create_unicode_string(text: str) -> object: Create a Unicode string object from the given UTF-8 encoded string. Parameters: text (str): A UTF-8 encoded string. Returns: object: A PyUnicodeObject representing the Unicode string. pass ``` **Function 2: Modify a Unicode String** ```python def modify_unicode_string(unicode_obj: object, index: int, new_char: str) -> object: Modify a Unicode string object by replacing the character at the specified index with a new character. Parameters: unicode_obj (object): A PyUnicodeObject representing the original Unicode string. index (int): The index of the character to be replaced (0-based). new_char (str): A single-character string to replace the existing character. Returns: object: A new PyUnicodeObject with the modified string. pass ``` **Function 3: Encode a Unicode String to UTF-8** ```python def encode_to_utf8(unicode_obj: object) -> bytes: Encode the given Unicode string object to a UTF-8 encoded bytes object. Parameters: unicode_obj (object): A PyUnicodeObject representing the Unicode string. Returns: bytes: The UTF-8 encoded representation of the string. pass ``` **Function 4: Decode a UTF-8 encoded byte string to Unicode** ```python def decode_from_utf8(byte_obj: bytes) -> object: Decode the given UTF-8 encoded bytes object back to a Unicode string object. Parameters: byte_obj (bytes): A UTF-8 encoded bytes object. Returns: object: A PyUnicodeObject representing the decoded Unicode string. pass ``` # Constraints 1. Assume all inputs are valid and focus on the use of Python310 APIs as described in the documentation. 2. Ensure no deprecated APIs are used in your implementations. 3. Efficiently handle memory and exceptions where applicable. # Example Usage ```python # Example usage of the functions: unicode_str = create_unicode_string(\\"Hello, World!\\") modified_str = modify_unicode_string(unicode_str, 7, \\"U\\") utf8_encoded = encode_to_utf8(modified_str) decoded_str = decode_from_utf8(utf8_encoded) assert decoded_str == modified_str ``` # Evaluation Criteria: 1. Correctness of function implementations. 2. Proper usage of Python310 Unicode APIs. 3. Avoidance of deprecated APIs. 4. Efficiency and handling of exceptions. All necessary information for solving the problem is provided. You may assume access to all functions and types as described in the documentation.","solution":"def create_unicode_string(text: str) -> str: Create a Unicode string object from the given UTF-8 encoded string. Parameters: text (str): A UTF-8 encoded string. Returns: str: A Unicode string. # In Python, all strings are Unicode by default. return text def modify_unicode_string(unicode_obj: str, index: int, new_char: str) -> str: Modify a Unicode string object by replacing the character at the specified index with a new character. Parameters: unicode_obj (str): A Unicode string. index (int): The index of the character to be replaced (0-based). new_char (str): A single-character string to replace the existing character. Returns: str: A new Unicode string with the modified content. if not (0 <= index < len(unicode_obj)): raise IndexError(\\"Index out of range\\") if len(new_char) != 1: raise ValueError(\\"New character must be a single character.\\") # Strings are immutable in Python, so we create a new string return unicode_obj[:index] + new_char + unicode_obj[index + 1:] def encode_to_utf8(unicode_obj: str) -> bytes: Encode the given Unicode string object to a UTF-8 encoded bytes object. Parameters: unicode_obj (str): A Unicode string. Returns: bytes: The UTF-8 encoded representation of the string. return unicode_obj.encode(\'utf-8\') def decode_from_utf8(byte_obj: bytes) -> str: Decode the given UTF-8 encoded bytes object back to a Unicode string object. Parameters: byte_obj (bytes): A UTF-8 encoded bytes object. Returns: str: A Unicode string. return byte_obj.decode(\'utf-8\')"},{"question":"Objective Write a Python script to manage directories and files using the `os` module. Problem Statement You are required to write a function `organize_files_by_extension` that takes a directory path as input and organizes all files in that directory into subdirectories based on their file extensions. Requirements: 1. The function should create a subdirectory for each file extension found in the provided directory if it doesn\'t already exist. 2. Each file should be moved to its corresponding subdirectory based on its extension. 3. If a file does not have an extension, it should be moved to a subdirectory named `other`. Function Signature ```python def organize_files_by_extension(directory: str) -> None: pass ``` Input - `directory`: A string representing the path to the directory to organize. Output - The function should not return anything. The organization should be done in place. Constraints - The directory may contain nested directories, but only the files in the top-level directory should be organized. - The function must handle cases where no files or only directories are present in the specified directory. - Assume the directory path provided always exists. Example Suppose the directory `/example` contains the following files: ``` example ├── file1.txt ├── file2.jpg ├── file3.txt ├── file4.png ├── file5 ``` After calling `organize_files_by_extension(\'/example\')`, the directory should be organized as: ``` example ├── txt │ ├── file1.txt │ ├── file3.txt ├── jpg │ ├── file2.jpg ├── png │ ├── file4.png ├── other │ ├── file5 ``` Notes: - Use the `os` module for file and directory manipulations. - You may also find the `shutil` module useful for moving files.","solution":"import os import shutil def organize_files_by_extension(directory: str) -> None: Organizes files in the specified directory into subdirectories based on their file extensions. If a file does not have an extension, it will be moved to a subdirectory named \'other\'. :param directory: str, The path to the directory to organize. if not os.path.isdir(directory): raise ValueError(\\"The provided path is not a directory.\\") for item in os.listdir(directory): item_path = os.path.join(directory, item) if os.path.isfile(item_path): _, ext = os.path.splitext(item) ext = ext.lstrip(\'.\').lower() sub_dir_name = ext if ext else \'other\' sub_dir_path = os.path.join(directory, sub_dir_name) if not os.path.exists(sub_dir_path): os.makedirs(sub_dir_path) shutil.move(item_path, os.path.join(sub_dir_path, item))"},{"question":"Objective Demonstrate your understanding of the `cProfile` and `pstats` modules by implementing a profiling function and analyzing the profiling results. Problem Statement You are given a Python script that calculates the nth Fibonacci number using both an iterative and recursive approach. Your task is to: 1. Profile the execution of the functions using the `cProfile` module. 2. Analyze the profiling results using the `pstats` module. 3. Identify which approach (iterative vs recursive) is more efficient for calculating the nth Fibonacci number. Script ```python def fib_recursive(n): if n <= 1: return n else: return fib_recursive(n - 1) + fib_recursive(n - 2) def fib_iterative(n): a, b = 0, 1 for _ in range(n): a, b = b, a + b return a def main(): n = 30 # You can change this value for testing print(\\"Recursive approach result:\\", fib_recursive(n)) print(\\"Iterative approach result:\\", fib_iterative(n)) if __name__ == \\"__main__\\": main() ``` Tasks 1. **Profile the Functions**: - Create a function `profile_fib_functions()` that profiles both `fib_recursive()` and `fib_iterative()` for calculating the 30th Fibonacci number. Use the `cProfile` module to generate profiling results and save them to separate files named `recursive_profile.dat` and `iterative_profile.dat`. 2. **Analyze the Profiling Results**: - Create a function `analyze_profiles()` that uses the `pstats` module to load and analyze the profiling data from `recursive_profile.dat` and `iterative_profile.dat`. - Print the top 10 functions sorted by cumulative time for each profiling result. - Determine which approach (iterative or recursive) is more efficient and explain why based on the profiling results. Constraints 1. The `fib_recursive()` and `fib_iterative()` functions should not be modified. 2. The profiling should be done separately for each function. 3. The analysis should clearly indicate the more efficient approach with a brief explanation. Requirements 1. Implement the `profile_fib_functions()` and `analyze_profiles()` functions. 2. Ensure that the profiling results are saved and analyzed correctly. 3. Provide a clear output indicating the more efficient approach. Expected Output Your implementation should produce profiling results and analysis similar to the following: ``` Profiling for the recursive approach saved to recursive_profile.dat Profiling for the iterative approach saved to iterative_profile.dat Top 10 functions sorted by cumulative time for recursive approach: ncalls tottime percall cumtime percall filename:lineno(function) ... [output truncated for brevity] ... Top 10 functions sorted by cumulative time for iterative approach: ncalls tottime percall cumtime percall filename:lineno(function) ... [output truncated for brevity] ... More efficient approach: Iterative Explanation: The iterative approach has a lower cumulative time compared to the recursive approach, making it more efficient for calculating the 30th Fibonacci number. ``` Good luck!","solution":"import cProfile import pstats import io def fib_recursive(n): if n <= 1: return n else: return fib_recursive(n - 1) + fib_recursive(n - 2) def fib_iterative(n): a, b = 0, 1 for _ in range(n): a, b = b, a + b return a def profile_fib_functions(): # Profile recursive approach profile_recursive = cProfile.Profile() profile_recursive.enable() fib_recursive(30) profile_recursive.disable() profile_recursive.dump_stats(\'recursive_profile.dat\') print(\\"Profiling for the recursive approach saved to recursive_profile.dat\\") # Profile iterative approach profile_iterative = cProfile.Profile() profile_iterative.enable() fib_iterative(30) profile_iterative.disable() profile_iterative.dump_stats(\'iterative_profile.dat\') print(\\"Profiling for the iterative approach saved to iterative_profile.dat\\") def analyze_profiles(): # Analyze recursive profile recursive_stats = pstats.Stats(\'recursive_profile.dat\') print(\\"Top 10 functions sorted by cumulative time for recursive approach:\\") recursive_stats.sort_stats(\'cumulative\').print_stats(10) # Analyze iterative profile iterative_stats = pstats.Stats(\'iterative_profile.dat\') print(\\"Top 10 functions sorted by cumulative time for iterative approach:\\") iterative_stats.sort_stats(\'cumulative\').print_stats(10) # Determine and explain more efficient approach recursive_cumtime = recursive_stats.total_tt iterative_cumtime = iterative_stats.total_tt if recursive_cumtime > iterative_cumtime: print(\\"More efficient approach: Iterative\\") print(\\"Explanation: The iterative approach has a lower cumulative time compared to the recursive approach, making it more efficient for calculating the 30th Fibonacci number.\\") else: print(\\"More efficient approach: Recursive\\") print(\\"Explanation: The recursive approach has a lower cumulative time compared to the iterative approach, making it more efficient for calculating the 30th Fibonacci number.\\") if __name__ == \\"__main__\\": profile_fib_functions() analyze_profiles()"},{"question":"You are provided with the `titanic` dataset using Seaborn. Your task is to perform exploratory data analysis and visualize various aspects of the dataset. Specifically, you need to perform the following tasks: 1. **Load the `titanic` dataset**: Load the dataset using Seaborn\'s built-in function. 2. **Inspect and prepare the data**: Perform basic data inspection to understand the dataset\'s structure. Check for any missing values and handle them appropriately if necessary. 3. **Visualize class distribution**: - Create a count plot of the passengers\' classes (`class`). - Group the counts by survival status (`survived`) and visualize the counts. 4. **Visualize age distribution**: - Create a histogram or KDE plot showing the age distribution of passengers. - Overlay the survival status on the same plot to distinguish between survived and non-survived passengers. 5. **Visualize survival by gender and class**: - Create a bar plot to show the survival rate based on gender and passenger class (`class`). - Use the `hue` parameter to differentiate between genders within each class. 6. **Composite plot**: - Combine the above visualizations into a single figure with multiple subplots for a comprehensive view of the dataset. # Input Format: - You don\'t need to provide any input; the `titanic` dataset can be directly loaded using Seaborn. # Output Format: - Relevant plots for each task should be displayed as output. # Constraints and Notes: - Ensure your plots are clearly labeled with titles, axis labels, legends, etc. - Handle missing values in an appropriate manner (ignoring or filling). # Example Code: ```python import seaborn as sns import matplotlib.pyplot as plt # Load the dataset titanic = sns.load_dataset(\\"titanic\\") # Task 1: Inspect the data print(titanic.info()) # Task 2: Visualize class distribution plt.figure(figsize=(12, 6)) # Count plot for class plt.subplot(2, 2, 1) sns.countplot(data=titanic, x=\\"class\\") plt.title(\\"Count of Passengers by Class\\") # Count plot for class grouped by survival plt.subplot(2, 2, 2) sns.countplot(data=titanic, x=\\"class\\", hue=\\"survived\\") plt.title(\\"Count of Passengers by Class and Survival Status\\") # Task 3: Visualize age distribution plt.subplot(2, 2, 3) sns.histplot(data=titanic, x=\\"age\\", hue=\\"survived\\", kde=True) plt.title(\\"Age Distribution by Survival Status\\") # Task 4: Visualize survival by gender and class plt.subplot(2, 2, 4) sns.barplot(data=titanic, x=\\"class\\", y=\\"survived\\", hue=\\"sex\\") plt.title(\\"Survival Rate by Gender and Class\\") plt.tight_layout() plt.show() ``` Evaluation: - Correctness of the plots. - Proper handling of missing values. - Clarity and readability of the plots (titles, labels, etc.). - Efficient and clean code.","solution":"import seaborn as sns import matplotlib.pyplot as plt def load_data(): Load the Titanic dataset using Seaborn\'s built-in function. return sns.load_dataset(\\"titanic\\") def inspect_and_prepare_data(df): Perform basic data inspection and handle missing values if necessary. For the sake of visualization, we will ignore missing values. print(df.info()) print(df.describe()) print(df.isnull().sum()) def visualize_class_distribution(df): Create a count plot of the passengers\' classes and group the counts by survival status. plt.figure(figsize=(12, 6)) plt.subplot(1, 2, 1) sns.countplot(data=df, x=\\"class\\") plt.title(\\"Count of Passengers by Class\\") plt.subplot(1, 2, 2) sns.countplot(data=df, x=\\"class\\", hue=\\"survived\\") plt.title(\\"Count of Passengers by Class and Survival Status\\") plt.tight_layout() plt.show() def visualize_age_distribution(df): Create a histogram or KDE plot showing the age distribution of passengers, overlaid with survival status. plt.figure(figsize=(12, 6)) sns.histplot(data=df, x=\\"age\\", hue=\\"survived\\", multiple=\\"stack\\", kde=True) plt.title(\\"Age Distribution by Survival Status\\") plt.xlabel(\\"Age\\") plt.ylabel(\\"Count\\") plt.show() def visualize_survival_by_gender_and_class(df): Create a bar plot to show the survival rate based on gender and passenger class. plt.figure(figsize=(12, 6)) sns.barplot(data=df, x=\\"class\\", y=\\"survived\\", hue=\\"sex\\", ci=None) plt.title(\\"Survival Rate by Gender and Class\\") plt.xlabel(\\"Class\\") plt.ylabel(\\"Survival Rate\\") plt.show() def composite_plot(df): Combine the visualizations into a single figure with multiple subplots. plt.figure(figsize=(16, 12)) plt.subplot(2, 2, 1) sns.countplot(data=df, x=\\"class\\") plt.title(\\"Count of Passengers by Class\\") plt.subplot(2, 2, 2) sns.countplot(data=df, x=\\"class\\", hue=\\"survived\\") plt.title(\\"Count of Passengers by Class and Survival Status\\") plt.subplot(2, 2, 3) sns.histplot(data=df, x=\\"age\\", hue=\\"survived\\", multiple=\\"stack\\", kde=True) plt.title(\\"Age Distribution by Survival Status\\") plt.xlabel(\\"Age\\") plt.ylabel(\\"Count\\") plt.subplot(2, 2, 4) sns.barplot(data=df, x=\\"class\\", y=\\"survived\\", hue=\\"sex\\", ci=None) plt.title(\\"Survival Rate by Gender and Class\\") plt.xlabel(\\"Class\\") plt.ylabel(\\"Survival Rate\\") plt.tight_layout() plt.show()"},{"question":"Question: Creating a Customizable Seaborn Plot You are tasked with creating a function that generates customizable seaborn plots based on user inputs. The function should demonstrate your understanding of seaborn\'s capability to adjust plot aesthetics, context, and styles dynamically. Function Signature ```python def create_custom_plot(data, plot_type, style=\\"darkgrid\\", context=\\"notebook\\", despine=False, **kwargs): Creates a customized seaborn plot based on user specifications. Parameters: data (DataFrame or array-like): The dataset that needs to be plotted. plot_type (str): Type of seaborn plot to create. Options: \'boxplot\', \'violinplot\', \'lineplot\', \'scatterplot\'. style (str): The seaborn style to apply. Default is \\"darkgrid\\". context (str): The seaborn context to apply. Options: \\"paper\\", \\"notebook\\", \\"talk\\", \\"poster\\". Default is \\"notebook\\". despine (bool): Whether to remove the top and right spines. Default is False. **kwargs: Additional keyword arguments to pass to the seaborn plotting function. Returns: None: Displays the plot. ``` Requirements 1. The function should accept the following parameters: - `data`: A DataFrame or array-like dataset to visualize. - `plot_type`: A string specifying the type of seaborn plot (boxplot, violinplot, lineplot, scatterplot). - `style`: A string specifying the seaborn plot style (darkgrid, whitegrid, dark, white, ticks). - `context`: A string specifying the seaborn plot context (paper, notebook, talk, poster). - `despine`: A boolean indicating whether to remove the top and right spines of the plot. - `**kwargs`: Additional keyword arguments that are passed to the seaborn plotting function. 2. Use appropriate seaborn functions to set the plot style and context. 3. Based on the value of `plot_type`, create the corresponding seaborn plot. 4. If `despine` is True, remove the top and right spines. 5. Pass any additional keyword arguments to the seaborn plotting function to allow further customization of the plot. 6. Display the final plot. Example Usage ```python import seaborn as sns import matplotlib.pyplot as plt import numpy as np import pandas as pd # Sample data data = pd.DataFrame(np.random.randn(100, 4), columns=list(\\"ABCD\\")) # Function call to create a boxplot create_custom_plot(data, plot_type=\\"boxplot\\", style=\\"whitegrid\\", context=\\"talk\\", despine=True, palette=\\"deep\\") # Function call to create a scatterplot create_custom_plot(data[[\'A\', \'B\']], plot_type=\\"scatterplot\\", style=\\"ticks\\", context=\\"paper\\", marker=\\"+\\") ``` Constraints - Ensure the input `plot_type` and `context` are valid. - The function should be robust and handle incorrect inputs gracefully, providing meaningful error messages. **Good Luck!**","solution":"import seaborn as sns import matplotlib.pyplot as plt def create_custom_plot(data, plot_type, style=\\"darkgrid\\", context=\\"notebook\\", despine=False, **kwargs): Creates a customized seaborn plot based on user specifications. Parameters: data (DataFrame or array-like): The dataset that needs to be plotted. plot_type (str): Type of seaborn plot to create. Options: \'boxplot\', \'violinplot\', \'lineplot\', \'scatterplot\'. style (str): The seaborn style to apply. Default is \\"darkgrid\\". context (str): The seaborn context to apply. Options: \\"paper\\", \\"notebook\\", \\"talk\\", \\"poster\\". Default is \\"notebook\\". despine (bool): Whether to remove the top and right spines. Default is False. **kwargs: Additional keyword arguments to pass to the seaborn plotting function. Returns: None: Displays the plot. # Set the seaborn style and context sns.set_style(style) sns.set_context(context) # Define a dictionary of possible plot functions plot_functions = { \'boxplot\': sns.boxplot, \'violinplot\': sns.violinplot, \'lineplot\': sns.lineplot, \'scatterplot\': sns.scatterplot } # Check if plot_type is valid if plot_type not in plot_functions: raise ValueError(f\\"Invalid plot_type: {plot_type}. Expected one of: {list(plot_functions.keys())}\\") # Generate the plot plot_function = plot_functions[plot_type] plot_function(data=data, **kwargs) # Despine if required if despine: sns.despine() # Show the plot plt.show()"},{"question":"**Objective**: Demonstrate your understanding of loading datasets from openml.org, preprocessing the data, and using it for a simple classification task. **Question**: You are required to perform the following tasks using scikit-learn and its datasets module: 1. **Load the Dataset**: - Use the `fetch_openml` function to load the \\"miceprotein\\" dataset from openml.org. 2. **Preprocess the Data**: - Split the dataset into features (`X`) and target (`y`). - Divide the dataset into a training set (80%) and a test set (20%) using `train_test_split` from scikit-learn. - Normalize the feature data to have zero mean and unit variance using `StandardScaler`. 3. **Train a Model**: - Train a `RandomForestClassifier` on the training data. 4. **Evaluate the Model**: - Evaluate the model on the test data and print the accuracy score. **Constraints**: - You must use `fetch_openml` to load the dataset. - Ensure reproducibility by setting a random seed for the train-test split and the RandomForestClassifier. **Input Format**: - None (all functions and operations should be encapsulated in your code). **Output Format**: - Print statements showing: - Shape of the dataset (features and target). - Shape of the training and test splits. - Accuracy of the trained model on the test data. # Example Output ``` Dataset shape (features, target): (1080, 77) (1080,) Training set shape: (864, 77) (864,) Test set shape: (216, 77) (216,) Model accuracy on test data: 0.85 ``` **Function Signature**: ```python def main(): from sklearn.datasets import fetch_openml from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score # Step 1: Load the data mice = fetch_openml(name=\'miceprotein\', version=4) # Step 2: Preprocess the data X = mice.data y = mice.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) # Step 3: Train the model clf = RandomForestClassifier(random_state=42) clf.fit(X_train, y_train) # Step 4: Evaluate the model y_pred = clf.predict(X_test) accuracy = accuracy_score(y_test, y_pred) # Print results print(f\\"Dataset shape (features, target): {X.shape} {y.shape}\\") print(f\\"Training set shape: {X_train.shape} {y_train.shape}\\") print(f\\"Test set shape: {X_test.shape} {y_test.shape}\\") print(f\\"Model accuracy on test data: {accuracy:.2f}\\") if __name__ == \\"__main__\\": main() ```","solution":"def main(): from sklearn.datasets import fetch_openml from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score # Step 1: Load the data mice = fetch_openml(name=\'miceprotein\', version=4) # Step 2: Preprocess the data X = mice.data y = mice.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) # Step 3: Train the model clf = RandomForestClassifier(random_state=42) clf.fit(X_train, y_train) # Step 4: Evaluate the model y_pred = clf.predict(X_test) accuracy = accuracy_score(y_test, y_pred) # Print results print(f\\"Dataset shape (features, target): {X.shape} {y.shape}\\") print(f\\"Training set shape: {X_train.shape} {y_train.shape}\\") print(f\\"Test set shape: {X_test.shape} {y_test.shape}\\") print(f\\"Model accuracy on test data: {accuracy:.2f}\\") if __name__ == \\"__main__\\": main()"},{"question":"**Objective:** To assess your understanding and ability to work with Python\'s \\"array\\" module, particularly focusing on creating arrays, performing various operations, and ensuring type safety. **Problem Statement:** You are required to implement a function `process_array` which satisfies the following requirements: 1. Takes as input: - `type_code` (a string): A single character denoting the array type. - `initializer` (a list or string): Initial values to populate the array. - `operations` (a list of dictionaries): Each dictionary describes an operation to perform on the array. 2. The function should: - Create an array using the given `type_code` and `initializer`. - Iterate through the `operations` list and apply each specified operation on the array. - Return the resultant array in the form of a Python list. **Operations:** Each operation dictionary in `operations` has the following structure: - `\\"operation\\"`: A string specifying the operation name. Possible values are: * `\\"append\\"` - Append a value to the end of the array. * `\\"insert\\"` - Insert a value at a specified index. * `\\"pop\\"` - Remove and return the element at a specified index (if provided), otherwise the last element. * `\\"remove\\"` - Remove the first occurrence of a value. * `\\"reverse\\"` - Reverse the array. * `\\"tobytes\\"` - Convert the array to bytes. * `\\"tolist\\"` - Convert the array to a list. - `\\"value\\"`: The value to use in the operation (for `\\"append\\"`, `\\"insert\\"`, and `\\"remove\\"` operations). - `\\"index\\"` (optional): For `\\"insert\\"` and `\\"pop\\"` operations, the index at which to perform the operation. **Constraints:** - The array must only contain elements appropriate for the specified `type_code`. - The function should handle invalid operations or invalid parameters gracefully by ignoring such operations. **Example:** ```python from array import array def process_array(type_code, initializer, operations): # Your implementation here # Example input type_code = \'i\' initializer = [1, 2, 3, 4] operations = [ {\\"operation\\": \\"append\\", \\"value\\": 5}, {\\"operation\\": \\"insert\\", \\"value\\": 0, \\"index\\": 0}, {\\"operation\\": \\"pop\\"}, {\\"operation\\": \\"remove\\", \\"value\\": 2}, {\\"operation\\": \\"reverse\\"} ] # Example usage result = process_array(type_code, initializer, operations) # Expected output: [0, 1, 3, 4] print(result) ``` **Notes:** - Use the `array` module from Python\'s standard library. - Ensure that the solution handles both required and optional fields in operation dictionaries. - You can assume that input `type_code` and `initializer` will always be valid for creating an array. - The function should return the final state of the array as a Python list after all operations have been applied.","solution":"from array import array def process_array(type_code, initializer, operations): arr = array(type_code, initializer) for operation in operations: op = operation.get(\\"operation\\") if op == \\"append\\": value = operation.get(\\"value\\") if value is not None: arr.append(value) elif op == \\"insert\\": value = operation.get(\\"value\\") index = operation.get(\\"index\\") if value is not None and index is not None: arr.insert(index, value) elif op == \\"pop\\": index = operation.get(\\"index\\", -1) if index >= 0 and index < len(arr): arr.pop(index) elif index == -1: arr.pop() elif op == \\"remove\\": value = operation.get(\\"value\\") if value in arr: arr.remove(value) elif op == \\"reverse\\": arr.reverse() elif op == \\"tobytes\\": return arr.tobytes() elif op == \\"tolist\\": return arr.tolist() return arr.tolist()"},{"question":"**Coding Assessment Question: Python Path Manipulations** # Objective You are tasked with implementing a function to generate various information from a given list of file paths. You will utilize the functions from the `os.path` module to achieve this. # Problem Statement Write a Python function `analyze_paths(paths: List[str]) -> Dict[str, Any]` that takes a list of file system paths and returns a dictionary containing the following keys and their associated values: 1. **abs_paths**: A list of absolute paths for each given path. 2. **basenames**: A list of base names (final components) for each path. 3. **common_path**: The longest common sub-path among all provided paths. 4. **dirnames**: A list of directory names for each path. 5. **sizes**: A list of sizes for each path that exists, otherwise `None`. 6. **last_modified**: A list of last modification times for each path that exists, otherwise `None`. # Function Signature ```python from typing import List, Dict, Any def analyze_paths(paths: List[str]) -> Dict[str, Any]: pass ``` # Input - `paths`: A list of strings, where each string is a file system path. # Output - Returns a dictionary with the following structure: ```python { \\"abs_paths\\": List[str], \\"basenames\\": List[str], \\"common_path\\": str, \\"dirnames\\": List[str], \\"sizes\\": List[Optional[int]], \\"last_modified\\": List[Optional[float]] } ``` # Constraints - The input list `paths` will contain between 1 and 100 path strings. - The path strings will be valid and well-formed. # Example Input ```python paths = [ \\"/usr/local/bin/python3.8\\", \\"/usr/local/bin/python3.9\\", \\"/usr/local/share/python3\\" ] ``` Output ```python { \\"abs_paths\\": [\\"/usr/local/bin/python3.8\\", \\"/usr/local/bin/python3.9\\", \\"/usr/local/share/python3\\"], \\"basenames\\": [\\"python3.8\\", \\"python3.9\\", \\"python3\\"], \\"common_path\\": \\"/usr/local\\", \\"dirnames\\": [\\"/usr/local/bin\\", \\"/usr/local/bin\\", \\"/usr/local/share\\"], \\"sizes\\": [45752, None, 15360], # example sizes in bytes \\"last_modified\\": [1609459200.0, None, 1612137600.0] # example last modification times as UNIX timestamps } ``` # Notes - Use functions from the `os.path` module to develop the solution accurately. - Ensure your implementation handles file paths correctly for both Unix and Windows environments. - Nonexistent paths should return `None` for size and last modification time. # Hints - Utilize `os.path.abspath` for absolute paths. - Leverage `os.path.basename` to get base names. - Use `os.path.commonpath` to find the common sub-path. - Apply `os.path.dirname` to extract directory names. - Fetch file size using `os.path.getsize` and handle exceptions for non-existent paths. - Retrieve the last modification time using `os.path.getmtime` and account for possible errors.","solution":"from typing import List, Dict, Any import os def analyze_paths(paths: List[str]) -> Dict[str, Any]: abs_paths = [os.path.abspath(path) for path in paths] basenames = [os.path.basename(path) for path in paths] common_path = os.path.commonpath(paths) dirnames = [os.path.dirname(path) for path in paths] sizes = [os.path.getsize(path) if os.path.exists(path) else None for path in paths] last_modified = [os.path.getmtime(path) if os.path.exists(path) else None for path in paths] return { \\"abs_paths\\": abs_paths, \\"basenames\\": basenames, \\"common_path\\": common_path, \\"dirnames\\": dirnames, \\"sizes\\": sizes, \\"last_modified\\": last_modified }"},{"question":"You are tasked with creating a secure communication system between a client and a server. The system should ensure that messages exchanged between the client and server are both authenticated and confidential. # Requirements: 1. **Message Authentication**: Use the `hmac` module to create a message authentication code (MAC) to ensure the integrity and authenticity of the message. 2. **Message Encryption**: Use the `secrets` module for generating secure random keys and initialization vectors (IVs). 3. **Hashing Algorithm**: Use the `hashlib` module to hash the messages before sending them. # Implementation Details: 1. Implement a function `generate_key()` that generates a random key of 16 bytes using the `secrets` module. 2. Implement a function `create_mac(key: bytes, message: str) -> str` that uses the HMAC (Hash-based Message Authentication Code) algorithm to create a MAC for the given message with the provided key using the `hmac` module. The function should return the MAC in hexadecimal format. 3. Implement a function `encrypt_message(key: bytes, message: str) -> tuple` that: - Uses the key to generate a secure random initialization vector (IV) of 16 bytes. - Encrypts the message using the IV and key. - Uses the `hashlib` module to hash the message. - Returns a tuple with the IV and the encrypted message. 4. Implement a function `decrypt_message(key: bytes, iv: bytes, encrypted_message: bytes) -> str` that: - Decrypts the message using the provided key and IV. - Validates the hash to ensure data integrity. # Constraints: - The message will be a string with a maximum length of 500 characters. - You can assume the existence of an encryption function and a decryption function that are out of the scope of this implementation task (For simplicity, consider using simple XOR encryption). # Expected Input and Output Formats: - Function `generate_key()`: No input, returns a bytes object. - Function `create_mac(key: bytes, message: str) -> str`: Takes a key (bytes) and a message (str) as input, returns a hexadecimal string representing the MAC. - Function `encrypt_message(key: bytes, message: str) -> tuple`: Takes a key (bytes) and a message (str) as input, returns a tuple containing the IV (bytes) and the encrypted message (bytes). - Function `decrypt_message(key: bytes, iv: bytes, encrypted_message: bytes) -> str`: Takes a key (bytes), IV (bytes), and an encrypted message (bytes) as input, returns the original message (str). Implement the aforementioned functions in Python.","solution":"import hmac import hashlib import secrets def generate_key() -> bytes: Generate a random key of 16 bytes using the secrets module. return secrets.token_bytes(16) def create_mac(key: bytes, message: str) -> str: Create a Message Authentication Code (MAC) using HMAC with the provided key and message. mac = hmac.new(key, message.encode(), hashlib.sha256) return mac.hexdigest() def encrypt_message(key: bytes, message: str) -> tuple: Encrypt the message using the provided key, generating a random IV. iv = secrets.token_bytes(16) encrypted_message = bytes([b ^ key[i % len(key)] for i, b in enumerate(message.encode())]) return iv, encrypted_message def decrypt_message(key: bytes, iv: bytes, encrypted_message: bytes) -> str: Decrypt the encrypted message using the provided key and IV. decrypted_message = bytes([b ^ key[i % len(key)] for i, b in enumerate(encrypted_message)]) return decrypted_message.decode()"},{"question":"**Objective:** In this task, you will implement a function that analyzes a dataset to answer specific questions. You are required to demonstrate your knowledge of pandas\' dataframe operations including data manipulation, filtering, aggregation, and serialization. **Problem Statement:** You are provided with a dataset containing information about various products, their sales across different regions, and the date of sale. You need to implement a function `analyze_sales_data` that performs the following operations: 1. **Read the Data:** Load the dataset from a CSV file into a pandas `DataFrame`. The CSV file path will be provided as an argument to the function. 2. **Data Cleaning:** - Ensure that there are no missing values in the columns `ProductID`, `Region`, and `Sales`. - Fill any missing values in the `Date` column with the value `2023-01-01`. 3. **Data Aggregation:** - Compute the total sales for each product in each region. - Compute the average sales per month for each product. 4. **Data Filtering:** - Filter out products that have total sales less than a given threshold. - Ensure the filtered dataset contains records only for the year 2023. 5. **Serialization:** - Save the filtered DataFrame to a new CSV file with the name \'filtered_sales_data.csv\'. **Function Signature:** ```python def analyze_sales_data(file_path: str, sales_threshold: float) -> None: pass ``` **Input:** - `file_path` (str): The path to the CSV file containing the sales data. - `sales_threshold` (float): The sales threshold below which products should be excluded from the result. **Output:** - The function should save the filtered DataFrame to a CSV file named \'filtered_sales_data.csv\'. **Constraints:** - The function should handle large datasets efficiently. - Make sure the final saved CSV file retains the original column structure. **Example:** Consider a dataset with the following structure: ``` ProductID,Region,Sales,Date P001,North,100,2023-03-01 P002,South,200,2023-02-15 P001,East,150,2023-01-12 ,,250, P003,West,1500,2023-06-23 P004,North,1000, P002,East,150,2022-11-11 ``` After processing with `analyze_sales_data(\'path/to/dataset.csv\', 500)`, the resulting \'filtered_sales_data.csv\' might look like: ``` ProductID,Region,Sales,Date P003,West,1500,2023-06-23 P004,North,1000,2023-01-01 ``` **Notes:** - Use appropriate pandas methods for data manipulation, aggregation, and filtering. - Ensure the function is robust and handles edge cases effectively.","solution":"import pandas as pd def analyze_sales_data(file_path: str, sales_threshold: float) -> None: # Load dataset into pandas DataFrame df = pd.read_csv(file_path) # Data Cleaning df.dropna(subset=[\'ProductID\', \'Region\', \'Sales\'], inplace=True) df[\'Date\'].fillna(\'2023-01-01\', inplace=True) # Data Aggregation total_sales = df.groupby([\'ProductID\', \'Region\'])[\'Sales\'].sum().reset_index() df[\'Date\'] = pd.to_datetime(df[\'Date\']) monthly_sales = df.set_index(\'Date\').groupby([\'ProductID\']).resample(\'M\').agg({\'Sales\': \'mean\'}).reset_index() # Data Filtering total_sales_filtered = total_sales.groupby(\'ProductID\').filter(lambda x: x[\'Sales\'].sum() >= sales_threshold) filtered_df = df[df[\'ProductID\'].isin(total_sales_filtered[\'ProductID\'].unique())] filtered_df = filtered_df[filtered_df[\'Date\'].dt.year == 2023] # Serialization filtered_df.to_csv(\'filtered_sales_data.csv\', index=False)"},{"question":"Problem Statement: Python Class and Iterator Implementation # Objective Implement a class `CustomList` that simulates a list but with incorporated iterator and enhanced functionalities. # Requirements 1. **Class Creation:** - Define a class `CustomList` that will act as a custom list wrapper. - Implement the constructor `__init__` which initializes the list. 2. **Attributes and Methods:** - The class should have an instance attribute `data` which stores the list elements. - Implement the following methods: - `add_element(self, elem)`: Adds an element to the list. - `remove_element(self, elem)`: Removes an element from the list. - `get_elements(self)`: Returns the elements in the list. 3. **Inheritance:** - Create a subclass `SortedCustomList` that inherits from `CustomList`. - Override the `add_element` method to ensure that elements are added in a sorted manner. - Implement an additional method `find_element(self, elem)` that returns the index of the element if it exists, else returns `-1`. 4. **Iterator Implementation:** - Implement the iterator protocol for `CustomList` class. - The class should be iterable such that its elements can be accessed in a `for` loop. 5. **Performance Constraints:** - Ensure that the `find_element` method in `SortedCustomList` performs faster than O(n) for large datasets. # Input/Output There is no direct input/output as this is a class implementation. However, ensure the following: ```python # Example Usage custom_list = CustomList() custom_list.add_element(5) custom_list.add_element(3) custom_list.remove_element(5) print(custom_list.get_elements()) # Expected Output: [3] sorted_list = SortedCustomList() sorted_list.add_element(5) sorted_list.add_element(3) sorted_list.add_element(2) print(sorted_list.get_elements()) # Expected Output: [2, 3, 5] print(sorted_list.find_element(3)) # Expected Output: 1 print(sorted_list.find_element(10)) # Expected Output: -1 # Iterator Usage for elem in sorted_list: print(elem) # Expected Output: 2 3 5 ``` Ensure to handle edge cases and validate input where necessary. # Constraints - Elements to be added to the list will be integers. # Performance Requirements - The `add_element` method in `SortedCustomList` must have a time complexity of O(log n) for inserting elements to maintain the sorting. - The `find_element` method in `SortedCustomList` must have a time complexity of O(log n).","solution":"class CustomList: def __init__(self): self.data = [] def add_element(self, elem): self.data.append(elem) def remove_element(self, elem): if elem in self.data: self.data.remove(elem) def get_elements(self): return self.data def __iter__(self): self._index = 0 return self def __next__(self): if self._index < len(self.data): result = self.data[self._index] self._index += 1 return result else: raise StopIteration class SortedCustomList(CustomList): def add_element(self, elem): if not self.data: self.data.append(elem) else: # Perform binary search to find the correct insertion point lo, hi = 0, len(self.data) while lo < hi: mid = (lo + hi) // 2 if self.data[mid] < elem: lo = mid + 1 else: hi = mid self.data.insert(lo, elem) def find_element(self, elem): # Perform binary search to find the element index lo, hi = 0, len(self.data) while lo < hi: mid = (lo + hi) // 2 if self.data[mid] == elem: return mid elif self.data[mid] < elem: lo = mid + 1 else: hi = mid return -1"},{"question":"Objective Implement a Python function that processes a list of tuples representing student grades and returns a dictionary that organizes the grades by student, ensuring proper type checks throughout. Problem Statement You are provided with a list of tuples where each tuple contains a student\'s name (a string) and their grade (an integer). Your task is to write a function `process_grades` that takes in this list and returns a dictionary where each key is a student\'s name and the corresponding value is a list of their grades. Your function should perform the following tasks: 1. Check that the input is a list of tuples, where each tuple contains a string and an integer. 2. Create a dictionary where each key is a student\'s name, and the value is a list of grades corresponding to that student. 3. If a student\'s name appears more than once in the input list, their grades should be accumulated in a list. 4. Ensure that if the input is not of the expected format, your function raises a `TypeError` with a descriptive message. Function Signature ```python def process_grades(grades: list) -> dict: pass ``` Input - `grades`: A list of tuples `(str, int)`, where the first element is the student\'s name (a string) and the second element is their grade (an integer). - Example: `[(\\"Alice\\", 90), (\\"Bob\\", 75), (\\"Alice\\", 95)]` Output - A dictionary where the keys are student names (strings) and the values are lists of grades (integers) corresponding to each student. - Example: `{\\"Alice\\": [90, 95], \\"Bob\\": [75]}` Constraints - You can assume that student names are unique strings. - Grades are integers between 0 and 100 inclusive. - The input list and tuples within it may be empty. Example Usage ```python grades = [(\\"Alice\\", 90), (\\"Bob\\", 75), (\\"Alice\\", 95)] result = process_grades(grades) print(result) # Output: {\\"Alice\\": [90, 95], \\"Bob\\": [75]} ``` Notes - Ensure your function includes type checks to validate that the input is a list of tuples containing a string and an integer. Performance Requirements - The implementation should be efficient, ideally with a time complexity of O(n), where n is the number of grades in the input list. Additional Information - Use appropriate error handling and type checking to ensure robustness.","solution":"def process_grades(grades): Processes a list of tuples representing student grades and returns a dictionary that organizes the grades by student. :param grades: List[Tuple[str, int]] :return: Dict[str, List[int]] :raises TypeError: If input is not a list of tuples with (str, int) if not isinstance(grades, list): raise TypeError(\\"Input must be a list of tuples\\") for grade in grades: if not isinstance(grade, tuple): raise TypeError(\\"Each item in the list must be a tuple\\") if len(grade) != 2: raise TypeError(\\"Each tuple must have exactly 2 elements\\") if not isinstance(grade[0], str): raise TypeError(\\"The first element of each tuple must be a string\\") if not isinstance(grade[1], int): raise TypeError(\\"The second element of each tuple must be an integer\\") result = {} for name, grade in grades: if name in result: result[name].append(grade) else: result[name] = [grade] return result"},{"question":"Design a `GaussianMixtureModel` class that utilizes scikit-learn\'s `GaussianMixture` class and demonstrates the following functionalities: 1. **Initialization**: The class should be initialized with parameters for the number of components, covariance type, and initialization method. 2. **Model Fitting**: Implement a method `fit_model` to fit the GMM to a provided dataset. 3. **Model Prediction**: Implement a method `predict_labels` to predict labels for given data points. 4. **BIC Calculation**: Implement a method `calculate_bic` which calculates and returns the Bayesian Information Criterion for the fitted model. # Function Signatures ```python class GaussianMixtureModel: def __init__(self, n_components: int, covariance_type: str, init_params: str): Initialize the GaussianMixtureModel with given parameters. :param n_components: Number of mixture components. :param covariance_type: Covariance type to be used (\'full\', \'tied\', \'diag\', \'spherical\'). :param init_params: Method for initialization (\'kmeans\', \'kmeans++\', \'random\', \'random_from_data\'). pass def fit_model(self, X: np.ndarray): Fit the Gaussian Mixture Model to the provided dataset. :param X: ndarray of shape (n_samples, n_features), The data to fit. :return: None pass def predict_labels(self, X: np.ndarray) -> np.ndarray: Predict the labels for the provided dataset using the trained model. :param X: ndarray of shape (n_samples, n_features), The data for prediction. :return: ndarray of shape (n_samples,), The predicted labels for each sample. pass def calculate_bic(self, X: np.ndarray) -> float: Calculate and return the Bayesian Information Criterion for the fitted model. :param X: ndarray of shape (n_samples, n_features), The data used for fitting the model. :return: float, The BIC score. pass ``` # Requirements 1. The class should handle errors for invalid parameters. 2. Use scikit-learn\'s `GaussianMixture` for fitting and predicting. 3. Ensure BIC calculation works correctly after fitting the model. # Example ```python # Sample Dataset import numpy as np from sklearn.datasets import make_blobs X, _ = make_blobs(n_samples=100, centers=3, n_features=2) # Model Initialization with 3 components, full covariance type, and kmeans initialization gmm_model = GaussianMixtureModel(n_components=3, covariance_type=\'full\', init_params=\'kmeans\') # Fitting the model gmm_model.fit_model(X) # Predicting labels labels = gmm_model.predict_labels(X) print(\\"Predicted Labels:\\", labels) # Calculating BIC bic = gmm_model.calculate_bic(X) print(\\"BIC Score:\\", bic) ``` This task will require the students to integrate their understanding of GMM, perform model fitting, predict labels, and calculate evaluation metrics like BIC, ensuring a thorough understanding of the scikit-learn GMM implementation.","solution":"from sklearn.mixture import GaussianMixture import numpy as np class GaussianMixtureModel: def __init__(self, n_components: int, covariance_type: str = \'full\', init_params: str = \'kmeans\'): Initialize the GaussianMixtureModel with given parameters. :param n_components: Number of mixture components. :param covariance_type: Covariance type to be used (\'full\', \'tied\', \'diag\', \'spherical\'). :param init_params: Method for initialization (\'kmeans\', \'random\'). if n_components <= 0: raise ValueError(\\"Number of components must be greater than 0.\\") valid_covariance_types = [\'full\', \'tied\', \'diag\', \'spherical\'] if covariance_type not in valid_covariance_types: raise ValueError(f\\"Invalid covariance type. Expected one of {valid_covariance_types}.\\") valid_init_params = [\'kmeans\', \'random\'] if init_params not in valid_init_params: raise ValueError(f\\"Invalid initialization method. Expected one of {valid_init_params}.\\") self.n_components = n_components self.covariance_type = covariance_type self.init_params = init_params self.model = GaussianMixture(n_components=self.n_components, covariance_type=self.covariance_type, init_params=self.init_params) def fit_model(self, X: np.ndarray): Fit the Gaussian Mixture Model to the provided dataset. :param X: ndarray of shape (n_samples, n_features), The data to fit. self.model.fit(X) def predict_labels(self, X: np.ndarray) -> np.ndarray: Predict the labels for the provided dataset using the trained model. :param X: ndarray of shape (n_samples, n_features), The data for prediction. :return: ndarray of shape (n_samples,), The predicted labels for each sample. return self.model.predict(X) def calculate_bic(self, X: np.ndarray) -> float: Calculate and return the Bayesian Information Criterion for the fitted model. :param X: ndarray of shape (n_samples, n_features), The data used for fitting the model. :return: float, The BIC score. return self.model.bic(X)"},{"question":"# **Coding Assessment Question: Testing Your Code with doctest** **Objective**: Demonstrate your understanding of the `doctest` module for testing Python code embedded in docstrings, and integrate these tests with the `unittest` framework. **Problem Statement** You are required to implement a Python module that provides a function to calculate the nth Fibonacci number. Additionally, you need to write `doctest` tests within the function\'s docstring to verify the correctness of the implementation. Finally, integrate these tests with the `unittest` framework so that they can be systematically executed. **Instructions** 1. **Function Implementation**: - Implement a function `fibonacci(n: int) -> int` that calculates the nth Fibonacci number. - The Fibonacci sequence starts with 0, 1, and the next number is obtained by summing the two preceding ones: 0, 1, 1, 2, 3, 5, 8, 13, ... 2. **Docstring with Examples**: - Include `doctest` style examples in the function\'s docstring to validate your implementation. - Test cases should include: - Basic cases: `fibonacci(0)`, `fibonacci(1)`, `fibonacci(2)` - Larger values: `fibonacci(10)`, `fibonacci(20)` - Edge cases: negative inputs should raise a `ValueError`. 3. **Integration with unittest**: - Create a `unittest` test suite that loads the doctests from your module and executes them. **Constraints and Requirements** - The implementation should handle inputs as specified. - Negative inputs must raise a `ValueError`. - The `unittest` suite should execute the tests without errors if the implementation is correct. **Performance Requirements** - Your solution should be efficient enough to handle reasonably large values of `n` (e.g., up to 40) without significant performance issues. **Example** Here is an outline of what your module might look like: ```python # fibonacci_module.py def fibonacci(n): Calculate the nth Fibonacci number. Parameters: n (int): The position in the Fibonacci sequence (0-indexed). Returns: int: The nth Fibonacci number. Raises: ValueError: If n is negative. Examples: >>> fibonacci(0) 0 >>> fibonacci(1) 1 >>> fibonacci(2) 1 >>> fibonacci(10) 55 >>> fibonacci(20) 6765 >>> fibonacci(-1) Traceback (most recent call last): ... ValueError: n must be a non-negative integer # Your implementation here pass if __name__ == \\"__main__\\": import doctest doctest.testmod() ``` Create a `unittest` test suite to integrate these doctests: ```python # test_fibonacci.py import unittest import doctest import fibonacci_module def load_tests(loader, tests, ignore): tests.addTests(doctest.DocTestSuite(fibonacci_module)) return tests if __name__ == \'__main__\': unittest.main() ``` **Submission** Submit both `fibonacci_module.py` and `test_fibonacci.py` files.","solution":"def fibonacci(n: int) -> int: Calculate the nth Fibonacci number. Parameters: n (int): The position in the Fibonacci sequence (0-indexed). Returns: int: The nth Fibonacci number. Raises: ValueError: If n is negative. Examples: >>> fibonacci(0) 0 >>> fibonacci(1) 1 >>> fibonacci(2) 1 >>> fibonacci(10) 55 >>> fibonacci(20) 6765 >>> fibonacci(-1) Traceback (most recent call last): ... ValueError: n must be a non-negative integer if n < 0: raise ValueError(\\"n must be non-negative\\") a, b = 0, 1 for _ in range(n): a, b = b, a + b return a if __name__ == \\"__main__\\": import doctest doctest.testmod()"},{"question":"In this exercise, you will implement a Python function that interacts with low-level details of floating-point objects. For this task, simulate some of the functionality described in the provided documentation using Python. # Objective Write a Python function that: 1. Takes a string representation of a number and returns a float object. 2. Takes a float object and returns its string representation. 3. Checks if an input is a float. 4. Gets the minimum and maximum representable float in Python. # Function Signature ```python def float_operations(number_str: str) -> tuple: Args: number_str (str): The input string that contains a numeric value. Returns: tuple: A tuple containing the following: - The float object created from the string. - The string representation of the float object. - A boolean indicating if the input is a float. - The minimum representable finite float. - The maximum representable finite float. pass ``` # Requirements 1. **String to Float Conversion**: Convert the input string to a float. 2. **Float to String Conversion**: Convert the float obtained back to its string representation. 3. **Float Check**: Check if the float object obtained is indeed a float. 4. **Float Boundaries**: Retrieve the minimum and maximum representable finite floats in Python. # Constraints - The input string is guaranteed to be a valid numeric representation. - You may not use any external libraries other than the Python standard library. # Example ```python # Input number_str = \\"123.456\\" # Expected Output (123.456, \'123.456\', True, 2.2250738585072014e-308, 1.7976931348623157e+308) # Explanation # - The float object created from the string \\"123.456\\" is 123.456. # - The string representation of 123.456 is \\"123.456\\". # - 123.456 is indeed a float, so True is returned. # - The minimum representable finite float in Python is approximately 2.2250738585072014e-308. # - The maximum representable finite float in Python is approximately 1.7976931348623157e+308. ``` # Notes - Do not worry about floating-point precision errors in this exercise. - Ensure all return values are in the specified order and type.","solution":"import sys def float_operations(number_str: str) -> tuple: Args: number_str (str): The input string that contains a numeric value. Returns: tuple: A tuple containing the following: - The float object created from the string. - The string representation of the float object. - A boolean indicating if the input is a float. - The minimum representable finite float. - The maximum representable finite float. # String to Float Conversion float_obj = float(number_str) # Float to String Conversion float_str = str(float_obj) # Float Check is_float = isinstance(float_obj, float) # Float Boundaries min_float = sys.float_info.min max_float = sys.float_info.max return (float_obj, float_str, is_float, min_float, max_float)"},{"question":"Buffer Manipulation with Deprecated Functions **Objective:** Implement a Python function that uses ctypes or a similar library to expose a string buffer and demonstrate interactions with the old buffer protocol functions, namely `PyObject_AsCharBuffer`, `PyObject_AsReadBuffer`, and `PyObject_AsWriteBuffer`. While these functions are deprecated in Python 3, they provide a useful exercise in understanding buffer manipulation. **Task:** 1. Create a function `create_buffer(string)`: - **Input:** A string. - **Output:** A ctypes buffer containing the string, null-terminated. 2. Create functions that mimic the behavior of `PyObject_AsCharBuffer`, `PyObject_AsReadBuffer`, and `PyObject_AsWriteBuffer` using ctypes: - **Input:** A ctypes buffer. 3. Your implementations of `PyObject_AsCharBuffer`, `PyObject_AsReadBuffer`, and `PyObject_AsWriteBuffer` should: - Retrieve and print pointers to the buffer\'s memory location. - Print the buffer length. - Handle and report errors if the buffer does not support the required interface. 4. Ensure your code tests these interactions with appropriate assertions and error checks. **Function Signatures:** ```python import ctypes def create_buffer(string: str) -> ctypes.Array: ... def PyObject_AsCharBuffer(buffer: ctypes.Array) -> (int, str, int): ... def PyObject_AsReadBuffer(buffer: ctypes.Array) -> (int, str, int): ... def PyObject_AsWriteBuffer(buffer: ctypes.Array) -> (int, str, int): ... # Example usage and expected outputs: buffer = create_buffer(\\"Hello, World\\") # Expected: (0, memory_address, 13) or an appropriate error print(PyObject_AsCharBuffer(buffer)) # Expected: (0, memory_address, 13) or an appropriate error print(PyObject_AsReadBuffer(buffer)) # Expected: (0, memory_address, 13) or an appropriate error print(PyObject_AsWriteBuffer(buffer)) ``` **Constraints:** - Use ctypes or a similar low-level library to manipulate memory buffers. - Handle errors gracefully and provide meaningful error messages. **Notes:** - This question is designed to test your understanding of buffer manipulation and memory handling in Python. - You are expected to demonstrate proficiency with ctypes and deprecated functions for compatibility purposes.","solution":"import ctypes def create_buffer(string: str) -> ctypes.Array: Create a ctypes buffer from a string. return ctypes.create_string_buffer(string.encode(\'utf-8\')) def PyObject_AsCharBuffer(buffer: ctypes.Array) -> (int, ctypes.POINTER(ctypes.c_char), int): Mimic PyObject_AsCharBuffer behavior. try: length = ctypes.sizeof(buffer) - 1 # Exclude the null terminator return (0, ctypes.cast(buffer, ctypes.POINTER(ctypes.c_char)), length) except Exception as e: return (-1, None, 0) def PyObject_AsReadBuffer(buffer: ctypes.Array) -> (int, ctypes.POINTER(ctypes.c_char), int): Mimic PyObject_AsReadBuffer behavior. try: length = ctypes.sizeof(buffer) - 1 # Exclude the null terminator return (0, ctypes.cast(buffer, ctypes.POINTER(ctypes.c_char)), length) except Exception as e: return (-1, None, 0) def PyObject_AsWriteBuffer(buffer: ctypes.Array) -> (int, ctypes.POINTER(ctypes.c_char), int): Mimic PyObject_AsWriteBuffer behavior. try: length = ctypes.sizeof(buffer) - 1 # Exclude the null terminator return (0, ctypes.cast(buffer, ctypes.POINTER(ctypes.c_char)), length) except Exception as e: return (-1, None, 0)"},{"question":"# Machine Learning Using Stochastic Gradient Descent In this exercise, you are tasked with implementing both a classification and a regression model using the Stochastic Gradient Descent (SGD) approach with `sklearn.linear_model.SGDClassifier` and `sklearn.linear_model.SGDRegressor`. Your implementation should demonstrate the ability to configure the models using various parameters and evaluate them on given datasets. Instructions: 1. **Load the Data:** - For classification, use the Iris dataset (`sklearn.datasets.load_iris`). - For regression, use the California Housing dataset (`sklearn.datasets.fetch_california_housing`). 2. **Preprocess the Data:** - Standardize the features using `StandardScaler`. 3. **Model Configuration and Training:** - For classification, configure and train an `SGDClassifier`: - Use `loss=\\"hinge\\"` (SVM-like) and `penalty=\\"l2\\"`. - Set `max_iter=1000`, `tol=1e-3`, `random_state=42`. - Enable shuffling of the training data. - For regression, configure and train an `SGDRegressor`: - Use `loss=\\"squared_error\\"` and `penalty=\\"l2\\"`. - Set `max_iter=1000`, `tol=1e-3`, `random_state=42`. - Enable shuffling of the training data. 4. **Model Evaluation:** - For the classifier, use accuracy score to evaluate model performance on the test set. - For the regressor, use mean squared error to evaluate model performance on the test set. 5. **Function Definitions:** - Define functions `train_classifier()` and `train_regressor()`, each returning the trained model and the evaluation metrics of the test set. 6. **Performance Output:** - Print the accuracy of the classification model. - Print the mean squared error of the regression model. # Expected Functions ```python def train_classifier(X_train, y_train, X_test, y_test): Train an SGDClassifier with specified parameters and evaluate performance. Args: X_train (ndarray): Training features. y_train (ndarray): Training targets. X_test (ndarray): Test features. y_test (ndarray): Test targets. Returns: tuple: trained SGDClassifier model, accuracy on test data. pass def train_regressor(X_train, y_train, X_test, y_test): Train an SGDRegressor with specified parameters and evaluate performance. Args: X_train (ndarray): Training features. y_train (ndarray): Training targets. X_test (ndarray): Test features. y_test (ndarray): Test targets. Returns: tuple: trained SGDRegressor model, mean squared error on test data. pass ``` # Example Execution: ```python # Load datasets from sklearn.datasets import load_iris, fetch_california_housing from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler # Load and split Iris dataset for classification iris = load_iris() X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42) # Load and split California Housing dataset for regression california = fetch_california_housing() X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(california.data, california.target, test_size=0.2, random_state=42) # Standardize datasets scaler_clf = StandardScaler().fit(X_train_clf) X_train_clf = scaler_clf.transform(X_train_clf) X_test_clf = scaler_clf.transform(X_test_clf) scaler_reg = StandardScaler().fit(X_train_reg) X_train_reg = scaler_reg.transform(X_train_reg) X_test_reg = scaler_reg.transform(X_test_reg) # Train and evaluate models classifier_model, classifier_accuracy = train_classifier(X_train_clf, y_train_clf, X_test_clf, y_test_clf) print(\\"Classifier Accuracy:\\", classifier_accuracy) regressor_model, regressor_mse = train_regressor(X_train_reg, y_train_reg, X_test_reg, y_test_reg) print(\\"Regressor Mean Squared Error:\\", regressor_mse) ``` # Constraints: - Use only the mentioned `sklearn` modules. - Ensure reproducibility by setting the random seed where applicable. - Standardize the data using `StandardScaler()`. # Performance Requirements: - Classification accuracy should be reasonable given the dataset and model constraints. - Regression mean squared error should provide insight into the fit of the model.","solution":"from sklearn.linear_model import SGDClassifier, SGDRegressor from sklearn.metrics import accuracy_score, mean_squared_error def train_classifier(X_train, y_train, X_test, y_test): Train an SGDClassifier with specified parameters and evaluate performance. Args: X_train (ndarray): Training features. y_train (ndarray): Training targets. X_test (ndarray): Test features. y_test (ndarray): Test targets. Returns: tuple: trained SGDClassifier model, accuracy on test data. clf = SGDClassifier(loss=\\"hinge\\", penalty=\\"l2\\", max_iter=1000, tol=1e-3, random_state=42, shuffle=True) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) accuracy = accuracy_score(y_test, y_pred) return clf, accuracy def train_regressor(X_train, y_train, X_test, y_test): Train an SGDRegressor with specified parameters and evaluate performance. Args: X_train (ndarray): Training features. y_train (ndarray): Training targets. X_test (ndarray): Test features. y_test (ndarray): Test targets. Returns: tuple: trained SGDRegressor model, mean squared error on test data. reg = SGDRegressor(loss=\\"squared_error\\", penalty=\\"l2\\", max_iter=1000, tol=1e-3, random_state=42, shuffle=True) reg.fit(X_train, y_train) y_pred = reg.predict(X_test) mse = mean_squared_error(y_test, y_pred) return reg, mse"},{"question":"Objective Assess the comprehension of Seaborn\'s `so.Plot` and `so.Dodge` functionalities by requiring the implementation of a function that generates a customized dodged bar plot. Problem Statement You are given a dataset representing sales data from different stores across various branches. Your task is to write a function `plot_sales_data` that generates a dodged bar plot using Seaborn\'s `objects` module. The dataset contains the following columns: - `branch`: The branch of the store (e.g., \'A\', \'B\', \'C\'). - `store`: The store identifier (e.g., \'Store 1\', \'Store 2\', \'Store 3\'). - `sales`: The total sales value. Your function should accomplish the following: 1. Load the dataset from a CSV file. 2. Create a bar plot to show the total sales for each store in each branch. 3. Use dodging to separate the bars by `branch`. 4. Ensure that any empty space caused by missing combinations is filled. 5. Add a small gap between the dodged bars for better visibility. 6. Customize the plot to have appropriate labels and titles. Function Signature ```python def plot_sales_data(file_path: str) -> None: # Your code here ``` Input - `file_path` (str): The path to the CSV file containing the sales data. Output - The function should display the plot but return `None`. Example ```python # Example usage plot_sales_data(\\"sales_data.csv\\") ``` Constraints - The CSV file is guaranteed to contain the `branch`, `store`, and `sales` columns. - The function should be efficient and handle reasonably sized datasets smoothly. Documentation for Reference Refer to the provided documentation snippets on how to use `so.Plot`, `so.Count`, and `so.Dodge` with appropriate parameters. Notes - You may customize the aesthetic properties of the plot as needed. - Ensure the plot is saved and displayed correctly without overlapping labels or other visual issues.","solution":"import seaborn.objects as so import pandas as pd import matplotlib.pyplot as plt def plot_sales_data(file_path: str) -> None: Generates a dodged bar plot showing total sales for each store in each branch. Parameters: file_path (str): The path to the CSV file containing the sales data. # Load the dataset from the CSV file data = pd.read_csv(file_path) # Create a bar plot with dodging to separate bars by branch p = (so.Plot(data, x=\'store\', y=\'sales\', color=\'branch\') .add(so.Bar(), so.Dodge(0.5)) .layout(size=(8, 5)) .label(x=\'Store\', y=\'Total Sales\', title=\'Total Sales for Each Store by Branch\')) # Display the plot p.show() # Save the plot plt.savefig(\'sales_data_plot.png\') plt.close()"},{"question":"You are tasked with creating a Python script to automate part of the process of setting up a source distribution for a Python project. Your script will generate a `MANIFEST.in` file based on certain criteria. Requirements: 1. **Input Data:** - A list of files in the project directory. Each file will be represented as a string, with directory structure indicated using forward slashes, e.g., `src/module.py`, `README.md`, `tests/test_example.py`. - A dictionary of inclusion/exclusion rules. The keys will be either `\\"include\\"` or `\\"exclude\\"`, and the values will be lists of file patterns (e.g., `[\\"*.py\\", \\"*.md\\"]`). 2. **Output Data:** - A `MANIFEST.in` file generated according to the specified inclusion and exclusion rules. The file should follow the format described in the provided documentation. 3. **Constraints:** - The `MANIFEST.in` file should start with a header comment: `# This file is generated by a script`. - Standard file patterns should only use asterisks (`*`) for matching files. You do not need to support more complex patterns. Example: **Input:** ```python files = [ \\"setup.py\\", \\"README.md\\", \\"src/module.py\\", \\"src/util.py\\", \\"tests/test_example.py\\" ] rules = { \\"include\\": [\\"*.py\\", \\"*.md\\"], \\"exclude\\": [\\"tests/*.py\\"] } ``` **Output:** A `MANIFEST.in` file with contents: ``` # This file is generated by a script include *.py include *.md prune tests/*.py ``` Function Signature: ```python def generate_manifest(files: list, rules: dict) -> None: pass ``` Notes: - The function should write the `MANIFEST.in` file to the current working directory. - Handle the order of commands: `include` commands should come before `prune` commands. - Your solution should demonstrate good practices in file handling and string manipulation. Performance Considerations: While the size of the file list and the simplicity of patterns is unlikely to cause performance issues for typical use cases, aim for clarity and efficiency in your implementation. Implement the `generate_manifest` function according to the requirements.","solution":"def generate_manifest(files, rules): Generates a MANIFEST.in file based on the provided files and rules. with open(\'MANIFEST.in\', \'w\') as f: f.write(\\"# This file is generated by a scriptn\\") # Process include rules if \\"include\\" in rules: for pattern in rules[\\"include\\"]: f.write(f\\"include {pattern}n\\") # Process exclude rules if \\"exclude\\" in rules: for pattern in rules[\\"exclude\\"]: f.write(f\\"prune {pattern}n\\")"},{"question":"Objective Implement a Naive Bayes classifier from scratch and compare its performance with `scikit-learn`\'s implementation on a given dataset. This will assess your understanding of the Naive Bayes algorithm, including probability estimations, decision rules, and handling different data types. Problem Statement 1. **Implement the Multinomial Naive Bayes classifier from scratch**: - Define a class `MyMultinomialNB`. - Implement methods for: - `fit(X, y)`: Train the model with the given training data `X` and labels `y`. - `predict(X)`: Predict the labels for the given data `X`. - `predict_proba(X)`: Predict the probability of the labels. 2. **Compare your implementation with `scikit-learn`\'s Multinomial Naive Bayes**: - Use the `MultinomialNB` from `sklearn.naive_bayes` to train and predict on the same dataset. 3. **Evaluate the performance**: - Calculate and print the accuracy, precision, recall, and F1-score for both your implementation and `scikit-learn`\'s implementation. 4. **Dataset**: - Use the `load_iris` dataset from `sklearn.datasets`. - Split the data into training and testing sets using `train_test_split` from `sklearn.model_selection`. Expected Input and Output Formats - **Input**: - Training data: 2D numpy array `X_train` - Training labels: 1D numpy array `y_train` - Test data: 2D numpy array `X_test` - Test labels: 1D numpy array `y_test` - **Output**: - Printed accuracy, precision, recall, and F1-score for both implementations. Constraints - Assume `X` is a numpy array with integer values (count-like data). - Assume `y` consists of integer class labels. Performance Requirements - The implementation should handle up to 10,000 samples efficiently. Example Code Skeleton ```python import numpy as np from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.naive_bayes import MultinomialNB from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score class MyMultinomialNB: def __init__(self, alpha=1.0): self.alpha = alpha def fit(self, X, y): # Implement the training process pass def predict(self, X): # Implement the prediction process pass def predict_proba(self, X): # Implement prediction of probabilities pass # Load dataset and split into train and test sets iris = load_iris() X, y = iris.data, iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0) # Train and evaluate your implementation my_nb = MyMultinomialNB() my_nb.fit(X_train, y_train) y_pred_my = my_nb.predict(X_test) print(\\"My MultinomialNB - Accuracy:\\", accuracy_score(y_test, y_pred_my)) print(\\"My MultinomialNB - Precision:\\", precision_score(y_test, y_pred_my, average=\'weighted\')) print(\\"My MultinomialNB - Recall:\\", recall_score(y_test, y_pred_my, average=\'weighted\')) print(\\"My MultinomialNB - F1-score:\\", f1_score(y_test, y_pred_my, average=\'weighted\')) # Train and evaluate scikit-learn\'s implementation sklearn_nb = MultinomialNB() sklearn_nb.fit(X_train, y_train) y_pred_sklearn = sklearn_nb.predict(X_test) print(\\"Sklearn MultinomialNB - Accuracy:\\", accuracy_score(y_test, y_pred_sklearn)) print(\\"Sklearn MultinomialNB - Precision:\\", precision_score(y_test, y_pred_sklearn, average=\'weighted\')) print(\\"Sklearn MultinomialNB - Recall:\\", recall_score(y_test, y_pred_sklearn, average=\'weighted\')) print(\\"Sklearn MultinomialNB - F1-score:\\", f1_score(y_test, y_pred_sklearn, average=\'weighted\')) ```","solution":"import numpy as np from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.naive_bayes import MultinomialNB from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score class MyMultinomialNB: def __init__(self, alpha=1.0): self.alpha = alpha self.class_log_prior_ = None self.feature_log_prob_ = None self.classes_ = None def fit(self, X, y): self.classes_, class_counts = np.unique(y, return_counts=True) self.class_log_prior_ = np.log(class_counts / y.size) smoothed_fc = np.array([np.sum(X[y==c], axis=0) + self.alpha for c in self.classes_]) smoothed_cc = np.array([np.sum(fc) for fc in smoothed_fc]) self.feature_log_prob_ = np.log(smoothed_fc / smoothed_cc[:, np.newaxis]) def predict(self, X): jll = self._joint_log_likelihood(X) return self.classes_[np.argmax(jll, axis=1)] def predict_proba(self, X): jll = self._joint_log_likelihood(X) log_prob_x = np.log(np.sum(np.exp(jll), axis=1)) return np.exp(jll - log_prob_x[:, np.newaxis]) def _joint_log_likelihood(self, X): return X @ self.feature_log_prob_.T + self.class_log_prior_ # Load dataset and split into train and test sets iris = load_iris() X, y = iris.data, iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0) # Train and evaluate your implementation my_nb = MyMultinomialNB() my_nb.fit(X_train, y_train) y_pred_my = my_nb.predict(X_test) print(\\"My MultinomialNB - Accuracy:\\", accuracy_score(y_test, y_pred_my)) print(\\"My MultinomialNB - Precision:\\", precision_score(y_test, y_pred_my, average=\'weighted\')) print(\\"My MultinomialNB - Recall:\\", recall_score(y_test, y_pred_my, average=\'weighted\')) print(\\"My MultinomialNB - F1-score:\\", f1_score(y_test, y_pred_my, average=\'weighted\')) # Train and evaluate scikit-learn\'s implementation sklearn_nb = MultinomialNB() sklearn_nb.fit(X_train, y_train) y_pred_sklearn = sklearn_nb.predict(X_test) print(\\"Sklearn MultinomialNB - Accuracy:\\", accuracy_score(y_test, y_pred_sklearn)) print(\\"Sklearn MultinomialNB - Precision:\\", precision_score(y_test, y_pred_sklearn, average=\'weighted\')) print(\\"Sklearn MultinomialNB - Recall:\\", recall_score(y_test, y_pred_sklearn, average=\'weighted\')) print(\\"Sklearn MultinomialNB - F1-score:\\", f1_score(y_test, y_pred_sklearn, average=\'weighted\'))"},{"question":"**Question: Advanced Seaborn Visualization with Jitter** You are provided with a dataset of penguins containing several attributes such as species, body mass, flipper length, and more. Your task is to visualize this data to understand the distribution and relationships between different attributes, using the seaborn visualization library. **Dataset:** You will use the penguins dataset which can be loaded using the `seaborn.load_dataset(\\"penguins\\")` function. **Task:** Write a Python function `create_jitter_plots` that takes no arguments and performs the following steps: 1. Load the penguins dataset. 2. Create a jittered scatter plot of `body_mass_g` (body mass in grams) versus `flipper_length_mm` (flipper length in mm). 3. Create jittered scatter plots between: - `species` and `body_mass_g` - `species` and `flipper_length_mm` Add jitter along both axes as necessary to avoid overlapping data points, ensuring the visualizations are clear. You should use appropriately chosen jitter parameters to clearly distinguish between data points. Your function should display all three plots. **Input:** - No input parameters. **Output:** - The function should display three plots as described above. Here is a template to help you get started: ```python import seaborn.objects as so from seaborn import load_dataset import matplotlib.pyplot as plt def create_jitter_plots(): # Load dataset penguins = load_dataset(\\"penguins\\") # Plot body_mass_g vs flipper_length_mm with jitter plot1 = ( so.Plot(penguins, x=\\"body_mass_g\\", y=\\"flipper_length_mm\\") .add(so.Dots(), so.Jitter(x=200, y=5)) ) plot1.show() # Plot species vs body_mass_g with jitter along the orientation axis plot2 = ( so.Plot(penguins, x=\\"species\\", y=\\"body_mass_g\\") .add(so.Dots(), so.Jitter(width=0.3)) ) plot2.show() # Plot species vs flipper_length_mm with jitter along the orientation axis plot3 = ( so.Plot(penguins, x=\\"species\\", y=\\"flipper_length_mm\\") .add(so.Dots(), so.Jitter(width=0.3)) ) plot3.show() # Call the function to generate plots create_jitter_plots() ``` **Constraints:** - Make sure to handle any missing data appropriately before plotting. - Do not hard-code the specific values for `x` and `y` jitter parameters; they should be reasoned based on the distribution of the data. **Notes:** - You can use additional seaborn or matplotlib utilities to customize and improve the readability of your plots. - Remember to interpret and present your plots clearly.","solution":"import seaborn as sns import matplotlib.pyplot as plt def create_jitter_plots(): # Load dataset penguins = sns.load_dataset(\\"penguins\\") # Drop rows with missing values penguins = penguins.dropna() # Plot body_mass_g vs flipper_length_mm with jitter plt.figure(figsize=(10, 6)) sns.stripplot(data=penguins, x=\\"body_mass_g\\", y=\\"flipper_length_mm\\", jitter=True) plt.title(\'Jittered Scatter Plot of Body Mass vs Flipper Length\') plt.xlabel(\'Body Mass (g)\') plt.ylabel(\'Flipper Length (mm)\') plt.show() # Plot species vs body_mass_g with jitter along the x-axis plt.figure(figsize=(10, 6)) sns.stripplot(data=penguins, x=\\"species\\", y=\\"body_mass_g\\", jitter=True) plt.title(\'Jittered Scatter Plot of Species vs Body Mass\') plt.xlabel(\'Species\') plt.ylabel(\'Body Mass (g)\') plt.show() # Plot species vs flipper_length_mm with jitter along the x-axis plt.figure(figsize=(10, 6)) sns.stripplot(data=penguins, x=\\"species\\", y=\\"flipper_length_mm\\", jitter=True) plt.title(\'Jittered Scatter Plot of Species vs Flipper Length\') plt.xlabel(\'Species\') plt.ylabel(\'Flipper Length (mm)\') plt.show()"},{"question":"# URL Shortener and Expander **Problem Description:** You are tasked with creating functions to both shorten and expand URLs using Python\'s `urllib` package. A shortened URL is a compact representation of a long URL, often used to simplify sharing. **Instructions:** 1. **Function 1: shorten_url** - **Input:** A string representing a long URL (e.g., \\"https://example.com/some/really/long/path\\"). - **Output:** A string representing a shortened URL (e.g., \\"https://short.url/abc123\\"). - **Note:** For the purpose of this exercise, you can simulate the shortening process by encoding the long URL in base64 and prefix it with \\"https://short.url/\\". 2. **Function 2: expand_url** - **Input:** A string representing a shortened URL (e.g., \\"https://short.url/abc123\\"). - **Output:** A string representing the original long URL (e.g., \\"https://example.com/some/really/long/path\\"). - **Note:** Decode the base64 string obtained from the shortened URL (assuming the shortening process as described). 3. **Function 3: is_accessible** - **Input:** A string representing a URL. - **Output:** A boolean value `True` if the URL is accessible (returns HTTP status code 200), otherwise `False`. - **Note:** Use `urllib.request` to perform an HTTP GET request and check the response status. 4. **Function 4: parse_domain** - **Input:** A string representing a URL. - **Output:** A string representing the domain of the URL (e.g., \\"example.com\\" for \\"https://example.com/some/path\\"). - **Note:** Use `urllib.parse` to correctly extract the domain. **Example:** ```python def shorten_url(long_url: str) -> str: pass def expand_url(short_url: str) -> str: pass def is_accessible(url: str) -> bool: pass def parse_domain(url: str) -> str: pass # Example usage: long_url = \\"https://example.com/some/really/long/path\\" short_url = shorten_url(long_url) print(short_url) # Output: \\"https://short.url/...\\" expanded_url = expand_url(short_url) print(expanded_url) # Output: \\"https://example.com/some/really/long/path\\" url = \\"https://example.com\\" print(is_accessible(url)) # Output: True or False based on actual URL accessibility domain = parse_domain(long_url) print(domain) # Output: \\"example.com\\" ``` **Constraints:** - The input URLs for all functions are valid and follow proper URL formatting. - Use the `urllib` package for URL handling wherever applicable. - For the `is_accessible` function, handle exceptions that may occur during the request and return `False` if the URL is not accessible. **Performance Requirements:** - The functions should handle typical URL lengths and ensure efficient execution for URL parsing and network requests. Implement these functions demonstrating your understanding of URL handling using the `urllib` package.","solution":"import base64 import urllib.parse import urllib.request def shorten_url(long_url: str) -> str: Shortens the given URL by encoding it in base64 and prefixing it with \\"https://short.url/\\". encoded_url = base64.urlsafe_b64encode(long_url.encode()).decode() return f\\"https://short.url/{encoded_url}\\" def expand_url(short_url: str) -> str: Expands the shortened URL by decoding the base64 part to retrieve the original URL. encoded_part = short_url.replace(\\"https://short.url/\\", \\"\\") return base64.urlsafe_b64decode(encoded_part.encode()).decode() def is_accessible(url: str) -> bool: Checks if the given URL is accessible (returns HTTP status code 200). try: request = urllib.request.Request(url, method=\'HEAD\') response = urllib.request.urlopen(request) return response.status == 200 except Exception: return False def parse_domain(url: str) -> str: Extracts and returns the domain from the given URL. parsed_url = urllib.parse.urlparse(url) return parsed_url.netloc"},{"question":"**Problem Statement: Data Serialization and Deserialization with `marshal`** You are given a Python script that needs to frequently save and load Python objects to files. You decide to use the `marshal` module for this purpose. Your task is to implement a pair of functions that use the `marshal` module to serialize and deserialize Python objects to/from files. # Function 1: `save_object` Write a function `save_object(obj: Any, file_path: str, version: int = marshal.version) -> None` that takes a Python object, a file path, and an optional version number, and saves the object to the specified file using the `marshal` module. **Input:** - `obj` (Any) - The Python object to be serialized. It must be of a type supported by the `marshal` module. - `file_path` (str) - The path to the file where the object should be saved. - `version` (int, optional) - The version of the marshal format to use. Default is `marshal.version`. **Output:** - None - The function saves the object to the specified file. **Constraints:** - Raise a `ValueError` if the object contains unsupported types. - Raise an `OSError` if the file cannot be written. # Function 2: `load_object` Write a function `load_object(file_path: str) -> Any` that takes a file path and loads the Python object from the specified file using the `marshal` module. **Input:** - `file_path` (str) - The path to the file from which the object should be loaded. **Output:** - The Python object that was deserialized from the file. **Constraints:** - Raise an `EOFError`, `ValueError`, or `TypeError` if no valid value is read or the data is malformed. - Raise an `OSError` if the file cannot be read. # Example Usage: ```python import os import marshal # Example object to serialize data = { \'numbers\': [1, 2, 3, 4.5], \'nested\': {\'a\': True, \'b\': None}, \'text\': \'example string\' } # Path to the file file_path = \'data.marshal\' # Saving the object save_object(data, file_path) # Loading the object loaded_data = load_object(file_path) print(loaded_data) # should output the same structure as `data` os.remove(file_path) # clean up file after usage ``` # Performance Requirements: - The functions should be able to handle files up to 10 MB efficiently. **Notes:** - Ensure exceptions are properly handled and meaningful error messages are provided. - Do not use third-party libraries; stick to Python\'s standard library.","solution":"import marshal def save_object(obj, file_path, version=marshal.version): Saves a Python object to a file using the marshal module. Parameters: obj (Any): The Python object to be serialized. file_path (str): The path to the file where the object should be saved. version (int): The version of the marshal format to use. Default is marshal.version. Raises: ValueError: If the object contains unsupported types. OSError: If the file cannot be written. try: with open(file_path, \'wb\') as file: marshal.dump(obj, file, version) except (ValueError, TypeError) as e: raise ValueError(\\"The object contains unsupported types.\\") from e except OSError as e: raise OSError(\\"The file cannot be written.\\") from e def load_object(file_path): Loads a Python object from a file using the marshal module. Parameters: file_path (str): The path to the file from which the object should be loaded. Returns: Any: The Python object that was deserialized from the file. Raises: EOFError, ValueError, TypeError: If no valid value is read or the data is malformed. OSError: If the file cannot be read. try: with open(file_path, \'rb\') as file: return marshal.load(file) except (EOFError, ValueError, TypeError) as e: raise ValueError(\\"Failed to deserialize the object.\\") from e except OSError as e: raise OSError(\\"The file cannot be read.\\") from e"},{"question":"# Python Coding Challenge: Serialization and Deserialization Objective: Create Python functions that simulate data marshalling (serialization) and unmarshalling (deserialization) processes using the built-in `marshal` module. Description: 1. **Serialization Function**: - Implement a function `serialize_data(data: Any, version: int) -> bytes` that: - Takes a Python object `data` and an integer `version`. - Serializes the `data` into bytes using the specified `version`. - Returns the serialized data as a byte string. 2. **Deserialization Function**: - Implement a function `deserialize_data(data_bytes: bytes) -> Any` that: - Takes a byte string `data_bytes` containing serialized data. - Deserializes the byte string back into the original Python object. - Returns the deserialized Python object. Constraints: - The `data` parameter can be any Python object (e.g., int, float, string, list, dict, etc.). - The `version` parameter for serialization must be an integer (0, 1, or 2). - Your implementation should handle relevant exceptions such as `EOFError`, `ValueError`, and `TypeError`. Performance Requirements: - The serialization and deserialization operations should handle reasonably large data efficiently. Input and Output Format: 1. **serialize_data(data: Any, version: int) -> bytes** - Input: - `data`: Any Python object to be serialized. - `version`: An integer representing the marshal version (0, 1, or 2). - Output: - A byte string representing the marshalled binary format of the input data. 2. **deserialize_data(data_bytes: bytes) -> Any** - Input: - `data_bytes`: A byte string containing serialized data. - Output: - The original Python object that was serialized. Example: ```python import marshal def serialize_data(data, version): if version not in (0, 1, 2): raise ValueError(\\"Invalid version. Must be 0, 1, or 2.\\") return marshal.dumps(data, version) def deserialize_data(data_bytes): try: return marshal.loads(data_bytes) except (EOFError, ValueError, TypeError) as e: return f\\"Deserialization error: {str(e)}\\" # Example usage: data = {\\"key\\": \\"value\\", \\"number\\": 42} version = 2 serialized = serialize_data(data, version) print(f\\"Serialized Data: {serialized}\\") deserialized = deserialize_data(serialized) print(f\\"Deserialized Data: {deserialized}\\") ``` Note: Ensure your functions are robust and include error handling for invalid inputs and potential exceptions during serialization and deserialization processes.","solution":"import marshal def serialize_data(data, version): Serializes a Python object using marshal with the specified version. Parameters: data (Any): The Python object to be serialized. version (int): The marshal version to be used (must be 0, 1, or 2). Returns: bytes: The serialized byte string. Throws: ValueError: If an invalid version is provided. if version not in (0, 1, 2): raise ValueError(\\"Invalid version. Version must be 0, 1, or 2.\\") return marshal.dumps(data, version) def deserialize_data(data_bytes): Deserializes a byte string using marshal. Parameters: data_bytes (bytes): The byte string to be deserialized. Returns: Any: The original Python object that was serialized. Throws: ValueError, EOFError, TypeError: If deserialization fails. try: return marshal.loads(data_bytes) except (EOFError, ValueError, TypeError) as e: return f\\"Deserialization error: {str(e)}\\""},{"question":"**Problem Statement:** You are tasked with implementing a secure file verification system using the `hashlib` module in Python. The system should handle different hash algorithms, allow for salted hashing, and produce a hexadecimal digest of the data. **Requirements:** 1. Implement a function `hash_file` that takes the following parameters: - `file_path` (str): The path to the file to be hashed. - `algorithm` (str): The name of the hash algorithm to use (e.g., \'sha256\', \'sha512\', \'blake2b\', etc.). - `salt` (bytes, optional): Optional salt for randomized hashing. - `personalization` (bytes, optional): Optional personalization string for the hash. The function should read the file in binary mode, update the hash with the file data, and return the hexadecimal string representation of the digest. **Constraints:** - If the specified `algorithm` is not available in ` hashlib.algorithms_available`, raise a `ValueError`. - If `salt` is provided, ensure it adheres to the length constraints specified for the chosen algorithm. Raise a `ValueError` if it does not. - Similarly, if `personalization` is provided, ensure it adheres to the length constraints specified for the chosen algorithm. Raise a `ValueError` if it does not. **Example Usage:** ```python # Example 1: Using sha256 algorithm without salt and personalization print(hash_file(\'example.txt\', \'sha256\')) # Example 2: Using blake2b algorithm with salt and personalization print(hash_file(\'example.txt\', \'blake2b\', salt=b\'mysalt\', personalization=b\'myperson\')) # Example 3: Using an invalid algorithm try: print(hash_file(\'example.txt\', \'invalid_algorithm\')) except ValueError as e: print(e) # Output: Algorithm not available # Example 4: Using blake2s algorithm with an invalid salt length try: print(hash_file(\'example.txt\', \'blake2s\', salt=b\'toolongsalt\')) except ValueError as e: print(e) # Output: Invalid salt length for blake2s ``` **Function Signature:** ```python def hash_file(file_path: str, algorithm: str, salt: bytes = None, personalization: bytes = None) -> str: pass ``` **Notes:** 1. Use `hashlib.new()` for creating generic hash objects if you do not want to use the named constructors directly. 2. Use exception handling to manage incorrect algorithm names or length constraints for salt and personalization. 3. Ensure to handle file reading using a context manager to safely open and read the file.","solution":"import hashlib def hash_file(file_path: str, algorithm: str, salt: bytes = None, personalization: bytes = None) -> str: if algorithm not in hashlib.algorithms_available: raise ValueError(\\"Algorithm not available\\") if algorithm.startswith(\'blake2\'): # Handle blake2-specific options if salt is not None or personalization is not None: hasher = hashlib.new(algorithm, salt=salt, person=personalization) else: hasher = hashlib.new(algorithm) else: if salt is not None or personalization is not None: raise ValueError(\\"Salt and personalization are only supported for blake2 algorithms\\") hasher = hashlib.new(algorithm) try: with open(file_path, \'rb\') as file: while chunk := file.read(8192): hasher.update(chunk) except FileNotFoundError: raise return hasher.hexdigest()"},{"question":"<|Analysis Begin|> The provided documentation details the usage of the `cProfile` and `profile` modules used for deterministic profiling in Python. These tools are essential for understanding the performance characteristics of a Python program by providing detailed statistics about function calls, such as call count, total time, cumulative time, and more. The `cProfile` module is a C extension and generally preferred for its reasonable overhead, while the `profile` module is written in pure Python and is more suitable when you need to extend the profiler. The `pstats` module is used to read, manipulate, and print the profiling results in a user-friendly manner. Key functionality includes starting and stopping the profiler, saving profiling data to a file, sorting results in various ways, and printing statistics. The context manager support added in Python 3.8 for `cProfile.Profile` makes it easier to profile specific blocks of code. Understanding the usage of these modules requires knowledge of how to run and interpret the profiling data, sort and filter the profile results, and manipulate the output using the `pstats` module. Using this understanding, we can craft a challenging and clear coding question focusing on implementing profiling for a given piece of code and analyzing the results using the concepts from `cProfile` and `pstats`. <|Analysis End|> <|Question Begin|> **Objective:** Implement a Python script using the `cProfile` and `pstats` modules to profile a given function. Analyze the profiling results to identify performance bottlenecks and suggest optimizations. **Question:** You are provided with a Python script that performs a sequence of computations. Your task is to: 1. Profile the `compute_statistics` function using `cProfile`. 2. Save the profiling results to a file. 3. Analyze the profiling results using the `pstats` module to identify the top 5 functions that consume the most cumulative time. 4. Implement and suggest a possible optimization based on your findings. **Constraints:** 1. The `compute_statistics` function takes a list of numbers as input. 2. Ensure that your solution runs efficiently with an input list of up to 100,000 numbers. **Input Format:** - A list of integers. **Output Format:** - A report printed to stdout that includes: 1. The top 5 functions that consume the most cumulative time. 2. A possible optimization based on the profiling results. **Example Input:** ```python data = [i for i in range(100000)] ``` **Example Output:** ``` Top 5 functions by cumulative time: 1. <function_name>: cumulative_time 2. <function_name>: cumulative_time 3. <function_name>: cumulative_time 4. <function_name>: cumulative_time 5. <function_name>: cumulative_time Suggested Optimization: <Your detailed optimization plan here> ``` **Code to Profile:** ```python def compute_statistics(data): import math statistics = { \'mean\': sum(data) / len(data), \'variance\': sum((x - sum(data) / len(data)) ** 2 for x in data) / len(data), \'std_dev\': math.sqrt(sum((x - sum(data) / len(data)) ** 2 for x in data) / len(data)), \'min\': min(data), \'max\': max(data), \'count\': len(data) } return statistics if __name__ == \\"__main__\\": import cProfile import pstats import io # Generate data data = [i for i in range(100000)] # Create a Profile object pr = cProfile.Profile() # Enable the profiler pr.enable() # Call the function to profile compute_statistics(data) # Disable the profiler pr.disable() # Save the profiling results with open(\\"profile_results.prof\\", \\"w\\") as f: ps = pstats.Stats(pr, stream=f) ps.sort_stats(\'cumulative\').print_stats(10) # Read and print the top 5 functions by cumulative time s = io.StringIO() ps = pstats.Stats(\'profile_results.prof\', stream=s).sort_stats(\'cumulative\') ps.print_stats(5) print(s.getvalue()) # Your suggested optimization plan below # ... ``` Note: Implement the `compute_statistics` function and the profiling part in the given script. Then provide a detailed report on the profiling results and suggest improvements.","solution":"import math import cProfile import pstats import io def compute_statistics(data): Computes statistical measures from a dataset. statistics = { \'mean\': sum(data) / len(data), \'variance\': sum((x - sum(data) / len(data)) ** 2 for x in data) / len(data), \'std_dev\': math.sqrt(sum((x - sum(data) / len(data)) ** 2 for x in data) / len(data)), \'min\': min(data), \'max\': max(data), \'count\': len(data) } return statistics def profile_and_analyze(data): # Create a Profile object pr = cProfile.Profile() # Enable the profiler pr.enable() # Call the function to profile compute_statistics(data) # Disable the profiler pr.disable() # Save the profiling results to a file with open(\\"profile_results.prof\\", \\"w\\") as f: ps = pstats.Stats(pr, stream=f) ps.sort_stats(\'cumulative\').print_stats() # Read and print the top 5 functions by cumulative time s = io.StringIO() ps = pstats.Stats(pr, stream=s).sort_stats(\'cumulative\') ps.print_stats(5) print(\\"Top 5 functions by cumulative time:\\") print(s.getvalue()) # Suggested optimization print(\\"Suggested Optimization:\\") print(\\"The current implementation recalculates the mean multiple times. We can optimize by recalculating the mean once and reusing it.\\") def optimized_compute_statistics(data): Computes statistical measures from a dataset with optimization. mean = sum(data) / len(data) statistics = { \'mean\': mean, \'variance\': sum((x - mean) ** 2 for x in data) / len(data), \'std_dev\': math.sqrt(sum((x - mean) ** 2 for x in data) / len(data)), \'min\': min(data), \'max\': max(data), \'count\': len(data) } return statistics if __name__ == \\"__main__\\": # Generate data data = [i for i in range(100000)] # Profile and analyze the original function profile_and_analyze(data) # Optionally, you can profile the optimized function to compare # pr = cProfile.Profile() # pr.enable() # optimized_compute_statistics(data) # pr.disable() # s = io.StringIO() # ps = pstats.Stats(pr, stream=s).sort_stats(\'cumulative\') # ps.print_stats(5) # print(\\"Top 5 functions by cumulative time (Optimized):\\") # print(s.getvalue())"},{"question":"Objective The purpose of this exercise is to assess your knowledge of the pandas DataFrame functionalities, including indexing, data manipulation, and descriptive statistics. Question Given a DataFrame `df` containing sales data for a retail company, perform the following tasks: 1. **Data Cleaning**: - Remove any rows where the sales amount is NaN. - Replace negative sales values with zero. 2. **Data Aggregation**: - Group the data by \'Store\' and compute the total, average, and maximum sales for each store. - Include only those stores which have total sales greater than a threshold value of 10,000. 3. **Descriptive Statistics**: - For the stores meeting the above criteria, compute the overall mean and median of their total sales. - Display the store(s) with the highest average sales. 4. **Reindexing**: - Reset the index of the resulting DataFrame. - Add a new column \'Store_Rank\' representing the rank of stores based on their total sales, in descending order. 5. **Output**: - Print the final DataFrame. Input - A DataFrame `df` with the following columns: - \'Date\': The date of the sale (datetime) - \'Store\': The store identifier (string) - \'Sales\': The sales amount (float) Constraints - Assume the DataFrame `df` is already provided and loaded in the environment. Sample Input ```python import pandas as pd from datetime import datetime data = { \'Date\': [datetime(2023, 1, 1), datetime(2023, 1, 2), datetime(2023, 1, 3), datetime(2023, 1, 4)], \'Store\': [\'A\', \'A\', \'B\', \'B\'], \'Sales\': [200.0, -150.0, None, 300.0] } df = pd.DataFrame(data) ``` Expected Output ```python # Placeholder for the final DataFrame # Sample Output: # Store Total_Sales Average_Sales Max_Sales Store_Rank # 0 B 300.0 300.0 300.0 1 ``` Submission Provide your solution as a function `process_sales_data(df)` which performs the above tasks and returns the final DataFrame. ```python import pandas as pd def process_sales_data(df): # Data Cleaning df = df.dropna(subset=[\'Sales\']) df[\'Sales\'] = df[\'Sales\'].apply(lambda x: max(x, 0)) # Data Aggregation grouped_df = df.groupby(\'Store\')[\'Sales\'].agg(Total_Sales=\'sum\', Average_Sales=\'mean\', Max_Sales=\'max\') filtered_df = grouped_df[grouped_df[\'Total_Sales\'] > 10000] # Descriptive Statistics overall_mean = filtered_df[\'Total_Sales\'].mean() overall_median = filtered_df[\'Total_Sales\'].median() max_avg_sales_store = filtered_df[filtered_df[\'Average_Sales\'] == filtered_df[\'Average_Sales\'].max()] # Reindexing final_df = filtered_df.reset_index() final_df[\'Store_Rank\'] = final_df[\'Total_Sales\'].rank(ascending=False, method=\'dense\') # Output print(final_df) return final_df ``` **Notes**: - The function is expected to handle the DataFrame as specified. - Make sure to test the function with multiple DataFrame samples to ensure its correctness.","solution":"import pandas as pd def process_sales_data(df): # Data Cleaning df = df.dropna(subset=[\'Sales\']) df[\'Sales\'] = df[\'Sales\'].apply(lambda x: max(x, 0)) # Data Aggregation grouped_df = df.groupby(\'Store\').agg( Total_Sales=(\'Sales\', \'sum\'), Average_Sales=(\'Sales\', \'mean\'), Max_Sales=(\'Sales\', \'max\') ) filtered_df = grouped_df[grouped_df[\'Total_Sales\'] > 10000] # Descriptive Statistics overall_mean = filtered_df[\'Total_Sales\'].mean() overall_median = filtered_df[\'Total_Sales\'].median() max_avg_sales_store = filtered_df[filtered_df[\'Average_Sales\'] == filtered_df[\'Average_Sales\'].max()] # Reindexing final_df = filtered_df.reset_index() final_df[\'Store_Rank\'] = final_df[\'Total_Sales\'].rank(ascending=False, method=\'dense\').astype(int) # Output print(final_df) return final_df"},{"question":"**Objective:** Demonstrate your understanding of the Python `token` module by writing functions to process a list of token values. # Problem Statement You are given a list of numeric token values. Implement a function named `process_tokens` that takes this list as input and returns a dictionary with the following information: 1. A list of human-readable names for the tokens. 2. A list indicating whether each token is terminal. 3. A list indicating whether each token is non-terminal. 4. A list indicating whether each token is an end-of-file marker. # Function Signature ```python def process_tokens(token_values: List[int]) -> Dict[str, List[Union[str, bool]]]: pass ``` # Input - `token_values` (List[int]): A list of numeric token values. It is guaranteed that all values in this list are valid token values as defined in the `token` module. # Output - A dictionary with the following structure: ```python { \\"token_names\\": List[str], # List of human-readable names for each token. \\"is_terminal\\": List[bool], # List of booleans where True indicates the token is terminal. \\"is_nonterminal\\": List[bool], # List of booleans where True indicates the token is non-terminal. \\"is_eof\\": List[bool] # List of booleans where True indicates the token is an end-of-file marker. } ``` # Example ```python from token import NAME, NUMBER, ENDMARKER token_values = [NAME, NUMBER, ENDMARKER] result = process_tokens(token_values) assert result == { \\"token_names\\": [\\"NAME\\", \\"NUMBER\\", \\"ENDMARKER\\"], \\"is_terminal\\": [True, True, True], \\"is_nonterminal\\": [False, False, False], \\"is_eof\\": [False, False, True] } ``` # Constraints - The function must use the `token` module\'s constants and functions. - Assume all token values in the input list are valid and do not require additional validation. # Note - You may import necessary elements from the `token` module to aid in the implementation of the function.","solution":"from typing import List, Dict, Union import token def process_tokens(token_values: List[int]) -> Dict[str, List[Union[str, bool]]]: token_names = [] is_terminal = [] is_nonterminal = [] is_eof = [] for token_value in token_values: token_name = token.tok_name[token_value] token_names.append(token_name) if token_value < token.N_TOKENS: is_terminal.append(True) is_nonterminal.append(False) is_eof.append(token_value == token.ENDMARKER) else: is_terminal.append(False) is_nonterminal.append(True) is_eof.append(False) return { \\"token_names\\": token_names, \\"is_terminal\\": is_terminal, \\"is_nonterminal\\": is_nonterminal, \\"is_eof\\": is_eof }"},{"question":"You are required to implement a set of functions using the `zlib` module in Python, demonstrating your understanding of compression and decompression processes. The provided functions will include: 1. **Compress Data:** Implement a function `compress_data(data: bytes, level: int = -1) -> bytes` that compresses the given data using the specified level of compression. 2. **Decompress Data:** Implement a function `decompress_data(data: bytes, wbits: int = zlib.MAX_WBITS) -> bytes` that decompresses the given compressed data. 3. **Compute and Verify Checksum:** Implement two functions `compute_adler32(data: bytes, value: int = 1) -> int` and `verify_adler32(data: bytes, expected_checksum: int, value: int = 1) -> bool` to compute the Adler-32 checksum and verify it against an expected checksum, respectively. # Function Specifications: 1. `compress_data(data: bytes, level: int = -1) -> bytes`: - **Input:** `data` (bytes) - the data to be compressed. `level` (int) - the compression level (default is -1). - **Output:** Compressed data as bytes. 2. `decompress_data(data: bytes, wbits: int = zlib.MAX_WBITS) -> bytes`: - **Input:** `data` (bytes) - the data to be decompressed. `wbits` (int) - parameter controlling the size of the history buffer and expected header/trailer format (default is `MAX_WBITS`). - **Output:** Decompressed data as bytes. 3. `compute_adler32(data: bytes, value: int = 1) -> int`: - **Input:** `data` (bytes) - the data for which the checksum will be computed. `value` (int) - the starting value of the checksum (default is 1). - **Output:** Adler-32 checksum as an integer. 4. `verify_adler32(data: bytes, expected_checksum: int, value: int = 1) -> bool`: - **Input:** `data` (bytes) - the data for which the checksum will be verified. `expected_checksum` (int) - the checksum to compare against. `value` (int) - the starting value of the checksum (default is 1). - **Output:** Boolean value indicating whether the computed checksum matches the expected checksum. # Constraints and Considerations: 1. **Compression Level:** Compression levels range from `0` (no compression) to `9` (maximum compression). The default level (`-1`) represents a balance between speed and compression. 2. **Window Size (wbits):** The window size influences memory usage and compression quality. Acceptable values range from `8` to `MAX_WBITS`. 3. **Checksums:** Ensure the checksum functions match the expected outputs according to the `zlib` module\'s definition. # Example Usage: ```python data = b\\"Hello, World!\\" compressed = compress_data(data) decompressed = decompress_data(compressed) assert data == decompressed checksum = compute_adler32(data) assert verify_adler32(data, checksum) assert not verify_adler32(data, 12345) # Example of a failed verification ``` # Testing: Your implementation will be tested against a variety of input data to ensure correctness, including edge cases such as empty data and data that mimics compressed formats. Ensure your code is efficient and follows best practices for handling bytes and stream data in Python.","solution":"import zlib def compress_data(data: bytes, level: int = -1) -> bytes: return zlib.compress(data, level) def decompress_data(data: bytes, wbits: int = zlib.MAX_WBITS) -> bytes: return zlib.decompress(data, wbits) def compute_adler32(data: bytes, value: int = 1) -> int: return zlib.adler32(data, value) def verify_adler32(data: bytes, expected_checksum: int, value: int = 1) -> bool: return zlib.adler32(data, value) == expected_checksum"},{"question":"**Problem Statement: Data Integrity Verification Utility** **Objective:** Create a Python utility that verifies the integrity of files using secure hash algorithms provided by the `hashlib` module. This utility should be able to generate and verify hash values for files using different algorithms. **Function to Implement:** ```python def verify_file_integrity(input_file_path: str, hash_algorithm: str, expected_hash: str) -> bool: Verifies the integrity of a file by comparing its hash value with an expected hash. Parameters: input_file_path (str): The path to the input file. hash_algorithm (str): The name of the hash algorithm to use (e.g., \'sha256\', \'blake2b\'). expected_hash (str): The expected hash value in hexadecimal format. Returns: bool: True if the hash of the file matches the expected hash, False otherwise. pass def generate_file_hash(input_file_path: str, hash_algorithm: str) -> str: Generates the hash value for a file using the specified hash algorithm. Parameters: input_file_path (str): The path to the input file. hash_algorithm (str): The name of the hash algorithm to use (e.g., \'sha256\', \'blake2b\'). Returns: str: The hash value in hexadecimal format. pass ``` **Detailed Description:** 1. **verify_file_integrity(input_file_path, hash_algorithm, expected_hash)**: - Reads the specified file in binary mode. - Creates a hash object using the specified algorithm (e.g., `hashlib.sha256()`). - Updates the hash object with the file\'s contents. - Compares the computed hash (in hexadecimal format) with the provided `expected_hash`. - Returns `True` if the hashes match, `False` otherwise. 2. **generate_file_hash(input_file_path, hash_algorithm)**: - Reads the specified file in binary mode. - Creates a hash object using the specified algorithm. - Updates the hash object with the file\'s contents. - Returns the computed hash in hexadecimal format. **Constraints:** - The `input_file_path` should be a valid path to a file. - The `hash_algorithm` should be one of the algorithms available in the `hashlib.algorithms_guaranteed` set. - The file size should be manageable within the system\'s memory limits. **Example Usage:** ```python # Generate hash value for a file file_path = \\"example.txt\\" algorithm = \\"sha256\\" hash_value = generate_file_hash(file_path, algorithm) print(f\\"Generated hash ({algorithm}): {hash_value}\\") # Verify file integrity expected_hash = \\"expected_hash_value\\" # Replace with the actual expected hash value is_valid = verify_file_integrity(file_path, algorithm, expected_hash) print(f\\"File integrity verified: {is_valid}\\") ``` **Note:** - Consider efficient handling of large files to avoid excessive memory usage. - Ensure exception handling for file operations and unsupported hash algorithms.","solution":"import hashlib def verify_file_integrity(input_file_path: str, hash_algorithm: str, expected_hash: str) -> bool: Verifies the integrity of a file by comparing its hash value with an expected hash. Parameters: input_file_path (str): The path to the input file. hash_algorithm (str): The name of the hash algorithm to use (e.g., \'sha256\', \'blake2b\'). expected_hash (str): The expected hash value in hexadecimal format. Returns: bool: True if the hash of the file matches the expected hash, False otherwise. file_hash = generate_file_hash(input_file_path, hash_algorithm) return file_hash == expected_hash def generate_file_hash(input_file_path: str, hash_algorithm: str) -> str: Generates the hash value for a file using the specified hash algorithm. Parameters: input_file_path (str): The path to the input file. hash_algorithm (str): The name of the hash algorithm to use (e.g., \'sha256\', \'blake2b\'). Returns: str: The hash value in hexadecimal format. if hash_algorithm not in hashlib.algorithms_guaranteed: raise ValueError(f\\"Unsupported hash algorithm: {hash_algorithm}\\") hash_obj = hashlib.new(hash_algorithm) with open(input_file_path, \\"rb\\") as file: while chunk := file.read(8192): hash_obj.update(chunk) return hash_obj.hexdigest()"}]'),z={name:"App",components:{PoemCard:C},data(){return{searchQuery:"",visibleCount:4,poemsData:S,isLoading:!1}},computed:{filteredPoems(){const a=this.searchQuery.trim().toLowerCase();return a?this.poemsData.filter(e=>e.question&&e.question.toLowerCase().includes(a)||e.solution&&e.solution.toLowerCase().includes(a)):this.poemsData},displayedPoems(){return this.searchQuery.trim()?this.filteredPoems:this.filteredPoems.slice(0,this.visibleCount)},hasMorePoems(){return!this.searchQuery.trim()&&this.visibleCount<this.poemsData.length}},methods:{async loadMore(){this.isLoading=!0,await new Promise(a=>setTimeout(a,1e3)),this.visibleCount+=4,this.isLoading=!1}}},F={class:"search-container"},N={class:"card-container"},R={key:0,class:"empty-state"},P=["disabled"],O={key:0},L={key:1};function D(a,e,l,p,s,r){const m=g("PoemCard");return i(),n("section",null,[e[4]||(e[4]=t("div",{class:"top-banner"},[t("div",{class:"top-banner-title"},[t("div",{class:"top-banner-title-text"},"🤔prompts chat🧠")])],-1)),t("div",F,[e[3]||(e[3]=t("span",{class:"search-icon"},"🔍",-1)),_(t("input",{type:"text",class:"search-input","onUpdate:modelValue":e[0]||(e[0]=o=>s.searchQuery=o),placeholder:"Search..."},null,512),[[y,s.searchQuery]]),s.searchQuery?(i(),n("button",{key:0,class:"clear-search",onClick:e[1]||(e[1]=o=>s.searchQuery="")}," ✕ ")):d("",!0)]),t("div",N,[(i(!0),n(b,null,v(r.displayedPoems,(o,f)=>(i(),w(m,{key:f,poem:o},null,8,["poem"]))),128)),r.displayedPoems.length===0?(i(),n("div",R,' No results found for "'+u(s.searchQuery)+'". ',1)):d("",!0)]),r.hasMorePoems?(i(),n("button",{key:0,class:"load-more-button",disabled:s.isLoading,onClick:e[2]||(e[2]=(...o)=>r.loadMore&&r.loadMore(...o))},[s.isLoading?(i(),n("span",L,"Loading...")):(i(),n("span",O,"See more"))],8,P)):d("",!0)])}const j=h(z,[["render",D],["__scopeId","data-v-b55f39b0"]]),U=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"chatai/67.md","filePath":"chatai/67.md"}'),M={name:"chatai/67.md"},B=Object.assign(M,{setup(a){return(e,l)=>(i(),n("div",null,[x(j)]))}});export{U as __pageData,B as default};
